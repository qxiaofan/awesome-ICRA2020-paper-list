
# International Conference on Robotics and Automation 2020
 
Welcome to ICRA 2020, the 2020 IEEE International Conference on Robotics and Automation.

This list is edited by [PaopaoRobot, 泡泡机器人](https://github.com/PaoPaoRobot) , the Chinese academic nonprofit organization. Recently we will classify these papers by topics. Welcome to follow our github and our WeChat Public Platform Account ( [paopaorobot_slam](https://mp.weixin.qq.com/s?__biz=MzI5MTM1MTQwMw==&mid=100000102&idx=1&sn=0a8a831a4f2c18443dbf436ef5d5ff8c&chksm=6c10bf625b6736748c9612879e166e510f1fe301b72ed5c5d7ecdd0f40726c5d757e975f37af&mpshare=1&scene=1&srcid=0530KxSLjUE9I38yLgfO2nVm&pass_ticket=0aB5tcjeTfmcl9u0eSVzN4Ag4tkpM2RjRFH8DG9vylE%3D#rd) ). Of course, you could contact with [daiwei.song@outlook.com](mailto://daiwei.song@outlook.com)



## Awards I: Service Robots; Medical Robotics
- Online Trajectory Planning through Combined Trajectory Optimization and Function Approximation: Application to the Exoskeleton Atalante

    Author: Duburcq, Alexis | Wandercraft
    Author: Chevaleyre, Yann | Univ. Paris Dauphine
    Author: Bredeche, Nicolas | Université Pierre Et Marie Curie
    Author: Boeris, Guilhem | Wandercraft
 
    keyword: Task Planning; Optimization and Optimal Control; Humanoid and Bipedal Locomotion

- Human-Centric Active Perception for Autonomous Observation

    Author: Kent, David | Georgia Institute of Technology
    Author: Chernova, Sonia | Georgia Institute of Technology
 
    keyword: Space Robotics and Automation; Human-Centered Robotics; Planning, Scheduling and Coordination

- Active Reward Learning for Co-Robotic Vision Based Exploration in Bandwidth Limited Environments

    Author: Jamieson, Stewart | Massachusetts Institute of Technology
    Author: How, Jonathan Patrick | Massachusetts Institute of Technology
    Author: Girdhar, Yogesh | Woods Hole Oceanographic Institution
 
    keyword: Human Factors and Human-in-the-Loop; Learning and Adaptive Systems; Marine Robotics

- Fault Tolerant Control in Shape-Changing Internal Robots

    Author: Balasubramanian, Lavanya | University of Sheffield
    Author: Wray, Tom | University of Sheffield
    Author: Damian, Dana | University of Sheffield
 
    keyword: Medical Robots and Systems; Flexible Robots; Failure Detection and Recovery

- Swing-Assist for Enhancing Stair Ambulation in a Primarily-Passive Knee Prosthesis

    Author: Lee, Jantzen | Vanderbilt University
    Author: Goldfarb, Michael | Vanderbilt University
 
    keyword: Prosthetics and Exoskeletons; Rehabilitation Robotics; Physically Assistive Devices

- A Multilayer-Multimodal Fusion Architecture for Pattern Recognition of Natural Manipulations in Percutaneous Coronary Interventions

    Author: Zhou, Xiao-Hu | Institute of Automation Chinese Academy of Sciences
    Author: Xie, Xiaoliang | Institutation of Automation, Chinese Academy of Sciences
    Author: Feng, Zhen-Qiu | Institute of Automation, Chinese Academy of Sciences
    Author: Hou, Zeng-Guang | Chinese Academy of Science
    Author: Bian, Gui-Bin | Institute of Automation, Chinese Academy of Sciences
    Author: Li, Rui-Qi | Institute of Automation, Chinese Academy of Sciences
    Author: Ni, ZhenLiang | Chinese Academy of Sciences
    Author: Liu, Shiqi | School of Automation, Harbin University of Science and Technolog
    Author: Zhou, Yan-Jie | Institute of Automation, Chinese Academy of Sciences
 
    keyword: Recognition; Sensor Fusion; Surgical Robotics: Steerable Catheters/Needles



## Awards II: Robot Mechanisms and Design; Automation
- Design of a Roller-Based Dexterous Hand for Object Grasping and Within-Hand Manipulation

    Author: Yuan, Shenli | Stanford University
    Author: Epps, Austin | Dexterity Systems
    Author: Nowak, Jerome | Stanford University
    Author: Salisbury, Kenneth | Stanford University
 
    keyword: Dexterous Manipulation; Grasping; Grippers and Other End-Effectors

- Swing-Assist for Enhancing Stair Ambulation in a Primarily-Passive Knee Prosthesis

    Author: Lee, Jantzen | Vanderbilt University
    Author: Goldfarb, Michael | Vanderbilt University
 
    keyword: Prosthetics and Exoskeletons; Rehabilitation Robotics; Physically Assistive Devices

- Asynchronous and Decoupled Control of the Position and the Stiffness of a Spatial RCM Tensegrity Mechanism for Needle Manipulation

    Author: Jurado Realpe, Jr | Université De Montpellier
    Author: Aiche, Guillaume | Université De Montpellier
    Author: Abdelaziz, Salih | LIRMM, University of Montpellier 2
    Author: Poignet, Philippe | LIRMM University of Montpellier CNRS
    
    keyword: Tendon/Wire Mechanism; Motion Control; Compliance and Impedance Control

- Form2Fit: Learning Shape Priors for Generalizable Assembly from Disassembly

    Author: Zakka, Kevin | Stanford, Google
    Author: Zeng, Andy | Google
    Author: Lee, Johnny | Google
    Author: Song, Shuran | Columbia University
 
    keyword: Perception for Grasping and Manipulation; Deep Learning in Robotics and Automation; RGB-D Perception

- Deep Visual Heuristics: Learning Feasibility of Mixed-Integer Programs for Manipulation Planning

    Author: Driess, Danny | University of Stuttgart
    Author: Oguz, Ozgur S. | Technical University of Munich
    Author: Ha, Jung-Su | University of Stuttgart
    Author: Toussaint, Marc | Tu Berlin
 
    keyword: Deep Learning in Robotics and Automation; Manipulation Planning; Learning and Adaptive Systems

- Securing Industrial Operators with Collaborative Robots: Simulation and Experimental Validation for a Carpentry Task

    Author: Benhabib, Nassim | Inria
    Author: Padois, Vincent | Inria Bordeaux
    Author: Daney, David | Inria Bordeaux - Sud Ouest
 
    keyword: Robot Safety; Physical Human-Robot Interaction; Physically Assistive Devices





## Awards III: Human-Robot Interaction (HRI); Multi-Robot Systems
- Preference-Based Learning for Exoskeleton Gait Optimization

    Author: Tucker, Maegan | California Institute of Technology
    Author: Novoseller, Ellen | California Institute of Technology
    Author: Kann, Claudia | California Institute of Technology
    Author: Sui, Yanan | Tsinghua University
    Author: Yue, Yisong | California Institute of Technology
    Author: Burdick, Joel | California Institute of Technology
    Author: Ames, Aaron | Caltech
 
    keyword: Learning and Adaptive Systems; Humanoid and Bipedal Locomotion; Prosthetics and Exoskeletons

- Perception-Action Coupling in Usage of Telepresence Cameras

    Author: Valiton, Alexandra | Worcester Polytechnic Institute
    Author: Li, Zhi | Worcester Polytechnic Institute
 
    keyword: Telerobotics and Teleoperation; Human Factors and Human-in-the-Loop; Human-Centered Robotics

- Human Interface for Teleoperated Object Manipulation with a Soft Growing Robot

    Author: Stroppa, Fabio | Stanford University
    Author: Luo, Ming | Stanford University
    Author: Yoshida, Kyle | Stanford University
    Author: Coad, Margaret M. | Stanford University
    Author: Blumenschein, Laura | Stanford University
    Author: Okamura, Allison M. | Stanford University
 
    keyword: Soft Robot Applications; Human Factors and Human-in-the-Loop; Gesture, Posture and Facial Expressions

- Efficient Large-Scale Multi-Drone Delivery Using Transit Networks

    Author: Choudhury, Shushman | Stanford University
    Author: Solovey, Kiril | Stanford University
    Author: Kochenderfer, Mykel | Stanford University
    Author: Pavone, Marco | Stanford University
 
    keyword: Multi-Robot Systems; Intelligent Transportation Systems; Planning, Scheduling and Coordination

- Efficient Multi-Agent Trajectory Planning with Feasibility Guarantee Using Relative Bernstein Polynomial

    Author: Park, Jungwon | Seoul National University
    Author: Kim, Junha | Seoul National University
    Author: Jang, Inkyu | Seoul National University
    Author: Kim, H. Jin | Seoul National University
 
    keyword: Path Planning for Multiple Mobile Robots or Agents; Collision Avoidance; Swarms

- Scalable Target-Tracking for Autonomous Vehicle Fleets

    Author: Shorinwa, Ola | Stanford University
    Author: Yu, Javier | Stanford University
    Author: Halsted, Trevor | Stanford University
    Author: Koufos, Alex | Stanford University
    Author: Schwager, Mac | Stanford University
 
    keyword: Sensor Networks; Distributed Robot Systems; Multi-Robot Systems


## Awards IV: Unmanned Aerial Vehicles; Robot Vision
- Design and Autonomous Stabilization of a Ballistically Launched Multirotor

    Author: Bouman, Amanda | Caltech
    Author: Nadan, Paul | Olin College
    Author: Anderson, Matthew | Jet Propulsion Laboratory
    Author: Pastor, Daniel | Caltech
    Author: Izraelevitz, Jacob | NASA Jet Propulsion Laboratory
    Author: Burdick, Joel | California Institute of Technology
    Author: Kennedy, Brett | Jet Propulsion Laboratory
 
    keyword: Aerial Systems: Perception and Autonomy; Aerial Systems: Applications

- A Morphable Aerial-Aquatic Quadrotor with Coupled Symmetric Thrust Vectoring

    Author: Tan, Yu Herng | National University of Singapore
    Author: Chen, Ben M. | Chinese University of Hong Kong
 
    keyword: Aerial Systems: Applications; Mechanism Design; Product Design, Development and Prototyping

- Nonlinear Vector-Projection Control for Agile Fixed-Wing Unmanned Aerial Vehicles

    Author: Hernandez Ramirez, Juan Carlos | McGill University
    Author: Nahon, Meyer | McGill University
 
    keyword: Aerial Systems: Mechanics and Control; Motion Control; Control Architectures and Programming

- OmniSLAM: Omnidirectional Localization and Dense Mapping for Wide-Baseline Multi-Camera Systems

    Author: Won, Changhee | Hanyang University
    Author: Seok, Hochang | Hanyang Univ
    Author: Cui, Zhaopeng | ETH Zurich
    Author: Pollefeys, Marc | ETH Zurich
    Author: Lim, Jongwoo | Hanyang University
 
    keyword: Omnidirectional Vision; SLAM; Mapping

- Metrically-Scaled Monocular SLAM Using Learned Scale Factors

    Author: Greene, William Nicholas | Massachusetts Institute of Technology
    Author: Roy, Nicholas | Massachusetts Institute of Technology
 
    keyword: SLAM; Visual-Based Navigation; Deep Learning in Robotics and Automation

- Graduated Non-Convexity for Robust Spatial Perception: From Non-Minimal Solvers to Global Outlier Rejection

    Author: Yang, Heng | MIT
    Author: Antonante, Pasquale | MIT
    Author: Tzoumas, Vasileios | Massachusetts Institute of Technology
    Author: Carlone, Luca | Massachusetts Institute of Technology
 
    keyword: Visual-Based Navigation; SLAM; Optimization and Optimal Control

## Awards V: Robot Manipulation; Cognitive Robotics
- 6-DOF Grasping for Target-Driven Object Manipulation in Clutter

    Author: Murali, Adithyavairavan | Carnegie Mellon University
    Author: Mousavian, Arsalan | NVIDIA
    Author: Eppner, Clemens | NVIDIA
    Author: Paxton, Chris | NVIDIA Research
    Author: Fox, Dieter | University of Washington
 
    keyword: Perception for Grasping and Manipulation; Grasping; RGB-D Perception

- Tactile Dexterity: Manipulation Primitives with Tactile Feedback

    Author: Hogan, Francois | Massachusetts Institute of Technology
    Author: Ballester, Jose | Massachusetts Institute of Technology
    Author: Dong, Siyuan | MIT
    Author: Rodriguez, Alberto | Massachusetts Institute of Technology
 
    keyword: Dexterous Manipulation; Force and Tactile Sensing; Dual Arm Manipulation

- Design of a Roller-Based Dexterous Hand for Object Grasping and Within-Hand Manipulation

    Author: Yuan, Shenli | Stanford University
    Author: Epps, Austin | Dexterity Systems
    Author: Nowak, Jerome | Stanford University
    Author: Salisbury, Kenneth | Stanford University
 
    keyword: Dexterous Manipulation; Grasping; Grippers and Other End-Effectors

- Semantic Linking Maps for Active Visual Object Search

    Author: Zeng, Zhen | University of Michigan
    Author: Röfer, Adrian | University of Bremen
    Author: Jenkins, Odest Chadwicke | University of Michigan
 
    keyword: Service Robots; Autonomous Agents; Domestic Robots 

- Adversarial Skill Networks: Unsupervised Robot Skill Learning from Video

    Author: Mees, Oier | Albert-Ludwigs-Universitét
    Author: Merklinger, Markus | Uni Freiburg
    Author: Kalweit, Gabriel | University of Freiburg
    Author: Burgard, Wolfram | Toyota Research Institute
 
    keyword: Deep Learning in Robotics and Automation; Visual Learning; Computer Vision for Automation

- Transient Behavior and Predictability in Manipulating Complex Objects

    Author: Nayeem, Rashida | Northeastern University
    Author: Bazzi, Salah | Northeastern University
    Author: Hogan, Neville | Massachusetts Institute of Technology
    Author: Sternad, Dagmar | Northeastern University
 
    keyword: Physical Human-Robot Interaction; Biologically-Inspired Robots; Dexterous Manipulation


## Awards VI: Best Student Paper Award; Best Conference Paper Award
- Design of a Roller-Based Dexterous Hand for Object Grasping and Within-Hand Manipulation

    Author: Yuan, Shenli | Stanford University
    Author: Epps, Austin | Dexterity Systems
    Author: Nowak, Jerome | Stanford University
    Author: Salisbury, Kenneth | Stanford University
 
    keyword: Dexterous Manipulation; Grasping; Grippers and Other End-Effectors

- An ERT-Based Robotic Skin with Sparsely Distributed Electrodes: Structure, Fabrication, and DNN-Based Signal Processing

    Author: Park, Kyungseo | Korea Advanced Institute of Science and Technology
    Author: Park, Hyunkyu | Korea Advanced Institute of Science and Technology
    Author: Lee, Hyosang | Max Planck Institute for Intelligent Systems
    Author: Park, Sungbin | Korea Advanced Institute of Science and Technology
    Author: Kim, Jung | KAIST
 
    keyword: Force and Tactile Sensing; Physical Human-Robot Interaction; Soft Robot Materials and Design

- 6-DOF Grasping for Target-Driven Object Manipulation in Clutter

    Author: Murali, Adithyavairavan | Carnegie Mellon University
    Author: Mousavian, Arsalan | NVIDIA
    Author: Eppner, Clemens | NVIDIA
    Author: Paxton, Chris | NVIDIA Research
    Author: Fox, Dieter | University of Washington
 
    keyword: Perception for Grasping and Manipulation; Grasping; RGB-D Perception

- Preference-Based Learning for Exoskeleton Gait Optimization

    Author: Tucker, Maegan | California Institute of Technology
    Author: Novoseller, Ellen | California Institute of Technology
    Author: Kann, Claudia | California Institute of Technology
    Author: Sui, Yanan | Tsinghua University
    Author: Yue, Yisong | California Institute of Technology
    Author: Burdick, Joel | California Institute of Technology
    Author: Ames, Aaron | Caltech
 
    keyword: Learning and Adaptive Systems; Humanoid and Bipedal Locomotion; Prosthetics and Exoskeletons

- Design of a Roller-Based Dexterous Hand for Object Grasping and Within-Hand Manipulation

    Author: Yuan, Shenli | Stanford University
    Author: Epps, Austin | Dexterity Systems
    Author: Nowak, Jerome | Stanford University
    Author: Salisbury, Kenneth | Stanford University
 
    keyword: Dexterous Manipulation; Grasping; Grippers and Other End-Effectors

- Prediction of Human Full-Body Movements with Motion Optimization and Recurrent Neural Networks

    Author: Kratzer, Philipp | University of Stuttgart
    Author: Toussaint, Marc | Tu Berlin
    Author: Mainprice, Jim | Max Planck Institute
 
    keyword: Human-Centered Robotics; Optimization and Optimal Control; Deep Learning in Robotics and Automation

## SLAM 

- Real-Time Graph-Based SLAM with Occupancy Normal Distributions Transforms

    Author: Schulz, Cornelia | University of Tübingen
    Author: Zell, Andreas | University of Tübingen
 
    keyword: SLAM; Performance Evaluation and Benchmarking; Software, Middleware and Programming Environments

    Abstract : Simultaneous Localization and Mapping (SLAM) is one of the basic problems in mobile robotics. While most approaches are based on occupancy grid maps, Normal Distributions Transforms (NDT) and mixtures like Occupancy Normal Distribution Transforms (ONDT) have been shown to represent sensor measurements more accurately. In this work, we slightly re-formulate the (O)NDT matching function such that it becomes a least squares problem that can be solved with various robust numerical and analytical non-linear optimizers. Further, we propose a novel global (O)NDT scan matcher for loop closure. In our evaluation, our NDT and ONDT methods are able to outperform the occupancy grid map based ones we adopted from Google's Cartographer implementation.

- Spatio-Temporal Non-Rigid Registration of 3D Point Clouds of Plants

    Author: Chebrolu, Nived | University of Bonn
    Author: L�be, Thomas | University of Bonn
    Author: Stachniss, Cyrill | University of Bonn
 
    keyword: SLAM; Robotics in Agriculture and Forestry

    Abstract : Analyzing sensor data of plants and monitoring plant performance is a central element in different agricultural robotics applications. In plant science, phenotyping refers to analyzing plant traits for monitoring growth, for describing plant properties, or characterizing the plant's overall performance. It plays a critical role in the agricultural tasks and in plant breeding. Recently, there is a rising interest in using 3D data obtained from laser scanners and 3D cameras to develop automated non-intrusive techniques for estimating plant traits. In this paper, we address the problem of registering 3D point clouds of the plants over time, which is a backbone of applications interested in tracking spatio-temporal traits of individual plants. Registering plants over time is challenging due to its changing topology, anisotropic growth, and non-rigid motion in between scans. We propose a novel approach that exploits the skeletal structure of the plant and determines correspondences over time and drives the registration process. Our approach explicitly accounts for the non-rigidity and the growth of the plant over time in the registration. We tested our approach on a challenging dataset acquired over the course of two weeks and successfully registered the 3D plant point clouds recorded with a laser scanner forming a basis for developing systems for automated temporal plant-trait analysis.

- Uncertainty-Based Adaptive Sensor Fusion for Visual-Inertial Odometry under Various Motion Characteristics

    Author: Nakashima, Ryo | Toshiba Corporation
    Author: Seki, Akihito | Toshiba Corporation
 
    keyword: SLAM; Sensor Fusion; Localization

    Abstract : We propose an uncertainty-based sensor fusion framework for visual-inertial odometry, which is the task of estimating relative motion using images and measurements from inertial measurement units. Visual-inertial odometry enables robust and scale-aware estimation of motion by incorporating sensor states, such as metric scale, velocity, and the direction of gravity, into the estimation. However, the observability of the states depends on sensor motion. For example, if the sensor moves in a constant velocity, scale and velocity cannot be observed from inertial measurements. Under these degenerate motions, existing methods may produce inaccurate results because they incorporate erroneous states estimated from non-informative inertial measurements. Our proposed framework is able to avoid this situation by adaptively switching estimation modes, which represents the states that should be incorporated, based on their uncertainties. These uncertainties can be obtained at a small computational cost by reusing the Jacobian matrices computed in bundle adjustment. Our approach consistently outperformed conventional sensor fusion in datasets with different motion characteristics, namely, the KITTI odometry dataset recorded by a ground vehicle and the EuRoC MAV dataset captured from a micro aerial vehicle.

- Loam_livox: A Fast, Robust, High-Precision LiDAR Odometry and Mapping Package for LiDARs of Small FoV

    Author: Lin, Jiarong | The University of Hong Kong
    Author: Zhang, Fu | University of Hong Kong
 
    keyword: SLAM; Localization; Mapping

    Abstract : LiDAR odometry and mapping (LOAM) has been playing an important role in autonomous vehicles, due to its ability to simultaneously localize the robot's pose and build high-precision, high-resolution maps of the surrounding environment. This enables autonomous navigation and safe path planning of autonomous vehicles. In this paper, we present a robust, real-time LOAM algorithm for LiDARs with small FoV and irregular samplings. By taking effort on both front-end and back-end, we address several fundamental challenges arising from such LiDARs, and achieve better performance in both precision and efficiency compared to existing baselines. To share our findings and to make contributions to the community, we open source our codes on Github

- Active SLAM Using 3D Submap Saliency for Underwater Volumetric Exploration

    Author: Suresh, Sudharshan | Carnegie Mellon University
    Author: Sodhi, Paloma | Carnegie Mellon University
    Author: Mangelson, Joshua | Brigham Young University
    Author: Wettergreen, David | Carnegie Mellon University
    Author: Kaess, Michael | Carnegie Mellon University
 
    keyword: SLAM; Marine Robotics; Motion and Path Planning

    Abstract : In this paper, we present an active SLAM framework for volumetric exploration of 3D underwater environments with multibeam sonar. Recent work in integrated SLAM and planning performs localization while maintaining volumetric free-space information. However, an absence of informative loop closures can lead to imperfect maps, and therefore unsafe behavior. To solve this, we propose a navigation policy that reduces vehicle pose uncertainty by balancing between volumetric exploration and revisitation. To identify locations to revisit, we build a 3D visual dictionary from real-world sonar data and compute a metric of submap saliency. Revisit actions are chosen based on propagated pose uncertainty and sensor information gain. Loop closures are integrated as constraints in our pose-graph SLAM formulation and these deform the global occupancy grid map. We evaluate our performance in simulation and real-world experiments, and highlight the advantages over an uncertainty-agnostic framework.

- Are We Ready for Service Robots? the OpenLORIS-Scene Datasets for Lifelong SLAM

    Author: Shi, Xuesong | Intel
    Author: Li, Dongjiang | Beijing Jiaotong University
    Author: Zhao, Pengpeng | Beihang University
    Author: Tian, Qinbin | Beijing Jiaotong University
    Author: Tian, YuXin | Beihang Universuty
    Author: Long, Qiwei | Beijingjiaotong University
    Author: Zhu, Chunhao | Beijing Jiaotong University
    Author: Song, Jingwei | Beijing Jiaotong University
    Author: Qiao, Fei | Tsinghua University
    Author: Song, Le | Gaussian Robotics
    Author: Guo, Yangquan | Gaussian Robotics
    Author: Wang, Zhigang | Intel Labs
    Author: Zhang, Yimin | Intel Corporation
    Author: Qin, Baoxing | NUS
    Author: Yang, Wei | Beijing Jiaotong University, School of Electronic and Information
    Author: Wang, Fangshi | Beijing Jiaotong University
    Author: Chan, Rosa H. M. | City University of Hong Kong
    Author: She, Qi | Intel Labs
 
    keyword: SLAM; Localization; Service Robots

    Abstract : Service robots should be able to operate autonomously in dynamic and daily changing environments over an extended period of time. While Simultaneous Localization And Mapping (SLAM) is one of the most fundamental problems for robotic autonomy, most existing SLAM works are evaluated with data sequences that are recorded in a short period of time. In real-world deployment, there can be out-of-sight scene changes caused by both natural factors and human activities. For example, in home scenarios, most objects may be movable, replaceable or deformable, and the visual features of the same place may be significantly different in some successive days. Such out-of-sight dynamics pose great challenges to the robustness of pose estimation, and hence a robot's long-term deployment and operation. To differentiate the forementioned problem from the conventional works which are usually evaluated in a static setting in a single run, the term textit{lifelong SLAM} is used here to address SLAM problems in an ever-changing environment over a long period of time. To accelerate lifelong SLAM research, we release the OpenLORIS-Scene datasets. The data are collected in real-world indoor scenes, for multiple times in each place to include scene changes in real life. We also design benchmarking metrics for lifelong SLAM, with which the robustness and accuracy of pose estimation are evaluated separately. The datasets and benchmark are available online at https://lifelong-robotic-vision.github.io


- Intensity Scan Context: Coding Intensity and Geometry Relations for Loop Closure Detection

    Author: Wang, Han | Nanyang Technological University
    Author: Wang, Chen | Carnegie Mellon University
    Author: Xie, Lihua | NanyangTechnological University
 
    keyword: SLAM; Recognition; Factory Automation

    Abstract : Loop closure detection is an essential and challenging problem in simultaneous localization and mapping (SLAM). It is often tackled with light detection and ranging (LiDAR) sensor due to its view-point and illumination invariant properties. Existing works on 3D loop closure detection often leverage on matching of local or global geometrical-only descriptors which discard intensity reading. In this paper we explore the intensity property from LiDAR scan and show that it can be effective for place recognition. We propose a novel global descriptor, intensity scan context (ISC), that explores both geometry and intensity characteristics. To improve the efficiency for loop closure detection, an efficient two-stage hierarchical re-identification process is proposed, including binary-operation based fast geometric relation retrieval and intensity structure re-identification. Thorough experiments including both local experiment and public datasets test have been conducted to evaluate the performance of the proposed method. Our method achieves better recall rate and recall precision than existing geometric-only methods.

- TextSLAM: Visual SLAM with Planar Text Features

    Author: Li, Boying | Shanghai Jiao Tong University
    Author: Zou, Danping | Shanghai Jiao Ton University
    Author: Sartori, Daniele | Shanghai Jiao Tong University
    Author: Pei, Ling | Shanghai Jiao Tong University
    Author: Yu, Wenxian | Shanghai Jiao Tong University
 
    keyword: SLAM; Visual-Based Navigation; Mapping

    Abstract : We propose to integrate text objects in man-made scenes tightly into the visual SLAM pipeline. The key idea of our novel text-based visual SLAM is to treat each detected text as a planar feature which is rich of textures and semantic meanings. The text feature is compactly represented by three parameters and integrated into visual SLAM by adopting the illumination-invariant photometric error. We also describe important details involved in implementing a full pipeline of text-based visual SLAM. To our best knowledge, this is the first visual SLAM method tightly coupled with the text features. We tested our method in both indoor and outdoor environments. The results show that with text features, the visual SLAM system becomes more robust and produces much more accurate 3D text maps that could be useful for navigation and scene understanding in robotic or augmented reality applications.

- FlowNorm: A Learning-Based Method for Increasing Convergence Range of Direct Alignment

    Author: Wang, Ke | Hong Kong University of Science and Technology
    Author: Wang, Kaixuan | Hong Kong University of Science and Technology
    Author: Shen, Shaojie | Hong Kong University of Science and Technology
 
    keyword: SLAM; Localization

    Abstract : Many works have been proposed to estimate camera poses by directly minimizing photometric error. However, due to the non-convex property of the direct alignment, proper initialization is still required for these methods. Many robust norm (e.g. Huber norm) have been proposed to deal with the outlier terms caused by incorrect initializations. These robust norms are solely defined on the magnitude of each error terms. In this paper, we propose a novel robust norm, named FlowNorm, that exploit the information from both the local error term and the global image registration information. While the local information is defined on patch alignments, the global information is estimated using a learning-based network. Using both the local and global information, we achieve a large convergence range that images can be aligned given large view angle changes or small overlaps. We further demonstrate the usability of the proposed robust norm by integrating it into direct methods, DSO and BA-Net, and generate more robust and accurate results in real-time.

- Redesigning SLAM for Arbitrary Multi-Camera Systems

    Author: Kuo, Juichung | ETH Zurich
    Author: Muglikar, Manasi | University of Zurich
    Author: Zhang, Zichao | Robotics and Perception Group, University of Zurich
    Author: Scaramuzza, Davide | University of Zurich
 
    keyword: SLAM; Localization; Visual-Based Navigation

    Abstract : Adding more cameras to SLAM systems improves robustness and accuracy but complicates the design of the visual front-end significantly. Thus, most systems in the literature are tailored for specific camera configurations. In this work, we aim at an adaptive SLAM system that works for arbitrary multi-camera setups. To this end, we revisit several common building blocks in visual SLAM. In particular, we propose an adaptive initialization scheme, a sensor-agnostic, information-theoretic keyframe selection algorithm, and a scalable voxel-based map. These techniques make little assumption about the actual camera setups and prefer theoretically grounded methods over heuristics. We adapt a state-of-the-art visual-inertial odometry with these modifications, and experimental results show that the modified pipeline can adapt to a wide range of camera setups (e.g., 2 to 6 cameras in one experiment) without the need of sensor-specific modifications or tuning.

- Dynamic SLAM: The Need for Speed

    Author: Henein, Mina | Australian National University
    Author: Zhang, Jun | Australian National University
    Author: Mahony, Robert | Australian National University
    Author: Ila, Viorela | The University of Sydney
 
    keyword: SLAM; Mapping

    Abstract : The static world assumption is standard in most simultaneous localisation and mapping (SLAM) algorithms. Increased deployment of autonomous systems to unstructured dynamic environments is driving a need to identify moving objects and estimate their velocity in real-time. Most existing SLAM based approaches rely on a database of 3D models of objects or impose significant motion constraints. In this paper, we propose a new feature-based, model-free, object-aware dynamic SLAM algorithm that exploits semantic segmentation to allow estimation of motion of rigid objects in a scene without the need to estimate the object poses or have any prior knowledge of their 3D models. The algorithm generates a map of dynamic and static structure and has the ability to extract velocities of rigid moving objects in the scene. Its performance is demonstrated on simulated, synthetic and real-world datasets.

- GradSLAM: Dense SLAM Meets Automatic Differentiation

    Author: Jatavallabhula, Krishna | Mila, Universite De Montreal
    Author: Iyer, Ganesh | International Institute of Information Technology, Hyderabad
    Author: Paull, Liam | Université De Montr�al
 
    keyword: SLAM; Mapping; Deep Learning in Robotics and Automation

    Abstract : The question of representation is central in the context of dense simultaneous localization and mapping (SLAM). Newer learning-based approaches have the potential to leverage data or task performance to directly inform the choice of representation. However, blending representation learning approaches with ``classical" SLAM systems has remained an open question, because of the highly modular and complex nature of classical SLAM systems. In robotics, the task of a SLAM system is often to transform raw sensor inputs to a distribution of the state(s) of the robot and the environment. If this transformation (SLAM) were expressible as a differentiable function, we could leverage task-based error signals over the outputs of this function to learn representations that optimize task performance. The challenge---however---is that several components of a typical dense SLAM system are non-differentiable. In this work, we propose a novel way of unifying gradient-based learning and SLAM. We propose the term gradSLAM, a methodology for posing SLAM systems as differentiable computational graphs. We demonstrate how to design differentiable trust-region optimizers, surface measurement and fusion schemes, as well as differentiate over rays, without sacrificing performance. This amalgamation of dense SLAM with computational graphs enables us to backprop all the way from 3D maps to 2D pixels, opening up new possibilities in gradient-based learning for SLAM.



- Long-Term Place Recognition through Worst-Case Graph Matching to Integrate Landmark Appearances and Spatial Relationships

    Author: Gao, Peng | Colorado School of Mines
    Author: Zhang, Hao | Colorado School of Mines
 
    keyword: SLAM; Localization

    Abstract : Place recognition is an important component for simultaneously localization and mapping in a variety of robotics applications. Recently, several approaches using landmark information to represent a place showed promising performance to address long-term environment changes. However, previous approaches do not explicitly consider changes of the landmarks, i,e., old landmarks may disappear and new ones often appear over time. In addition, representations used in these approaches to represent landmarks are limited, based upon visual or spatial cues only. In this paper, we introduce a novel worst-case graph matching approach that integrates spatial relationships of landmarks with their appearances for long-term place recognition. Our method designs a graph representation to encode distance and angular spatial relationships as well as visual appearances of landmarks in order to represent a place. Then, we formulate place recognition as a graph matching problem under the worst-case scenario. Our approach matches places by computing the similarities of distance and angular spatial relationships of the landmarks that have the least similar appearances (i.e., worst-case). If the worst appearance similarity of landmarks is small, two places are identified to be not the same, even though their graph representations have high spatial relationship similarities. We evaluate our approach over two public benchmark datasets for long-term place recognition, including St. Lucia and CMU-VL. Th

- Linear RGB-D SLAM for Atlanta World

    Author: Joo, Kyungdon | Korea Advanced Institute of Science and Technology (KAIST)
    Author: Oh, Tae-Hyun | MIT
    Author: Rameau, Francois | KAIST, RCV Lab
    Author: Bazin, Jean-Charles | KAIST
    Author: Kweon, In So | KAIST
 
    keyword: SLAM; RGB-D Perception; Localization

    Abstract : We present a new linear method for RGB-D based simultaneous localization and mapping (SLAM). Compared to existing techniques relying on the Manhattan world assumption defined by three orthogonal directions, our approach is designed for the more general scenario of the Atlanta world. It consists of a vertical direction and a set of horizontal directions orthogonal to the vertical direction and thus can represent a wider range of scenes. Our approach leverages the structural regularity of the Atlanta world to decouple the non-linearity of camera pose estimations. This allows us separately to estimate the camera rotation and then the translation, which bypasses the inherent non-linearity of traditional SLAM techniques. To this end, we introduce a novel tracking-by-detection scheme to estimate the underlying scene structure by Atlanta representation. Thereby, we propose an Atlanta frame-aware linear SLAM framework which jointly estimates the camera motion and a planar map supporting the Atlanta structure through a linear Kalman filter. Evaluations on both synthetic and real datasets demonstrate that our approach provides favorable performance compared to existing state-of-the-art methods while extending their working range to the Atlanta world.

- Stereo Visual Inertial Odometry with Online Baseline Calibration

    Author: Fan, Yunfei | Meituan-Dianping Group
    Author: Wang, Ruofu | University of Southern California
    Author: Mao, Yinian | Meituan-Dianping Group
 
    keyword: SLAM; Sensor Fusion

    Abstract : Stereo-vision devices have rigorous requirements for extrinsic parameter calibration. In Stereo Visual Inertial Odometry (VIO), inaccuracy in or changes to camera extrinsic parameters may lead to serious degradation in estimation performance. In this manuscript, we propose an online calibration method for stereo VIO extrinsic parameters correction. In particular, we focus on Multi-State Constraint Kalman Filter (MSCKF [1]) framework to implement our method. The key component is to formulate stereo extrinsic parameters as part of the state variables and model the Jacobian of feature reprojection error with respect to stereo extrinsic parameters as sub-block of update Jacobian. Therefore we can estimate stereo extrinsic parameters simultaneously with inertial measurement unit (IMU) states and camera poses. Experiments on EuRoC dataset and real-world outdoor dataset demonstrate that the proposed algorithm produce higher positioning accuracy than the original S-MSCKF [2], and the noise of camera extrinsic parameters are self-corrected within the system.

- Lidar-Monocular Visual Odometry Using Point and Line Features

    Author: Huang, Shi-Sheng | Tsinghua University, Beijing
    Author: Ma, Zeyu | Tsinghua University
    Author: Mu, Tai-Jiang | Tsinghua University, Beijing, PRC
    Author: Fu, Hongbo | City University of Hong Kong
    Author: Hu, Shi-Min | Tsinghua University
 
    keyword: SLAM; Visual-Based Navigation; Sensor Fusion

    Abstract : We introduce a novel lidar-monocular visual odometry approach using point and line features. Compared to previous point-only based lidar-visual odometry, our approach leverages more environment structure information by introducing both point and line features into pose estimation. We provide a robust method for point and line depth extraction, and formulate the extracted depth as prior factors for point-line bundle adjustment. This method greatly reduces the features' 3D ambiguity and thus improves the pose estimation accuracy. Besides, we also provide a purely visual motion tracking method and a novel scale correction scheme, leading to an efficient lidar-monocular visual odometry system with high accuracy. The evaluations on the public KITTI odometry benchmark show that our technique achieves more accurate pose estimation than the state-of-the-art approaches, and is sometimes even better than those leveraging semantic information.

- Probabilistic Data Association Via Mixture Models for Robust Semantic SLAM

    Author: Doherty, Kevin | Massachusetts Institute of Technology
    Author: Baxter, David | Massachusetts Institute of Technology
    Author: Schneeweiss, Edward | University of Massachusetts Amherst
    Author: Leonard, John | MIT
 
    keyword: SLAM; Visual-Based Navigation; Semantic Scene Understanding

    Abstract : Modern robotic systems sense the environment geometrically, through sensors like cameras, lidar, and sonar, as well as semantically, often through visual models learned from data, such as object detectors. We aim to develop robots that can use all of these sources of information for reliable navigation, but each is corrupted by noise. Rather than assume that object	detection will eventually achieve near perfect performance across the lifetime of a robot, in this work we represent and cope with the semantic and geometric uncertainty inherent in object detection methods. Specifically, we model data association ambiguity, which is typically non-Gaussian, in a way that is amenable to solution within the common nonlinear Gaussian formulation of simultaneous localization and mapping (SLAM). We do so by eliminating data association variables from the inference process through max-marginalization, preserving standard Gaussian posterior assumptions. The result is a	max-mixture-type model that accounts for multiple data association hypotheses. We provide experimental results on indoor	and outdoor semantic navigation tasks with noisy odometry and object detection and find that the ability of the proposed approach to represent multiple hypotheses, including the �null'' hypothesis, gives substantial robustness advantages in comparison to alternative semantic SLAM approaches.

- Closed-Loop Benchmarking of Stereo Visual-Inertial SLAM Systems: Understanding the Impact of Drift and Latency on Tracking Accuracy

    Author: Zhao, Yipu | Facebook Inc
    Author: Smith, Justin | Georgia Institute of Technology
    Author: Karumanchi, Sambhu Harimanas | National Institute of Technology Karnataka, Surathkal
    Author: Vela, Patricio | Georgia Institute of Technology
 
    keyword: SLAM; Performance Evaluation and Benchmarking; Localization

    Abstract : Visual-inertial SLAM is essential for robot navigation in GPS-denied environments, e.g. indoor, underground. Conventionally, the performance of visual-inertial SLAM is evaluated with open-loop analysis, with a focus on the drift level of SLAM systems. In this paper, we raise the question on the importance of visual estimation latency in closed-loop navigation tasks, such as accurate trajectory tracking. To understand the impact of both drift and latency on visual-inertial SLAM systems, a closed-loop benchmarking simulation is conducted, where a robot is commanded to follow a desired trajectory using the feedback from visual-inertial estimation. By extensively evaluating the trajectory tracking performance of representative state-of-the-art visual-inertial SLAM systems, we reveal the importance of latency reduction in visual estimation module of these systems. The findings suggest directions of future improvements for visual-inertial SLAM.

- Metrically-Scaled Monocular SLAM Using Learned Scale Factors

    Author: Greene, William Nicholas | Massachusetts Institute of Technology
    Author: Roy, Nicholas | Massachusetts Institute of Technology
 
    keyword: SLAM; Visual-Based Navigation; Deep Learning in Robotics and Automation

    Abstract : We propose an efficient method for monocular simultaneous localization and mapping (SLAM) that is capable of estimating metrically-scaled motion without additional sensors or hardware acceleration by integrating metric depth predictions from a neural network into a geometric SLAM factor graph. Unlike learned end-to-end SLAM systems, ours does not ignore the relative geometry directly observable in the images. Unlike existing learned depth estimation approaches, ours leverages the insight that when used to estimate scale, learned depth predictions need only be coarse in image space. This allows us to shrink our network to the point that performing inference on a standard CPU becomes computationally tractable.<p>We make several improvements to our network architecture and training procedure to address the lack of depth observability when using coarse images, which allows us to estimate spatially coarse, but depth-accurate predictions in only 30 ms per frame without GPU acceleration. At runtime we incorporate the learned metric data as unary scale factors in a Sim(3) pose graph. Our method is able to generate accurate, scaled poses without additional sensors, hardware accelerators, or special maneuvers and does not ignore or corrupt the observable epipolar geometry. We show compelling results on the KITTI benchmark dataset in addition to real-world experiments with a handheld camera.

- Inertial-Only Optimization for Visual-Inertial Initialization

    Author: Campos, Carlos | Universidad De Zaragoza
    Author: Montiel, J.M.M | I3A. Universidad De Zaragoza
    Author: Tardos, Juan D. | Universidad De Zaragoza
 
    keyword: SLAM; Mapping; Localization

    Abstract : We formulate for the first time visual-inertial initialization as an optimal estimation problem, in the sense of maximum-a-posteriori (MAP) estimation. This allows us to properly take into account IMU measurement uncertainty, which was neglected in previous methods that either solved sets of algebraic equations, or minimized ad-hoc cost functions using least squares. Our exhaustive initialization tests on EuRoC dataset show that our proposal largely outperforms the best methods in the literature, being able to initialize in less than 4 seconds in almost any point of the trajectory, with a scale error of 5.3% on average. This initialization has been integrated into ORB-SLAM Visual-Inertial boosting its robustness and efficiency while maintaining its excellent accuracy.

- Hierarchical Quadtree Feature Optical Flow Tracking Based Sparse Pose-Graph Visual-Inertial SLAM

    Author: Xie, Hongle | Shanghai Jiao Tong University
    Author: Chen, Weidong | Shanghai Jiao Tong University
    Author: Wang, Jingchuan | Shanghai Jiao Tong University
    Author: Wang, Hesheng | Shanghai Jiao Tong University
 
    keyword: SLAM; Localization; Sensor Fusion

    Abstract : Accurate, robust and real-time localization under constrained-resources is a critical problem to be solved. In this paper, we present a new sparse pose-graph visual-inertial SLAM (SPVIS). Unlike the existing methods that are costly to deal with a large number of redundant features and 3D map points, which are inefficient for improving positioning accuracy, we focus on the concise visual cues for high-precision pose estimating. We propose a novel hierarchical quadtree based optical flow tracking algorithm, it achieves high accuracy and robustness within very few concise features, which is only about one fifth features of the state-of-the-art visual-inertial SLAM algorithms. Benefiting from the efficient optical flow tracking, our sparse pose-graph optimization time cost achieves bounded complexity. By selecting and optimizing the informative features in sliding window and local VIO, the computational complexity is bounded, it achieves low time cost in long-term operation. We compare with the state-of-the-art VIO/VI-SLAM systems on the challenging public datasets by the embedded platform without GPUs, the results effectively verify that the proposed method has better real-time performance and localization accuracy.

- Keypoint Description by Descriptor Fusion Using Autoencoders

    Author: Dai, Zhuang | Guangdong University of Technology
    Author: Huang, Xinghong | Guangdong University of Technology
    Author: Chen, Weinan | The Chinese University of Hong Kong
    Author: Chen, Chuangbin | Guangdong University of Technology
    Author: He, Li | Guangdong University of Technology
    Author: Wen, Shuhuan | Yanshan University
    Author: Zhang, Hong | University of Alberta
 
    keyword: SLAM; Localization; Visual Learning

    Abstract : Keypoint matching is an important operation in computer vision and its applications such as visual simultaneous localization and mapping (SLAM) in robotics. This matching operation heavily depends on the descriptors of the keypoints, and it must be performed reliably when images undergo conditional changes such as those in illumination and viewpoint. In this paper, a descriptor fusion model (DFM) is proposed to create a robust keypoint descriptor by fusing CNN-based descriptors using autoencoders. Our DFM architecture can be adapted to either trained or pre-trained CNN models. Based on the performance of existing CNN descriptors, we choose HardNet and DenseNet169 as representatives of trained and pre-trained descriptors. Our proposed DFM is evaluated on the latest benchmark datasets in computer vision with challenging conditional changes. The experimental results show that DFM is able to achieve state-of-the-art performance, with the mean mAP that is 6.34% and 6.42% higher than HardNet and DenseNet169, respectively.

- Towards Noise Resilient SLAM

    Author: Thyagharajan, Anirud | Intel Labs
    Author: Mandal, Dipan | Intel Labs
    Author: Ji Omer, Om | Intel Labs
    Author: Subramoney, Sreenivas | Intel Labs
 
    keyword: SLAM; RGB-D Perception; Visual Tracking

    Abstract : Sparse-indirect SLAM systems have been dominantly popular due to their computational efficiency and photometric invariance properties. Depth sensors are critical to SLAM frameworks for providing scale information to the 3D world, yet known to be plagued by a wide variety of noise sources, possessing lateral and axial components. In this work, we demonstrate the detrimental impact of these depth noise components on the performance of the state-of-the-art sparse-indirect SLAM system (ORB-SLAM2). We propose (i) Map-Point Consensus based Outlier Rejection (MC-OR) to counter lateral noise, and (ii) Adaptive Virtual Camera (AVC) to combat axial noise accurately. MC-OR utilizes consensus information between multiple sightings of the same landmark to disambiguate noisy depth and filter it out before pose optimization. In AVC, we introduce an error vector as an accurate representation of the axial depth error. We additionally propose an adaptive algorithm to find the virtual camera location for projecting the error used in the objective function of the pose optimization. Our techniques work equally well for stereo image pairs and RGB-D input directly used by sparse-indirect SLAM systems. Our methods were tested on the TUM (RGB-D) and EuRoC (stereo) datasets and we show that they outperform existing state-of-the-art ORB-SLAM2 by 2-3x, especially in sequences critically affected by depth noise.

- LAMP: Large-Scale Autonomous Mapping and Positioning for Exploration of Perceptually-Degraded Subterranean Environments

    Author: Ebadi, Kamak | Santa Clara University
    Author: Chang, Yun | MIT
    Author: Palieri, Matteo | Polytechnic University of Bari
    Author: Stephens, Alex | University of Sydney
    Author: Hatteland, Alexander Haugland | ETH University
    Author: Heiden, Eric | University of Southern California
    Author: Thakur, Abhishek | Aptiv Tro
    Author: Morrell, Benjamin | The University of Sydney
    Author: Carlone, Luca | Massachusetts Institute of Technology
    Author: Agha-mohammadi, Ali-akbar | NASA-JPL, Caltech
    Author: Wood, Sally | Santa Clara University
    Author: Funabiki, Nobuhiro | University of Tokyo
 
    keyword: SLAM; Multi-Robot Systems; Search and Rescue Robots

    Abstract : Simultaneous Localization and Mapping (SLAM) in large-scale, unknown, and complex subterranean environments is a challenging problem. Sensors have to operate in off-nominal conditions; uneven and slippery terrains make wheel odometry inaccurate, while long corridors without salient features make exteroceptive sensing ambiguous and prone to drift; finally, spurious loop closures that are frequent in environments with repetitive appearance, such as tunnels and mines, could result in a significant distortion of the entire map. These challenges are in stark contrast with the need to build highly-accurate 3D maps to support a wide variety of applications, ranging from disaster response to the exploration of underground extraterrestrial worlds. This paper reports on the implementation and testing of a lidar-based multi-robot SLAM system developed in the context of the DARPA Subterranean Challenge. We present a system architecture to enhance subterranean operation, including an accurate lidar-based front-end, and a flexible and robust back-end that automatically rejects outlying loop closures. We present an extensive evaluation in large-scale, challenging subterranean environments, including the results obtained in the Tunnel Circuit of the DARPA Subterranean Challenge. Finally, we discuss potential improvements, limitations of the state of the art, and future research directions.


- Modeling Semi-Static Scenes with Persistence Filtering in Visual SLAM

    Author: Hashemifar, Zakieh | Zoox, University at Buffalo
    Author: Dantu, Karthik | University of Buffalo
 
    keyword: SLAM; Mapping; RGB-D Perception

    Abstract : Many existing SLAM approaches rely on the assumption of static environments for accurate performance. However, several robot applications require them to traverse repeatedly in semi-static or dynamic environments. There has been some recent research interest in designing persistence filters to reason about persistence in such scenarios. Our goal in this work is to incorporate such persistence reasoning in visual SLAM. To this end, we incorporate persistence filters [1] into ORB-SLAM, a well-known visual SLAM algorithm. We observe that the simple integration of their proposal results in inefficient persistence reasoning. Through a series of modifications and using two locally collected datasets, we demonstrate the utility of such persistence filtering as well as our customizations in ORB- SLAM. Overall, incorporating persistence filtering could result in a significant reduction in map size (about 30% in the best case) and a corresponding reduction in run-time while retaining similar accuracy to methods that use much larger maps.

- Broadcast Your Weaknesses: Cooperative Active Pose-Graph SLAM for Multiple Robots

    Author: Chen, Yongbo | University of Technology, Sydney
    Author: Zhao, Liang | University of Technology Sydney
    Author: Lee, Ki Myung Brian | University of Technology Sydney
    Author: Yoo, Chanyeol | University of Technology Sydney
    Author: Huang, Shoudong | University of Technology, Sydney
    Author: Fitch, Robert | University of Technology Sydney
 
    keyword: SLAM; Path Planning for Multiple Mobile Robots or Agents; Multi-Robot Systems

    Abstract : In this paper, we propose a low-cost, high-efficiency framework for cooperative active pose-graph simultaneous localization and mapping (SLAM) for multiple robots in three-dimensional (3D) environments based on graph topology. Based on the selection of weak connections in pose graphs, this method aims to find the best trajectories for optimal information exchange to repair these weaknesses opportunistically when robots move near them. Based on tree-connectivity, which is greatly related to the D-optimality metric of the Fisher information matrix (FIM), we explore the relationship between measurement (edge) selection and pose-measurement (node-edge) selection, which often occurs in active SLAM, in terms of information increment. The measurement selection problem is formulated as a submodular optimization problem and solved by an exhaustive method using rank-1 updates. We decide which robot takes the selected measurements through a bidding framework where each robot computes its predicted cost. Finally, based on a novel continuous trajectory optimization method, these additional measurements collected by the winning robot are sent to the requesting robot to strengthen its pose graph. In simulations and experiments, we validate our approach by comparing against existing methods. Further, we demonstrate online communication based on offline planning results using two unmanned aerial vehicles (UAVs).

- FlowFusion: Dynamic Dense RGB-D SLAM Based on Optical Flow

    Author: Zhang, Tianwei | The University of Tokyo
    Author: Zhang, Huayan | Beijing University of Civil Engineering and Architecture
    Author: Li, Yang | The University of Tokyo
    Author: Nakamura, Yoshihiko | University of Tokyo
    Author: Zhang, Lei | Beijing University of Civil Engineering and Architecture
 
    keyword: Inventory Management; Logistics

    Abstract : Dynamic environments are challenging for visual SLAM since the moving objects occlude the static environment features and lead to wrong camera motion estimation. In this paper, we present a novel dense RGB-D SLAM solution that simultaneously accomplishes the dynamic/static segmentation and camera ego-motion estimation as well as the static background reconstructions. Our novelty is using optical flow residuals to highlight the dynamic semantics in the RGB-D point clouds and provide more accurate and efficient dynamic/static segmentation for camera tracking and background reconstructions. Dense reconstruction results on both public datasets and the real dynamic environments indicate the proposed approach achieved accurate and efficient performances in both dynamic and static environment compared to state-of-the-art approaches.

- Efficient Algorithms for Maximum Consensus Robust Fitting (I)

    Author: Wen, Fei | Shanghai Jiao Tong University
    Author: Ying, Rendong | Shanghai Jiao Tong University
    Author: Gong, Zheng | Shanghai Jiao Tong University
    Author: Liu, Peilin | Shanghai Jiao Tong Universit
 
    keyword: Probability and Statistical Methods; Visual-Based Navigation; SLAM

    Abstract : Maximum consensus robust fitting is a fundamental problem in many computer vision applications, such as vision-based robotic navigation and mapping. While exact search algorithms are computationally demanding, randomized algorithms are cheap but the solution quality is not guaranteed. Deterministic algorithms fill the gap between these two kinds of algorithms, which have better solution quality than randomized algorithms while be much faster than exact algorithms. In this paper, we develop two highly-efficient deterministic algorithms based on the alternating direction method of multipliers (ADMM) and proximal block coordinate descent (BCD) frameworks. Particularly, the proposed BCD algorithm is guaranteed convergent. Further, on the slack variable in the BCD algorithm, which indicates the inliers and outliers, we establish some meaningful properties, such as support convergence within finite iterations and convergence to restricted strictly local minimizer. Compared with state-of-the-art algorithms, the new algorithms with initialization from a randomized or convex relaxed algorithm can achieve improved solution quality while being much more efficient (e.g., more than an order of magnitude faster).<p>An application of the new ADMM algorithm in simultaneous localization and mapping (SLAM) has also been provided to demonstrate its effectiveness. Code for reproducing the results is available at https://github.com/FWen/emc.git.

- MulRan: Multimodal Range Dataset for Urban Place Recognition

    Author: Kim, Giseop | KAIST(Korea Advanced Institute of Science and Technology)
    Author: Park, Yeong Sang | KAIST
    Author: Cho, Younghun | KAIST
    Author: Jeong, Jinyong | KAIST
    Author: Kim, Ayoung | Korea Advanced Institute of Science Technology
 
    keyword: Range Sensing; Localization; SLAM

    Abstract : This paper introduces a multimodal range dataset namely for radio detection and ranging (radar) and light detection and ranging (LiDAR) specifically targeting the urban environment. By extending our workshop paper [1] to a larger scale, this dataset focuses on the range sensor-based place recognition and provides 6D baseline trajectories of a vehicle for place recognition ground truth. Provided radar data support both raw-level and image-format data, including a set of time-stamped 1D intensity arrays and 360 &#9702; polar images, respectively. In doing so, we provide flexibility between raw data and image data depending on the purpose of the research. Unlike existing datasets, our focus is at capturing both temporal and structural diversities for range-based place recognition research. For evaluation, we applied and validated that our previous location descriptor and its search algorithm [2] are highly effective for radar place recognition method. Furthermore, the result shows that radar-based place recognition outperforms LiDAR-based one exploiting its longer-range measurements. The dataset is available from https://sites.google.com/view/mulran-pr

- GPO: Global Plane Optimization for Fast and Accurate Monocular SLAM Initialization

    Author: Du, Sicong | Institute of Automation&#65292;Chinese Academy of Sciences
    Author: Guo, Hengkai | ByteDance AI Lab
    Author: Chen, Yao | ByteDance Inc
    Author: Woods, Yilun | Institute of Automation&#65292;Chinese Academy of Sciences
    Author: Meng, Xiangbing | Institute of Automation&#65292;Chinese Academy of Sciences
    Author: Wen, Linfu | ByteDance AI Lab
    Author: Wang, Feiyue | Institute of Automation, Chinese Academy of Sciences
 
    keyword: SLAM; Localization

    Abstract : Initialization is essential to monocular Simultaneous Localization and Mapping (SLAM) problems. This paper focuses on a novel initialization method for monocular SLAM based on planar features. The algorithm starts by homography estimation in a sliding window. It then proceeds to a global plane optimization (GPO) to obtain camera poses and the plane normal. 3D points can be recovered using planar constraints without triangulation. The proposed method fully exploits the plane information from multiple frames and avoids the ambiguities in homography decomposition. We validate our algorithm on the collected chessboard dataset against baseline implementations and present extensive analysis. Experimental results show that our method outperforms the &#64257;ne-tuned baselines in both accuracy and real-time.

- Large-Scale Volumetric Scene Reconstruction Using LiDAR

    Author: K�hner, Tilman | FZI Forschungszentrum Informatik
    Author: K�mmerle, Julius | FZI Forschungszentrum Informatik
 
    keyword: Range Sensing; Mapping; SLAM

    Abstract : Large-scale 3D scene reconstruction is an important task in autonomous driving and other robotics applications as having an accurate representation of the environment is necessary to safely interact with it. Reconstructions are used for numerous tasks ranging from localization and mapping to planning. In robotics, volumetric depth fusion is the method of choice for indoor applications since the emergence of commodity RGB-D cameras due to its robustness and high reconstruction quality. In this work we present an approach for volumetric depth fusion using LiDAR sensors as they are common on most autonomous cars. We present a framework for large-scale mapping of urban areas considering loop closures. Our method creates a meshed representation of an urban area from recordings over a distance of 3.7 km with a high level of detail on consumer graphics hardware in several minutes. The whole process is fully automated and does not need any user interference. We quantitatively evaluate our results from a real world application. Also, we investigate the effects of the sensor model that we assume on reconstruction quality by using synthetic data.

- Topological Mapping for Manhattan-Like Repetitive Environments

    Author: Puligilla, Sai Shubodh | IIIT Hyderabad
    Author: Tourani, Satyajit | IIIT Hyderabad
    Author: Vaidya, Tushar | IIIT Hyderabad
    Author: Singh Parihar, Udit | IIIT Hyderabad
    Author: Sarvadevabhatla, Ravi Kiran | IIIT Hyderabad
    Author: Krishna, Madhava | IIIT Hyderabad
 
    keyword: SLAM; Mapping; Computer Vision for Automation

    Abstract : We showcase a topological mapping framework for a challenging indoor warehouse setting. At the most     Abstract level,	the warehouse	is represented as a Topological Graphwhere the nodes of the graph represent a particular warehouse topological construct (e.g. rackspace, corridor) and the edges denote the existence of	 a path between two neighbouring nodes or topologies. At	the intermediate level,	the map is represented as a Manhattan Graph where the nodes and edges are characterized by Manhattan properties and as a Pose Graphat the lower-most level of detail. The topological constructs are learned	 via a Deep	 Convolutional	 Network while the relational properties between topological instances are learnt via	a Siamese-style Neural Network. In	the paper, we show that maintaining     Abstractions such	as Topological Graph and manhattan Graph help in recovering an	accurate Pose	Graphstarting from a highly erroneous and unoptimized Pose Graph. We show how this is achieved by embedding topological and manhattan relations, as well as Manhattan Graph, aided loop closure relations	as constraints in the backend Pose Graph optimization framework. The recovery of near ground-truth Pose	Graph on real-world indoor warehouse scenes vindicate the efficacy of the proposed framework.

-  Structure-Aware COP-SLAM

    Author: Li, Liang | Eindhoven University of Technology
    Author: Dubbelman, Gijs | Eindhoven University of Technology

- Robust RGB-D Camera Tracking Using Optimal Key-Frame Selection

    Author: Han, Kyung Min | Ewha Woman's Univeristy
    Author: Kim, Young J. | Ewha Womans University
 
    keyword: Mapping; RGB-D Perception; SLAM

    Abstract : We propose a novel RGB-D camera tracking system that robustly reconstructs hand-held RGB-D camera sequences. The robustness of our system is achieved by two independent features of our method: adaptive visual odometry (VO) and integer programming-based key-frame selection. Our VO method adaptively interpolates the camera motion results of the direct VO and the iterative closed point to yield more optimal results than existing methods such as Elastic-Fusion. Moreover, our keyframe selection method locates globally optimum key-frames using a comprehensive objective function in a deterministic manner rather than heuristic or experience-based rules that prior methods mostly rely on. As a result, our method can complete reconstruction even if the camera fails to be tracked due to discontinuous camera motions, such as kidnap events, when conventional systems need to backtrack the scene. We validated our tracking system on 25 TUM benchmark sequences against state-of-the-art works, such as ORBSLAM2, Elastic-Fusion, and DVO SLAM, and experimentally showed that our method has smaller and more robust camera trajectory errors than these systems.


- Voxgraph: Globally Consistent, Volumetric Mapping Using Signed Distance Function Submaps

    Author: Reijgwart, Victor | ETH Zurich
    Author: Millane, Alexander James | ETH Zurich
    Author: Oleynikova, Helen | Microsoft
    Author: Siegwart, Roland | ETH Zurich
    Author: Cadena Lerma, Cesar | ETH Zurich
    Author: Nieto, Juan | ETH Zurich
 
    keyword: SLAM; Aerial Systems: Perception and Autonomy; Mapping

    Abstract : Globally consistent dense maps are a key requirement for long-term robot navigation in complex environments. While previous works have addressed the challenges of dense mapping and global consistency, most require more computational resources than may be available on-board small robots. We propose a framework that creates globally consistent volumetric maps on a CPU and is lightweight enough to run on computationally constrained platforms.<p>Our approach represents the environment as a collection of overlapping SDF submaps, and maintains global consistency by computing an optimal alignment of the submap collection. By exploiting the underlying SDF representation, we generate correspondence-free constraints between submap pairs that are computationally efficient enough to optimize the global problem each time a new submap is added. </p><p>We deploy the proposed system on a hexacopter MAV with an Intel i7-8650U CPU in two realistic scenarios: mapping a large-scale area using a 3D LiDAR, and mapping an industrial space using a RGB-D camera. In the large-scale outdoor experiments, the system optimizes a 120x80m map in less than 4s and produces absolute trajectory RMSEs of less than 1m over 400m trajectories. Our complete system, called voxgraph, will be available open source.

- DeepFactors: Real-Time Probabilistic Dense Monocular SLAM

    Author: Czarnowski, Jan | Imperial College London
    Author: Laidlow, Tristan | Imperial College London
    Author: Clark, Ronald | Imperial College London
    Author: Davison, Andrew J | Imperial College London
 
    keyword: SLAM; Deep Learning in Robotics and Automation; Mapping

    Abstract : The ability to estimate rich geometry and camera motion from monocular imagery is fundamental to future interactive robotics and augmented reality applications. Different approaches have been proposed that vary in scene geometry representation (sparse landmarks, dense maps), the consistency metric used for optimising the multi-view problem, and the use of learned priors. We present a SLAM system that unifies these methods in a probabilistic framework while still maintaining real-time performance. This is achieved through the use of a learned compact depth map representation and reformulating three different types of errors: photometric, reprojection and geometric, which we make use of within standard factor graph software. We evaluate our system on trajectory estimation and depth reconstruction on real-world sequences and present various examples of estimated dense geometry.

- DOOR-SLAM: Distributed, Online, and Outlier Resilient SLAM for Robotic Teams

    Author: Lajoie, Pierre-Yves | École Polytechnique De Montr�al
    Author: Ramtoula, Benjamin | École Polytechnique De Montr�al, École Polytechnique Fédérale De
    Author: Chang, Yun | MIT
    Author: Carlone, Luca | Massachusetts Institute of Technology
    Author: Beltrame, Giovanni | Ecole Polytechnique De Montreal
 
    keyword: SLAM; Multi-Robot Systems; Localization

    Abstract : To achieve collaborative tasks, robots in a team need to have a shared understanding of the environment and their location within it. Distributed Simultaneous Localization and Mapping (SLAM) offers a practical solution to localize the robots without relying on an external positioning system (e.g. GPS) and with minimal information exchange. Unfortunately, current distributed SLAM systems are vulnerable to perception outliers and therefore tend to use very conservative parameters for inter-robot place recognition. However, being too conservative comes at the cost of rejecting many valid loop-closure candidates, which results in less accurate trajectory estimates. This paper introduces DOOR-SLAM, a fully distributed SLAM system with an outlier rejection mechanism that can work with less conservative parameters. DOOR-SLAM is based on peer-to-peer communication and does not require full connectivity among the robots. DOOR-SLAM includes two key modules: a pose graph optimizer combined with a distributed pairwise consistent measurement set maximization algorithm to reject spurious inter-robot loop closures; and a distributed SLAM front-end that detects inter-robot loop closures without exchanging raw sensor data. The system has been evaluated in simulations, benchmarking datasets, and field experiments, including tests in GPS-denied subterranean environments.

- Windowed Bundle Adjustment Framework for Unsupervised Learning of Monocular Depth Estimation with U-Net Extension and Clip Loss

    Author: Zhou, Lipu | Carnegie Mellon University
    Author: Kaess, Michael | Carnegie Mellon University
 
    keyword: SLAM; Mapping

    Abstract : This paper presents a self-supervised framework for learning depth from monocular videos. In particular, the main contributions of this paper include: (1) We present a windowed bundle adjustment framework to train the network. Compared to most previous works that only consider constraints from consecutive frames, our framework increases the camera baseline and introduces more constraints to avoid overfitting. (2) We extend the widely used U-Net architecture by applying a Spatial Pyramid Net (SPN) and a Super Resolution Net (SRN). The SPN fuses information from an image spatial pyramid for the depth estimation, which addresses the context information attenuation problem of the original U-Net. The SRN learns to estimate a high resolution depth map from a low resolution image, which can benefit the recovery of details. (3) We adopt a clip loss function to handle moving objects and occlusions that were solved by designing complicated network or requiring extra information (such as segmentation mask [1]) in previous works. Experimental results show that our algorithm provides state-of-the-art results on the KITTI benchmark.

- StructVIO : Visual-Inertial Odometry with Structural Regularity of Man-Made Environments (I)

    Author: Zou, Danping | Shanghai Jiao Ton University
    Author: Wu, Yuanxin | Shanghai Jiao Tong University
    Author: Pei, Ling | Shanghai Jiao Tong University
    Author: Ling, Haibin | Temple University
    Author: Yu, Wenxian | Shanghai Jiao Tong University
 
    keyword: SLAM; Localization; Visual-Based Navigation

    Abstract : In this paper, we propose a novel visual-inertial odometry (VIO) approach that adopts structural regularity in man-made environments. Instead of using Manhattan world assumption, we use Atlanta world model to describe such regularity. An Atlanta world is a world that contains multiple local Manhattan worlds with different heading directions. Each local Manhattan world is detected on the fly, and their headings are gradually refined by the state estimator when new observations are received. With full exploration of structural lines that aligned with each local Manhattan worlds, our VIO method becomes more accurate and robust, as well as more flexible to different kinds of complex man-made environments. Through benchmark tests and real-world tests, the results show that the proposed approach outperforms existing visual-inertial systems in large-scale man-made environments.


- Flow-Motion and Depth Network for Monocular Stereo and Beyond

    Author: Wang, Kaixuan | Hong Kong University of Science and Technology
    Author: Shen, Shaojie | Hong Kong University of Science and Technology
 
    keyword: SLAM; Visual Learning; Aerial Systems: Perception and Autonomy

    Abstract : We propose a learning-based method that solves monocular stereo and can be extended to fuse depth information from multiple target frames. Given two unconstrained images from a monocular camera with known intrinsic calibration, our network estimates relative camera poses and the depth map of the source image. The core contribution of the proposed method is threefold. First, a network is tailored for static scenes that jointly estimates the optical flow and camera motion. By the joint estimation, the optical flow search space is gradually reduced resulting in an efficient and accurate flow estimation. Second, a novel triangulation layer is proposed to encode the estimated optical flow and camera motion while avoiding common numerical issues caused by epipolar. Third, beyond two-view depth estimation, we further extend the above networks to fuse depth information from multiple target images and estimate the depth map of the source image. To further benefit the research community, we introduce tools to generate photorealistic structure-from-motion datasets such that deep networks can be well trained and evaluated. The proposed method is compared with previous methods and achieves state-of-the-art results within less time. Images from real-world applications and Google Earth are used to demonstrate the generalization ability of the method.

- Online LiDAR-SLAM for Legged Robots with Robust Registration and Deep-Learned Loop Closure

    Author: Ramezani, Milad | University of Oxford
    Author: Tinchev, Georgi | University of Oxford
    Author: Iuganov, Egor | University of Oxford
    Author: Fallon, Maurice | University of Oxford
 
    keyword: SLAM; Legged Robots; Deep Learning in Robotics and Automation

    Abstract : In this paper, we present a 3D factor-graph LiDAR-SLAM system which incorporates a state-of-the-art deeply learned feature-based loop closure detector to enable a legged robot to localize and map in industrial environments. Point clouds are accumulated using an inertial-kinematic state estimator before being aligned using ICP registration. To close loops we use a loop proposal mechanism which matches individual segments between clouds. We trained a descriptor offline to match these segments. The efficiency of our method comes from carefully designing the network architecture to minimize the number of parameters such that this deep learning method can be deployed in real-time using only the CPU of a legged robot, a major contribution of this work. The set of odometry and loop closure factors are updated using pose graph optimization. Finally we present an efficient risk alignment prediction method which verifies the reliability of the registrations. Experimental results at an industrial facility demonstrated the robustness and flexibility of our system, including autonomous following paths derived from the SLAM map.

- Hybrid Camera Pose Estimation with Online Partitioning for SLAM

    Author: Li, Xinyi | Temple University
    Author: Ling, Haibin | Temple University
 
    keyword: SLAM; Localization; Visual-Based Navigation

    Abstract : This paper presents a hybrid real-time camera pose estimation framework with a novel partitioning scheme and introduces motion averaging to monocular Simultaneous Localization and Mapping (SLAM) systems. Breaking through the limitations of fixed-size temporal partitioning in most conventional SLAM pipelines, the proposed approach significantly improves the accuracy of local bundle adjustment by gathering spatially-strongly-connected cameras into each block. With the dynamic initialization using intermediate computation values, our proposed self-adaptive Levenberg-Marquardt solver achieves a quadratic convergence rate to further enhance the efficiency of the local optimization. Moreover, the dense data association between blocks by virtue of our co-visibility-based partitioning enables us to explore and implement motion averaging to efficiently align the blocks globally, updating camera motion estimations on-the-fly. Experiment results on benchmarks convincingly demonstrate the practicality and robustness of our proposed approach by outperforming conventional SLAM/SfM systems by orders of magnitude.

- Analysis of Minima for Geodesic and Chordal Cost for a Minimal 2D Pose-Graph SLAM Problem

    Author: Kong, Felix Honglim | The University of Technology Sydney
    Author: Zhao, Jiaheng | University of Technology Sydney
    Author: Zhao, Liang | University of Technology Sydney
    Author: Huang, Shoudong | University of Technology, Sydney
 
    keyword: SLAM

    Abstract : In this paper, we show that for a minimal 2D pose-graph SLAM problem, even in the ideal case of perfect measurements and spherical covariance, using geodesic distance (in 2D, the ``wrap function'') to compare angles results in multiple suboptimal local minima. We numerically estimate regions of attraction to these local minima for some examples, give evidence to show that they are of nonzero measure, and that these regions grow in size as noise is added. In contrast, under the same assumptions, we show that the chordal distance representation of angle error has a unique minimum up to periodicity. For chordal cost, we find that initial conditions failing to converge to the global minimum are far fewer, fail because of numerical issues, and do not seem to grow with noise in our examples.

- Voxel Map for Visual SLAM

    Author: Muglikar,, Manasi | University of Zurich
    Author: Zhang, Zichao | Robotics and Perception Group, University of Zurich
    Author: Scaramuzza, Davide | University of Zurich
 
    keyword: SLAM; Mapping; Localization

    Abstract : In modern visual SLAM systems, it is a standard practice to retrieve potential candidate map points from overlapping keyframes for further feature matching or direct tracking. In this work, we argue that keyframes are not the optimal choice for this task, due to several inherent limitations, such as weak geometric reasoning and poor scalability. We propose a voxel-map representation to ef&#64257;ciently retrieve map points for visual SLAM. In particular, we organize the map points in a regular voxel grid. Visible points from a camera pose are queried by sampling the camera frustum in a raycasting manner, which can be done in constant time using an ef&#64257;cient voxel hashing method. Compared with keyframes, the retrieved points using our method are geometrically guaranteed to fall in the camera &#64257;eld-of-view, and occluded points can be identi&#64257;ed and removed to a certain extend. This method also naturally scales up to large scenes and complicated multicamera con&#64257;gurations. Experimental results show that our voxel map representation is as ef&#64257;cient as a keyframe map with 5 keyframes and provides signi&#64257;cantly higher localization accuracy (average 46% improvement in RMSE) on the EuRoC dataset. The proposed voxel-map representation is a general approach to a fundamental functionality in visual SLAM and widely applicable

## Deep Learning in Robotics and Automation 

- Learning 3D-Aware Egocentric Spatial-Temporal Interaction Via Graph Convolutional Networks

    Author: Li, Chengxi | Purdue University
    Author: Meng, Yue | IBM T. J. Watson Research Center
    Author: Chan, Stanley | Purdue University
    Author: Chen, Yi-Ting | Honda Research Institute USA
 
    keyword: Deep Learning in Robotics and Automation; Semantic Scene Understanding; Computer Vision for Transportation

    Abstract : To enable intelligent automated driving systems, a promising strategy is to understand how human drives and interacts with road users in complicated driving situations. In this paper, we propose a 3D-aware egocentric spatial-temporal interaction framework for automated driving applications. Graph convolution networks (GCN) is devised for interaction modeling. We introduce three novel concepts into GCN. First, we decompose egocentric interactions into ego-thing and egostuff interaction, modeled by two GCNs. In both GCNs, ego nodes are introduced to encode the interaction between thing objects (e.g., car and pedestrian), and interaction between stuff objects (e.g., lane marking and traffic light). Second, objects' 3D locations are explicitly incorporated into GCN to better model egocentric interactions. Third, to implement ego-stuff interaction in GCN, we propose a MaskAlign operation to extract features for irregular objects. We validate the proposed framework on tactical driver behavior recognition. Extensive experiments are conducted using Honda Research Institute Driving Dataset, the largest dataset with diverse tactical driver behavior annotations. Our framework demonstrates substantial performance boost over baselines on the two experimental settings by 3.9% and 6.0%, respectively. Furthermore, we visualize the learned affinity matrices, which encode ego-thing and ego-stuff interactions, to showcase the proposed framework can capture interactions effectively.

- C-3PO: Cyclic-Three-Phase Optimization for Human-Robot Motion Retargeting Based on Reinforcement Learning

    Author: Kim, Taewoo | University of Science and Technology
    Author: Lee, Joo-Haeng | ETRI
 
    keyword: Deep Learning in Robotics and Automation; Social Human-Robot Interaction; Gesture, Posture and Facial Expressions

    Abstract : Motion retargeting between heterogeneous polymorphs with different sizes and kinematic configurations requires a comprehensive knowledge of (inverse) kinematics. Moreover, it is non-trivial to provide a kinematic independent general solution. In this study, we developed a cyclic three-phase optimization method based on deep reinforcement learning for human-robot motion retargeting. The motion retargeting learning is performed using refined data in a latent space by the cyclic and filtering paths of our method. In addition, the humanin-the-loop based three-phase approach provides a framework for the improvement of the motion retargeting policy by both quantitative and qualitative manners. Using the proposed C-3PO method, we were successfully able to learn the motion retargeting skill between the human skeleton and motion of the multiple robots such as NAO, Pepper, Baxter and C-3PO.

- AP-MTL: Attention Pruned Multi-Task Learning Model for Real-Time Instrument Detection and Segmentation in Robot-Assisted Surgery

    Author: Islam, Mobarakol | National University of Singapore
    Author: Vs, Vibashan | National Institute of Technology
    Author: Ren, Hongliang | Faculty of Engineering, National University of Singapore
 
    keyword: Deep Learning in Robotics and Automation; Medical Robots and Systems; Surgical Robotics: Laparoscopy

    Abstract : Surgical scene understanding and multi-tasking learning are crucial for image-guided robotic surgery. Training a real-time robotic system for the detection and segmentation of high-resolution images provides a challenging problem with the limited computational resource. The perception drawn can be applied in effective real-time feedback, surgical skill assessment, and human-robot collaborative surgeries to enhance surgical outcomes. For this purpose, we develop a novel end-to-end trainable real-time Multi-Task Learning (MTL) model with weight-shared encoder and task-aware detection and segmentation decoders. Optimization of multiple tasks at the same convergence point is vital and present a complex problem. Thus, we propose an asynchronous task-aware optimization (ATO) technique to calculate task-oriented gradients and train the decoders independently. Moreover, MTL models are always computationally expensive, which hinder real-time applications. To address this challenge, we introduce a global attention dynamic pruning (GADP) by removing less significant and sparse parameters. We further design a skip squeeze and excitation (SE) module, which suppresses weak features, excites significant features and performs dynamic spatial and channel-wise feature re-calibration. Validating on the robotic instrument segmentation dataset of MICCAI endoscopic vision challenge, our model significantly outperforms state-of-the-art segmentation and detection models, including best-performed mod

- Automatic Gesture Recognition in Robot-Assisted Surgery with Reinforcement Learning and Tree Search

    Author: Gao, Xiaojie | The Chinese University of Hong Kong
    Author: Jin, Yueming | The Chinese University of Hong Kong
    Author: Dou, Qi | The Chinese University of Hong Kong
    Author: Heng, Pheng Ann | The Chinese University of Hong Kong
 
    keyword: Computer Vision for Medical Robotics; Deep Learning in Robotics and Automation; Recognition

    Abstract : Automatic surgical gesture recognition is fundamental for improving intelligence in robot-assisted surgery, such as conducting complicated tasks of surgery surveillance and skill evaluation. However, current methods treat each frame individually and produce the outcomes without effective consideration on future information. In this paper, we propose a framework based on reinforcement learning and tree search for joint surgical gesture segmentation and classification. An agent is trained to segment and classify the surgical video in a human-like manner whose direct decisions are re-considered by tree search appropriately. Our proposed tree search algorithm unites the outputs from two designed neural networks, i.e., policy and value network. With the integration of complementary information from distinct models, our framework is able to achieve the better performance than baseline methods using either of the neural networks. For an overall evaluation, our developed approach consistently outperforms the existing methods on the suturing task of JIGSAWS dataset in terms of accuracy, edit score and F1 score. Our study highlights the utilization of tree search to refine actions in reinforcement learning framework for surgical robotic applications.

- Towards Privacy-Preserving Ego-Motion Estimation Using an Extremely Low-Resolution Camera

    Author: Shariati, Armon | University of Pennsylvania
    Author: Holz, Christian | ETH Zurich
    Author: Sinha, Sudipta | Microsoft Research
 
    keyword: Deep Learning in Robotics and Automation; SLAM; Human-Centered Robotics

    Abstract : Ego-motion estimation is a core task in robotic systems as well as in augmented and virtual reality applications. It is often solved using visual-inertial odometry, which involves using one or more emph{always-on} cameras on mobile robots and wearable devices. As consumers increasingly use such devices in their homes and workplaces, which are filled with sensitive details, the role of privacy in such camera-based approaches is of ever increasing importance.<p>In this paper, we introduce the first solution to perform emph{privacy-preserving} ego-motion estimation. We recover camera ego-motion from an extremely low-resolution monocular camera by estimating dense optical flow at a higher spatial resolution (i.e., 4x super resolution). We propose textit{SRFNet} for directly estimating Super-Resolved Flow, a novel convolutional neural network model that is trained in a supervised setting using ground-truth optical flow. We also present a weakly supervised approach for training a variant of SRFNet on real videos where ground truth flow is unavailable. On image pairs with known relative camera orientations, we use SRFNet to predict the auto-epipolar flow that arises from pure camera translation, from which we robustly estimate the camera translation direction. We evaluate our super-resolved optical flow estimates and camera translation direction estimates on the Sintel and KITTI odometry datasets, where our methods outperform several baselines. Our results indicate that robust ego

- ACNN: A Full Resolution DCNN for Medical Image Segmentation

    Author: Zhou, Xiao-Yun | Imperial College London
    Author: Zheng, Jian-Qing | University of Oxford
    Author: Li, Peichao | Imperial College London
    Author: Yang, Guang-Zhong | Shanghai Jiao Tong University
 
    keyword: Deep Learning in Robotics and Automation; Computer Vision for Medical Robotics; Medical Robots and Systems

    Abstract : Deep Convolutional Neural Networks (DCNNs) are used extensively in medical image segmentation and hence 3D navigation for robot-assisted Minimally Invasive Surgeries (MISs). However, current DCNNs usually use down sampling layers for increasing the receptive field and gaining     Abstract semantic information. These down sampling layers decrease the spatial dimension of feature maps, which can be detrimental to image segmentation. Atrous convolution is an alternative for the down sampling layer. It increases the receptive field whilst maintains the spatial dimension of feature maps. In this paper, a method for effective atrous rate setting is proposed to achieve the largest and fully-covered receptive field with a minimum number of atrous convolutional layers. Furthermore, a new and full resolution DCNN - Atrous Convolutional Neural Network (ACNN), which incorporates cascaded atrous II-blocks, residual learning and Instance Normalization (IN) is proposed. Application results of the proposed ACNN to Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) image segmentation demonstrate that the proposed ACNN can achieve higher segmentation Intersection over Unions (IoUs) than U-Net and Deeplabv3+, but with reduced trainable parameters.

- RoNIN: Robust Neural Inertial Navigation in the Wild: Benchmark, Evaluations, &amp; New Methods

    Author: Herath, Sachini | Simon Fraser University
    Author: Yan, Hang | Washington University in St. Louis
    Author: Furakawa, Yasutaka | Simon Fraser University
 
    keyword: Deep Learning in Robotics and Automation; Human Detection and Tracking; Sensor Fusion

    Abstract : This paper sets a new foundation for data-driven inertial navigation research, where the task is the estimation of horizontal positions and heading direction of a moving subject from a sequence of IMU sensor measurements from a phone. In contrast to existing methods, our method can handle varying phone orientations and placements.<p>More concretely, the paper presents 1) a new benchmark containing more than 40 hours of IMU sensor data from 100 human subjects with ground-truth 3D trajectories under natural human motions; 2) novel neural inertial navigation architectures, making significant improvements for challenging motion cases; and 3) qualitative and quantitative evaluations of the competing methods over three inertial navigation benchmarks. We share the code and data to promote further research (http://ronin.cs.sfu.ca).

- Segmenting 2K-Videos at 36.5 FPS with 24.3 GFLOPs: Accurate and Lightweight Realtime Semantic Segmentation Network

    Author: Oh, Dokwan | Samsung Electronics
    Author: Ji, Daehyun | Samsung Advanced Institute of Technology
    Author: Jang, Cheolhun | Samsung Advanced Institute of Technology
    Author: Hyun, Yoonsuk | Samsung Electronics
    Author: Bae, Hong S. | SAMSUNG
    Author: Hwang, Sung Ju | KAIST
 
    keyword: Deep Learning in Robotics and Automation; Object Detection, Segmentation and Categorization; AI-Based Methods

    Abstract : We propose a fast and lightweight end-to-end convolutional network architecture for real-time segmentation of high resolution videos, NfS-SegNet, that can segment 2K-videos at 36.5 FPS with 24.3 GFLOPS. This speed and computation-efficiency is due to following reasons: 1) The encoder network, NfS-Net, is optimized for speed with simple building blocks without memory-heavy operations such as depthwise convolutions, and outperforms state-of-the-art lightweight CNN architectures such as SqueezeNet [2], MobileNet v1 [3] &amp; v2 [4] and ShuffleNet v1 [5] &amp; v2 [6] on image classification with significantly higher speed. 2) The NfS-SegNet has an asymmetric architecture with deeper encoder and shallow decoder, whose design is based on our empirical finding that the decoder is the main bottleneck in computation with relatively small contribution to the final performance. 3) Our novel uncertainty-aware knowledge distillation method guides the teacher model to focus its knowledge transfer on the most difficult image regions. We validate the performance of NfS-SegNet with the CITYSCAPE [1] benchmark, on which it achieves state-of-the-art performance among lightweight segmentation models in terms of both accuracy and speed.

- Temporally Consistent Horizon Lines

    Author: Kluger, Florian | University of Hannover
    Author: Ackermann, Hanno | Institute of Information Processing, Leibniz Universitét Hannove
    Author: Yang, Michael Ying | University of Twente
    Author: Rosenhahn, Bodo | Institute of Information Processing, Leibniz Universitét Hannove
 
    keyword: Deep Learning in Robotics and Automation; Computer Vision for Other Robotic Applications; Computer Vision for Transportation

    Abstract : The horizon line is an important geometric feature for many image processing and scene understanding tasks in computer vision. For instance, in navigation of autonomous vehicles or driver assistance, it can be used to improve 3D reconstruction as well as for semantic interpretation of dynamic environments. While both algorithms and datasets exist for single images, the problem of horizon line estimation from video sequences has not gained attention. In this paper, we show how convolutional neural networks are able to utilise the temporal consistency imposed by video sequences in order to increase the accuracy and reduce the variance of horizon line estimates. A novel CNN architecture with an improved residual convolutional LSTM is presented for temporally consistent horizon line estimation. We propose an adaptive loss function that ensures stable training as well as accurate results. Furthermore, we introduce an extension of the KITTI dataset which contains precise horizon line labels for 43699 images across 72 video sequences. A comprehensive evaluation shows that the proposed approach consistently achieves superior performance compared with existing methods.

- Full-Scale Continuous Synthetic Sonar Data Generation with Markov Conditional Generative Adversarial Networks

    Author: Jegorova, Marija | University of Edinburgh
    Author: Karjalainen, Antti Ilari | SeeByte Ltd
    Author: Vazquez-Diosdado, Jose | SeeByte Ltd
    Author: Hospedales, Timothy | Queen Mary University of London
 
    keyword: Deep Learning in Robotics and Automation; Object Detection, Segmentation and Categorization; Simulation and Animation

    Abstract : Deployment and operation of autonomous underwater vehicles is expensive and time-consuming. High-quality realistic sonar data simulation could be of benefit to multiple applications, including training of human operators for post-mission analysis, as well as tuning and validation of autonomous target recognition (ATR) systems for underwater vehicles. Producing realistic synthetic sonar imagery is a challenging problem as the model has to account for specific artefacts of real acoustic sensors, vehicle altitude, and a variety of environmental factors. We propose a novel method for generating realistic-looking sonar side-scans of full-length missions, called Markov Conditional pix2pix (MC-pix2pix). Quantitative assessment results confirm that the quality of the produced data is almost indistinguishable from real. Furthermore, we show that bootstrapping ATR systems with MC-pix2pix data can improve the performance. Synthetic data is generated 18 times faster than real acquisition speed, with full user control over the topography of the generated data.

- Real-Time Soft Body 3D Proprioception Via Deep Vision-Based Sensing

    Author: Wang, Ruoyu | New York University
    Author: Wang, Shiheng | New York University
    Author: Du, Songyu | New York University
    Author: Xiao, Erdong | New York University
    Author: Yuan, Wenzhen | Carnegie Mellon University
    Author: Feng, Chen | New York University
 
    keyword: Deep Learning in Robotics and Automation; Modeling, Control, and Learning for Soft Robots; Computer Vision for Automation

    Abstract : Soft bodies made from flexible and deformable materials are popular in many robotics applications, but their proprioceptive sensing has been a long-standing challenge. In other words, there has hardly been a method to measure and model the high-dimensional 3D shapes of soft bodies with internal sensors. We propose a framework to measure the high-resolution 3D shapes of soft bodies in real-time with embedded cameras. The cameras capture visual patterns inside a soft body, and a convolutional neural network (CNN) produces a latent code representing the deformation state, which can then be used to reconstruct the body's 3D shape using another neural network. We test the framework on various soft bodies, such as a Baymax-shaped toy, a latex balloon, and some soft robot fingers, and achieve real-time computation (&lt;2.5ms/frame) for robust shape estimation with high precision (&lt;1% relative error) and high resolution. We believe the method could be applied to soft robotics and human-robot interaction for proprioceptive shape sensing. Our code is available at: https://ai4ce.github.io/DeepSoRo/.

- A General Framework for Uncertainty Estimation in Deep Learning

    Author: Loquercio, Antonio | UZH, University of Zurich
    Author: Segu, Mattia | ETH Zurich
    Author: Scaramuzza, Davide | University of Zurich
 
    keyword: Deep Learning in Robotics and Automation; AI-Based Methods; Autonomous Agents

    Abstract : Neural networks predictions are unreliable when the input sample is out of the training distribution or corrupted by noise. Being able to detect such failures automatically is fundamental to integrate deep learning algorithms into robotics. Current approaches for uncertainty estimation of neural networks require changes to the network and optimization process, typically ignore prior knowledge about the data, and tend to make over-simplifying assumptions which underestimate uncertainty. To address these limitations, we propose a novel framework for uncertainty estimation. Based on Bayesian belief networks and Monte-Carlo sampling, our framework not only fully models the different sources of prediction uncertainty, but also incorporates prior data information, e.g. sensor noise. We show theoretically that this gives us the ability to capture uncertainty better than existing methods. In addition, our framework has several desirable properties: (i) it is agnostic to the network architecture and task; (ii) it does not require changes in the optimization process; (iii) it can be applied to already trained architectures. We thoroughly validate the proposed framework through extensive experiments on both computer vision and control tasks, where we outperform previous methods by up to 23% in accuracy.


- Learning Local Behavioral Sequences to Better Infer Non-Local Properties in Real Multi-Robot Systems

    Author: Choi, Taeyeong | Arizona State University
    Author: Kang, Sehyeok | Arizona State University
    Author: Pavlic, Theodore | Arizona State University
 
    keyword: Deep Learning in Robotics and Automation; Recognition; Localization

    Abstract : When members of a multi-robot team follow regular motion rules sensitive to robots and other environmental factors within sensing range, the team itself may become an informational fabric for gaining situational awareness without explicit signalling among robots. In our previous work [1], we used machine learning to develop a scalable module, trained only on data from 3-robot teams, that could predict the positions of all robots in larger multi-robot teams based only on observations of the movement of a robot's nearest neighbor. Not only was this approach scalable from 3-to-many robots, but it did not require knowledge of the control laws of the robots under observation, as would a traditional observer-based approach. However, performance was only tested in simulation and could only be a substitute for explicit communication for short periods of time or in cases of very low sensing noise. In this work, we apply more sophisticated machine learning methods to data from a physically realized robotic team to develop Remote Teammate Localization (ReTLo) modules that can be used in realistic environments. To be specific, we adopt Long�Short-Term�Memory (LSTM) [2] to learn the evolution of behaviors in a modular team, which has the effect of greatly reducing errors from regression outcomes. In contrast with our previous work in simulation, all of the experiments conducted in this work were conducted on the Thymio physical, two-wheeled robotic platform.

- Unsupervised Geometry-Aware Deep LiDAR Odometry

    Author: Cho, Younggun | Korea Advanced Institute of Science and Technology
    Author: Kim, Giseop | KAIST(Korea Advanced Institute of Science and Technology)
    Author: Kim, Ayoung | Korea Advanced Institute of Science Technology
 
    keyword: Deep Learning in Robotics and Automation; SLAM; Range Sensing

    Abstract : Learning-based ego-motion estimation approaches have recently drawn strong interest from researchers, mostly focusing on visual perception. A few learning-based approaches using Light Detection and Ranging (LiDAR) have been reported; however, they heavily rely on a supervised learning manner. Despite the meaningful performance of these approaches, supervised training requires ground-truth pose labels, which is the bottleneck for real-world applications. Differing from these approaches, we focus on unsupervised learning for LiDAR odometry (LO) without trainable labels. Achieving trainable LO in an unsupervised manner, we introduce the uncertainty-aware loss with geometric confidence, thereby allowing the reliability of the proposed pipeline. Evaluation on the KITTI, Complex Urban, and Oxford RobotCar datasets demonstrate the prominent performance of the proposed method compared to conventional model-based methods. The proposed method shows a comparable result against SuMa (in KITTI), LeGO-LOAM (in Complex Urban), and Stereo-VO (in Oxford RobotCar). The video and extra-information of the paper are described in https://sites.google.com/view/deeplo.

- SA-Net: Robust State-Action Recognition for Learning from Observations

    Author: Soans, Nihal | University of Georgia
    Author: Asali, Ehsan | University of Georgia
    Author: Hong, Yi | University of Georgia
    Author: Doshi, Prashant | University of Georgia
 
    keyword: Deep Learning in Robotics and Automation; Learning from Demonstration; RGB-D Perception

    Abstract : Learning from observation (LfO) offers a new paradigm for transferring task behavior to robots. LfO requires the robot to observe the task being performed and decompose the sensed streaming data into sequences of state-action pairs, which are then input to LfO methods. Thus, recognizing the state-action pairs correctly and quickly in sensed data is a crucial prerequisite. We present SA-Net a deep neural network architecture that recognizes state-action pairs from RGB-D data streams. SA-Net performs well in two replicated robotic applications of LfO -- one involving mobile ground robots and another involving a robotic manipulator -- which demonstrates that the architecture could generalize well to differing contexts. Comprehensive evaluations including deployment on a physical robot show that SA-Net significantly improves on the accuracy of the previous methods under various conditions.

- A Generative Approach for Socially Compliant Navigation

    Author: Tsai, Chieh-En | Carnegie Mellon University
    Author: Oh, Jean | Carnegie Mellon University
 
    keyword: Deep Learning in Robotics and Automation; Social Human-Robot Interaction; Human-Centered Robotics

    Abstract : Robots navigating in human crowds need to optimize their paths not only for their task performance but also for their compliance to social norms. One of the key challenges in this context is the lack of standard metrics for evaluating and optimizing a socially compliant behavior. Existing works in social navigation can be grouped according to the differences in their optimization objectives. For instance, the reinforcement learning approaches tend to optimize on the comfort aspect of the socially compliant navigation, whereas the inverse reinforcement learning approaches are designed to achieve natural behavior. In this paper, we propose NaviGAN, a generative navigation algorithm that jointly optimizes both of the comfort and naturalness aspects. Our approach is designed as an adversarial training framework that can learn to generate a navigation path that is both optimized for achieving a goal and for complying with latent social rules. A set of experiments has been carried out on multiple datasets to demonstrate the strengths of the proposed approach quantitatively. We also perform extensive experiments using a physical robot in a real-world environment to qualitatively evaluate the trained social navigation behavior. The video recordings of the robot experiments can be found in the link: https://youtu.be/61blDymjCpw.

- Scalable Multi-Task Imitation Learning with Autonomous Improvement

    Author: Singh, Avi | UC Berkeley
    Author: Jang, Eric | Google
    Author: Irpan, Alexander | Google
    Author: Kappler, Daniel | X (Google)
    Author: Dalal, Murtaza | University of California Berkeley
    Author: Levine, Sergey | UC Berkeley
    Author: Khansari, Mohi | Google X
    Author: Finn, Chelsea | Stanford University
 
    keyword: Deep Learning in Robotics and Automation

    Abstract : While robot learning has demonstrated promising results for enabling robots to automatically acquire new skills, a critical challenge in deploying learning-based systems is scale: acquiring enough data for the robot to effectively generalize broadly. Imitation learning, in particular, has remained a stable and powerful approach for robot learning, but critically relies on expert operators for data collection. In this work, we target this challenge, aiming to build an imitation learning system that can continuously improve through autonomous data collection, while simultaneously avoiding the explicit use of reinforcement learning, to maintain the stability, simplicity, and scalability of supervised imitation. To accomplish this, we cast the problem of imitation with autonomous improvement into a multi-task setting. We utilize the insight that, in a multi-task setting, a failed attempt at one task might represent a successful attempt at another task. This allows us to leverage the robot's own trials as demonstrations for tasks other than the one that the robot actually attempted. In contrast to prior imitation learning approaches, our method can autonomously collect data with sparse supervision for continuous improvement, and in contrast to reinforcement learning algorithms, our method can effectively improve from sparse, task-agnostic reward signals.

- Motion2Vec: Semi-Supervised Representation Learning from Surgical Videos

    Author: Tanwani, Ajay Kumar | UC Berkeley
    Author: Sermanet, Pierre | Google
    Author: Yan, Andy | UC Berkeley
    Author: Anand, Raghav | UC Berkeley
    Author: Phielipp, Mariano | Intel Corporation
    Author: Goldberg, Ken | UC Berkeley
 
    keyword: Deep Learning in Robotics and Automation; Learning from Demonstration; Learning and Adaptive Systems

    Abstract : Learning meaningful visual representations in an embedding space can facilitate generalization in downstream tasks such as action segmentation and imitation. In this paper, we learn a motion-centric representation of surgical video demonstrations by grouping them into action segments/sub-goals/options in a semi-supervised manner. We present Motion2Vec, an algorithm that learns a deep embedding feature space from video observations by minimizing a metric learning loss in a Siamese network: images from the same action segment are pulled together while pushed away from randomly sampled images of other segments. The embeddings are iteratively segmented with a recurrent neural network for a given parametrization of the embedding space after pre-training the Siamese network. We only use a small set of labeled video segments to semantically align the embedding space and assign pseudo-labels to the remaining unlabeled data by inference on the learned model parameters. We demonstrate the use of this representation to imitate surgical suturing kinematic motions from publicly available videos of the JIGSAWS dataset. Results give 85.5% segmentation accuracy on average suggesting performance improvement over several state-of-the-art baselines, while kinematic pose imitation gives 0.94 centimeter error in position per observation on the test set. Videos, code and data are available at: https://sites.google.com/view/motion2vec


- PointAtrousGraph: Deep Hierarchical Encoder-Decoder with Point Atrous Convolution for Unorganized 3D Points

    Author: Pan, Liang | National University of Singapore
    Author: Chew, Chee Meng | National University of Singapore
    Author: Lee, Gim Hee | National University of Singapore
 
    keyword: Deep Learning in Robotics and Automation; Computer Vision for Other Robotic Applications; Semantic Scene Understanding

    Abstract : Motivated by the success of encoding multi-scale contextual information for image analysis, we propose our PointAtrousGraph (PAG) - a deep permutation-invariant hierarchical encoder-decoder for efficiently exploiting multi-scale edge features in point clouds. Our PAG is constructed by several novel modules, such as Point Atrous Convolution (PAC), Edge-preserved Pooling (EP) and Edge-preserved Unpooling (EU). Similar with atrous convolution, our PAC can effectively enlarge receptive fields of filters and thus densely learn multi-scale point features. Following the idea of non-overlapping max-pooling operations, we propose our EP to preserve critical edge features during subsampling. Correspondingly, our EU modules gradually recover spatial information for edge features. In addition, we introduce chained skip subsampling/upsampling modules that directly propagate edge features to the final stage. Particularly, our proposed auxiliary loss functions can further improve our performance. Experimental results show that our PAG outperform previous state-of-the-art methods on various 3D semantic perception applications.

- Learning Error Models for Graph SLAM

    Author: Reymann, Christophe | LAAS-CNRS
    Author: Lacroix, Simon | LAAS/CNRS
 
    keyword: Deep Learning in Robotics and Automation; SLAM; Mapping

    Abstract : Following recent developments, this paper investigates the possibility to predict uncertainty models for monocular graph SLAM using topological features of the problem. An architecture to learn relative (i.e. inter-keyframe) uncertainty models using the resistance distance in the covisibility graph is presented. The proposed architecture is applied to simulated UAV coverage path planning trajectories and an analysis of the approaches strengths and shortcomings is provided.

- SMArT: Training Shallow Memory-Aware Transformers for Robotic Explainability

    Author: Cornia, Marcella | University of Modena and Reggio Emilia
    Author: Baraldi, Lorenzo | Université Degli Studi Di Modena E Reggio Emilia
    Author: Cucchiara, Rita | Université Degli Studi Di Modena E Reggio Emilia
 
    keyword: Deep Learning in Robotics and Automation; Object Detection, Segmentation and Categorization

    Abstract : The ability to generate natural language explanations conditioned on the visual perception is a crucial step towards autonomous agents which can explain themselves and communicate with humans. While the research efforts in image and video captioning are giving promising results, this is often done at the expense of the computational requirements of the approaches, limiting their applicability to real contexts. In this paper, we propose a fully-attentive captioning algorithm which can provide state-of-the-art performances on language generation while restricting its computational demands. Our model is inspired by the Transformer model and employs only two Transformer layers in the encoding and decoding stages. Further, it incorporates a novel memory-aware encoding of image regions. Experiments demonstrate that our approach achieves competitive results in terms of caption quality while featuring reduced computational demands. Further, to evaluate its applicability on autonomous agents, we conduct experiments on simulated scenes taken from the perspective of domestic robots.

- A 3D-Deep-Learning-Based Augmented Reality Calibration Method for Robotic Environments Using Depth Sensor Data

    Author: K�stner, Linh | Technische Universitét Berlin
    Author: Frasineanu, Vlad-Catalin | TU Berlin
    Author: Lambrecht, Jens | Technische Universitét Berlin
 
    keyword: Deep Learning in Robotics and Automation; Object Detection, Segmentation and Categorization; AI-Based Methods

    Abstract : Augmented Reality and mobile robots are gaining increased attention within industries due to the high potential to make processes cost and time efficient. To facilitate augmented reality, a calibration between the Augmented Reality device and the environment is necessary. This is a challenge when dealing with mobile robots due to the mobility of all entities making the environment dynamic. On this account, we propose a novel approach to calibrate Augmented Reality devices using 3D depth sensor data. We use the depth camera of a Head Mounted Augmented Reality Device, the Microsoft Hololens, for deep learning-based calibration. Therefore, we modified a neural network based on the recently published VoteNet architecture which works directly on raw point cloud input observed by the Hololens. We achieve satisfying results and eliminate external tools like markers, thus enabling a more intuitive and flexible work flow for Augmented Reality integration. The results are adaptable to work with all depth cameras and are promising for further research. Furthermore, we introduce an open source 3D point cloud labeling tool, which is to our knowledge the first open source tool for labeling raw point cloud data.

- Adversarial Feature Training for Generalizable Robotic Visuomotor Control

    Author: Chen, Xi | KTH
    Author: Ghadirzadeh, Ali | KTH Royal Institute of Technology, Aalto University
    Author: Bj�rkman, M�rten | KTH
    Author: Jensfelt, Patric | KTH - Royal Institute of Technology
 
    keyword: Deep Learning in Robotics and Automation; Perception for Grasping and Manipulation

    Abstract : Deep reinforcement learning (RL) has enabled training action-selection policies, end-to-end, by learning a function which maps image pixels to action outputs. However, it's application to visuomotor robotic policy training has been limited because of the challenge of large-scale data collection when working with physical hardware. A suitable visuomotor policy should perform well not just for the task-setup it has been trained for, but also for all varieties of the task, including novel objects at different viewpoints surrounded by task-irrelevant objects. However, it is impractical for a robotic setup to sufficiently collect interactive samples in a RL framework to generalize well to novel aspects of a task. <p>In this work, we demonstrate that by using adversarial training for domain transfer, it is possible to train visuomotor policies based on RL frameworks, and then transfer the acquired policy to other novel task domains. We propose to leverage the deep RL capabilities to learn complex visuomotor skills for uncomplicated task setups, and then exploit transfer learning to generalize to new task domains provided only still images of the task in the target domain. We evaluate our method on two real robotic tasks, picking and pouring, and compare it to a number of prior works, demonstrating its superiority.

- Efficient Bimanual Manipulation Using Learned Task Schemas

    Author: Chitnis, Rohan | Massachusetts Institute of Technology
    Author: Tulsiani, Shubham | Facebook AI Research
    Author: Gupta, Saurabh | UIUC
    Author: Gupta, Abhinav | Carnegie Mellon University
 
    keyword: Deep Learning in Robotics and Automation; Perception for Grasping and Manipulation; Dual Arm Manipulation

    Abstract : We address the problem of effectively composing skills to solve sparse-reward tasks in the real world. Given a set of parameterized skills (such as exerting a force or doing a top grasp at a location), our goal is to learn policies that invoke these skills to efficiently solve such tasks. Our insight is that for many tasks, the learning process can be decomposed into learning a state-independent task schema (a sequence of skills to execute) and a policy to choose the parameterizations of the skills in a state-dependent manner. For such tasks, we show that explicitly modeling the schema's state-independence can yield significant improvements in sample efficiency for model-free reinforcement learning algorithms. Furthermore, these schemas can be transferred to solve related tasks, by simply re-learning the parameterizations with which the skills are invoked. We find that doing so enables learning to solve sparse-reward tasks on real-world robotic systems very efficiently. We validate our approach experimentally over a suite of robotic bimanual manipulation tasks, both in simulation and on real hardware. See videos at http://tinyurl.com/chitnis-schema.

- BayesOD: A Bayesian Approach for Uncertainty Estimation in Deep Object Detectors

    Author: Harakeh, Ali | University of Toronto
    Author: Smart, Michael | University of Waterloo
    Author: Waslander, Steven Lake | University of Toronto
 
    keyword: Deep Learning in Robotics and Automation; Object Detection, Segmentation and Categorization; Probability and Statistical Methods

    Abstract : When incorporating deep neural networks into robotic systems, a major challenge is the lack of uncertainty measures associated with their output predictions. Methods for uncertainty estimation in the output of deep object detectors (DNNs) have been proposed in recent works, but have had limited success due to 1) information loss at the detectors non-maximum suppression (NMS) stage, and 2) failure to take into account the multitask, many-to-one nature of anchor-based object detection. To that end, we introduce BayesOD, an uncertainty estimation approach that reformulates the standard object detector inference and Non-Maximum suppression components from a Bayesian perspective. Experiments performed on four common object detection datasets show that BayesOD provides uncertainty estimates that are better correlated with the accuracy of detections, manifesting as a significant reduction of 9.77%-13.13% on the minimum Gaussian uncertainty error metric and a reduction of 1.63%-5.23% on the minimum Categorical uncertainty error metric. Code will be released at https://github.com/asharakeh/bayes-od-rc.

- Learning Object Placements for Relational Instructions by Hallucinating Scene Representations

    Author: Mees, Oier | Albert-Ludwigs-Universitét
    Author: Emek, Alp | University of Freiburg
    Author: Vertens, Johan | University of Freiburg
    Author: Burgard, Wolfram | Toyota Research Institute
 
    keyword: Deep Learning in Robotics and Automation; Cognitive Human-Robot Interaction; Computer Vision for Automation

    Abstract : Human-centered environments contain a wide variety of spatial relations between everyday objects. For autonomous robots to interact with humans effectively in such environments, they should be able to reason about the best way to place objects in order to follow natural language instructions based on spatial relations. In this work, we present a convolutional neural network for estimating pixelwise object placement probabilities for a set of spatial relations from a single input image. During training, our network receives the learning signal by classifying hallucinated high-level scene representations as an auxiliary task. Unlike previous approaches, our method does not require ground truth data for the pixelwise relational probabilities or 3D models of the objects, which significantly expands the applicability in practical robotics scenarios. Our results, based on both real-world data and human-robot experiments, demonstrate the effectiveness of our method in reasoning about the best way to place objects to reproduce a spatial relation. Videos of our experiments can be found at https://youtu.be/zaZkHTWFMKM

- FADNet: A Fast and Accurate Network for Disparity Estimation

    Author: Wang, Qiang | Hong Kong Baptist University
    Author: Shi, Shaohuai | Hong Kong Baptist University
    Author: Zheng, Shizhen | HKBU
    Author: Zhao, Kaiyong | Hong Hong Baptist University
    Author: Chu, Xiaowen | Hong Kong Baptist University
 
    keyword: Deep Learning in Robotics and Automation; RGB-D Perception; Visual Learning

    Abstract : Deep neural networks (DNNs) have achieved great success in the area of computer vision. The disparity estimation problem tends to be addressed by DNNs which achieve much better prediction accuracy in stereo matching than traditional hand-crafted feature based methods. On one hand, however, the designed DNNs require significant memory and computation resources to accurately predict the disparity, especially for those 3D convolution based networks, which makes it difficult for deployment in real-time applications. On the other hand, existing computation-efficient networks lack expression capability in large-scale datasets so that they cannot make an accurate prediction in many scenarios. To this end, we propose an efficient and accurate deep network for disparity estimation named FADNet with three main features: 1) It exploits efficient 2D based correlation layers with stacked blocks to preserve fast computation; 2) It combines the residual structures to make the deeper model easier to learn; 3) It contains multi-scale predictions so as to exploit a multi-scale weight scheduling training technique to improve the accuracy. We conduct experiments to demonstrate the effectiveness of FADNet on two popular datasets, Scene Flow and KITTI 2015. Experimental results show that FADNet achieves state-of-the-art prediction accuracy, and runs at a significant order of magnitude faster speed than existing 3D models. The codes of FADNet are available at https://github.com/HKBU-HPML/FADNet.

- Training Adversarial Agents to Exploit Weaknesses in Deep Control Policies

    Author: Kuutti, Sampo | University of Surrey
    Author: Fallah, Saber | University of Surrey
    Author: Bowden, Richard | University of Surrey
 
    keyword: Deep Learning in Robotics and Automation; Autonomous Agents; Collision Avoidance

    Abstract : Deep learning has become an increasingly com- mon technique for various control problems, such as robotic arm manipulation, robot navigation, and autonomous vehicles. However, the downside of using deep neural networks to learn control policies is their opaque nature and the difficulties of validating their safety. As the networks used to obtain state- of-the-art results become increasingly deep and complex, the rules they have learned and how they operate become more challenging to understand. This presents an issue, since in safety-critical applications the safety of the control policy must be ensured to a high confidence level. In this paper, we propose an automated black box testing framework based on adversarial reinforcement learning. The technique uses an adversarial agent, whose goal is to degrade the performance of the target model under test. We test the approach on an autonomous vehicle problem, by training an adversarial reinforcement learning agent, which aims to cause a deep neural network- driven autonomous vehicle to collide. Two neural networks trained for autonomous driving are compared, and the results from the testing are used to compare the robustness of their learned control policies. We show that the proposed framework is able to find weaknesses in both control policies that were not evident during online testing and therefore, demonstrate a significant benefit over manual testing methods.

- TRASS: Time Reversal As Self-Supervision

    Author: Nair, Suraj | Stanford University
    Author: Babaeizadeh, Mohammad | UIUC
    Author: Finn, Chelsea | Stanford University
    Author: Levine, Sergey | UC Berkeley
    Author: Kumar, Vikash | Google-Brain
 
    keyword: Deep Learning in Robotics and Automation

    Abstract : A longstanding challenge in robot learning for manipulation tasks has been the ability to generalize to varying initial conditions, diverse objects, and changing objectives. Learning based approaches have shown promise in producing robust policies, but require heavy supervision and large number of environment interactions, especially from visual inputs. We propose a novel self-supervision technique that uses time-reversal to provide high level supervision to reach goals. In particular, we introduce the time-reversal model (TRM), a self-supervised model which explores outward from a set of goal states and learns to predict these trajectories in reverse. This provides a high level plan towards goals, allowing us to learn complex manipulation tasks with no demonstrations or exploration at test time. We test our method on the domain of assembly, specifically the mating of tetris-style block pairs. Using our method operating atop visual model predictive control, we are able to assemble tetris blocks on a KuKa IIWA-7 using only uncalibrated RGB camera input, and generalize to unseen block pairs. Project's-page: https://sites.google.com/view/time-reversal

- Federated Imitation Learning: A Novel Framework for Cloud Robotic Systems with Heterogeneous Sensor Data

    Author: Liu, Boyi | Chinese Academy of Sciences
    Author: Wang, Lujia | Shenzhen Institutes of Advanced Technology
    Author: Liu, Ming | Hong Kong University of Science and Technology
    Author: Xu, Cheng-Zhong | University of Macau
 
    keyword: Big Data in Robotics and Automation; Deep Learning in Robotics and Automation; Motion and Path Planning

    Abstract : Humans are capable of learning a new behavior by observing others to perform the skill. Similarly, robots can also implement this by imitation learning. Furthermore, if with external guidance, humans can master the new behavior more efficiently. So, how can robots achieve this? To address the issue, we present a novel framework named FIL. It provides a heterogeneous knowledge fusion mechanism for cloud robotic systems. Then, a knowledge fusion algorithm in FIL is proposed. It enables the cloud to fuse heterogeneous knowledge from local robots and generate guide models for robots with service requests. After that, we introduce a knowledge transfer scheme to facilitate local robots acquiring knowledge from the cloud. With FIL, a robot is capable of utilizing knowledge from other robots to increase its imitation learning in accuracy and efficiency. Compared with transfer learning and meta-learning, FIL is more suitable to be deployed in cloud robotic systems. Finally, we conduct experiments of a self-driving task for robots (cars). The experimental results demonstrate that the shared model generated by FIL increases imitation learning efficiency of local robots in cloud robotic systems.


- Uncertainty Quantification with Statistical Guarantees in End-To-End Autonomous Driving Control

    Author: Michelmore, Rhiannon | University of Oxford
    Author: Wicker, Matthew | Oxford University
    Author: Laurenti, Luca | Oxford University
    Author: Cardelli, Luca | Oxford University
    Author: Gal, Yarin | University of Cambridge
    Author: Kwiatkowska, kwiatkowska_floc18_4YQkwtC9 | University of Oxford
 
    keyword: Probability and Statistical Methods; Autonomous Vehicle Navigation; Deep Learning in Robotics and Automation

    Abstract : Deep neural network controllers for autonomous driving have recently benefited from significant performance improvements, and have begun deployment in the real world. Prior to their widespread adoption, safety guarantees are needed on the controller behaviour that properly take account of the uncertainty within the model as well as sensor noise. Bayesian neural networks, which assume a prior over the weights, have been shown capable of producing such uncertainty measures, but properties surrounding their safety have not yet been quantified for use in autonomous driving scenarios. In this paper, we develop a framework based on a state-of-the-art simulator for evaluating end-to-end Bayesian controllers. In addition to computing pointwise uncertainty measures that can be computed in real time and with statistical guarantees, we also provide a method for estimating the probability that, given a scenario, the controller keeps the car safe within a finite horizon. We experimentally evaluate the quality of uncertainty computation by several Bayesian inference methods in different scenarios and show how the uncertainty measures can be combined and calibrated for use in collision avoidance. Our results suggest that uncertainty estimates can greatly aid decision making in autonomous driving.

- Autonomously Navigating a Surgical Tool Inside the Eye by Learning from Demonstration

    Author: Kim, Ji Woong | Johns Hopkins University
    Author: He, Changyan | Beihang University
    Author: Urias, Muller | Wilmer Eye Institute
    Author: Gehlbach, Peter | Johns Hopkins Medical Institute
    Author: Hager, Gregory | Johns Hopkins University
    Author: Iordachita, Ioan Iulian | Johns Hopkins University
    Author: Kobilarov, Marin | Johns Hopkins University
 
    keyword: Deep Learning in Robotics and Automation; Surgical Robotics: Planning; Visual Servoing

    Abstract : A fundamental challenge in retinal surgery is safely navigating a surgical tool to a desired goal position on the retinal surface while avoiding damage to surrounding tissues, a procedure that typically requires tens-of-microns accuracy. In practice, the surgeon relies on depth-estimation skills to localize the tool-tip with respect to the retina in order to perform the tool-navigation task, which can be prone to human error. To alleviate such uncertainty, prior work has introduced ways to assist the surgeon by estimating the tool-tip distance to the retina and providing haptic or auditory feedback. However, automating the tool-navigation task itself remains unsolved and largely unexplored. Such a capability, if reliably automated, could serve as a building block to streamline complex procedures and reduce the chance for tissue damage. Towards this end, we propose to automate the tool-navigation task by mimicking the perception-action feedback loop of a demonstrated expert trajectory. Specifically, a deep network is trained to imitate expert trajectories toward various locations on the retina based on recorded visual servoing to a given goal specified by the user. The proposed autonomous navigation system is evaluated in simulation and in physical experiments using a silicone eye phantom. We show that the network can reliably navigate a needle surgical tool to various desired locations within 137 �m accuracy in physical experiments and 94 �m in simulation on average.

- Learn-To-Recover: Retrofitting UAVs with Reinforcement Learning-Assisted Flight Control under Cyber-Physical Attacks

    Author: Fei, Fan | Purdue University
    Author: Tu, Zhan | Purdue University
    Author: Xu, Dongyan | Purdue University
    Author: Deng, Xinyan | Purdue University
 
    keyword: Deep Learning in Robotics and Automation; Failure Detection and Recovery; AI-Based Methods

    Abstract : In this paper, we present a generic fault-tolerant control (FTC) strategy via reinforcement learning (RL). We demonstrate the effectiveness of this method on quadcopter unmanned aerial vehicles (UAVs). The fault-tolerant control policy is trained to handle actuator and sensor fault/attack. Unlike traditional FTC, this policy does not require fault detection and diagnosis (FDD) nor tailoring the controller for specific attack scenarios. Instead, the policy is running simultaneously alongside the stabilizing controller without the need for on-detection activation. The effectiveness of the policy is compared with traditional active and passive FTC strategies against actuator and sensor faults. We compare their performance in position control tasks via simulation and experiments on quadcopters. The result shows that the strategy can effectively tolerate different types of attacks/faults and maintain the vehicle's position, outperforming the other two methods.

- Model-Based Reinforcement Learning for Physical Systems without Velocity and Acceleration Measurements

    Author: Romeres, Diego | Mitsubishi Electric Research Laboratories
    Author: Dalla Libera, Alberto | University of Padova
    Author: Jha, Devesh | Mitsubishi Electric Research Laboratories
    Author: Yerazunis, William | Mitsubishi Electric Research Laboratory
    Author: Nikovski, Daniel | MERL
 
    keyword: Model Learning for Control; Dynamics

    Abstract : In this paper, we propose a derivative-free model learning framework for Reinforcement Learning (RL) algorithms based on Gaussian Process Regression (GPR). In many mechanical systems, only positions can be measured by the sensing instruments. Then, instead of representing the system state as suggested by the physics with a collection of positions, velocities, and accelerations, we define the state as the set of past position measurements. However, the equation of motions derived by physical first principles cannot be directly applied in this framework, being functions of velocities and accelerations. For this reason, we introduce a novel derivative-free physically-inspired kernel, which can be easily combined with nonparametric derivative-free Gaussian Process models. Tests performed on two real platforms show that the considered state definition combined with the proposed model improves estimation performance and data-efficiency w.r.t. traditional models based on GPR. Finally, we validate the proposed framework by solving two RL control problems for two real robotic systems.

- Towards the Probabilistic Fusion of Learned Priors into Standard Pipelines for 3D Reconstruction

    Author: Laidlow, Tristan | Imperial College London
    Author: Czarnowski, Jan | Imperial College London
    Author: Nicastro, Andrea | Imperial College London
    Author: Clark, Ronald | Imperial College London
    Author: Leutenegger, Stefan | Imperial College London
 
    keyword: Deep Learning in Robotics and Automation; Mapping

    Abstract : The best way to combine the results of deep learning with standard 3D reconstruction pipelines remains an open problem. While systems that pass the output of traditional multi-view stereo approaches to a network for regularisation currently seem to get the best results, it may be preferable to treat deep neural networks as separate components whose results can be probabilistically fused into geometry-based systems. Unfortunately, the error models required to do this are not well understood. Recently, a few systems have achieved good results by having their networks predict probability distributions rather than single values. We propose using this approach to fuse a learned single-view depth prior into a standard 3D reconstruction system.<p>Our system is capable of incrementally producing dense depth maps for a set of keyframes. We train a deep neural network to predict discrete, nonparametric probability distributions for the depth of each pixel from a single image. We then fuse this ``probability volume'' with another probability volume based on photometric consistency. We argue that combining these two sources will result in a volume that is better conditioned. To extract depth maps from the volume, we minimise a cost function that includes a regularisation term based on network predicted surface normals and boundaries. Through a series of experiments, we demonstrate that each of these components improves the overall performance of the system.

- Learning Natural Locomotion Behaviors for Humanoid Robots Using Human Bias

    Author: Yang, Chuanyu | University of Edinburgh
    Author: Yuan, Kai | University of Edinburgh
    Author: Heng, Shuai | Harbin Institute of Technology
    Author: Komura, Taku | University of Edinburgh
    Author: Li, Zhibin | University of Edinburgh
 
    keyword: Deep Learning in Robotics and Automation; Humanoid and Bipedal Locomotion; Learning from Demonstration

    Abstract : This paper presents a new learning framework that leverages the knowledge from imitation learning, deep reinforcement learning, and control theories to achieve human-style locomotion that is natural, dynamic, and robust for humanoids. We proposed novel approaches to introduce human bias, ie motion capture data and a special Multi-Expert network structure. We used the Multi-Expert network structure to smoothly blend behavioral features, and used the augmented reward design for the task and imitation rewards. Our reward design is more composable, tunable, and explainable by using fundamental concepts from conventional humanoid control. We rigorously validated and benchmarked the learning framework which consistently produced robust locomotion behaviors in various test scenarios. Further, we demonstrated the capability of learning robust and versatile policies in the presence of disturbances, such as terrain irregularities and external pushes.

- Aggressive Online Control of a Quadrotor Via Deep Network Representations of Optimality Principles

    Author: Li, Shuo | TU Delft
    Author: Ozturk, Ekin | European Space Agency
    Author: De Wagter, Christophe | Delft University of Technology
    Author: de Croon, Guido | TU Delft / ESA
    Author: Izzo, Dario | European Space Agency
 
    keyword: Deep Learning in Robotics and Automation; Optimization and Optimal Control; Aerial Systems: Mechanics and Control

    Abstract : Optimal control holds great potential to improve a variety of robotic applications. The application of optimal control on-board limited platforms has been severely hindered by the large computational requirements of current state of the art implementations. In this work, we make use of a deep neural network to directly map the robot states to control actions. The network is trained offline to imitate the optimal control computed by a time consuming direct nonlinear method. A mixture of time optimality and power optimality is considered with a continuation parameter used to select the predominance of each objective. We apply our networks (termed G&amp;CNets) to aggressive quadrotor control, first in simulation and then in the real world. We give insight into the factors that influence the �reality gap� between the quadrotor model used by the offline optimal control method and the real quadrotor. Furthermore, we explain how we set up the model and the control structure on-board of the real quadrotor to successfully close this gap and perform time-optimal maneuvers in the real world. Finally, G&amp;CNet's performance is compared to state-of- the-art differential-flatness-based optimal control methods. We show, in the experiments, that G&amp;CNets lead to significantly faster trajectory execution due to, in part, the less restrictive nature of the allowed state-to-input mappings.

- Visual Object Search by Learning Spatial Context

    Author: Druon, Raphael | Paul Sabatier University
    Author: Yoshiyasu, Yusuke | CNRS-AIST JRL
    Author: Kanezaki, Asako | National Institute of Advanced Industrial Science and Technology
    Author: Watt, Alassane Mamadou | CentraleSupelec
 
    keyword: Deep Learning in Robotics and Automation; Visual-Based Navigation; Autonomous Agents

    Abstract : We present a visual navigation approach that uses context information to navigate an agent to find and reach a target object. To learn context from the objects present in the scene, we transform visual information into an intermediate representation called context grid which essentially represents how much the object at the location is semantically similar to the target object. As this representation can encode the target object and other objects together, it allows us to navigate an agent in a human-inspired way: the agent will go to the likely place by seeing surrounding context objects in the beginning when the target is not visible and, once the target object comes into sight, it will reach the target quickly. Since context grid does not directly contain visual or semantic feature values that change according to introductions of new objects, such as new instances of the same object with different appearance or an object from a slightly different class, our navigation model generalizes well to unseen scenes/objects. Experimental results show that our approach outperforms previous approaches in navigating in unseen scenes, especially for broad scenes. We also evaluated human performances in the target-driven navigation task and compared with machine learning based navigation approaches including this work.

- Salient View Selection for Visual Recognition of Industrial Components

    Author: Kim, Seong-heum | Korea Electronics Technology Institute (KETI)
    Author: Choe, Gyeongmin | KAIST
    Author: Park, Min-Gyu | KETI
    Author: Kweon, In So | KAIST
 
    keyword: Deep Learning in Robotics and Automation; Big Data in Robotics and Automation; Computer Vision for Manufacturing

    Abstract : We introduce a new method to find a salient viewpoint with a deep representation, according to ease of semantic segmentation. The main idea in our segmentation network is to utilize the multipath network with informative two views. In order to collect training samples, we assume all the information of designed components and even error tolerances are available. Before installing the actual camera layout, we simulate different model descriptions in a physically correct way and determine the best viewing parameters to retrieve a correct instance model from an established database. By selecting the salient viewpoint, we better understand fine-grained shape variations with specular materials. From the fixed top-view, our system initially predicts a 3-DoF pose of a testing object in a data-driven way, and precisely align the model with a refined semantic mask. Under various conditions of our system setup, the presented method is experimentally validated. A robotic assembly task with our vision solution is also successfully demonstrated.

- Low to High Dimensional Modality Reconstruction Using Aggregated Fields of View

    Author: Gunasekar, Kausic | Arizona State University
    Author: Qiu, Qiang | Duke Univeristy
    Author: Yang, Yezhou | Arizona State University
 
    keyword: Deep Learning in Robotics and Automation; Computer Vision for Other Robotic Applications; Robot Safety

    Abstract : Real world robotics systems today deal with data from a multitude of modalities, especially for tasks such as navigation and recognition. The performance of those systems can drastically degrade when one or more modalities become inaccessible, due to factors such as sensors' malfunctions or adverse environments. Here, we argue modality hallucination as one effective way to ensure consistent modality availability and thereby reduce unfavorable consequences. While hallucinating data from a modality with richer information, e.g., RGB to depth, has been researched extensively, we investigate the more challenging low-to-high modality hallucination with interesting use cases in robotics and autonomous systems. We present a novel hallucination architecture that aggregates information from multiple fields of view of the local neighborhood to recover the lost information from the extant modality. The process is implemented by capturing a non-linear mapping between the data modalities and the learned mapping is used to aid the extant modality to mitigate the risk posed to the system in the adverse scenarios which involve modality loss. We also conduct extensive classification and segmentation experiments on UW-RGBD and NYUD datasets and demonstrate that hallucination indeed allays the negative effects of the modality loss.

- Learning Fast Adaptation with Meta Strategy Optimization

    Author: Yu, Wenhao | Georgia Institute of Technology
    Author: Tan, Jie | Google
    Author: Bai, Yunfei | Google X
    Author: Coumans, Erwin | Google Inc
    Author: Ha, Sehoon | Google Brain
 
    keyword: Deep Learning in Robotics and Automation; Learning and Adaptive Systems; Legged Robots

    Abstract : The ability to walk in new scenarios is a key milestone on the path toward real-world applications of legged robots. In this work, we introduce Meta Strategy Optimization, a meta-learning algorithm for training policies with latent variable inputs that can quickly adapt to new scenarios with a handful of trials in the target environment. The key idea behind MSO is to expose the same adaptation process, Strategy Optimization (SO), to both the training and testing phases. This allows MSO to effectively learn locomotion skills as well as a latent space that is suitable for fast adaptation. We evaluate our method on a real quadruped robot and demonstrate successful adaptation in various scenarios, including sim-to-real transfer, walking with a weakened motor, or climbing up a slope. Furthermore, we quantitatively analyze the generalization capability of the trained policy in simulated environments. Both real and simulated experiments show that our method outperforms previous methods in adaptation to novel tasks.

- Deep Neural Network Approach in Robot Tool Dynamics Identification for Bilateral Teleoperation

    Author: Su, Hang | Politecnico Di Milano
    Author: Qi, Wen | Politecnico Di Milano
    Author: Yang, Chenguang | University of the West of England
    Author: Sandoval, Juan Sebasti�n | Université D'Orl�ans
    Author: Ferrigno, Giancarlo | Politecnico Di Milano
    Author: De Momi, Elena | Politecnico Di Milano
 
    keyword: Deep Learning in Robotics and Automation; Force and Tactile Sensing; Telerobotics and Teleoperation

    Abstract : For bilateral teleoperation, the haptic feedback demands the availability of accurate force information transmitted from the remote site. Nevertheless, due to the limitation of the size, the force sensor is usually attached outside of the patient's abdominal cavity for the surgical operation. Hence, it measures not only the interaction forces on the surgical tip but also the surgical tool dynamics. In this paper, a model-free based deep convolutional neural network (DCNN) structure is proposed for the tool dynamics identification, which features fast computation and noise robustness. After the tool dynamics identification using DCNN, the calibration is performed, and the bilateral teleoperation is demonstrated to verify the proposed method. The comparison results prove that the proposed DCNN model promises prominent performance than other methods. Low computational time (0.0031 seconds) is ensured by the rectified linear unit (ReLU) function, and the DCNN approach provides superior accuracy for predicting the noised dynamics force and enable its feasibility for bilateral teleoperation.
- Learning Matchable Image Transformations for Long-Term Metric Visual Localization

    Author: Clement, Lee | University of Toronto
    Author: Gridseth, Mona | University of Toronto
    Author: Tomasi, Justin | University of Toronto
    Author: Kelly, Jonathan | University of Toronto
 
    keyword: Deep Learning in Robotics and Automation; Visual Learning; Visual-Based Navigation

    Abstract : Long-term metric self-localization is an essential capability of autonomous mobile robots, but remains challenging for vision-based systems due to appearance changes caused by lighting, weather, or seasonal variations. While experience-based mapping has proven to be an effective technique for bridging the 'appearance gap,' the number of experiences required for reliable metric localization over days or months can be very large, and methods for reducing the necessary number of experiences are needed for this approach to scale. Taking inspiration from color constancy theory, we learn a nonlinear RGB-to-grayscale mapping that explicitly maximizes the number of inlier feature matches for images captured under different lighting and weather conditions, and use it as a pre-processing step in a conventional single-experience localization pipeline to improve its robustness to appearance change. We train this mapping by approximating the target non-differentiable localization pipeline with a deep neural network, and find that incorporating a learned low-dimensional context feature can further improve cross-appearance feature matching. Using synthetic and real-world datasets, we demonstrate substantial improvements in localization performance across day-night cycles, enabling continuous metric localization over a 30-hour period using a single mapping experience, and allowing experience-based localization to scale to long deployments with dramatically reduced data requirements.

- OriNet: Robust 3-D Orientation Estimation with a Single Particular IMU

    Author: Abolfazli Esfahani, Mahdi | Nanyang Technologicl University
    Author: Wang, Han | Nanyang Technological University
    Author: Wu, Keyu | Nanyang Technological University
    Author: Yuan, Shenghai | Nanyang Technological University
 
    keyword: Deep Learning in Robotics and Automation; Intelligent Transportation Systems; AI-Based Methods

    Abstract : Estimating the robot's heading is a crucial requirement in odometry systems which are attempting to estimate the movement trajectory of a robot. Small errors in the orientation estimation result in a significant difference between the estimated and real trajectory, and failure of the odometry system. The odometry problem becomes much more complicated for micro flying robots since they cannot carry massive sensors. In this manner, they should benefit from the small size and low-cost sensors, such as IMU, to solve the odometry problem, and industries always look for such solutions. However, IMU suffers from bias and measurement noise, which makes the problem of position and orientation estimation challenging to be solved by a single IMU. While there are numerous studies on the fusion of IMU with other sensors, this study illustrates the power of the first deep learning framework for estimating the full 3D orientation of the flying robots (as yaw, pitch, and roll in quaternion coordinates) accurately with the presence of a single IMU. A particular IMU should be utilized during the training and testing of the proposed system. Besides, a method based on the Genetic Algorithm is introduced to measure the IMU bias in each execution. The results show that the proposed method improved the flying robots' ability to estimate their orientation displacement by approximately 80% with the presence of a single particular IMU.

- Learning Densities in Feature Space for Reliable Segmentation of Indoor Scenes

    Author: Marchal, Nicolas Paul | ETH Zurich
    Author: Moraldo, Charlotte | ETH Zurich
    Author: Blum, Hermann | ETH Zurich
    Author: Siegwart, Roland | ETH Zurich
    Author: Cadena Lerma, Cesar | ETH Zurich
    Author: Gawel, Abel Roman | ETH Zurich
 
    keyword: Deep Learning in Robotics and Automation; Semantic Scene Understanding; Visual Learning

    Abstract : Deep learning has enabled remarkable advances in scene understanding, particularly in semantic segmentation tasks. Yet, current state of the art approaches are limited to a closed set of classes, and fail when facing novel elements, also known as out of distribution (OoD) data. This is a problem as autonomous agents will inevitably come across a wide range of objects, all of which cannot be included during training. We propose a novel method to distinguish any object (foreground) from empty building structure (background) in indoor environments. We use normalizing flow to estimate the probability distribution of high-dimensional background descriptors. Foreground objects are therefore detected as areas in an image for which the descriptors are unlikely given the background distribution. As our method does not explicitly learn the representation of individual objects, its performance generalizes well outside of the training examples. Our model results in an innovative solution to reliably segment foreground from background in indoor scenes, which opens the way to a safer deployment of robots in human environments.

- A Multimodal Target-Source Classifier with Attention Branches to Understand Ambiguous Instructions for Fetching Daily Objects

    Author: Magassouba, Aly | NICT
    Author: Sugiura, Komei | National Institute of Information and Communications Tech
    Author: Kawai, Hisashi | National Institute of Information and Communications Technology
 
    keyword: Deep Learning in Robotics and Automation; Domestic Robots

    Abstract : In this study,	we focus on multimodal language understanding for fetching instructions in domestic service robots context. This task consists of predicting a target object as instructed by the user given an image and an unstructured sentence, such as ``Bring me the yellow box (from the wooden cabinet) .'' This is challenging because of the ambiguity of natural language, i.e., the relevant information may be missing or there might be several candidates. To solve such a task, we propose the multimodal target-source classifier model with attention branch (MTCM-AB), which is an extension of the MTCM. Our methodology uses the attention branch network (ABN) to develop a multimodal attention mechanism based on linguistic and visual inputs. Experimental validation using a standard dataset showed that the MTCM-AB outperformed both state-of-the-art methods and MTCM. In particular the MTCM-AB accuracy on average was 90.1% while human performance was 90.3% on PFN-PIC dataset.

- On-Board Deep-Learning-Based Unmanned Aerial Vehicle Fault Cause Detection and Identification

    Author: Sadhu, Vidyasagar | Rutgers University
    Author: Zonouz, Saman | Rutgers University
    Author: Pompili, Dario | Rutgers University
 
    keyword: Deep Learning in Robotics and Automation

    Abstract : With the increase in use of Unmanned Aerial Vehicles (UAVs)/drones, it is important to detect and identify causes of failure in real time for proper recovery from a potential crash-like scenario or post incident forensics analysis. The cause of crash could be either a fault in the sensor/actuator system, a physical damage/attack, or a cyber attack on the drone's software. In this paper, we propose novel architectures based on deep Convolutional and Long Short-Term Memory Neural Networks (CNNs and LSTMs) to detect (via Autoencoder) and classify drone mis-operations based on real-time sensor data. The proposed architectures are able to learn high-level features automatically from the raw sensor data and learn the spatial and temporal dynamics in the sensor data. We validate the proposed deep-learning architectures via simulations and real-world experiments on a drone. Empirical results show that our solution is able to detect (with over 90% accuracy) and classify various types of drone mis-operations (with about 99% accuracy (simulation data) and upto 85% accuracy (experimental data)).

- Learning One-Shot Imitation from Humans without Humans

    Author: Bonardi, Alessandro | Imperial College London
    Author: James, Stephen | Imperial College London
    Author: Davison, Andrew J | Imperial College London
 
    keyword: Deep Learning in Robotics and Automation; Perception for Grasping and Manipulation; Learning from Demonstration

    Abstract : Humans can naturally learn to execute a new task by seeing it performed by other individuals once, and then reproduce it in a variety of configurations. Endowing robots with this ability of imitating humans from third person is a very immediate and natural way of teaching new tasks. Only recently, through meta-learning, there have been successful attempts to one-shot imitation learning from humans; however, these approaches require a lot of human resources to collect the data in the real world to train the robot. But is there a way to remove the need for real world human demonstrations during training? We show that with Task-Embedded Control Networks, we can infer control polices by embedding human demonstrations that can condition a control policy and achieve one-shot imitation learning. Importantly, we do not use a real human arm to supply demonstrations during training, but instead leverage domain randomisation in an application that has not been seen before: sim-to-real transfer on humans. Upon evaluating our approach on pushing and placing tasks in both simulation and in the real world, we show that in comparison to a system that was trained on real-world data we are able to achieve similar results by utilising only simulation data.


- Adversarial Skill Networks: Unsupervised Robot Skill Learning from Video

    Author: Mees, Oier | Albert-Ludwigs-Universitét
    Author: Merklinger, Markus | Uni Freiburg
    Author: Kalweit, Gabriel | University of Freiburg
    Author: Burgard, Wolfram | Toyota Research Institute
 
    keyword: Deep Learning in Robotics and Automation; Visual Learning; Computer Vision for Automation

    Abstract : Key challenges for the deployment of reinforcement learning (RL) agents in the real world are the discovery, representation and reuse of skills in the absence of a reward function. To this end, we propose a novel approach to learn a task-agnostic skill embedding space from unlabeled multi-view videos. Our method learns a general skill embedding independently from the task context by using an adversarial loss. We combine a metric learning loss, which utilizes temporal video coherence to learn a state representation, with an entropy regularized adversarial skill-transfer loss. The metric learning loss learns a disentangled representation by attracting simultaneous viewpoints of the same observations and repelling visually similar frames from temporal neighbors. The adversarial skill-transfer loss enhances re-usability of learned skill embeddings over multiple task domains. We show that the learned embedding enables training of continuous control policies to solve novel tasks that require the interpolation of previously seen skills. Our extensive evaluation with both simulation and real world data demonstrates the effectiveness of our method in learning transferable skills from unlabeled interaction videos and composing them for new tasks. Code, pretrained models and dataset are available at http://robotskills.cs. uni-freiburg.de

- Event-Based Angular Velocity Regression with Spiking Networks

    Author: Gehrig, Mathias | University of Zurich
    Author: Shrestha, Sumit Bam | Temasek Laboratories @ National University of Singapore
    Author: Mouritzen, Daniel S. | University of Zurich and ETH Zurich
    Author: Scaramuzza, Davide | University of Zurich
 
    keyword: Deep Learning in Robotics and Automation; Visual Learning; Probability and Statistical Methods

    Abstract : Spiking Neural Networks (SNNs) are bio-inspired networks that process information conveyed as temporal spikes rather than numeric values. Due to their spike-based computational model, SNNs can process output from event-based, asynchronous sensors without any pre-processing at extremely lower power unlike standard artificial neural networks. Yet, SNNs have not enjoyed the same rise of popularity as artificial neural networks. This not only stems from the fact that their input format is rather unconventional but also due to the challenges in training spiking networks. Despite their temporal nature and recent algorithmic advances, they have been mostly evaluated on classification problems. We propose, for the first time, a temporal regression problem of numerical values given events from an event-camera. We specifically investigate the prediction of the 3-DOF angular velocity of a rotating event-camera with an SNN. The difficulty of this problem arises from the prediction of angular velocities continuously in time directly from irregular, asynchronous event-based input. To assess the performance of SNNs on this task, we introduce a large-scale synthetic dataset generated from real-world panoramic images and show that we can successfully train an SNN to perform angular velocity regression.

- Visual Odometry Revisited: What Should Be Learnt?

    Author: Zhan, Huangying | The University of Adelaide
    Author: Weerasekera, Chamara Saroj | The University of Adelaide
    Author: Bian, Jiawang | University of Adelaide
    Author: Reid, Ian | University of Adelaide
 
    keyword: Deep Learning in Robotics and Automation; Visual-Based Navigation; Localization

    Abstract : In this work we present a monocular visual odometry (VO) algorithm which leverages geometry-based methods and deep learning. Most existing VO/SLAM systems with superior performance are based on geometry and have to be carefully designed for different application scenarios. Moreover, most monocular systems suffer from scale-drift issue. Some recent deep learning works learn VO in an end-to-end manner but the performance of these deep systems is still not comparable to geometry-based methods. In this work, we revisit the basics of VO and explore the right way for integrating deep learning with epipolar geometry and Perspective-n-Point (PnP) method. Specifically, we train two convolutional neural networks (CNNs) for estimating single-view depths and two-view optical flows as intermediate outputs. With the deep predictions, we design a simple but robust frame-to-frame VO algorithm (DF-VO) which outperforms pure deep learning-based and geometry-based methods. More importantly, our system does not suffer from the scale-drift issue being aided by a scale consistent single-view depth CNN. Extensive experiments on KITTI dataset shows the robustness of our system and a detailed ablation study shows the effect of different factors in our system. Code is available at here: DF-VO.

- 3D Scene Geometry-Aware Constraint for Camera Localization with Deep Learning

    Author: Tian, Mi | Meituan-Dianping Group
    Author: Nie, Qiong | Meituan-Dianping Group
    Author: Shen, Hao | Meituan-Dianping Group
 
    keyword: Deep Learning in Robotics and Automation; Localization

    Abstract : Camera localization is a fundamental and key component of autonomous driving vehicles and mobile robots to localize themselves globally for further environment perception, path planning and motion control. Recently end-to-end approaches based on convolutional neural network have been much studied to achieve or even exceed 3D-geometry based traditional methods. In this work, we propose a compact network for absolute camera pose regression. Inspired from those traditional methods, a 3D scene geometry-aware constraint is also introduced by exploiting all available information including motion, depth and image contents. We add this constraint as a regularization term to our proposed network by defining a pixel-level photometric loss and an image-level structural similarity loss. To benchmark our method, different challenging scenes including indoor and outdoor environment are tested with our proposed approach and state-of-the-arts. And the experimental results demonstrate significant performance improvement of our method on both prediction accuracy and convergence efficiency.

- ACDER: Augmented Curiosity-Driven Experience Replay

    Author: Li, Boyao | Institute of Automation, Chinese Academy of Sciences
    Author: Lu, Tao | The Hi-Tech Innovation Engineering Center
    Author: Li, Jiayi | Institute of Automation, Chinese Academy of Sciences
    Author: Lu, Ning | Institute of Automation, Chinese Academy of Sciences
    Author: Cai, Yinghao | Institute of Automation, Chinese Academy of Sciences
    Author: Wang, Shuo | Chinese Academy of Sciences
 
    keyword: Deep Learning in Robotics and Automation; AI-Based Methods

    Abstract : Exploration in environments with sparse feedback remains a challenging research problem in reinforcement learning (RL). When the RL agent explores the environment randomly, it results in low exploration efficiency, especially in robotic manipulation tasks with high dimensional continuous state and action space. In this paper, we propose a novel method, called Augmented Curiosity-Driven Experience Replay (ACDER), which leverages (i) a new goal-oriented curiosity-driven exploration to encourage the agent to pursue novel and task-relevant states more purposefully and (ii) the dynamic initial states selection as an automatic exploratory curriculum to further improve the sample-efficiency. Our approach complements Hindsight Experience Replay (HER) by introducing a new way to pursue valuable states. Experiments conducted on four challenging robotic manipulation tasks with binary rewards, including Reach, Push, Pick&amp;Place and Multi-step Push. The empirical results show that our proposed method significantly outperforms existing methods in the first three basic tasks and also achieves satisfactory performance in multi-step robotic task learning.

- TrueRMA: Learning Fast and Smooth Robot Trajectories with Recursive Midpoint Adaptations in Cartesian Space

    Author: Kiemel, Jonas | Karlsruhe Institute of Technology
    Author: Mei�ner, Pascal | Karlsruhe Institute of Technology
    Author: Kroeger, Torsten | Karlsruher Institut F�r Technologie (KIT)
 
    keyword: Deep Learning in Robotics and Automation; Big Data in Robotics and Automation

    Abstract : We present TrueRMA, a data-efficient, model-free method to learn cost-optimized robot trajectories over a wide range of starting points and endpoints. The key idea is to calculate trajectory waypoints in Cartesian space by recursively predicting orthogonal adaptations relative to the midpoints of straight lines. We generate a differentiable path by adding circular blends around the waypoints, calculate the corresponding joint positions with an inverse kinematics solver and calculate a time-optimal parameterization considering velocity and acceleration limits. During training, the trajectory is executed in a physics simulator and costs are assigned according to a user-specified cost function which is not required to be differentiable. Given a starting point and an endpoint as input, a neural network is trained to predict midpoint adaptations that minimize the cost of the resulting trajectory via reinforcement learning. We successfully train a KUKA iiwa robot to keep a ball on a plate while moving between specified points and compare the performance of TrueRMA against two baselines. The results show that our method requires less training data to learn the task while generating shorter and faster trajectories.

## Motion and Path Planning

- Hyperproperties for Robotics: Planning Via HyperLTL

    Author: Wang, Yu | Duke University
    Author: Siddhartha, Nalluri | Duke University
    Author: Pajic, Miroslav | Duke University
 
    keyword: Formal Methods in Robotics and Automation; Motion and Path Planning; Robot Safety

    Abstract : There is a growing interest on formal methods-based robotic planning for temporal logic objectives. In this work, we extend the scope of existing synthesis methods to hyper-temporal logics. We are motivated by the fact that important planning objectives, such as optimality, robustness, and privacy, (maybe implicitly) involve the interrelation between multiple paths. Such objectives are thus hyperproperties, and cannot be expressed with usual temporal logics like the linear temporal logic (LTL). We show that such hyperproperties can be expressed by HyperLTL, an extension of LTL to multiple paths. To handle the complexity of planning with HyperLTL specifications, we introduce a symbolic approach for synthesizing planning strategies on discrete transition systems. Our planning method is evaluated on several case studies.

-     Abstractions for Computing All Robotic Sensors That Suffice to Solve a Planning Problem

    Author: Zhang, Yulin | Texas A&amp;M University
    Author: Shell, Dylan | Texas A&amp;M University
 
    keyword: Formal Methods in Robotics and Automation; Reactive and Sensor-Based Planning

    Abstract : Whether a robot can perform some specific task depends on several aspects, including the robot's sensors and the plans it possesses. We are interested in search algorithms that treat plans and sensor designs jointly, yielding solutions---i.e., plan and sensor characterization pairs---if and only if they exist. Such algorithms can help roboticists explore the space of sensors to aid in making design trade-offs. Generalizing prior work where sensors are modeled     Abstractly as sensor maps on p-graphs, the present paper increases the potential sensors which can be sought significantly. But doing so enlarges a problem currently on the outer limits of being considered tractable. Toward taming this complexity, two contributions are made: (1) we show how to represent the search space for this more general problem and describe data structures that enable whole sets of sensors to be summarized via a single special representative; (2) we give a means by which other structure (either task domain knowledge, sensor technology or fabrication constraints) can be incorporated to reduce the sets to be enumerated. These lead to algorithms that we have implemented and which suffice to solve particular problem instances, albeit only of small scale. Nevertheless, the algorithm aids in helping understand what attributes sensors must possess and what information they must provide in order to ensure a robot can achieve its goals despite non-determinism.	

- T* : A Heuristic Search Based Path Planning Algorithm for Temporal Logic Specifications

    Author: Khalidi, Danish | IIT Kanpur
    Author: Gujarathi, Dhaval | SAP Labs, India
    Author: Saha, Indranil | IIT Kanpur
 
    keyword: Formal Methods in Robotics and Automation; Motion and Path Planning; Task Planning

    Abstract : The fundamental path planning problem for a mobile robot involves generating a trajectory for point-to-point navigation while avoiding obstacles. Heuristic-based search algorithms like A* have been shown to be efficient in solving such planning problems. Recently, there has been an increased interest in specifying complex path planning problem using temporal logic. In the state-of-the-art algorithm, the temporal logic path planning problem is reduced to a graph search problem, and Dijkstra's shortest path algorithm is used to compute the optimal trajectory satisfying the specification.<p>The A* algorithm, when used with an appropriate heuristic for the distance from the destination, can generate an optimal path in a graph more efficiently than Dijkstra's shortest path algorithm. The primary challenge for using A* algorithm in temporal logic path planning is that there is no notion of a single destination state for the robot. We present a novel path planning algorithm T* that uses the A* search procedure opportunistically to generate an optimal trajectory satisfying a temporal logic query. Our experimental results demonstrate that T* achieves an order of magnitude improvement over the state-of-the-art algorithm to solve many temporal logic path planning problems in 2-D as well as 3-D workspaces.

- Global/local Motion Planning Based on Dynamic Trajectory Reconfiguration and Dynamical Systems for Autonomous Surgical Robots

    Author: Sayols, Narcis | Universitat Politecnica De Catalunya
    Author: Sozzi, Alessio | University of Ferrara
    Author: Piccinelli, Nicola | University of Verona
    Author: Hernansanz, Albert | UPC (Universitat Politecnicade Catalunya)
    Author: Casals, Alicia | UniversitatPolitècnica De Catalunya, Barcelona Tech
    Author: Bonfe, Marcello | University of Ferrara
    Author: Muradore, Riccardo | University of Verona
 
    keyword: Collision Avoidance; Motion and Path Planning; Surgical Robotics: Laparoscopy

    Abstract : This paper addresses the generation of collision-free trajectories for the autonomous execution of assistive tasks in Robotic Minimally Invasive Surgery (R-MIS). The proposed approach takes into account geometric constraints related to the desired task, like for example the direction to approach the final target and the presence of moving obstacles. The developed motion planner is structured as a two-layer architecture: a global level computes smooth spline-based trajectories that are continuously updated using virtual potential fields; a local level, exploiting Dynamical Systems based obstacle avoidance, ensures collision free connections among the spline control points. The proposed architecture is validated in a realistic surgical scenario.

- Deep Imitative Reinforcement Learning for Temporal Logic Robot Motion Planning with Noisy Semantic Observations

    Author: Gao, Qitong | Duke University
    Author: Pajic, Miroslav | Duke University
    Author: Zavlanos, Michael M. | Duke University
 
    keyword: Formal Methods in Robotics and Automation; Deep Learning in Robotics and Automation

    Abstract : In this paper, we propose a Deep Imitative Q-learning (DIQL) method to synthesize control policies for mobile robots that need to satisfy Linear Temporal Logic (LTL) specifications using noisy semantic observations of their surroundings. The robot sensing error is modeled using probabilistic labels defined over the states of a Labeled Transition System (LTS) and the robot mobility is modeled using a Labeled Markov Decision Process (LMDP) with unknown transition probabilities. We use existing product-based model checkers (PMCs) as experts to guide the Q-learning algorithm to convergence. To the best of our knowledge, this is the first approach that models noise in semantic observations using probabilistic labeling functions and employs existing model checkers to provide suboptimal instructions to the Q-learning agent.

- Minimal 3D Dubins Path with Bounded Curvature and Pitch Angle

    Author: V�&#328;a, Petr | Czech Technical University in Prague
    Author: Alves Neto, Armando | Universidade Federal De Minas Gerais
    Author: Faigl, Jan | Czech Technical University in Prague
    Author: Guimar�es Macharet, Douglas | Universidade Federal De Minas Gerais
 
    keyword: Motion and Path Planning; Nonholonomic Motion Planning; Aerial Systems: Applications

    Abstract : In this paper, we address the problem of finding cost-efficient three-dimensional paths that satisfy the maximum allowed curvature and the pitch angle of the vehicle. For any given initial and final configurations, the problem is decoupled into finding the horizontal and vertical parts of the path separately. Although the individual paths are modeled as two-dimensional Dubins curves using closed-form solutions, the final 3D path is constructed using the proposed local optimization to find a cost-efficient solution. Moreover, based on the decoupled approach, we provide a lower bound estimation of the optimal path that enables us to determine the quality of the found heuristic solution. The proposed solution has been evaluated using existing benchmark instances and compared with state-of-the-art approaches. Based on the reported results and lower bounds, the proposed approach provides paths close to the optimal solution while the computational requirements are in hundreds of microseconds. Besides, the proposed method provides paths with fewer turns than others, which make them easier to be followed by the vehicle's controller.

- Adaptively Informed Trees (AIT*): Fast Asymptotically Optimal Path Planning through Adaptive Heuristics

    Author: Strub, Marlin Polo | University of Oxford
    Author: Gammell, Jonathan | University of Oxford
 
    keyword: Motion and Path Planning; Autonomous Vehicle Navigation; Space Robotics and Automation

    Abstract : Informed sampling-based planning algorithms exploit problem knowledge for better search performance. This knowledge is often expressed as heuristic estimates of solution cost and used to order the search. The practical improvement of this informed search depends on the accuracy of the heuristic.<p>Selecting an appropriate heuristic is difficult. Heuristics applicable to an entire problem domain are often simple to define and inexpensive to evaluate but may not be beneficial for a specific problem instance. Heuristics specific to a problem instance are often difficult to define or expensive to evaluate but can make the search itself trivial.</p><p>This paper presents Adaptively Informed Trees (AIT*), an almost-surely asymptotically optimal sampling-based planner based on BIT*. AIT* adapts its search to each problem instance by using an asymmetric bidirectional search to simultaneously estimate and exploit a problem-specific heuristic. This allows it to quickly find initial solutions and converge towards the optimum. AIT* solves the tested problems as fast as RRT-Connect while also converging towards the optimum.

- Informing Multi-Modal Planning with Synergistic Discrete Leads

    Author: Kingston, Zachary | Rice University
    Author: Wells, Andrew | Rice University
    Author: Moll, Mark | Rice University
    Author: Kavraki, Lydia | Rice University
 
    keyword: Motion and Path Planning; Manipulation Planning

    Abstract : Robotic manipulation problems are inherently continuous, but typically have underlying discrete structure, e.g., whether or not an object is grasped. This means many problems are multi-modal and in particular have a continuous infinity of modes. For example, in a pick-and-place manipulation domain, every grasp and placement of an object is a mode. Usually manipulation problems require the robot to transition into different modes, e.g., going from a mode with an object placed to another mode with the object grasped. To successfully find a manipulation plan, a planner must find a sequence of valid single-mode motions as well as valid transitions between these modes. Many manipulation planners have been proposed to solve tasks with multi-modal structure. However, these methods require mode-specific planners and fail to scale to very cluttered environments or to tasks that require long sequences of transitions. This paper presents a general layered planning approach to multi-modal planning that uses a discrete "lead" to bias search towards useful mode transitions. The difficulty of achieving specific mode transitions is captured online and used to bias search towards more promising sequences of modes. We demonstrate our planner on complex scenes and show that significant performance improvements are tied to both our discrete "lead" and our continuous representation.

- Hierarchical Coverage Path Planning in Complex 3D Environments

    Author: Cao, Chao | Carnegie Mellon University
    Author: Zhang, Ji | Carnegie Mellon University
    Author: Travers, Matthew | Carnegie Mellon University
    Author: Choset, Howie | Carnegie Mellon University
 
    keyword: Motion and Path Planning; Aerial Systems: Applications

    Abstract : State-of-the-art coverage planning methods perform well in simple environments but take an ineffectively long time to converge to an optimal solution in complex three-dimensional (3D) environments. As more structures are present in the same volume of workspace, these methods slow down as they spend more time searching for all of the nooks and crannies concealed in three-dimensional spaces. This work presents a method for coverage planning that employs a multi-resolution hierarchical framework to solve the problem at two different levels, producing much higher efficiency than the state-of-the-art. First, a high-level algorithm separates the environment into multiple subspaces at different resolutions and computes an order of the subspaces for traversal. Second, a low-level sampling-based algorithm solves for paths within the subspaces for detailed coverage. In experiments, we evaluate our method using real-world datasets from complex three-dimensional scenes. Our method finds paths that are constantly shorter and converges at least ten times faster than the state-of-the-art. Further, we show results of a physical experiment where a lightweight UAV follows the paths to realize the coverage.

- Perception-Aware Time Optimal Path Parameterization for Quadrotors

    Author: Spasojevic, Igor | MIT
    Author: Murali, Varun | Massachusetts Institute of Technology
    Author: Karaman, Sertac | Massachusetts Institute of Technology
 
    keyword: Motion and Path Planning; Aerial Systems: Perception and Autonomy; Visual-Based Navigation

    Abstract : The increasing popularity of quadrotors has given rise to a class of predominantly vision-driven vehicles. This paper addresses the problem of perception-aware time optimal path parametrization for quadrotors. Although many different choices of perceptual modalities are available, the low weight and power budgets of quadrotor systems makes a camera ideal for on-board navigation and estimation algorithms. However, this does come with a set of challenges. The limited field of view of the camera can restrict the visibility of salient regions in the environment, which dictates the necessity to consider perception and planning jointly. The main contribution of this paper is an efficient time optimal path parametrization algorithm for quadrotors with limited field of view constraints. We show in a simulation study that a state-of-the-art controller can track planned trajectories, and we validate the proposed algorithm on a quadrotor platform in experiments.

- Generating Visibility-Aware Trajectories for Cooperative and Proactive Motion Planning

    Author: Buckman, Noam | Massachusetts Institute of Technology
    Author: Pierson, Alyssa | Massachusetts Institute of Technology
    Author: Karaman, Sertac | Massachusetts Institute of Technology
    Author: Rus, Daniela | MIT
 
    keyword: Motion and Path Planning; Autonomous Vehicle Navigation; Cooperating Robots

    Abstract : The safety of an autonomous vehicle not only depends on its own perception of the world around it, but also on the perception and recognition from other vehicles. If an ego vehicle considers the uncertainty other vehicles have about itself, then by reducing the estimated uncertainty it can increase its safety. In this paper, we focus on how an ego vehicle plans its trajectories through the blind spots of other vehicles. We create visibility-aware planning, where the ego vehicle chooses its trajectories such that it reduces the perceived uncertainty other vehicles may have about the state of the ego vehicle. We present simulations of traffic and highway environments, where an ego vehicle must pass another vehicle, make a lane change, or traverse a partially-occluded intersection. Emergent behavior shows that when using visibility-aware planning, the ego vehicle spends less time in a blind spot, and may slow down before entering the blind spot so as to increase the likelihood other vehicles perceive the ego vehicle.

- An Obstacle-Interaction Planning Method for Navigation of Actuated Vine Robots

    Author: Selvaggio, Mario | Université Degli Studi Di Napoli Federico II
    Author: Ramirez, Luis Adrian | University of California, Irvine
    Author: Naclerio, Nicholas | University of California, Santa Barbara
    Author: Siciliano, Bruno | Univ. Napoli Federico II
    Author: Hawkes, Elliot Wright | University of California, Santa Barbara
 
    keyword: Motion and Path Planning; Modeling, Control, and Learning for Soft Robots

    Abstract : The field of soft robotics is grounded on the idea that, due to their inherent compliance, soft robots can safely interact with the environment. Thus, the development of effective planning and control pipelines for soft robots should incorporate reliable robot-environment interaction models. This strategy enables soft robots to effectively exploit contacts to autonomously navigate and accomplish tasks in the environment. However, for a class of soft robots, namely vine-inspired, tip-extending or "vine" robots, such interaction models and the resulting planning and control strategies do not exist. In this paper, we analyze the behavior of vine robots interacting with their environment and propose an obstacle-interaction model that characterizes the bending and wrinkling deformation induced by the environment. Starting from this, we devise a novel obstacle-interaction planning method for these robots. We show how obstacle interactions can be effectively leveraged to enlarge the set of reachable workspace for the robot tip, and verify our findings with both simulated and real experiments. Our work improves the capabilities of this new class of soft robot, helping to advance the field of soft robotics.

- A New Path Planning Architecture to Consider Motion Uncertainty in Natural Environment

    Author: Mizuno, Michihiro | The University of Tokyo
    Author: Kubota, Takashi | JAXA ISAS
 
    keyword: Motion and Path Planning; Field Robots; Space Robotics and Automation

    Abstract : This paper proposes a new path planning archi- tecture with consideration of motion uncertainty for wheeled robots in rough terrain. The proposed scheme uses particles to express the uncertainty propagation in the complicated environments constructed with various types of terrain. Also, RRT (Rapidly-exploring Random Tree) is expanded based on the uncertainty of each node in order to prevent increasing the accumulated position uncertainty. As a result, the generated path recudes the times of path-following and re-planning due to inaccurate localization. The effetiveness of the proposed method is evaluated in the simulation using the motion uncertainty models obtained by experiments. The results show that the proposed method decreases the position uncertainty while it keeps the probability to avoid collisions and to reach the goal area compared with conventional approaches.

- Revisiting the Asymptotic Optimality of RRT*

    Author: Solovey, Kiril | Stanford University
    Author: Janson, Lucas | Harvard University
    Author: Schmerling, Edward | Waymo
    Author: Frazzoli, Emilio | ETH Zurich
    Author: Pavone, Marco | Stanford University
 
    keyword: Motion and Path Planning

    Abstract : RRT* is one of the most widely used sampling-based algorithms for asymptotically-optimal motion planning. RRT* laid the foundations for optimality in motion planning as a whole, and inspired the development of numerous new algorithms in the field, many of which build upon RRT* itself. In this paper, we first identify a logical gap in the optimality proof of RRT*, which was developed in Karaman and Frazzoli (2011). Then, we present an alternative and mathematically-rigorous proof for asymptotic optimality. Our proof suggests that the connection radius used by RRT* should be increased from gamma left(frac{log n}{n}right)^{1/d} to gamma' left(frac{log n}{n}right)^{1/(d+1)} in order to account for the additional dimension of time that dictates the samples' ordering. Here gamma, gamma' are constants, and n, d are the number of samples and the dimension of the problem, respectively.

- Sample Complexity of Probabilistic Roadmaps Via Epsilon Nets

    Author: Tsao, Matthew | Stanford University
    Author: Solovey, Kiril | Stanford University
    Author: Pavone, Marco | Stanford University
 
    keyword: Motion and Path Planning

    Abstract : We study fundamental theoretical aspects of probabilistic roadmaps (PRM) in the finite time (non-asymptotic) regime. In particular, we investigate how completeness and optimality guarantees of the approach are influenced by the underlying deterministic sampling distribution X and connection radius r. We develop the notion of (delta,epsilon)-completeness of the parameters X, r, which indicates that for every motion-planning problem of clearance at least delta&gt;0, PRM using X, r returns a solution no longer than 1+epsilon times the shortest delta-clear path. Leveraging the concept of epsilon-nets, we characterize in terms of lower and upper bounds the number of samples needed to guarantee (delta,epsilon)-completeness. This is in contrast with previous work which mostly considered the asymptotic regime in which the number of samples tends to infinity. In practice, we propose a sampling distribution inspired by epsilon-nets that achieves nearly the same coverage as grids while using significantly fewer samples.

- Reinforcement Learning Based Manipulation Skill Transferring for Robot-Assisted Minimally Invasive Surgery

    Author: Su, Hang | Politecnico Di Milano
    Author: Hu, Yingbai | Technische Universitét M�nchen
    Author: Li, Zhijun | University of Science and Technology of China
    Author: Knoll, Alois | Tech. Univ. Muenchen TUM
    Author: Ferrigno, Giancarlo | Politecnico Di Milano
    Author: De Momi, Elena | Politecnico Di Milano
 
    keyword: Motion and Path Planning; Kinematics; Medical Robots and Systems

    Abstract : The complexity of surgical operation can be released significantly if surgical robots can learn the manipulation skills by imitation from complex tasks demonstrations such as puncture, suturing, and knotting, etc.. This paper proposes a reinforcement learning algorithm based manipulation skill transferring technique for robot-assisted Minimally Invasive Surgery by Teaching by Demonstration. It employed Gaussian mixture model and Gaussian mixture Regression based dynamic movement primitive to model the high-dimensional human-like manipulation skill after multiple demonstrations. Furthermore, this approach fascinates the learning and trial phase performed offline, which reduces the risks and cost for the practical surgical operation. Finally, it is demonstrated by transferring manipulation skills for reaching and puncture using a KUKA LWR4+ robot in a lab setup environment. The results show the effectiveness of the proposed approach for modelling and learning of human manipulation skill.

- Safe Mission Planning under Dynamical Uncertainties

    Author: Lu, Yimeng | ETH Zurich
    Author: Kamgarpour, Maryam | University of British Columbia
 
    keyword: Motion and Path Planning; Search and Rescue Robots; Formal Methods in Robotics and Automation

    Abstract : This paper considers safe robot mission planning in uncertain dynamical environments. This problem arises in applications such as surveillance, emergency rescue and autonomous driving. It is a challenging problem due to modeling and integrating dynamical uncertainties into a safe planning framework, and &#64257;nding a solution in a computationally tractable way. In this work, we &#64257;rst develop a probabilistic model for dynamical uncertainties. Then, we provide a framework to generate a path that maximizes safety for complex missions by incorporating the uncertainty model. We also devise a Monte Carlo method to obtain a safe path ef&#64257;ciently. Finally, we evaluate the performance of our approach and compare it to potential alternatives in several case studies.

- An Iterative Quadratic Method for General-Sum Differential Games with Feedback Linearizable Dynamics

    Author: Fridovich-Keil, David | University of California, Berkeley
    Author: Rubies Royo, Vicenc | UC Berkeley
    Author: Tomlin, Claire | UC Berkeley
 
    keyword: Path Planning for Multiple Mobile Robots or Agents; Multi-Robot Systems; Motion and Path Planning

    Abstract : Iterative linear-quadratic (ILQ) methods are widely used in the nonlinear optimal control community. Recent work has applied similar methodology in the setting of multi-player general-sum differential games. Here, ILQ methods are capable of finding local equilibria in interactive motion planning problems in real-time. As in most iterative procedures, however, this approach can be sensitive to initial conditions and hyperparameter choices, which can result in poor computational performance or even unsafe trajectories. In this paper, we focus our attention on a broad class of dynamical systems which are feedback linearizable, and exploit this structure to improve both algorithmic reliability and runtime. We showcase our new algorithm in three distinct traffic scenarios, and observe that in practice our method converges significantly more often and more quickly than was possible without exploiting the feedback linearizable structure.

- Real-Time UAV Path Planning for Autonomous Urban Scene Reconstruction

    Author: Kuang, Qi | Beihang University
    Author: WuJinbo, WuJinbo | BUAA
    Author: Pan, Jia | University of Hong Kong
    Author: Zhou, Bin | Beihang University
 
    keyword: Motion and Path Planning; Computer Vision for Other Robotic Applications; Visual-Based Navigation

    Abstract : Unmanned aerial vehicles (UAVs) are frequently used for large-scale scene mapping and reconstruction. However, in most cases, drones are operated manually, which should be more effective and intelligent. In this article, we present a method of real-time UAV path planning for autonomous urban scene reconstruction. Considering the obstacles and time costs, we utilize the top view to generate the initial path. Then we estimate the building heights and take close-up pictures that reveal building details through a SLAM framework. To predict the coverage of the scene, we propose a novel method which combines information on reconstructed point clouds and possible coverage areas. The experimental results reveal that the reconstruction quality of our method is good enough. Our method is also more time-saving than the state-of-the-arts.

- A Fast Marching Gradient Sampling Strategy for Motion Planning Using an Informed Certificate Set
 
    Author: Shi, Shenglei | Huazhong University of Science and Technology
    Author: Chen, Jiankui | Huazhong University of Science and Technology
    Author: Xiong, Youlun | Huazhong University of Science and Technology
 
    keyword: Motion and Path Planning

    Abstract : We present a novel fast marching gradient sampling strategy to accelerate the convergence speed of sampling-based motion planning algorithms. This strategy is based on an informed certificate set which consists of the robot states with exact collision status as well as the minimum distance and the gradient to the nearest obstacle. The informed certificate set covers almost the whole planning space such that it contains rich information for the planner. The best quality point in this set is selected as the marching seed to guide the search graph move steadily to the goal set. Besides, the distance and gradient information of the marching seed helps to generate a new sample with almost sure collision status. When a feasible solution has been found, this set can construct the restricted subset that can truly improve current path quality. This marching gradient sampling strategy is applied to the RRT (Rapidly exploring random tree) and RRT* algorithms. Simulation experiments demonstrate that the convergence speed to a feasible solution or to the optimal solution is almost twice faster than that of the safety certificate algorithms.

- Privacy-Aware UAV Flights through Self-Configuring Motion Planning

    Author: Luo, Yixing | Peking University
    Author: Yu, Yijun | The Open University
    Author: Jin, Zhi | Peking University
    Author: Li, Yao | Zhejiang Sci-Tech University
    Author: Ding, Zuohua | Zhejiang Sci-Tech University
    Author: Zhou, Yuan | Nanyang Technological University
    Author: Liu, Yang | Nanyang Technological University
 
    keyword: Motion and Path Planning; Robust/Adaptive Control of Robotic Systems; Energy and Environment-Aware Automation

    Abstract : During flights, an unmanned aerial vehicle (UAV) may not be allowed to move across certain areas due to soft constraints such as privacy restrictions. Current methods on self-adaption focus mostly on motion planning such that the trajectory does not trespass predetermined restricted areas. When the environment is cluttered with uncertain obstacles, however, these motion planning algorithms are not flexible enough to find a trajectory that satisfies additional privacy-preserving requirements within a tight time budget during the flights. In this paper, we propose a privacy risk aware motion planning method through the reconfiguration of privacy-sensitive sensors. It minimises environmental impact by re-configuring the sensor during flight, while still guaranteeing the hard safety and energy constraints such as collision avoidance and timeliness. First, we formulate a model for assessing privacy risks of dynamically detected restricted areas. In case the UAV cannot find a feasible solution to satisfy both hard and soft constraints from the current configuration, our decision making method can then produce an optimal reconfiguration of the privacy-sensitive sensor with a more efficient trajectory. We evaluate the proposal through various simulations with different settings in a virtual environment and also validate the approach through real test flights on DJI Matrice 100 UAV.

- Improved C-Space Exploration and Path Planning for Robotic Manipulators Using Distance Information

    Author: Lacevic, Bakir | University of Sarajevo
    Author: Osmankovic, Dinko | Faculty of Electrical Engineering Sarajevo
 
    keyword: Motion and Path Planning

    Abstract : We present a simple method to quickly explore C-spaces of robotic manipulators and thus facilitate path planning. The method is based on a novel geometrical structure called generalized bur. It is a star-like tree, rooted at a given point in free C-space, with an arbitrary number of guaranteed collision-free edges computed using distance information from the workspace and simple forward kinematics. Generalized bur captures large portions of free C-space, enabling accelerated exploration. The workspace is assumed to be decomposable into a finite set of (possibly overlapping) convex obstacles. When plugged in a suitable RRT-like planning algorithm, generalized burs enable significant performance improvements, while at the same time enabling exact collision-free paths.

- Tuning-Free Contact-Implicit Trajectory Optimization

    Author: Onol, Aykut Ozgun | Northeastern University
    Author: Corcodel, Radu Ioan | Mitsubishi Electric Research Laboratories
    Author: Long, Philip | Irish Manufacturing Research
    Author: Padir, Taskin | Northeastern University
 
    keyword: Motion and Path Planning; Planning, Scheduling and Coordination; Optimization and Optimal Control

    Abstract : We present a contact-implicit trajectory optimization framework that can plan contact-interaction trajectories for different robot architectures and tasks using a trivial initial guess and without requiring any parameter tuning. This is achieved by using a relaxed contact model along with an automatic penalty adjustment loop for suppressing the relaxation. Moreover, the structure of the problem enables us to exploit the contact information implied by the use of relaxation in the previous iteration, such that the solution is explicitly improved with little computational overhead. We test the proposed approach in simulation experiments for non-prehensile manipulation using a 7-DOF arm and a mobile robot and for planar locomotion using a humanoid-like robot in zero gravity. The results demonstrate that our method provides an out-of-the-box solution with good performance for a wide range of applications.

- PPCPP: A Predator�Prey-Based Approach to Adaptive Coverage Path Planning (I)

    Author: Hassan, Mahdi | University of Technology, Sydney
    Author: Liu, Dikai | University of Technology, Sydney
 
    keyword: Motion and Path Planning; Learning and Adaptive Systems; Collision Avoidance

    Abstract : Most of the existing coverage path planning (CPP)algorithms do not have the capability of enabling a robot to handle unexpected changes in the coverage area of interest. Examples of unexpected changes include the sudden introduction of stationary or dynamic obstacles in the environment and change in the reachable area for coverage (e.g., due to imperfect base localization by an industrial robot). Thus, a novel adaptive CPP approach is developed that is efficient to respond to changes in real-time while aiming to achieve complete coverage with minimal cost. As part of the approach, a total reward function that incorporates three rewards is designed where the first reward is inspired by the predator�prey relation, the second reward is related to continuing motion in a straight direction, and the third reward is related to covering the boundary.The total reward function acts as a heuristic to guide the robot at each step. For a given map of an environment, model parameters are first tuned offline tominimize the path length while assuming no obstacles. It is shown that applying these learned parameters during real-time adaptive planning in the presence of obstacles will still result in a coverage path with a length close to the optimized path length.Many case studies with various scenarios are presented to validate the approach and to perform numerous comparisons.

- Advanced BIT* (ABIT*): Sampling-Based Planning with Advanced Graph-Search Techniques

    Author: Strub, Marlin Polo | University of Oxford
    Author: Gammell, Jonathan | University of Oxford
 
    keyword: Motion and Path Planning; Space Robotics and Automation; Autonomous Vehicle Navigation

    Abstract : Path planning is an active area of research essential for many applications in robotics. Popular techniques include graph-based searches and sampling-based planners. These approaches are powerful but have limitations.<p>This paper continues work to combine their strengths and mitigate their limitations using a unified planning paradigm. It does this by viewing the path planning problem as the two subproblems of search and approximation and using advanced graph-search techniques on a sampling-based approximation.</p><p>This perspective leads to Advanced BIT*. ABIT* combines truncated anytime graph-based searches, such as ATD*, with anytime almost-surely asymptotically optimal sampling-based planners, such as RRT*. This allows it to quickly find initial solutions and then converge towards the optimum in an anytime manner. ABIT* outperforms existing single-query, sampling-based planners on the tested problems in R<sup>4</sup> and R<sup>8</sup>, and was demonstrated on real-world problems with NASA/JPL-Caltech.

- Voxel-Based General Voronoi Diagram for Complex Data with Application on Motion Planning

    Author: Dorn, Sebastian | Daimler
    Author: Wolpert, Nicola | HFT Stuttgart
    Author: Sch�mer, Elmar | Mainz University
 
    keyword: Motion and Path Planning; Computational Geometry

    Abstract : One major challenge in Assembly Sequence Planning (ASP) for complex real-world CAD-scenarios is to find appropriate disassembly paths for all assembled parts. Such a path places demands on its length and clearance. In the past, it became apparent that planning the disassembly path based on the (approximate) General Voronoi Diagram (GVD) is a good approach to achieve these requirements. But for complex real-world data, every known solution for computing the GVD is either too slow or very memory consuming, even if only approximating the GVD. We present a new approach for computing the approximate GVD and demonstrate its practicability using a representative vehicle data set. We can calculate an approximation of the GVD within minutes and meet the accuracy requirement of some few millimeters for the subsequent path planning. This is achieved by voxelizing the surface with a common errorbounded GPU render approach. We then use an error-bounded wavefront propagation technique and combine it with a novel hash table-based data structure, the so-called Voronoi Voxel History (VVH). On top of the GVD, we present a novel approach for the creation of a General Voronoi Diagram Graph (GVDG) that leads to an extensive roadmap. This roadmap can be used to suggest appropriate disassembly paths for the later task of motion planning.

- Dynamic Movement Primitives for Moving Goals with Temporal Scaling Adaptation

    Author: Koutras, Leonidas | Aristotle University of Thessaloniki
    Author: Doulgeri, Zoe | Aristotle University of Thessaloniki
 
    keyword: Motion and Path Planning

    Abstract : In this work, we propose an augmentation to the Dynamic Movement Primitives (DMP) framework which allows the system to generalize to moving goals without the use of any known or approximation model for estimating the goal's motion. We aim to maintain the demonstrated velocity levels during the execution to the moving goal, generating motion profiles appropriate for human robot collaboration. The proposed method employs a modified version of a DMP, learned by a demonstration to a static goal, with adaptive temporal scaling in order to achieve reaching of the moving goal with the learned kinematic pattern. Only the current position and velocity of the goal are required. The goal's reaching error and its derivative is proved to converge to zero via contraction analysis. The theoretical results are verified by simulations and experiments on a KUKA LWR4+ robot.

- Navigating Discrete Difference Equation Governed WMR by Virtual Linear Leader Guided HMPC

    Author: Huang, Chao | Nanjing University
    Author: Chen, Xin | Nanjing University
    Author: Tang, Enyi | Nanjing University
    Author: He, Mengda | Teesside University
    Author: Bu, Lei | Nanjing University
    Author: Qin, Shengchao | Teesside University
    Author: Zeng, Yifeng | Teesside University
 
    keyword: Nonholonomic Motion Planning; Optimization and Optimal Control; Motion and Path Planning

    Abstract : In this paper, we revisit model predictive control (MPC), for the classical wheeled mobile robot (WMR) navigation problem. We prove that the reachable set based hierarchical MPC (HMPC), a state-of-the-art MPC, cannot handle WMR navigation in theory due to the non-existence of non-trivial linear system with an under-approximate reachable set of WMR. Nevertheless, we propose a virtual linear leader based MPC (VLL-MPC) to enable HMPC structure. Different from current HMPCs, we use a virtual linear system with an under-approximate path set rather than the traditional reachable set to guide the WMR. We provide a valid construction of the virtual linear leader. We prove the stability of VLL-MPC, and discuss its complexity. In the experiment, we demonstrate the advantage of VLL-MPC empirically by comparing it with NMPC, LMPC and anytime RRT* in several scenarios.

- Dispertio: Optimal Sampling for Safe Deterministic Sampling-Based Motion Planning

    Author: Palmieri, Luigi | Robert Bosch GmbH
    Author: Bruns, Leonard | KTH Royal Institute of Technology
    Author: Meurer, Michael | German Aerospace Center (DLR) and RWTH Aachen University (RWTH)
    Author: Arras, Kai Oliver | Bosch Research
 
    keyword: Nonholonomic Motion Planning; Motion and Path Planning; Robot Safety

    Abstract : A key challenge in robotics is the efficient generation of optimal robot motion with safety guarantees in cluttered environments. Recently, deterministic optimal sampling-based motion planners have been shown to achieve good performance towards this end, in particular in terms of planning efficiency, final solution cost, quality guarantees as well as non-probabilistic completeness. Yet their application is still limited to relatively simple systems (i.e., linear, holonomic, Euclidean state spaces). In this work, we extend this technique to the class of symmetric and optimal driftless systems by presenting Dispertio, an offline dispersion optimization technique for computing sampling sets, aware of differential constraints, for sampling-based robot motion planning. We prove that the approach, when combined with PRM*, is deterministically complete and retains asymptotic optimality. Furthermore, in our experiments we show that the proposed deterministic sampling technique outperforms several baselines and alternative methods in terms of planning efficiency and solution cost.

- Aggregation and Localization of Simple Robots in Curved Environments

    Author: Moan, Rachel | Winthrop University
    Author: Montano, Victor | University of Houston
    Author: Becker, Aaron | University of Houston
    Author: O'Kane, Jason | University of South Carolina
 
    keyword: Nonholonomic Motion Planning; Medical Robots and Systems; Localization

    Abstract : This paper is about the closely-related problems of localization and aggregation for extremely simple robots, for which the only available action is to move in a given direction as far as the geometry of the environment allows. Such problems may arise, for example, in biomedical applications, wherein a large group of tiny robots moves in response to a shared external stimulus. Specifically, we extend the prior work on these kinds of problems presenting two algorithms for localization in environments with curved (rather than polygonal) boundaries and under low-friction models of interaction with the environment boundaries. We present both simulations and physical demonstrations to validate the approach.

- Interpretable Run-Time Monitoring and Replanning for Safe Autonomous Systems Operations

    Author: Di Franco, Carmelo | University of Virginia
    Author: Bezzo, Nicola | University of Virginia
 
    keyword: Motion and Path Planning; Aerial Systems: Applications; Collision Avoidance

    Abstract : Autonomous robots, especially aerial vehicles, when subject to disturbances, uncertainties, and noises may experience variations from their desired states and deviations from the planned trajectory which may lead them into an unsafe state (e.g., a collision). It is thus necessary to monitor their states at run-time when operating in uncertain and cluttered environments and intervene to guarantee their and the surrounding's safety. While Reachability Analysis (RA) has been successfully used to provide safety guarantees, it doesn't provide explanations on why a system is predicted to be unsafe and what type of corrective actions to perform to change the decision. In this work we propose a novel approach for run-time monitoring that leverages a library of previously observed trajectories together with decision tree theory to predict if the system will be safe/unsafe and provide an explanation to understand the causes of the prediction. We design an interpretable monitor that checks at run-time if the vehicle may become unsafe and plan safe corrective actions if found unsafe. For each prediction, we provide a logical explanation -- a decision rule -- that includes information about the causes that lead to the predicted safety decision. The explanation also includes a set of counterfactual rules that shows what system variables may bring the system to the opposite safety decision, if changed. We leverage such an explanation to plan corrective actions that always keep the vehicle s

- An Efficient Sampling-Based Method for Online Informative Path Planning in Unknown Environments

    Author: Schmid, Lukas Maximilian | ETH Zurich
    Author: Pantic, Michael | ETH Zurich
    Author: Khanna, Raghav | ETH Zurich
    Author: Ott, Lionel | University of Sydney
    Author: Siegwart, Roland | ETH Zurich
    Author: Nieto, Juan | ETH Zurich
 
    keyword: Motion and Path Planning; Aerial Systems: Perception and Autonomy; Reactive and Sensor-Based Planning

    Abstract : The ability to plan informative paths online is essential to robot autonomy. In particular, sampling-based approaches are often used as they are capable of using arbitrary information gain formulations. However, they are prone to local minima, resulting in sub-optimal trajectories, and sometimes do not reach global coverage. In this paper, we present a new RRT*-inspired online informative path planning algorithm. Our method continuously expands a single tree of candidate trajectories and rewires segments to maintain the tree and refine intermediate trajectories. This allows the algorithm to achieve global coverage and maximize the utility of a path in a global context, using a single objective function. We demonstrate the algorithm's capabilities in the applications of autonomous indoor exploration as well as accurate Truncated Signed Distance Field (TSDF)-based 3D reconstruction on-board a Micro Aerial Vehicle (MAV). We study the impact of commonly used information gain and cost formulations in these scenarios and propose a novel TSDF-based 3D reconstruction gain and cost-utility formulation. Detailed evaluation in realistic simulation environments show that our approach outperforms state of the art methods in these tasks. Experiments on a real MAV demonstrate the ability of our method to robustly plan in real-time, exploring an indoor environment with on-board sensing and computation. We make our framework available for future research.

- Koopman Operator Method for Chance-Constrained Motion Primitive Planning

    Author: Gutow, Geordan | Georgia Institute of Technology
    Author: Rogers, Jonathan | Georgia Institute of Technology
 
    keyword: Motion and Path Planning; Collision Avoidance; Probability and Statistical Methods

    Abstract : The use of motion primitives to plan trajectories has received significant attention in the robotics literature. This work considers the application of motion primitives to path planning and obstacle avoidance problems in which the system is subject to significant parametric and/or initial condition uncertainty. In problems involving parametric uncertainty, optimal path planning is achieved by minimizing the expected value of a cost function subject to probabilistic (chance) constraints on vehicle-obstacle collisions. The Koopman operator provides an efficient means to compute expected values for systems under parametric uncertainty. In the context of motion planning, these include both the expected cost function and chance constraints. This work describes a maneuver-based planning method that leverages the Koopman operator to minimize an expected cost while satisfying user-imposed risk tolerances. The developed method is illustrated in two separate examples using a Dubins car model subject to parametric uncertainty in its dynamics or environment. Prediction of constraint violation probability is compared with a Monte Carlo method to demonstrate the advantages of the Koopman-based calculation.

- Robust Humanoid Contact Planning with Learned Zero and One-Step Capturability Prediction

    Author: Lin, Yu-Chi | University of Michigan
    Author: Righetti, Ludovic | New York University
    Author: Berenson, Dmitry | University of Michigan
 
    keyword: Motion and Path Planning; Humanoid and Bipedal Locomotion; Deep Learning in Robotics and Automation

    Abstract : Humanoid robots maintain balance and navigate by controlling the contact wrenches applied to the environment. While it is possible to plan dynamically-feasible motion that applies appropriate wrenches using existing methods, a humanoid may also be affected by external disturbances. Existing systems typically rely on controllers to reactively recover from disturbances. However, such controllers may fail when the robot cannot reach contacts capable of rejecting a given disturbance. In this paper, we propose a search-based footstep planner which aims to maximize the probability of the robot successfully reaching the goal without falling as a result of a disturbance. The planner considers not only the poses of the planned contact sequence, but also alternative contacts near the planned contact sequence that can be used to recover from external disturbances. Although this additional consideration significantly increases the computation load, we train neural networks to efficiently predict multi-contact zero-step and one-step capturability, which allows the planner to generate robust contact sequences efficiently. Our results show that our approach generates footstep sequences that are more robust to external disturbances than a conventional footstep planner in four challenging scenarios.

- Differential Flatness Based Path Planning with Direct Collocation on Hybrid Modes for a Quadrotor with a Cable-Suspended Payload

    Author: Zeng, Jun | University of California, Berkeley
    Author: Kotaru, Venkata Naga Prasanth | University of California Berkeley
    Author: Mueller, Mark Wilfried | University of California, Berkeley
    Author: Sreenath, Koushil | University of California, Berkeley
 
    keyword: Motion and Path Planning; Aerial Systems: Applications; Optimization and Optimal Control

    Abstract : Generating agile maneuvers for a quadrotor with a cable-suspended load is a challenging problem. State-of-the-art approaches often need significant computation time and complex parameter tuning. We use a coordinate-free geometric formulation and exploit a differential flatness based hybrid model of a quadrotor with a cable-suspended payload. We perform direct collocation on the differentially-flat hybrid system, and use complementarity constraints to avoid specifying hybrid mode sequences. The non-differentiable obstacle avoidance constraints are reformulated using dual variables, resulting in smooth constraints. We show that our approach has lower computational time than the state-of-the-art and guarantees feasibility of the trajectory with respect to both the system dynamics and input constraints without the need to tune lots of parameters. We validate our approach on a variety of tasks in both simulations and experiments, including navigation through waypoints and obstacle avoidance.

- A Real-Time Approach for Chance-Constrained Motion Planning with Dynamic Obstacles

    Author: Castillo-Lopez, Manuel | University of Luxembourg
    Author: Ludivig, Philippe | University of Luxembourg
    Author: Sajadi-Alamdari, Seyed Amin | University of Luxembourg
    Author: Sanchez-Lopez, Jose Luis | Interdisciplinary Center for Security, Reliability and Trust (Sn
    Author: Olivares-Mendez, Miguel A. | Interdisciplinary Centre for Security, Reliability and Trust - U
    Author: Voos, Holger | University of Luxembourg
 
    keyword: Motion and Path Planning; Collision Avoidance; Optimization and Optimal Control

    Abstract : Uncertain dynamic obstacles such as pedestrians or vehicles pose a major challenge for optimal robot navigation with safety guarantees. Previous work on motion planning have followed two main strategies to provide a safe bound on an obstacle's space: a polyhedron, such as a cuboid, or a nonlinear differentiable surface, such as an ellipsoid. The former approach relies on disjunctive programming which, in general, is N P-hard and its size grows exponentially with the number of obstacles. The latter approach needs to be linearized locally to find a tractable evaluation of the chance constraints, which reduces dramatically the remaining free space and leads to over-conservative trajectories or even unfeasibility. In this work, we present a hybrid approach that eludes the pitfalls of both strategies while maintaining the same safety guarantees. The key idea consists in obtaining safe differentiable bounds on the disjunctive chance constraints on the obstacles. The resulting nonlinear optimization problem is free of obstacle linearization and disjunctive programming, and therefore, it can be efficiently solved to meet fast real-time requirements with multiple obstacles. We validate our approach through mathematical proof, simulation and real experiments with an aerial robot using nonlinear model predictive control to avoid pedestrians.

- Learning When to Trust a Dynamics Model for Planning in Reduced State Spaces

    Author: McConachie, Dale Steven | University of Michigan, Ann Arbor
    Author: Power, Thomas | Robotics Institute, University of Michigan
    Author: Mitrano, Peter | University of Michigan
    Author: Berenson, Dmitry | University of Michigan
 
    keyword: Motion and Path Planning; Learning and Adaptive Systems

    Abstract : When the dynamics of a system are difficult to model and/or time-consuming to evaluate, such as in deformable object manipulation tasks, motion planning algorithms struggle to find feasible plans efficiently. Such problems are often reduced to state spaces where the dynamics are straightforward to model and evaluate. However, such reductions usually discard information about the system for the benefit of computational efficiency, leading to cases where the true and reduced dynamics disagree on the result of an action. This paper presents a formulation for planning in reduced state spaces that uses a classifier to bias the planner away from state-action pairs that are not reliably feasible under the true dynamics. We present a method to generate and label data to train such a classifier, as well as an application of our framework to rope manipulation, where we use a Virtual Elastic Band (VEB) approximation to the true dynamics. Our experiments with rope manipulation demonstrate that the classifier significantly improves the success rate of our RRT-based planner in several difficult scenarios which are designed to cause the VEB to produce incorrect predictions in key parts of the environment.

-  MIST: A Single-Query Path Planning Approach Using Memory and Information-Sharing Trees

    Author: Rakita, Daniel | University of Wisconsin-Madison
    Author: Mutlu, Bilge | University of Wisconsin-Madison
    Author: Gleicher, Michael | University of Wisconsin-Madison

- Fast Planning Over Roadmaps Via Selective Densification

    Author: Saund, Brad | University of Michigan
    Author: Berenson, Dmitry | University of Michigan
 
    keyword: Motion and Path Planning

    Abstract : We propose the Selective Densification method for fast motion planning through configuration space. We create a sequence of roadmaps by iteratively adding configurations. We organize these roadmaps into layers and add edges between identical configurations between layers. We find a path using best-first search, guided by our proposed estimate of remaining planning time. This estimate prefers to expand nodes closer to the goal and nodes on sparser layers.<p>We present proofs of the path quality and maximum depth of nodes expanded using our proposed graph and heuristic. We also present experiments comparing Selective Densification to bidirectional RRT-connect, as well as many graph search approaches. In difficult environments that require exploration on the dense layers we find Selective Densification finds solutions faster than all other approaches.

- Refined Analysis of Asymptotically-Optimal Kinodynamic Planning in the State-Cost Space

    Author: Kleinbort, Michal | Tel Aviv University
    Author: Granados, Edgar | Rutgers
    Author: Solovey, Kiril | Stanford University
    Author: Bonalli, Riccardo | Stanford University
    Author: Bekris, Kostas E. | Rutgers, the State University of New Jersey
    Author: Halperin, Dan | Tel Aviv University
 
    keyword: Motion and Path Planning; Optimization and Optimal Control

    Abstract : We present a novel analysis of AO-RRT: a tree-based planner for motion planning with kinodynamic constraints, originally described by Hauser and Zhou (AO-X, 2016). AO-RRT explores the state-cost space and has been shown to efficiently obtain high-quality solutions in practice without relying on the availability of a computationally-intensive two-point boundary-value solver. Our main contribution is an optimality proof for the single-tree version of the algorithm---a variant that was not analyzed before. Our proof only requires a mild and easily-verifiable set of assumptions on the problem and system: Lipschitz-continuity of the cost function and the dynamics. In particular, we prove that for any system satisfying these assumptions, any trajectory having a piecewise-constant control function and positive clearance from the obstacles can be approximated arbitrarily well by a trajectory found by AO-RRT. We also discuss practical aspects of AO-RRT and present experimental comparisons of variants of the algorithm.

- Polygon-Based Random Tree Search Planning for Variable Geometry Truss Robot

    Author: Park, Sumin | Seoul National University
    Author: Bae, Jangho | Seoul National University
    Author: Lee, Seohyeon | Hanyang University
    Author: Yim, Mark | University of Pennsylvania
    Author: Kim, Jongwon | Seoul National University
    Author: Seo, TaeWon | Hanyang University
 
    keyword: Motion and Path Planning; Cellular and Modular Robots

    Abstract : This paper proposes the use of a polygon-based random tree path planning algorithm for a variable geometry topology system (VGT). By combining a path planning algorithm and our previous non-impact locomotion algorithm, the proposed VGT system reaches a objective point. The proposed path planning algorithm provides desired set of support polygons with a modified rapid random tree algorithm. The algorithm can significantly reduce distortion of the VGT system while moving by limiting the deformation of the desired support polygon. With this algorithm feature, constraint violations of the system were significantly reduced when using a normal rapid random tree algorithm for path planning. The performance of the algorithm was validated using the simulation results.

- An Iterative Dynamic Programming Approach to the Multipoint Markov-Dubins Problem

    Author: Frego, Marco | University of Trento
    Author: Bevilacqua, Paolo | University of Trento
    Author: Saccon, Enrico | University of Trento
    Author: Palopoli, Luigi | University of Trento
    Author: Fontanelli, Daniele | University of Trento
 
    keyword: Motion and Path Planning; Nonholonomic Motion Planning; Computational Geometry

    Abstract : A new solution to the multipoint Markov-Dubins problem via Iterative Dynamic Programming is herein presented. The shortest path problem connecting a sequence of given points in the plane while maintaining angle continuity and bounded curvature is presented. As in the classic two points Dubins problem, the solution is a juxtaposition of line segments and circle arcs. This problem is relevant for the path planning of a non-holonomic robot, such as a wheeled vehicle. The proposed method is robust and computationally inexpensive with respect to existing solutions and is therefore suitable to be integrated as motion primitive into Dubins-based applications, e.g. orienteering problems or waypoint following robotics.

- GOMP: Grasp-Optimized Motion Planning for Bin Picking

    Author: Ichnowski, Jeffrey | UC Berkeley
    Author: Danielczuk, Michael | UC Berkeley
    Author: Xu, Jingyi | Technical University of Munich
    Author: Satish, Vishal | UC Berkeley
    Author: Goldberg, Ken | UC Berkeley
 
    keyword: Motion and Path Planning

    Abstract : Rapid and reliable robot bin picking is a critical challenge in automating warehouses, often measured in picks-per-hour (PPH). We explore increasing PPH using faster motions based on optimizing over a set of candidate grasps. The source of this set of grasps is two-fold: (1) grasp-analysis tools such as Dex-Net generate multiple candidate grasps, and (2) each of these grasps has a degree of freedom about which a robot gripper can rotate. In this paper, we present Grasp-Optimized Motion Planning (GOMP), an algorithm that speeds up the execution of a bin-picking robot's operations by incorporating robot dynamics and a set of candidate grasps produced by a grasp planner into an optimizing motion planner. We compute motions by optimizing with sequential quadratic programming (SQP) and iteratively updating trust regions to account for the non-convex nature of the problem. In our formulation, we constrain the motion to remain within the mechanical limits of the robot while avoiding obstacles. We further convert the problem to a time-minimization by repeatedly shorting a time horizon of a trajectory until the SQP is infeasible. In experiments with a UR5, GOMP achieves a speedup of 9x over a baseline planner.

- Motion Planning and Task Allocation for a Jumping Rover Team

    Author: Tan, Kai Chuen | Ohio State University
    Author: Jung, Myungjin | The Ohio State University
    Author: Shyu, Isaac | Ohio State University
    Author: Changhuang, Wan | The Ohio State University
    Author: Dai, Ran | The Ohio State University
 
    keyword: Motion and Path Planning; Hybrid Logical/Dynamical Planning and Verification; Planning, Scheduling and Coordination

    Abstract : This paper presents a cooperative robotic team composed of unmanned ground vehicles (UGVs) with hybrid operational modes to tackle the multiple traveling salesman problem (mTSP) with obstacles. The hybrid operational modes allow every UGV in the team to not only travel on a ground surface but also jump over obstacles. We name these UGVs jumping rovers. The jumping capability provides a flexible form of locomotion by leaping and landing on top of obstacles instead of navigating around obstacles. To solve the mTSP, an optimal path between any two objective points in an mTSP is determined by the optimized rapidly-exploring random tree method, named RRT*, and is further improved through a refined RRT* algorithm to find a smoother path between targets. We then formulate the mTSP as a mixed-integer linear programming (MILP) problem to search for the most cost-effective combination of paths for multiple UGVs. The effectiveness of the hybrid operational modes and optimized motion with assigned tasks is verified in an indoor, physical experimental environment using customized jumping rovers.

- Active 3D Modeling Via Online Multi-View Stereo

    Author: Song, Soohwan | KAIST
    Author: Kim, Daekyum | Korea Advanced Institute of Science and Technology
    Author: Jo, Sungho | Korea Advanced Institute of Science and Technology (KAIST)
 
    keyword: Motion and Path Planning; Aerial Systems: Perception and Autonomy; Computer Vision for Automation

    Abstract : Multi-view stereo (MVS) algorithms have been commonly used to model large-scale structures. When processing MVS, image acquisition is an important issue because its reconstruction quality depends heavily on the acquired images. Recently, an explore-then-exploit strategy has been used to acquire images for MVS. This method first constructs a coarse model by exploring an entire scene using a pre-allocated camera trajectory. Then, it rescans the unreconstructed regions from the coarse model. However, this strategy is inefficient because of the frequent overlap of the initial and rescanning trajectories. Furthermore, given the complete coverage of images, MVS algorithms do not guarantee an accurate reconstruction result.<p>In this study, we propose a novel view path-planning method based on an online MVS system. This method aims to incrementally construct the target three-dimensional (3D) model in real time. View paths are continually planned based on online feedbacks from the partially constructed model. The obtained paths fully cover low-quality surfaces while maximizing the reconstruction performance of MVS. Experimental results demonstrate that the proposed method can construct high quality 3D models with one exploration trial, without any rescanning trial as in the explore-then-exploit method.

- Reoriented Short-Cuts (RSC): An Adjustment Method for Locally Optimal Path Short-Cutting in High DoF Configuration Spaces

    Author: Holston, Alexander Christopher | Korean Advanced Institude of Science and Technology
    Author: Kim, Jong-Hwan | KAIST
 
    keyword: Motion and Path Planning

    Abstract : This paper presents Reoriented Short-Cuts (RSC): A modification of the traditional short-cut technique, allowing almost sure, single homotopy class, asymptotic convergence in high degree of freedom (DoF) problems. An additional Informed Gaussian Sampling (IGS) technique is also presented for convergence comparison. Traditionally, Short-Cut methods are used as a final technique to further optimize an initially found path. Typical short-cut methods fail as a single DoF may converge faster than the remaining, creating a zero-volume region between path segments and objects, halting further improvements. Previous attempts to solve this separate DoFs individually, drastically increasing collision checking computation. RSC and IGS control the shifting of the vertex to be Short-Cut, moving vertex positions by reorienting the line segments, removing the zero-volume convergence region. These methods are compared to similar strategies in a variety of problems including random worlds, and robot manipulation, to show the convergence across both translation and rotation oriented problems.

- Learning Resilient Behaviors for Navigation under Uncertainty Environments

    Author: Fan, Tingxiang | The University of Hong Kong
    Author: Long, Pinxin | Baidu Inc
    Author: Liu, Wenxi | Fuzhou University
    Author: Pan, Jia | University of Hong Kong
    Author: Yang, Ruigang | University of Kentucky
    Author: Manocha, Dinesh | University of Maryland
 
    keyword: Motion and Path Planning; Deep Learning in Robotics and Automation

    Abstract : Deep reinforcement learning has great potential to acquire complex, adaptive behaviors for autonomous agents automatically. However, the underlying neural network polices have not been widely deployed in real-world applications, especially in these safety-critical tasks (e.g., autonomous driving). One of the reasons is that the learned policy cannot perform flexible and resilient behaviors as traditional methods to adapt to diverse environments. In this paper, we consider the problem that a mobile robot learns adaptive and resilient behaviors for navigating in unseen uncertain environments while avoiding collisions. We present a novel approach for uncertainty-aware navigation by introducing an uncertainty-aware predictor to model the environmental uncertainty, and we propose a novel uncertainty-aware navigation network to learn resilient behaviors in the prior unknown environments. To train the proposed uncertainty-aware network more stably and efficiently, we present the temperature decay training paradigm, which balances exploration and exploitation during the training process. Our experimental evaluation demonstrates that our approach can learn resilient behaviors in diverse environments and generate adaptive trajectories according to environmental uncertainties.

- Motion Planning Explorer: Visualizing Local Minima Using a Local-Minima Tree

    Author: Orthey, Andreas | University Stuttgart
    Author: Fr�sz, Benjamin | University of Stuttgart
    Author: Toussaint, Marc | University of Stuttgart
 
    keyword: Motion and Path Planning; Nonholonomic Motion Planning; Formal Methods in Robotics and Automation

    Abstract : Motion planning problems often have many local minima. Those minima are important to visualize to let a user guide, prevent or predict motions. Towards this goal, we develop the motion planning explorer, an algorithm to let users interactively explore a tree of local-minima. Following ideas from Morse theory, we define local minima as paths invariant under minimization of a cost functional. The localminima are grouped into a local-minima tree using lowerdimensional projections specified by a user. The user can then interactively explore the local-minima tree, thereby visualizing the problem structure and guide or prevent motions. We show the motion planning explorer to faithfully capture local minima in four realistic scenarios, both for holonomic and certain nonholonomic robots.

- Fog Robotics Algorithms for Distributed Motion Planning Using Lambda Serverless Computing

    Author: Ichnowski, Jeffrey | University of North Carolina at Chapel Hill
    Author: Lee, William | University of North Carolina - Chapel Hill
    Author: Murta, Victor | University of North Carolina at Chapel Hill
    Author: Paradis, Samuel | University of California, Berkeley
    Author: Alterovitz, Ron | University of North Carolina at Chapel Hill
    Author: Gonzalez, Joseph E. | UC Berkeley
    Author: Stoica, Ion | UC Berkeley
    Author: Goldberg, Ken | UC Berkeley
 
    keyword: Motion and Path Planning

    Abstract : For robots using motion planning algorithms such as RRT and RRT*, the computational load can vary by orders of magnitude as the complexity of the local environment changes. To adaptively provide such computation, we propose Fog Robotics algorithms in which cloud-based serverless lambda computing provides parallel computation on demand. To use this parallelism, we propose novel motion planning algorithms that scale effectively with an increasing number of serverless computers. However, given that the allocation of computing is typically bounded by both monetary and time constraints, we show how prior learning can be used to efficiently allocate resources at runtime. We demonstrate the algorithms and application of learned parallel allocation in both simulation and with the Fetch commercial mobile manipulator using Amazon Lambda to complete a sequence of sporadically computationally intensive motion planning tasks.

- Exploration of 3D Terrains Using Potential Fields with Elevation-Based Local Distortions

    Author: Maffei, Renan | Universidade Federal Do Rio Grande Do Sul
    Author: Praisler de Souza, Marcos | Universidade Federal Do Rio Grande Do Sul
    Author: Mantelli, Mathias Fassini | Federal University of Rio Grande Do Sul
    Author: Pittol, Diego | Federal University of Rio Grande Do Sul
    Author: Kolberg, Mariana | UFRGS
    Author: Jorge, Vitor | ITA
 
    keyword: Motion and Path Planning; Mapping

    Abstract : Mobile robots can be used in numerous outdoor tasks such as patrolling, delivery applications, and military. In order to deploy mobile robots in this kind of environment, where there are different challenges like slopes, elevations, or even holes, they should be able to detect such challenges and determine the best path to accomplish their tasks. In this paper, we are proposing an exploration approach based on potential fields with local distortions, in which we define preferences in uneven terrains to avoid high declivity regions without compromising the best path. The approach was implemented and tested in simulated environments, considering a ground robot embedded with two 2D LIDAR sensors, and the experiments demonstrated the efficiency of our method.

- R3T: Rapidly-Exploring Random Reachable Set Tree for Optimal Kinodynamic Planning of Nonlinear Hybrid Systems

    Author: Wu, Albert | Massachusetts Institute of Technology
    Author: Sadraddini, Sadra | MIT
    Author: Tedrake, Russ | Massachusetts Institute of Technology
 
    keyword: Motion and Path Planning; Hybrid Logical/Dynamical Planning and Verification; Optimization and Optimal Control

    Abstract : We introduce R3T, a reachability-based variant of the rapidly-exploring random tree (RRT) algorithm that is suitable for (optimal) kinodynamic planning in nonlinear and hybrid systems. We developed tools to approximate reachable sets using polytopes and perform sampling-based planning with them. This method has a unique advantage in hybrid systems: different dynamic modes in the reachable set can be explicitly represented using multiple polytopes. We prove that under mild assumptions, R3T is probabilistically complete in kinodynamic systems, and asymptotically optimal through rewiring. Moreover, R3T provides a formal verification method for reachability analysis of nonlinear systems. The advantages of R3T are demonstrated with case studies on nonlinear, hybrid, and contact-rich robotic systems.

- DeepSemanticHPPC: Hypothesis-Based Planning Over Uncertain Semantic Point Clouds

    Author: Han, Yutao | Cornell University
    Author: Lin, Hubert | Cornell University
    Author: Banfi, Jacopo | Cornell University
    Author: Bala, Kavita | Cornell University
    Author: Campbell, Mark | Cornell University
 
    keyword: Motion and Path Planning; Visual-Based Navigation; Semantic Scene Understanding

    Abstract : Planning in unstructured environments is challenging - it relies on sensing, perception, scene reconstruction, and reasoning about various uncertainties. We propose DeepSemanticHPPC, a novel uncertainty-aware hypothesis-based planner for unstructured environments. Our algorithmic pipeline consists of: a deep Bayesian neural network which segments surfaces with uncertainty estimates; a flexible point cloud scene representation; a next-best-view planner which minimizes the uncertainty of scene semantics using sparse visual measurements; and a hypothesis-based path planner that proposes multiple kinematically feasible paths with evolving safety confidences given next-best-view measurements. Our pipeline iteratively decreases semantic uncertainty along planned paths, filtering out unsafe paths with high confidence. We show that our framework plans safe paths in real-world environments where existing path planners typically fail.

- Balancing Actuation and Computing Energy in Motion Planning

    Author: Sudhakar, Soumya | Massachusetts Institute of Technology
    Author: Karaman, Sertac | Massachusetts Institute of Technology
    Author: Sze, Vivienne | Massachusetts Institute of Technology
 
    keyword: Motion and Path Planning

    Abstract : We study a novel class of motion planning problems, inspired by emerging low-energy robotic vehicles, such as insect-size flyers, chip-size satellites, and high-endurance autonomous blimps, for which the energy consumed by computing hardware during planning a path can be as large as the energy consumed by actuation hardware during the execution of the same path. We propose a new algorithm, called Compute Energy Included Motion Planning (CEIMP). CEIMP operates similarly to any other anytime planning algorithm, except it stops when it estimates further computing will require more computing energy than potential savings in actuation energy. We show that CEIMP has the same asymptotic computational complexity as existing sampling-based motion planning algorithms, such as PRM*. We also show that CEIMP outperforms the average baseline of using maximum computing resources in realistic computational experiments involving 10 floor plans from MIT buildings. In one representative experiment, CEIMP outperforms the average baseline 90.6% of the time when energy to compute one more second is equal to the energy to move one more meter, and 99.7% of the time when energy to compute one more second is equal to or greater than the energy to move 3 more meters.

- Posterior Sampling for Anytime Motion Planning on Graphs with Expensive-To-Evaluate Edges

    Author: Hou, Brian | University of Washington
    Author: Choudhury, Sanjiban | University of Washington
    Author: Lee, Gilwoo | University of Washington
    Author: Mandalika, Aditya | University of Washington
    Author: Srinivasa, Siddhartha | University of Washington
 
    keyword: Motion and Path Planning; Learning and Adaptive Systems

    Abstract : Collision checking is a computational bottleneck in motion planning, requiring lazy algorithms that explicitly reason about when to perform this computation. Optimism in the face of collision uncertainty minimizes the number of checks before finding the shortest path. However, this may take a prohibitively long time to compute, with no other feasible paths discovered during this period. For many real-time applications, we instead demand strong anytime performance, defined as minimizing the cumulative lengths of the feasible paths yielded over time. We introduce Posterior Sampling for Motion Planning (PSMP), an anytime lazy motion planning algorithm that leverages learned posteriors on edge collisions to quickly discover an initial feasible path and progressively yield shorter paths. PSMP obtains an expected regret bound of tilde{O}(sqrt{S A T}) and outperforms comparative baselines on a set of 2D and 7D planning problems.

## Aerial Systems: Mechanics and Control

- Model Reference Adaptive Control of Multirotor for Missions with Dynamic Change of Payloads During Flight

    Author: Maki, Toshiya | University of Tokyo
    Author: Zhao, Moju | The University of Tokyo
    Author: Shi, Fan | The University of Tokyo
    Author: Okada, Kei | The University of Tokyo
    Author: Inaba, Masayuki | The University of Tokyo
 
    keyword: Aerial Systems: Mechanics and Control; Robust/Adaptive Control of Robotic Systems

    Abstract : Carrying payloads in air is a major mission for multirotor aerial robot. However, the presence of payloads on multirotor aerial robot has a risk of degrading the performance of the flight controller. This concern becomes obvious especially when carrying objects not securely attached to the body or performing aerial manipulation. Therefore, controller with the ability to adapt itself to the effects of payloads on flight stability is needed. This paper proposes a novel nonlinear multiple-input and multiple-output (MIMO) model reference adaptive control (MRAC) system for attitude control of multirotor aerial robots which can dynamically compensate change in the position of center of gravity and inertia caused by payloads. Stability and robustness of the controller are experimentally confirmed in quadrotor and transformable multirotor, and experiments modeling practical applications are conducted for each aerial robot system, proving the utility of the controller.

- Adaptive Air Density Estimation for Precise Tracking Control and Accurate External Wrench Observation for Flying Robots

    Author: Maier, Moritz | German Aerospace Center (DLR)
    Author: Keppler, Manuel | German Aerospace Center (DLR)
    Author: Ott, Christian | German Aerospace Center (DLR)
    Author: Albu-Sch�ffer, Alin | DLR - German Aerospace Center
 
    keyword: Aerial Systems: Mechanics and Control; Robust/Adaptive Control of Robotic Systems; Aerial Systems: Applications

    Abstract : Air density changes depending on the local atmosphere and affects the rotor thrust of flying robots. This effect has to be compensated by the flight controller in order to realize precise tracking of a desired trajectory. So far, the influence of the air density has been disregarded or only considered implicitly in the control of flying robots. In this work, a nonlinear adaptive control approach is presented. It explicitly considers the air density in the dynamical model and enables air density estimation and tracking control under changing atmospheric conditions and with added payload. Furthermore, the estimated air density is used to enhance the accuracy of a state-of-the-art external wrench estimator. The adaptive control approach is evaluated in simulations and experiments with a quadrocopter and a coaxial hexacopter.

- The Tiercel: A Novel Autonomous Micro Aerial Vehicle That Can Map the Environment by Flying into Obstacles

    Author: Mulgaonkar, Yash | University of Pennsylvania
    Author: Liu, Wenxin | University of Pennsylvania
    Author: Thakur, Dinesh | University of Pennsylvania
    Author: Daniilidis, Kostas | University of Pennsylvania
    Author: Taylor, Camillo Jose | University of Pennsylvania
    Author: Kumar, Vijay | University of Pennsylvania
 
    keyword: Aerial Systems: Mechanics and Control; Aerial Systems: Perception and Autonomy; Biologically-Inspired Robots

    Abstract : Autonomous flight through unknown environments in the presence of obstacles is a challenging problem for micro aerial vehicles (MAVs). A majority of the current state-of-art research assumes obstacles as opaque objects that can be easily sensed by optical sensors such as cameras or LiDARs. However in indoor environments with glass walls and windows, or scenarios with smoke and dust, robots (even birds) have a difficult time navigating through the unknown space.<p>In this paper, we present the design of a new class of micro aerial vehicles that achieves autonomous navigation and are robust to collisions. In particular, we present the Tiercel MAV: a small, agile, light weight and collision-resilient robot powered by a cellphone grade CPU. Our design exploits contact to infer the presence of transparent or reflective obstacles like glass walls, integrating touch with visual perception for SLAM. The Tiercel is able to localize using visual-inertial odometry (VIO) running on board the robot with a single downward facing fisheye camera and an IMU. We show how our collision detector design and experimental set up enable us to characterize the impact of collisions on VIO. We further develop a planning strategy to enable the Tiercel to fly autonomously in an unknown space, sustaining collisions and creating a 2D map of the environment. Finally we demonstrate a swarm of three autonomous Tiercel robots safely navigating and colliding through an obstacle field to reach their objectives.

- Full-Pose Manipulation Control of a Cable-Suspended Load with Multiple UAVs under Uncertainties

    Author: Sanalitro, Dario | LAAS-CNRS
    Author: Savino, Heitor J | Laboratory for Analysis and Architecture of Systems
    Author: Tognon, Marco | LAAS-CNRS
    Author: Cortes, Juan | LAAS-CNRS
    Author: Franchi, Antonio | University of Twente
 
    keyword: Aerial Systems: Mechanics and Control; Multi-Robot Systems; Mobile Manipulation

    Abstract : In this work we propose an uncertainty-aware controller for the FlyCrane system, a statically rigid cable-suspended aerial manipulator using the minimum number of aerial robots and cables. The force closure property of the FlyCrane makes it ideal for applications where high precision is required and external disturbances should be compensated. The proposed control requires the knowledge of the nominal values of a minimum number of uncertain kinematic parameters, thus simplifying the identification process and the controller implementation. We propose an optimization-based tuning method of the control gains that ensures stability despite parameter uncertainty and maximizes the H-infinity performance. The validity of the proposed framework is shown through real experiments.

- Learning Pugachev's Cobra Maneuver for Tail-Sitter UAVs Using Acceleration Model
 
    Author: Xu, Wei | University of Hong Kong
    Author: Zhang, Fu | University of Hong Kong
 
    keyword: Aerial Systems: Mechanics and Control; Learning and Adaptive Systems; Robust/Adaptive Control of Robotic Systems

    Abstract : The Pugachev's cobra maneuver is a dramatic and demanding maneuver requiring the aircraft to fly at extremely high Angle of Attacks (AOA) where stalling occurs. This paper considers this maneuver on tail-sitter UAVs. We present a simple yet very effective feedback-iterative learning position control structure to regulate the altitude error and lateral displacement during the maneuver. Both the feedback controller and the iterative learning controller are based on the aircraft acceleration model, which is directly measurable by the onboard accelerometer. Moreover, the acceleration model leads to an extremely simple dynamic model that does not require any model identification in designing the position controller, greatly simplifying the implementation of the iterative learning control. Real-world outdoor flight experiments on the ``Hong Hu" UAV, an aerobatic yet efficient quadrotor tail-sitter UAV of small-size, are provided to show the effectiveness of the proposed controller.

- Adaptive Control of Variable-Pitch Propellers: Pursuing Minimum-Effort Operation

    Author: Henderson, Travis | CSE, UMN
    Author: Papanikolopoulos, Nikos | University of Minnesota
 
    keyword: Aerial Systems: Mechanics and Control; Aerial Systems: Applications

    Abstract : As Unmanned Aerial Vehicles (UAVs) become more commonly used in industry, their performance will continue to be challenged. A performance bottleneck that is crucial to overcome is the design of electric propulsion systems for UAVs that operate in disparate flight modes (e.g., hovering and forward-moving flight). While flight mode dissimilarity presents a fundamental design challenge for fixed-geometry propulsion systems, variable-geometry systems such as the Variable Pitch Propeller (VPP) ones are able to provide superior propulsion performance across a wide range of flight modes. This work builds on previous work by the     Authors and presents a VPP system control and estimation framework for safe near-optimal propulsion system behavior across the whole operation state space of any UAV. Multiple validations are presented to support the feasibility of the approach.


- Design and Control of a Variable Aerial Cable Towed System

    Author: Li, Zhen | Ecole Centrale Nantes
    Author: Erskine, Julian | Ecole Centrale De Nantes
    Author: Caro, Stéphane | CNRS/LS2N
    Author: Chriette, Abdelhamid | Ecole Centrale De Nantes
 
    keyword: Aerial Systems: Mechanics and Control; Tendon/Wire Mechanism; Parallel Robots

    Abstract : Aerial Cable Towed Systems (ACTS) are composed of several Unmanned Aerial Vehicles (UAVs) connected to a payload by cables. Compared to towing objects from individual aerial vehicles, an ACTS has significant advantages such as heavier payload capacity, modularity, and full control of the payload pose. They are however generally large with limited ability to meet geometric constraints while avoiding collisions between UAVs. This paper presents the modeling, performance analysis, design, and a proposed controller for a novel ACTS with variable cable lengths, named Variable Aerial Cable Towed System (VACTS).<p>Winches are embedded on the UAVs for actuating the cable lengths similar to a Cable-Driven Parallel Robot to increase the versatility of the ACTS. The general geometric, kinematic and dynamic models of the VACTS are derived, followed by the development of a centralized feedback linearization controller. The design is based on a wrench analysis of the VACTS, without constraining the cables to pass through the UAV center of mass, as in current works. Additionally, the performance of the VACTS and ACTS are compared showing that the added versatility comes at the cost of payload and configuration flexibility. A prototype confirms the feasibility of the system.

- Novel Model-Based Control Mixing Strategy for a Coaxial Push-Pull Multirotor

    Author: Chebbi, Jawhar | ISAE-SUPAERO &amp; Donecle
    Author: Defa�, Fran�ois | IUT Tarbes - GEII - Université De Toulouse
    Author: Briere, Yves | Université De Toulouse ISAE
    Author: Deruaz-Pepin, Alban | Donecle
 
    keyword: Aerial Systems: Mechanics and Control; Calibration and Identification; Force Control

    Abstract : A Coaxial push-pull multirotor is a Vertical Take- Off and Landing (VTOL) Unmanned Aerial Vehicle (UAV) having <i>2n</i> (<i>n &#8712; &#8469;<sup>*</sup></i>) rotors arranged in <i>n</i> blocks of two coaxial contra-rotating rotors. A model-based control allocation algorithm (mixer) for this architecture is proposed. The novelty of the approach lies in the fact that the coaxial aerodynamic interference occurring between the pairs of superimposed rotors is not neglected but rather nonlinear empiric models of the coaxial aerodynamic thrust and torque are used to build the mixer. Real flight experiments were conducted and the new approach showed promising results.

- Robust Quadcopter Control with Artificial Vector Fields

    Author: Rezende, Adriano | Universidade Federal De Minas Gerais
    Author: Gon�alves, Vinicius Mariano | UFMG
    Author: Dias Nunes, Arthur Henrique | Federal University of Minas Gerais
    Author: Pimenta, Luciano | Universidade Federal De Minas Gerais
 
    keyword: Aerial Systems: Mechanics and Control; Motion Control; Motion and Path Planning

    Abstract : This article presents a path tracking control strategy for a quadcopter to follow a time varying curve. The control is based on artificial vector fields. The construction of the field is based on a well known technique in the literature. Next, control laws are developed to impose the behavior of the vector field to a second order integrator model. Finally, control laws are developed to impose the dynamics of the controlled second order integrator to a quadcopter model, which assumes the thrust and the angular rates as input commands. Asymptotic convergence of the whole system is proved by showing that the individual systems in cascade connection are input-to-state stable. We also analyze the influence of norm-bounded disturbances in the control inputs to evaluate the robustness of the controller. We show that bounded disturbances originate limited deviations from the target curve. Simulations and a real robot experiment exemplify and validate the developed theory.

- Global Identification of the Propeller Gains and Dynamic Parameters of Quadrotors from Flight Data

    Author: Six, Damien | IIT
    Author: Briot, S�bastien | LS2N
    Author: Erskine, Julian | Ecole Centrale De Nantes
    Author: Chriette, Abdelhamid | Ecole Centrale De Nantes
 
    keyword: Aerial Systems: Mechanics and Control; Dynamics; Underactuated Robots

    Abstract : Several methods can be applied to estimate the propeller thrust and torque coefficients and dynamics parameters of quadrotor UAVs. These parameters are necessary for many controllers that have been proposed for these vehicles. However, these methods require the use of specific test benches, which do not well simulate real flight conditions.<p>In this paper, a new method is introduced which allows the identification of the propeller coefficients and dynamic parameters of a quadrotor in a single procedure. It is based on a Total-Least-Square identification technique, does not require any specific test bench and needs only a measurement of the mass of the quadrotor and a recording of data from a flight that can be performed manually by an operator.</p><p>Because the symmetries of classic quadrotors limit the performance of the algorithm, an extension of the procedure is proposed. Two types of flights are then used: one with the initial quadrotor and a second flight with an additional payload on the vehicle that modifies the mass distribution. This new procedure, which is validated experimentally, increases the performance of the identification and allows an estimation of all the relevant dynamic parameters of the quadrotor near hovering conditions.

- Gemini: A Compact yet Efficient Bi-Copter UAV for Indoor Applications

    Author: Qin, Youming | The University of Hong Kong
    Author: Xu, Wei | University of Hong Kong
    Author: Lee, Adrian | University of California, Davis
    Author: Zhang, Fu | University of Hong Kong
 
    keyword: Aerial Systems: Mechanics and Control; Aerial Systems: Applications

    Abstract : Quad-copters are the premier platform for data collection tasks, yet their ability to collect data in indoor narrow spaces is severely compromised due to their huge size when carrying heavy sensors. In this paper, we study a bi-copter UAV configuration that has similar levels of versatility and improves the compactness or efficiency at the same time. Such an arrangement allows for the preservation of propeller size, meaning that we can effectively reduce the horizontal width of the UAV while still maintains the same payload capacity. Furthermore, pitch, roll and yaw control can also be achieved through mechanically simple means as well, increasing reliability and precision. We also found that the Gemini platform is the most power-efficient yet practical solution for indoor applications among all the twelve common UAV configurations. This paper will detail the entire process of creating the platform from picking the ideal propeller through aerodynamic analysis, system design, optimization, implementation, control, and real flight tests that demonstrate its ability to function seamlessly.

- Direct Force Feedback Control and Online Multi-Task Optimization for Aerial Manipulators

    Author: Nava, Gabriele | Istituto Italiano Di Tecnologia
    Author: Sabl�, Quentin | LAAS-CNRS
    Author: Tognon, Marco | LAAS-CNRS
    Author: Pucci, Daniele | Italian Institute of Technology
    Author: Franchi, Antonio | University of Twente
 
    keyword: Aerial Systems: Mechanics and Control; Force Control; Optimization and Optimal Control

    Abstract : In this paper we present an optimization-based method for controlling aerial manipulators in physical contact with the environment. The multi-task control problem, which includes hybrid force-motion tasks, energetic tasks, and position/postural tasks, is recast as a quadratic programming problem with equality and inequality constraints, which is solved online. Thanks to this method, the aerial platform can be exploited at its best to perform the multi-objective tasks, with tunable priorities, while hard constraints such as contact maintenance, friction cones, joint limits, maximum and minimum propeller speeds are all respected. An on-board force/torque sensor mounted at the end effector is used in the feedback loop in order to cope with model inaccuracies and reject external disturbances. Real experiments with a multi-rotor platform and a multi-DoF lightweight manipulator demonstrate the applicability and effectiveness of the proposed approach in the real world.

- Nonlinear Vector-Projection Control for Agile Fixed-Wing Unmanned Aerial Vehicles

    Author: Hernandez Ramirez, Juan Carlos | McGill University
    Author: Nahon, Meyer | McGill University
 
    keyword: Aerial Systems: Mechanics and Control; Motion Control; Control Architectures and Programming

    Abstract : Agile fixed-wing aircraft integrate the efficient, high-speed capabilities of conventional fixed-wing platforms with the extreme maneuverability of rotorcraft. This work presents a nonlinear control strategy that harnesses these capabilities to enable autonomous flight through aggressive, time-constrained, three-dimensional trajectories. The cascaded control structure consists of two parts; an inner attitude control loop developed on the Special Orthornormal group that avoids singularities commonly associated with other parametrizations, and an outer position control loop that jointly determines the thrust command and attitude references by implementing a novel vector-projection algorithm. The objective of the algorithm is to decouple roll from the reference attitude to ensure that thrust and lift forces can always be pointed such that position errors converge to zero. The proposed control system represents a single, unified solution that remains effective throughout the aircraft's flight envelope, including aerobatic operation. Controller performance is verified through simulations and experimental flight tests; results show the unified control scheme is capable of performing a wide range of operations that would normally require multiple, single-purpose controllers, and their associated switching logic.

- Adaptive Nonlinear Control of Fixed-Wing VTOL with Airflow Vector Sensing

    Author: Shi, Xichen | California Institute of Technology
    Author: Spieler, Patrick | Caltech
    Author: Tang, Ellande | California Institute of Technology
    Author: Lupu, Elena-Sorina | California Institute of Technology
    Author: Tokumaru, Phillip | AeroVironment, Inc
    Author: Chung, Soon-Jo | Caltech
 
    keyword: Aerial Systems: Mechanics and Control; Robust/Adaptive Control of Robotic Systems; Learning and Adaptive Systems

    Abstract : Fixed-wing vertical take-off and landing (VTOL) aircraft pose a unique control challenge that stems from complex aerodynamic interactions between wings and rotors. Thus, accurate estimation of external forces is indispensable for achieving high performance flight. In this paper, we present a composite adaptive nonlinear tracking controller for a fixed-wing VTOL. The method employs online adaptation of linear force models, and generates accurate estimation for wing and rotor forces in real-time based on information from a three-dimensional airflow sensor. The controller is implemented on a custom-built fixed-wing VTOL, which shows improved velocity tracking and force prediction during the transition stage from hover to forward flight, compared to baseline flight controllers.

- The Reconfigurable Aerial Robotic Chain: Modeling and Control

    Author: Nguyen, Dinh Huan | University of Nevada, Reno
    Author: Dang, Tung | University of Nevada, Reno
    Author: Alexis, Kostas | University of Nevada, Reno
 
    keyword: Aerial Systems: Mechanics and Control

    Abstract : This paper overviews the system design, modeling and control of the Aerial Robotic Chain. This new design corresponds to a reconfigurable robotic system of systems consisting of multilinked micro aerial vehicles that presents the ability to cross narrow sections, morph its shape, ferry significant payloads, offer the potential of distributed sensing and processing, and enable system extendability. We present the system dynamics for any number of connected aerial vehicles, followed by the controller design involving a model predictive position control loop combined with multiple parallel angular controllers on SO(3). Evaluation studies both in simulation and through experiments based on our ARC-Alpha prototype are depicted and involve coordinated maneuvering and shape configuration to cross narrow windows.

- Direct Acceleration Feedback Control of Quadrotor Aerial Vehicles

    Author: Hamandi, Mahmoud | INSA Toulouse
    Author: Tognon, Marco | LAAS-CNRS
    Author: Franchi, Antonio | University of Twente
 
    keyword: Aerial Systems: Mechanics and Control; Robust/Adaptive Control of Robotic Systems

    Abstract : In this paper we propose to control a quadrotor through direct acceleration feedback. The proposed method, while simple in form, alleviates the need for accurate estimation of platform parameters such as mass and propeller effectiveness. In order to use efficaciously the noisy acceleration measurements in direct feedback, we propose a novel regression-based filter that exploits the knowledge on the commanded propeller speeds, and extracts smooth platform acceleration with minimal delay. Our tests show that the controller exhibits a few millimeter error when performing real world tasks with fast changing mass and effectiveness, e.g., in pick and place operation and in turbulent conditions. Finally, we benchmark the direct acceleration controller against the PID strategy and show the clear advantage of using high-frequency and low-latency acceleration measurements directly in the control feedback, especially in the case of low frequency position measurements that are typical for real outdoor conditions.

- Trajectory Tracking Nonlinear Model Predictive Control for an Overactuated MAV

    Author: Brunner, Maximilian | ETH Zurich
    Author: Bodie, Karen | ETH Zurich
    Author: Kamel, Mina | Autonomous Systems Lab, ETH Zurich
    Author: Pantic, Michael | ETH Zurich
    Author: Zhang, Weixuan | ETH Zurich
    Author: Nieto, Juan | ETH Zurich
    Author: Siegwart, Roland | ETH Zurich
 
    keyword: Aerial Systems: Mechanics and Control; Optimization and Optimal Control

    Abstract : This work presents a method to control omnidirectional micro aerial vehicles (OMAVs) for the tracking of 6-DoF trajectories in free space. A rigid body model based approach is applied in a receding horizon fashion to generate optimal wrench commands that can be constrained to meet limits given by the mechanical design and actuators of the platform. Allocation of optimal actuator commands is performed in a separate step. A disturbance observer estimates forces and torques that may arise from unmodeled dynamics or external disturbances and fuses them into the optimization to achieve offset-free tracking. Experiments on a fully overactuated MAV show the tracking performance and compare it against a classical PD-based controller.

- Optimal Oscillation Damping Control of Cable-Suspended Aerial Manipulator with a Single IMU Sensor

    Author: Sarkisov, Yuri | Skolkovo Institute of Science and Technology
    Author: Kim, Min Jun | DLR
    Author: Coelho, Andre | German Aerospace Center (DLR)
    Author: Tsetserukou, Dzmitry | Skolkovo Institute of Science and Technology
    Author: Ott, Christian | German Aerospace Center (DLR)
    Author: Kondak, Konstantin | German Aerospace Center
 
    keyword: Aerial Systems: Mechanics and Control; Aerial Systems: Applications

    Abstract : This paper presents a design of oscillation damp- ing control for the cable-Suspended Aerial Manipulator (SAM). The SAM is modeled as a double pendulum, and it can generate a body wrench as a control action. The main challenge is the fact that there is only one onboard IMU sensor which does not provide full information on the system state. To overcome this difficulty, we design a controller motivated by a simplified SAM model. The proposed controller is very simple yet robust to model uncertainties. Moreover, we propose a gain tuning rule by formulating the proposed controller in the form of output feedback linear quadratic regulation problem. Consequently, it is possible to quickly dampen oscillations with minimal energy consumption. The proposed approach is validated through simulations and experiments.


- Upset Recovery Control for Quadrotors Subjected to a Complete Rotor Failure from Large Initial Disturbances

    Author: Sun, Sihao | Delft University of Technology
    Author: Baert, Matthias | Technical University Delft
    Author: Strack van Schijndel, Bram Adriaan | Delft University of Technology
    Author: de Visser, Coen | TU Delft
 
    keyword: Aerial Systems: Mechanics and Control; Robot Safety; Dynamics

    Abstract : This study has developed a fault-tolerant controller that is able to recover a quadrotor from arbitrary initial orientations and angular velocities, despite the complete failure of a rotor. This cascaded control method includes a position/altitude controller, an almost-global convergence attitude controller, and a control allocation method based on quadratic programming. As a major novelty, a constraint of undesirable angular velocity is derived and fused into the control allocator, which significantly improves the recovery performance. For validation, we have conducted a set of Monte-Carlo simulation to test the reliability of the proposed method of recovering the quadrotor from arbitrary initial attitude/rate conditions. In addition, real-life flight tests have been performed. The results demonstrate that the post-failure quadrotor can recover after being casually tossed into the air.

- Identification and Evaluation of a Force Model for Multirotor UAVs

    Author: Letalenet, Alexandre | Sorbonne Université
    Author: Morin, Pascal | UPMC
 
    keyword: Aerial Systems: Mechanics and Control; Dynamics

    Abstract : This paper proposes a model identification method and evaluation of a force model for multirotor UAVs. The model incorporates propellers' aerodynamics derived from momentum and blade element theories, as well as aerodynamics of the UAV's structure and actuation dynamics. A two-steps identification approach of the model parameters is proposed. The model is identified and evaluated from outdoor experiments with flight speeds exceeding 10m/s.

- Preliminary Study of an Aerial Manipulator with Elastic Suspension

    Author: Yigit, Arda | University of Strasbourg
    Author: Grappe, Gustave | University of Strasbourg
    Author: Cuvillon, Loic | University of Strasbourg
    Author: Durand, Sylvain | INSA Strasbourg &amp; ICube
    Author: Gangloff, Jacques | University of Strasbourg
 
    keyword: Aerial Systems: Mechanics and Control; Visual Servoing; Flexible Robots

    Abstract : This paper presents a preliminary study of an Aerial Manipulator suspended by a spring to a robotic carrier. The suspended aerial manipulator is actuated by six pairs of contra-rotating propellers generating a 6-DoF wrench. Simulations show path following results using a computed torque (feedback linearization) control strategy. Active vibration canceling is validated experimentally on a first prototype.

- Towards Low-Latency High-Bandwidth Control of Quadrotors Using Event Cameras

    Author: Sugimoto, Rika | University of Zurich
    Author: Gehrig, Mathias | University of Zurich
    Author: Brescianini, Dario | University of Zurich
    Author: Scaramuzza, Davide | University of Zurich
 
    keyword: Aerial Systems: Mechanics and Control; Visual Servoing; Sensor-based Control

    Abstract : Event cameras are a promising candidate to enable high speed vision-based control due to their low sensor latency and high temporal resolution. However, purely event-based feedback has yet to be used in the control of drones. In this work, a first step towards implementing low-latency high-bandwidth control of quadrotors using event cameras is taken. In particular, this paper addresses the problem of one-dimensional attitude tracking using a dualcopter platform equipped with an event camera. The event-based state estimation consists of a modified Hough transform algorithm combined with a Kalman filter that outputs the roll angle and angular velocity of the dualcopter relative to a horizon marked by a black-and-white disk. The estimated state is processed by a proportional-derivative attitude control law that computes the rotor thrusts required to track the desired attitude. The proposed attitude tracking scheme shows promising results of event-camera-driven closed loop control: the state estimator performs with an update rate of 1 kHz and a latency determined to be 12 milliseconds, enabling attitude tracking at speeds of over 1600 degrees per second.

- Perception-Constrained and Motor-Level Nonlinear MPC for Both Underactuated and Tilted-Propeller UAVs

    Author: Jacquet, Martin | LAAS, CNRS
    Author: Corsini, Gianluca | LAAS-CNRS
    Author: Bicego, Davide | LAAS-CNRS
    Author: Franchi, Antonio | University of Twente
 
    keyword: Aerial Systems: Mechanics and Control; Motion Control; Aerial Systems: Perception and Autonomy

    Abstract : In this paper, we present a Perception-constrained Nonlinear Model Predictive Control (NMPC) framework for the real-time control of multi-rotor aerial vehicles. Our formulation considers both constraints from a perceptive sensor and realistic actuator limitations that are the rotor minimum and maximum speeds and accelerations. The formulation is meant to be generic and considers a large range of multi-rotor platforms (such as underactuated quadrotors or tilted-propellers hexarotors) since it does not rely on differential flatness for the dynamical equation, and a broad range of sensors, such as cameras, lidars, etc... The perceptive constraints are expressed to maintain visibility of a feature point in the sensor's field of view, while performing a reference maneuver. We demonstrate both in simulation and real experiments that our framework is able to exploit the full capabilities of the multi-rotor to achieve the motion under the aforementioned constraints, and control in real-time the platform at a motor-torque level, to avoid the use of an intermediate unconstrained trajectory tracker.

- Coordinate-Free Dynamics and Differential Flatness of a Class of 6DOF Aerial Manipulators

    Author: Welde, Jake | University of Pennsylvania
    Author: Kumar, Vijay | University of Pennsylvania
 
    keyword: Aerial Systems: Mechanics and Control; Motion Control of Manipulators; Dynamics

    Abstract : In this work, we derive a coordinate-free formulation of the coupled dynamics of a class of 6DOF aerial manipulators consisting of an underactuated quadrotor equipped with a 2DOF articulated manipulator, and demonstrate that the system is differentially flat with respect to the end effector pose. In particular, we require the center of mass of the entire system to be fixed in the end effector frame, suggesting a reasonable mechanical design criterion. We make use of an inertial decoupling transformation to demonstrate differential flatness, allowing us to plan dynamically feasible trajectories for the system in the space of the 6DOF pose of the end effector, which is ideal for achieving precise manipulator tasks. Simulation results validate the flatness-based planning methodology for our dynamic model, and its usefulness is demonstrated in a simulated aerial videography task.

## Autonomous Driving 

- Goal Directed Occupancy Prediction for Lane Following Actors

    Author: Kaniarasu, Poornima | Uber Advanced Technology Group (Jan 11, 2016 - Dec 18, 2019)
    Author: Haynes, Galen Clark | Uber ATG
    Author: Marchetti-Bowick, Micol | Uber Advanced Technologies Group
 
    keyword: Autonomous Vehicle Navigation; Deep Learning in Robotics and Automation; Intelligent Transportation Systems

    Abstract : Predicting the possible future behaviors of vehicles that drive on shared roads is a crucial task for safe autonomous driving. Many existing approaches to this problem strive to distill all possible vehicle behaviors into a simplified set of high-level actions. However, these action categories do not suffice to describe the full range of maneuvers possible in the complex road networks we encounter in the real world. To combat this deficiency, we propose a new method that leverages the mapped road topology to reason over possible goals and predict the future spatial occupancy of dynamic road actors. We show that our approach is able to accurately predict future occupancy that remains consistent with the mapped lane geometry and naturally captures multi-modality based on the local scene context while also not suffering from the mode collapse problem observed in prior work.

- Intent-Aware Pedestrian Prediction for Adaptive Crowd Navigation

    Author: Katyal, Kapil | Johns Hopkins University Applied Physics Lab
    Author: Hager, Gregory | Johns Hopkins University
    Author: Huang, Chien-Ming | Johns Hopkins University
 
    keyword: Autonomous Vehicle Navigation; Human Detection and Tracking; Deep Learning in Robotics and Automation

    Abstract : Mobile robots capable of navigating seamlessly and safely in pedestrian rich environments promise to bring robotic assistance closer to our daily lives. In this paper we draw on insights of how humans move in crowded spaces to explore how to recognize pedestrian navigation intent, how to predict pedestrian motion and how a robot may adapt its navigation policy dynamically when facing unexpected human movements. Our approach is to develop algorithms that replicate this behavior. We experimentally demonstrate the effectiveness of our prediction algorithm using real-world pedestrian datasets and achieve comparable or better prediction accuracy compared to several state-of-the-art approaches. Moreover, we show that confidence of pedestrian prediction can be used to adjust the risk of a navigation policy adaptively to afford the most comfortable level as measured by the frequency of personal space violation in comparison with baselines. Furthermore, our adaptive navigation policy is able to reduce the number of collisions by 43% in the presence of novel pedestrian motion not seen during training.

- Brno Urban Dataset - the New Data for Self-Driving Agents and Mapping Tasks

    Author: Ligocki, Adam | Brno University of Technology
    Author: Jelinek, Ales | Brno University of Technology
    Author: Zalud, Ludek | Brno University of Technology
 
    keyword: Autonomous Vehicle Navigation; Range Sensing; Mapping

    Abstract : Autonomous driving is a dynamically growing field of research, where quality and amount of experimental data is critical. Although several rich datasets are available these days, the demands of researchers and technical possibilities are evolving. Through this paper, we bring a new dataset recorded in Brno - Czech Republic. It offers data from four WUXGA cameras, two 3D LiDARs, inertial measurement unit, infrared camera and especially differential RTK GNSS receiver with centimetre accuracy which, to the best knowledge of the     Authors, is not available from any other public dataset so far. In addition, all the data are precisely timestamped with sub-millisecond precision to allow wider range of applications. At the time of publishing of this paper, recordings of more than 350 km of rides in varying environment are shared at: https://github.com/RoboticsBUT/Brno-Urban-Dataset.

- Efficient Uncertainty-Aware Decision-Making for Automated Driving Using Guided Branching

    Author: Zhang, Lu | The Hong Kong University of Science and Technology
    Author: Ding, Wenchao | Hong Kong University of Science and Technology
    Author: Chen, Jing | Hong Kong University of Science and Technology
    Author: Shen, Shaojie | Hong Kong University of Science and Technology
 
    keyword: Autonomous Vehicle Navigation; Intelligent Transportation Systems

    Abstract : Decision-making in dense traffic scenarios is challenging for automated vehicles (AVs) due to potentially stochastic behaviors of other traffic participants and perception uncertainties (e.g., tracking noise and prediction errors, etc.). Although the partially observable Markov decision process (POMDP) provides a systematic way to incorporate these uncertainties, it quickly becomes computationally intractable when scaled to the real-world large-size problem. In this paper, we present an efficient uncertainty-aware decision-making (EUDM) framework, which generates long-term lateral and longitudinal behaviors in complex driving environments in real-time. The computation complexity is controlled to an appropriate level by two novel techniques, namely, the domain-specific closed-loop policy tree (DCP-Tree) structure and conditional focused branching (CFB) mechanism. The key idea is utilizing domain-specific expert knowledge to guide the branching in both action and intention space. The proposed framework is validated using both onboard sensing data captured by a real vehicle and an interactive multi-agent simulation platform. We also release the code of our framework to accommodate benchmarking.

- Imitative Reinforcement Learning Fusing Vision and Pure Pursuit for Self-Driving

    Author: Peng, Mingxing | Sun Yat-Sen University
    Author: Gong, Zhihao | Sun Yat-Sen University
    Author: Sun, Chen | University of Waterloo
    Author: Chen, Long | Sun Yat-Sen University
    Author: Cao, Dongpu | University of Waterloo
 
    keyword: Autonomous Vehicle Navigation; Autonomous Agents; Deep Learning in Robotics and Automation

    Abstract : Autonomous urban driving navigation is still an open problem and has ample room for improvement in unknown complex environments and terrible weather conditions. In this paper, we propose a two-stage framework, called IPP-RL, to handle these problems. IPP means an Imitation learning method fusing visual information with the additional steering angle calculated by Pure-Pursuit (PP) method, and RL means using Reinforcement Learning for further training. In our IPP model, the visual information captured by camera can be compensated by the calculated steering angle, thus it could perform well under bad weather conditions. However, imitation learning performance is limited by the driving data severely. Thus we use a reinforcement learning method-Deep Deterministic Policy Gradient (DDPG)-in the second stage training, which shares the learned weights from pretrained IPP model. In this way, our IPP-RL can lower the dependency of imitation learning on demonstration data and solve the problem of low exploration efficiency caused by randomly initialized weights in reinforcement learning. Moreover, we design a more reasonable reward function and use the n-step return to update the critic-network in DDPG. Our experiments on CARLA driving benchmark demonstrate that our IPP-RL is robust to lousy weather conditions and shows remarkable generalization capability in unknown environments on navigation task.

- Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian Recognition in Autonomous Driving

    Author: Savkin, Artem | TUM
    Author: Lapotre, Thomas | TUM
    Author: Strauss, Kevin | Technical Universtity of Munich
    Author: Akbar, Uzair | Technical University of Munich
    Author: Tombari, Federico | Technische Universitét M�nchen
 
    keyword: Autonomous Vehicle Navigation; Virtual Reality and Interfaces; Computer Vision for Transportation

    Abstract : In the autonomous driving area synthetic data is crucial for cover specific traffic scenarios which autonomous vehicle must handle. This data commonly introduces domain gap between synthetic and real domains. In this paper we deploy data augmentation to generate custom traffic scenarios with VRUs in order to improve pedestrian recognition. We provide a pipeline for augmentation of the Cityscapes dataset with virtual pedestrians. In order to improve augmentation realism of the pipeline we reveal a novel generative network architecture for adversarial learning of the data-set lighting conditions. We also evaluate our approach on the tasks of semantic and instance segmentation.


- A*3D Dataset: Towards Autonomous Driving in Challenging Environments

    Author: Pham, Quang-Hieu | Singapore University of Technology and Design (SUTD)
    Author: Sevestre, Pierre | CentraleSup�lec
    Author: Pahwa, Ramanpreet Singh | Institute for Infocomm Research, Singapore
    Author: Zhan, Huijing | Institute for Infocomm Research
    Author: Mustafa, Armin | University of Surrey
    Author: Pang, Chun Ho | Institute for Infocomm Research, A*STAR Research Entities
    Author: Chen, Yuda | Institute for Infocomm Research, A*STAR Research Entities
    Author: Chandrasekhar, Vijay | Institute for Infocomm Research
    Author: Lin, Jie | Institute for Infocomm Research
 
    keyword: Object Detection, Segmentation and Categorization; Performance Evaluation and Benchmarking; Deep Learning in Robotics and Automation

    Abstract : With the increasing global popularity of self-driving cars, there is an immediate need for challenging real-world datasets for benchmarking and training various computer vision tasks such as 3D object detection. Existing datasets either represent simple scenarios or provide only day-time data. In this paper, we introduce a new challenging A*3D dataset which consists of RGB images and LiDAR data with a significant diversity of scene, time, and weather. The dataset consists of high-density images (&#8776;10 times more than the pioneering KITTI dataset), heavy occlusions, a large number of night-time frames (&#8776;3 times the nuScenes dataset), addressing the gaps in the existing datasets to push the boundaries of tasks in autonomous driving research to more challenging highly diverse environments. The dataset contains 39K frames, 7 classes, and 230K 3D object annotations. An extensive 3D object detection benchmark evaluation on the A*3D dataset for various attributes such as high density, day-time/night-time, gives interesting insights into the advantages and limitations of training and testing 3D object detection in real-world setting.

- SegVoxelNet: Exploring Semantic Context and Depth-Aware Features for 3D Vehicle Detection from Point Cloud

    Author: Yi, Hongwei | Peking University
    Author: Shi, Shaoshuai | The Chinese University of Hong Kong
    Author: Ding, Mingyu | The University of Hong Kong
    Author: Sun, Jiankai | The Chinese University of Hong Kong
    Author: Xu, Kui | Tsinghua University
    Author: Zhou, Hui | Sensetime Group Limited
    Author: Wang, Zhe | SenseTime Group Limited
    Author: Li, Sheng | Peking University
    Author: Wang, Guoping | Peking University
 
    keyword: Object Detection, Segmentation and Categorization; Autonomous Vehicle Navigation; Autonomous Agents

    Abstract : 3D vehicle detection based on point cloud is a challenging task in real-world applications such as autonomous driving. Despite significant progress has been made, we observe two aspects to be further improved. First, the semantic context information in LiDAR is seldom explored in previous works, which may help identify ambiguous vehicles. Second, the distribution of point cloud on vehicles varies continuously with increasing depths, which may not be well modeled by a single model. In this work, we propose a unified model SegVoxelNet to address the above two problems. A semantic context encoder is proposed to leverage the free-of-charge semantic segmentation masks in the bird eye view. Suspicious regions could be highlighted while noisy regions are suppressed by this module. To better deal with vehicles at different depths, a novel depth-aware head is designed to explicitly model the distribution differences and each part of the depth-aware head is made to focus on its own target detection range. Extensive experiments on the KITTI dataset show that the proposed method outperforms the state-of-the-art alternatives in both accuracy and efficiency with point cloud as input only.

- Fine-Grained Driving Behavior Prediction Via Context-Aware Multi-Task Inverse Reinforcement Learning
 
    Author: Nishi, Kentaro | Yahoo Japan Corporation
    Author: Shimosaka, Masamichi | Tokyo Institute of Technology
 
    keyword: Big Data in Robotics and Automation; Learning from Demonstration; Motion and Path Planning

    Abstract : Research on advanced driver assistance systems for reducing risks to vulnerable road users (VRUs) has recently gained popularity because the traffic accident reduction rate for VRUs is still small. Dealing with unexpected VRU movements on residential roads requires proficient acceleration and deceleration. Although fine-grained prediction of driving behavior through inverse reinforcement learning (IRL) has been reported with promising results in recent years, learning of a precise model fails when driving strategies vary with contextual factors, i.e., weather, time of day, road width, and traffic direction. In this work, we propose a novel multi-task IRL approach with a multilinear reward function to incorporate contextual information into the model. This approach can provide precise long-term prediction of fine-grained driving behavior while adjusting to context. Experimental results using actual driving data over 141 km with various contexts and roads confirm the success of this approach in terms of predicting defensive driving strategy even in unknown situations.

- How to Keep HD Maps for Automated Driving up to Date

    Author: Pannen, David | BMW Group
    Author: Liebner, Martin | BMW Group
    Author: Hempel, Wolfgang | BMW Group
    Author: Burgard, Wolfram | Toyota Research Institute
 
    keyword: Mapping; Intelligent Transportation Systems; SLAM

    Abstract : The current state of the art in automotive high definition digital (HD) map generation based on dedicated mapping vehicles cannot reliably keep these maps up to date because of the low traversal frequencies. Anonymized data collected from the fleet of vehicles that is already on the road provides a huge potential to outperform such state of the art solutions in robustness, safety and up-to-dateness of the map while achieving comparable quality. We thus present a solution based on crowdsourced data to (i) detect changes in the map independent of the type of change, (ii) automatically trigger map update jobs for parts of the map, and (iii) create and integrate map patches to keep the map always up to date. The developed solution provides a crowdsourced up to date HD map to make reliable prior information on lane markings and road edges available to automated driving functions.

- Binary DAD-Net: Binarized Driveable Area Detection Network for Autonomous Driving

    Author: Frickenstein, Alexander | BMW Group
    Author: Vemparala, Manoj Rohit | BMW Group
    Author: Mayr, Jakob | BMW Group
    Author: Nagaraja, Naveen Shankar | BMW Group
    Author: Unger, Christian | BMW Group
    Author: Tombari, Federico | Technische Universitét M�nchen
    Author: Stechele, Walter | Technical University of Munich
 
    keyword: Object Detection, Segmentation and Categorization; Deep Learning in Robotics and Automation

    Abstract : Drivable area detection is a key component for various applications in the field of autonomous driving (AD), such as ground-plane detection, obstacle detection and maneuver planning. Additionally, bulky and over-parameterized networks can be easily forgone and replaced with smaller networks for faster inference on embedded systems. The drivable area detection, posed as a two class segmentation task, can be efficiently modeled with slim binary networks. This paper proposes a novel textit{binarized drivable area detection network (binary DAD-Net)}, which uses only binary weights and activations in the encoder, the bottleneck, and the decoder part. The latent space of the bottleneck is efficiently increased (x32 -&gt; x16 downsampling) through binary dilated convolutions, learning more complex features. Along with automatically generated training data, the binary DAD-Net outperforms state-of-the-art semantic segmentation networks on public datasets. In comparison to a full-precision model, our approach has a x14.3 reduced compute complexity on an FPGA and it requires only 0.9MB memory resources. Therefore, commodity SIMD-based AD-hardware is capable of accelerating the binary DAD-Net.

- Learning Robust Control Policies for End-To-End Autonomous Driving from Data-Driven Simulation

    Author: Amini, Alexander | Massachusetts Institute of Technology
    Author: Gilitschenski, Igor | Massachusetts Institute of Technology
    Author: Phillips, Jacob | Massachusetts Institute of Technology
    Author: Moseyko, Julia | Massachusetts Institute of Technology
    Author: Banerjee, Rohan | Massachusetts Institute of Technology
    Author: Karaman, Sertac | Massachusetts Institute of Technology
    Author: Rus, Daniela | MIT
 
    keyword: Deep Learning in Robotics and Automation; Visual Learning; Computer Vision for Transportation

    Abstract : In this work, we present a data-driven simulation and training engine capable of learning end-to-end autonomous vehicle control policies using only sparse rewards. By leveraging real, human-collected trajectories through an environment, we render novel training data that allows virtual agents to drive along a continuum of new local trajectories consistent with the road appearance and semantics, each with a different view of the scene. We demonstrate the ability of policies learned within our simulator to generalize to and navigate in previously unseen real-world roads, without access to any human control labels during training. Our results validate the learned policy onboard a full-scale autonomous vehicle, including in previously un-encountered scenarios, such as new roads and novel, complex, near-crash situations. Our methods are scalable, leverage reinforcement learning, and apply broadly to situations requiring effective perception and robust operation in the physical world.


- FG-GMM-Based Interactive Behavior Estimation for Autonomous Driving Vehicles in Ramp Merging Control

    Author: Lyu, Yiwei | Carnegie Mellon University
    Author: Dong, Chiyu | DiDi Labs
    Author: Dolan, John M. | Carnegie Mellon University
 
    keyword: Intelligent Transportation Systems

    Abstract : Interactive behavior is important for autonomous driving vehicles, especially for scenarios like ramp merging which require significant social interaction between autonomous driving vehicles and human-driven cars. This paper enhances our previous Probabilistic Graphical Model (PGM) merging control model for the interactive behavior of autonomous driving vehicles. To better estimate the interactive behavior for autonomous driving cars, a Factor Graph (FG) is used to describe the dependency among observations and estimate other cars' intentions. Real trajectories are used to approximate the model instead of human-designed models or cost functions. Forgetting factors and a Gaussian Mixture Model (GMM) are also applied in the intention estimation process for stabilization, interpolation and smoothness. The advantage of the factor graph is that the relationship between its nodes can be described by self-defined functions, instead of probabilistic relationships as in PGM, giving more flexibility. Continuity of GMM also provides higher accuracy than the previous discrete speed transition model. The proposed method enhances the overall performance of intention estimation, in terms of collision rate and average distance between cars after merging, which means it is safer and more efficient.

- Cooperative Perception and Localization for Cooperative Driving

    Author: Miller, Aaron | Carnegie Mellon University
    Author: Rim, Kyungzun | Carnegie Mellon University
    Author: Chopra, Parth | Honda R&amp;D Americas, Inc
    Author: Kelkar, Paritosh | Honda R&amp;D Americas, Inc
    Author: Likhachev, Maxim | Carnegie Mellon University
 
    keyword: Intelligent Transportation Systems; Sensor Fusion; Multi-Robot Systems

    Abstract : Fully autonomous vehicles are expected to share the road with less advanced vehicles for a significant period of time. Furthermore, an increasing number of vehicles on the road are equipped with a variety of low-fidelity sensors which provide some perception and localization data, but not at a high enough quality for full autonomy. In this paper, we develop a perception and localization system that allows a vehicle with low-fidelity sensors to incorporate high-fidelity observations from a vehicle in front of it, allowing both vehicles to operate with full autonomy. The resulting system generates perception and localization information that is both low-noise in regions covered by high-fidelity sensors and avoids false negatives in areas only observed by low-fidelity sensors, while dealing with latency and dropout of the communication link between the two vehicles. At its core, the system uses a set of Extended Kalman filters which incorporate observations from both vehicles' sensors and extrapolate them using information about the road geometry. The perception and localization algorithms are evaluated both in simulation and on real vehicles as part of a full cooperative driving system.

- Learning to Drive Off Road on Smooth Terrain in Unstructured Environments Using an On-Board Camera and Sparse Aerial Images

    Author: Manderson, Travis | McGill University
    Author: Wapnick, Stefan | McGill University
    Author: Meger, David Paul | McGill University
    Author: Dudek, Gregory | McGill University
 
    keyword: Learning and Adaptive Systems

    Abstract : We present a method for learning to drive on smooth terrain while simultaneously avoiding collisions in challenging off-road and unstructured outdoor environments using only visual inputs. Our approach applies a hybrid model-based and model-free reinforcement learning method that is entirely self-supervised in labeling terrain roughness and collisions using on-board sensors. Notably, we provide both first-person and overhead aerial image inputs to our model. We find that the fusion of these complementary inputs improves planning foresight and makes the model robust to visual obstructions. Our results show the ability to generalize to environments with plentiful vegetation, various types of rock, and sandy trails. During evaluation, our policy attained 90% smooth terrain traversal and reduced the proportion of rough terrain driven over by 6.1 times compared to a model using only first-person imagery. Video and project details can be found at www.cim.mcgill.ca/mrl/offroad_driving/

- RoadTrack: Realtime Tracking of Road Agents in Dense and Heterogeneous Environments

    Author: Chandra, Rohan | University of Maryland
    Author: Bhattacharya, Uttaran | UMD College Park
    Author: Randhavane, Tanmay | UNC
    Author: Bera, Aniket | University of Maryland
    Author: Manocha, Dinesh | University of Maryland
 
    keyword: Intelligent Transportation Systems; Visual Tracking; Agent-Based Systems

    Abstract : We present a realtime tracking algorithm, RoadTrack, to track heterogeneous road-agents in dense traffic videos. Our approach is designed for traffic scenarios that consist of different road-agents such as pedestrians, two-wheelers, cars, buses, etc. sharing the road. We use the tracking-by-detection approach where we track a road-agent by matching the appearance or bounding box region in the current frame with the predicted bounding box region propagated from the previous frame. Roadtrack uses a novel motion model called the Simultaneous Collision Avoidance and Interaction (SimCAI) model to predict the motion of road-agents by modeling collision avoidance and interactions between the road-agents for the next frame. We demonstrate the advantage of RoadTrack on a dataset of dense traffic videos and observe an accuracy of 75.8% on this dataset, outperforming prior state-of-the-art tracking algorithms by at least 5.2%. RoadTrack operates in realtime at approximately 30 fps and is at least 4 times faster than prior tracking algorithms on standard tracking datasets.

- Cooperative Control of Heterogeneous Connected Vehicle Platoons: An Adaptive Leader-Following Approach

    Author: Hu, Junyan | The University of Manchester
    Author: Bhowmick, Parijat | University of Manchester
    Author: Arvin, Farshad | University of Manchester
    Author: Lanzon, Alexander | The University of Manchester
    Author: Lennox, Barry | The University of Manchester
 
    keyword: Intelligent Transportation Systems; Robust/Adaptive Control of Robotic Systems; Motion Control

    Abstract : Automatic cruise control of a platoon of multiple connected vehicles in an automated highway system has drawn significant attention of the control practitioners over the past two decades due to its ability to reduce traffic congestion problems, improve traffic throughput and enhance safety of highway traffic. This paper proposes a two-layer distributed control scheme to maintain the string stability of a heterogeneous and connected vehicle platoon moving in one dimension with constant spacing policy assuming constant velocity of the lead vehicle. A feedback linearization tool is applied first to transform the nonlinear vehicle dynamics into a linear heterogeneous state-space model and then a distributed adaptive control protocol has been designed to keep equal inter-vehicular spacing between any consecutive vehicles while maintaining a desired longitudinal velocity of the entire platoon. The proposed scheme utilizes only the neighbouring state information (i.e. relative distance, velocity and acceleration) and the leader is not required to communicate with each and every one of the following vehicles directly since the interaction topology of the vehicle platoon is designed to have a spanning tree rooted at the leader. Simulation results demonstrated the effectiveness of the proposed platoon control scheme. Moreover, the practical feasibility of the scheme was validated by hardware experiments with real robots.

- Semantic Segmentation with Unsupervised Domain Adaptation under Varying Weather Conditions for Autonomous Vehicles

    Author: Erkent, Ozgur | Inria
    Author: Laugier, Christian | INRIA
 
    keyword: Intelligent Transportation Systems; Semantic Scene Understanding; Learning and Adaptive Systems

    Abstract : Semantic information provides a valuable source for scene understanding around autonomous vehicles in order to plan their actions and make decisions; however, varying weather conditions reduce the accuracy of the semantic segmentation. We propose a method to adapt to varying weather conditions without supervision, namely without labeled data. We update the parameters of a deep neural network (DNN) model that is pre-trained on the known weather condition (source domain) to adapt it to the new weather conditions (target domain) without forgetting the segmentation in the known weather condition. Furthermore, we don't require the labels from the source domain during adaptation training. The parameters of the DNN are optimized to reduce the distance between the distribution of the features from the images of old and new weather conditions. To measure this distance, we propose three alternatives: W-GAN, GAN and maximum-mean discrepancy (MMD). We evaluate our method on various datasets with varying weather conditions. The results show that the accuracy of the semantic segmentation is improved for varying conditions after adaptation with the proposed method.

- Deep Merging: Vehicle Merging Controller Based on Deep Reinforcement Learning with Embedding Network

    Author: Ippei, Nishitani | Toyota Motor Corporation
    Author: Yang, Hao | McMaster University
    Author: Guo, Rui | Toyota InfoTechnology Center USA
    Author: Keshavamurthy, Shalini | Toyota North America
    Author: Oguchi, Kentaro | Toyota InfoTechnology Center, USA
 
    keyword: Deep Learning in Robotics and Automation; Autonomous Vehicle Navigation; AI-Based Methods

    Abstract : Vehicles at highway merging sections must make lane changes to join the highway. This lane change can generate congestion. To reduce congestion, vehicles should merge so as not to affect traffic flow as much as possible. In our study, we propose a vehicle controller called Deep Merging that uses deep reinforcement learning to improve the merging efficiency of vehicles while considering the impact on traffic flow. The system uses the images of a merging section as input to output the target vehicle speed. Moreover, an embedding network for estimating the controlled vehicle speed is introduced to the deep reinforcement learning network architecture to improve the learning efficiency. In order to show the effectiveness of the proposed method, the merging behavior and traffic conditions in several situations are verified by experiments using a traffic simulator. Through these experiments, it is confirmed that the proposed method enables controlled vehicles to effectively merge without adversely affecting to the traffic flow.

- Radar As a Teacher: Weakly Supervised Vehicle Detection Using Radar Labels

    Author: Chadwick, Simon | University of Oxford
    Author: Newman, Paul | Oxford University
 
    keyword: Deep Learning in Robotics and Automation; Object Detection, Segmentation and Categorization

    Abstract : It has been demonstrated that the performance of an object detector degrades when it is used outside the domain of the data used to train it. However, obtaining training data for a new domain can be time consuming and expensive. In this work we demonstrate how a radar can be used to generate plentiful (but noisy) training data for image-based vehicle detection. We then show that the performance of a detector trained using the noisy labels can be considerably improved through a combination of noise-aware training techniques and relabelling of the training data using a second viewpoint. In our experiments, using our proposed process improves average precision by more than 17 percentage points when training from scratch and 10 percentage points when fine-tuning a pre-trained model.

- Robust Lane Detection with Binary Integer Optimization

    Author: Brandes, Kathleen | Massachusetts Institute of Technology
    Author: Wang, Allen | Massachusetts Institute of Technology
    Author: Shah, Rushina | Massachusetts Institute of Technology
 
    keyword: Autonomous Vehicle Navigation; Motion and Path Planning; Optimization and Optimal Control

    Abstract : Formula Student Driverless (FSD) is a competition where student teams compete to build an autonomous racecar. The main dynamic event in FSD is trackdrive, where the racecar traverses an unknown track whose boundaries are demarcated by cones. One challenge of the event is to determine the track boundaries based on cone locations in the presence of false positive cone detections, sharp turns and uncertain cone color information while traversing the track. In this work, we present a binary integer optimization that encapsulates this problem, along with taking into account competition rule specifications, such as cone spacing and track width. This optimization routine is implemented in simulation, and on an autonomous electric racecar. We present our approach, and analyze its latency, accuracy, and robustness to uncertain cone detections. This approach is used on-vehicle to solve the real-time boundary generation problem during the competition.

- A Synchronization Approach for Achieving Cooperative Adaptive Cruise Control Based Non-Stop Intersection Passing

    Author: Liu, Zhe | The Chinese University of Hong Kong
    Author: Wei, Huanshu | Chinese University of Hong Kong
    Author: Hu, Hanjiang | Shanghai Jiao Tong University
    Author: Suo, Chuanzhe | The Chinese University of Hong Kong
    Author: Wang, Hesheng | Shanghai Jiao Tong University
    Author: Li, Haoang | The Chinese University of Hong Kong
    Author: Liu, Yunhui | Chinese University of Hong Kong
 
    keyword: Intelligent Transportation Systems; Autonomous Vehicle Navigation

    Abstract : Cooperative adaptive cruise control (CACC) of intelligent vehicles contributes to improving cruise control performance, reducing traffic congestion, saving energy and increasing traffic flow capacity. In this paper, we resolve the CACC problem from the viewpoint of synchronization control, our main idea is to introduce the spatial-temporal synchronization mechanism into vehicle platoon control to achieve the robust CACC and to further realize the non-stop intersection control. Firstly, by introducing the cross-coupling based space synchronization mechanism, a distributed control algorithm is presented to achieve the single-lane CACC in the presence of vehicle-to-vehicle (V2V) communications, which enables autonomous vehicles to track the desired platoon trajectory while synchronizing their longitudinal velocities to keeping the expected inter-vehicle distance. Secondly, by designing the enter-time scheduling mechanism (temporal synchronization), a high-level intersection control strategy is proposed to command vehicles to form a virtual platoon to pass through the intersection without stopping. Thirdly, a Lyapunov-based time-domain stability analysis approach is presented. Compared with the traditional string stability based approach, the proposed approach guarantees the global asymptotical convergence of the proposed CACC system. Experiments in the small-scale simulated system demonstrate the effectiveness of the proposed approach.

- Self-Supervised Linear Motion Deblurring

    Author: Liu, Peidong | ETH Zurich
    Author: Janai, Joel | Max Planck Institute for Intelligent Systems, Autonomous Vision
    Author: Pollefeys, Marc | ETH Zurich
    Author: Sattler, Torsten | Chalmers University of Technology
    Author: Geiger, Andreas | Max Planck Institute for Intelligent Systems, Tübingen
 
    keyword: Deep Learning in Robotics and Automation; Computer Vision for Other Robotic Applications; Computer Vision for Automation

    Abstract : Motion blurry images challenge many computer vision algorithms, e.g., feature detection, motion estimation, or object recognition. Deep convolutional neural networks are state-of-the-art for image deblurring. However, obtaining training data with corresponding sharp and blurry image pairs can be difficult. In this paper, we present a differentiable reblur model for self-supervised motion deblurring, which enables the network to learn from real-world blurry image sequences without relying on sharp images for supervision. Our key insight is that motion cues obtained from consecutive images yield sufficient information to inform the deblurring task. We therefore formulate deblurring as an inverse rendering problem, taking into account the physical image formation process: we first predict two deblurred images from which we estimate the corresponding optical flow. Using these predictions, we re-render the blurred images and minimize the difference with respect to the original blurry inputs. We use both synthetic and real dataset for experimental evaluations. Our experiments demonstrate that self-supervised single image deblurring is really feasible and leads to visually compelling results.

- Urban Driving with Conditional Imitation Learning

    Author: Hawke, Jeffrey | Wayve
    Author: Shen, Richard | Wayve
    Author: Gurau, Corina | Oxford University
    Author: Sharma, Siddharth | Wayve Technologies
    Author: Reda, Daniele | University of British Columbia // Wayve
    Author: Nikolov, Nikolay | Imperial College London
    Author: Mazur, Przemys&#322;aw | Wayve Technologies
    Author: Micklethwaite, Sean David | Wayve
    Author: Shah, Amar | Wayve
    Author: Kendall, Alex | University of Cambridge
 
    keyword: Deep Learning in Robotics and Automation; AI-Based Methods; Computer Vision for Transportation

    Abstract : Hand-crafting generalised decision-making rules for real-world urban autonomous driving is hard. Alternatively, learning behaviour from easy-to-collect human driving demonstrations is appealing. Prior work has studied imitation learning (IL) for autonomous driving with a number of limitations. Examples include only performing lane-following rather than following a user-defined route, only using a single camera view or heavily cropped frames lacking state observability, only lateral (steering) control, but not longitudinal (speed) control and a lack of interaction with traffic. Importantly, the majority of such systems have been primarily evaluated in simulation - a simple domain, which lacks real-world complexities. Motivated by these challenges, we focus on learning representations of semantics, geometry and motion with computer vision for IL from human driving demonstrations. As our main contribution, we present an end-to-end conditional imitation learning approach, combining both lateral and longitudinal control on a real vehicle for following urban routes with simple traffic. We address inherent dataset bias by data balancing, training our final policy on approximately 30 hours of demonstrations gathered over six months. We evaluate our method on an autonomous vehicle by driving 35km of novel routes in European urban streets.


- Simulation-Based Reinforcement Learning for Real-World Autonomous Driving

    Author: Osi&#324;ski, B&#322;a&#380;ej | University of Warsaw, Deepsense.ai
    Author: Jakubowski, Adam | Deepsense.ai
    Author: Zi&#281;cina, Pawe&#322; | Deepsense.ai
    Author: Mi&#322;o&#347;, Piotr | Institute of Mathematics of the Polish Academy of Sciences, Deep
    Author: Galias, Christopher | Jagiellonian University, Deepsense.ai
    Author: Homoceanu, Silviu | Volkswagen AG
    Author: Michalewski, Henryk | University of Warsaw
 
    keyword: Autonomous Vehicle Navigation; Visual-Based Navigation; Deep Learning in Robotics and Automation

    Abstract : We use reinforcement learning in simulation to obtain a driving system controlling a full-size real-world vehicle. The driving policy takes RGB images from a single camera and their semantic segmentation as input. We use mostly synthetic data, with labelled real-world data appearing only in the training of the segmentation network.<p>Using reinforcement learning in simulation and synthetic data is motivated by lowering costs and engineering effort.</p><p>In real-world experiments we confirm that we achieved successful sim-to-real policy transfer. Based on the extensive evaluation, we analyze how design decisions about perception, control, and training impact the real-world performance.

- Driving Style Encoder: Situational Reward Adaptation for General-Purpose Planning in Automated Driving

    Author: Rosbach, Sascha | Volkswagen AG
    Author: James, Vinit | Volkswagen AG
    Author: Grossjohann, Simon | Volkswagen AG
    Author: Homoceanu, Silviu | Volkswagen AG
    Author: Li, Xing | Volkswagen AG
    Author: Roth, Stefan | TU Darmstadt
 
    keyword: Learning from Demonstration; Deep Learning in Robotics and Automation; Motion and Path Planning

    Abstract :  General-purpose planning algorithms for automated driving combine mission, behavior, and local motion planning. Such planning algorithms map features of the environment and driving kinematics into complex reward functions. To achieve this, planning experts often rely on linear reward functions. The specification and tuning of these reward functions is a tedious process and requires significant experience. Moreover, a manually designed linear reward function does not generalize across different driving situations. In this work, we propose a deep learning approach based on inverse reinforcement learning that generates situation-dependent reward functions. Our neural network provides a mapping between features and actions of sampled driving policies of a model-predictive control-based planner and predicts reward functions for upcoming planning cycles. In our evaluation, we compare the driving style of reward functions predicted by our deep network against clustered and linear reward functions. Our proposed deep learning approach outperforms clustered linear reward functions and is at par with linear reward functions with a-priori knowledge about the situation.

- Analysis and Prediction of Pedestrian Crosswalk Behavior During Automated Vehicle Interactions

    Author: Jayaraman, Suresh Kumaar | University of Michigan
    Author: Tilbury, Dawn | University of Michigan
    Author: Yang, X. Jessie | University of Michigan
    Author: Pradhan, Anuj | University of Massachusetts Amherst
    Author: Robert, Lionel | University of Michigan
 
    keyword: Autonomous Vehicle Navigation; Human-Centered Robotics; Human Detection and Tracking

    Abstract : For safe navigation around pedestrians, automated vehicles (AVs) need to plan their motion by accurately predicting pedestrians' trajectories over long time horizons. Current approaches to AV motion planning around crosswalks predict only for short time horizons (1-2 s) and are based on data from pedestrian interactions with human-driven vehicles (HDVs). In this paper, we develop a hybrid systems model that uses pedestrians' gap acceptance behavior and constant velocity dynamics for long-term pedestrian trajectory prediction when interacting with AVs. Results demonstrate the applicability of the model for long-term (&gt; 5 s) pedestrian trajectory prediction at crosswalks. Further, we compared measures of pedestrian crossing behaviors in the immersive virtual environment (when interacting with AVs) to that in the real world (results of published studies of pedestrians interacting with HDVs), and found similarities between the two. These similarities demonstrate the applicability of the hybrid model of AV interactions developed from an immersive virtual environment (IVE) for real-world scenarios for both AVs and HDVs.

- The Oxford Radar RobotCar Dataset: A Radar Extension to the Oxford RobotCar Dataset

    Author: Barnes, Dan | University of Oxford
    Author: Gadd, Matthew | University of Oxford
    Author: Murcutt, Paul | Oxford University
    Author: Newman, Paul | Oxford University
    Author: Posner, Ingmar | Oxford University
 
    keyword: Big Data in Robotics and Automation; Autonomous Vehicle Navigation; SLAM

    Abstract : In this paper we present The Oxford Radar RobotCar Dataset, a new dataset for researching scene understanding using Millimetre-Wave FMCW scanning radar data.The target application is autonomous vehicles where this modality is robust to environmental conditions such as fog, rain, snow, or lens flare, which typically challenge other sensor modalities such as vision and LIDAR.<p>The data were gathered in January 2019 over thirty-two traversals of a central Oxford route spanning a total of 280km of urban driving. It encompasses a variety of weather, traffic, and lighting conditions. This 4.7TB dataset consists of over 240000 scans from a Navtech CTS350-X radar and 2.4 million scans from two Velodyne HDL-32E 3D LIDARs; along with six cameras, two 2D LIDARs, and a GPS/INS receiver. In addition we release ground truth optimised radar odometry to provide an additional impetus to research in this domain. </p><p>The full dataset is available for download at: ori.ox.ac.uk/datasets/radar-robotcar-dataset

- Multi-Modal Experts Network for Autonomous Driving

    Author: Fang, Shihong | New York University
    Author: Choromanska, Anna | New York University Tandon School of Engineering
 
    keyword: Autonomous Vehicle Navigation; Deep Learning in Robotics and Automation

    Abstract : End-to-end learning from sensory data has shown promising results in autonomous driving. While employing many sensors enhances world perception and should lead to more robust and reliable behavior of autonomous vehicles, it is challenging to train and deploy such network and at least two problems are encountered in the considered setting. The first one is the increase of computational complexity with the number of sensing devices. The other is the phenomena of network overfitting to the simplest and most informative input. We address both challenges with a novel, carefully tailored multi-modal experts network architecture and propose a multi-stage training procedure. The network contains a gating mechanism, which selects the most relevant input at each inference time step using a mixed discrete-continuous policy. We demonstrate the plausibility of the proposed approach on our 1/6 scale truck equipped with three cameras and one LiDAR.

- Spatiotemporal Relationship Reasoning for Pedestrian Intent Prediction

    Author: Liu, Bingbin | Stanford University
    Author: Adeli, Ehsan | Stanford University
    Author: Cao, Zhangjie | Stanford University
    Author: Lee, Kuan-Hui | Toyota Research Institute
    Author: Shenoi, Abhijeet | Stanford University
    Author: Gaidon, Adrien | Toyota Research Institute
    Author: Niebles, Juan Carlos | Stanford University
 
    keyword: Autonomous Vehicle Navigation; Visual-Based Navigation; Computer Vision for Transportation

    Abstract : Reasoning over visual data is a desirable capability for robotics applications. Such reasoning enables forecasting of the next events or actions in videos. In recent years, various models have been developed based on convolution operations for prediction or forecasting, but they lack the ability to reason over spatiotemporal data and infer the relationships of objects in the scene. In this paper, we present a framework based on graph convolution to uncover the spatiotemporal relationships in the scene for reasoning about pedestrian intent. A scene graph is built on top of segmented object instances within and across video frames. Pedestrian intent (future action of crossing or not-crossing) is crucial information for autonomous vehicles to navigate safely and smoothly. We approach the problem of intent prediction from two different perspectives and anticipate the intention-to-cross. We introduce a new dataset designed specifically for autonomous-driving scenarios in areas with dense pedestrian populations: the Stanford-TRI Intent Prediction (STIP) dataset. Our experiments on STIP and another benchmark dataset show that our graph modeling framework is able to predict the intention-to-cross of the pedestrians with an accuracy of 79.10% on STIP and 79.28% on Joint Attention for Autonomous Driving (JAAD) dataset up to one second earlier than when the actual crossing happens. These results outperform baseline and previous work. Refer to stip.stanford.edu for dataset and code.

- TunerCar: A Superoptimization Toolchain for Autonomous Racing

    Author: O'Kelly, Matthew | University of Pennsylvania
    Author: Zheng, Hongrui | University of Pennsylvania
    Author: Jain, Achin | University of Pennsylvania
    Author: Auckley, Joseph | University of Pennsylvania
    Author: Luong, Kim | University of Pennsylvania
    Author: Mangharam, Rahul | University of Pennsylvania
 
    keyword: Autonomous Vehicle Navigation; Motion and Path Planning; Education Robotics

    Abstract : TunerCar is a toolchain that jointly optimizes racing strategy, planning methods, control algorithms, and vehicle parameters for an autonomous racecar. In this paper, we detail the target hardware, software, simulators, and systems infrastructure for this toolchain. Our methodology employs a parallel implementation of CMA-ES which enables simulations to proceed 6 times faster than real-world rollouts. We show our approach can reduce the lap times in autonomous racing, given a fixed computational budget. For all tested tracks, our method provides the lowest lap time, and relative improvements in lap time between 7-21%. We demonstrate improvements over a naive random search method with equivalent computational budget of over 15 seconds/lap, and improvements over expert solutions of over 2 seconds/lap. We further compare the performance of our method against hand-tuned solutions submitted by over 30 international teams, comprised of graduate students working in the field of autonomous vehicles. Finally, we discuss the effectiveness of utilizing an online planning mechanism to reduce the reality gap between our simulation and actual tests.

- Risk Assessment and Planning with Bidirectional Reachability for Autonomous Driving

    Author: Yu, Ming-Yuan | University of Michigan
    Author: Johnson-Roberson, Matthew | University of Michigan
    Author: Vasudevan, Ram | University of Michigan
 
    keyword: Autonomous Vehicle Navigation; Collision Avoidance; Motion and Path Planning

    Abstract : Risk assessment to quantify the danger associated with taking a certain action is critical to navigating safely through crowded urban environments during autonomous driving. Risk assessment and subsequent planning is usually done by first tracking and predicting trajectories of other agents, such as vehicles and pedestrians, and then choosing an action to avoid future collisions. However, few existing risk assessment algorithms handle occlusion and other sensory limitations effectively. One either assesses the risk in the worst-case scenario and thus makes the ego vehicle overly conservative, or predicts as many hidden agents as possible and thus makes the computation intensive. This paper explores the possibility of efficient risk assessment under occlusion via both forward and backward reachability. The proposed algorithm can not only identify the location of risk-inducing factors, but can also be used during motion planning. The proposed method is evaluated on various four-way highly occluded intersections with up to five other vehicles in the scene. Compared with other risk assessment algorithms, the proposed method shows better efficiency, meaning that the ego vehicle reaches the goal at a higher speed. In addition, it also lowers the median collision rate by 7.5� when compared to state of the art techniques.

- MapLite: Autonomous Intersection Navigation without a Detailed Prior Map

    Author: Ort, Teddy | Massachusetts Institute of Technology
    Author: Jatavallabhula, Krishna | Mila, Universite De Montreal
    Author: Banerjee, Rohan | Massachusetts Institute of Technology
    Author: Gottipati, Sai Krishna | MILA, University of Montreal
    Author: Bhatt, Dhaivat | IIIT-Hyderabad
    Author: Gilitschenski, Igor | Massachusetts Institute of Technology
    Author: Paull, Liam | Université De Montr�al
    Author: Rus, Daniela | MIT
 
    keyword: Autonomous Vehicle Navigation; Intelligent Transportation Systems; Field Robots

    Abstract : In this work, we present MapLite: a one-click autonomous navigation system capable of piloting a vehicle to an arbitrary desired destination point given only a sparse publicly available topometric map (from OpenStreetMap). The onboard sensors are used to segment the road region and register the topometric map in order to fuse the high-level navigation goals with a variational path planner in the vehicle frame. This enables the system to plan trajectories that correctly navigate road intersections without the use of an external localization system such as GPS or a detailed prior map. Since the topometric maps already exist for the vast majority of roads, this solution greatly increases the geographical scope for autonomous mobility solutions. We implement MapLite on a full-scale autonomous vehicle and exhaustively test it on over 15km of road including over 100 autonomous intersection traversals. We further extend these results through simulated testing to validate the system on complex road junction topologies such as traffic circles.

- Game Theoretic Decision Making Based on Real Sensor Data for Autonomous Vehicles' Maneuvers in High Traffic

    Author: Garzon Oviedo, Mario | Delft University of Technology
    Author: Spalanzani, Anne | INRIA / Univ. Grenoble Alpes
 
    keyword: Autonomous Vehicle Navigation; Intelligent Transportation Systems; Cognitive Human-Robot Interaction

    Abstract : This paper presents an approach for implementing game theoretic decision making in combination with realistic sensory data input so as to allow an autonomous vehicle to perform manoeuvrers, such as lane change or merge in high traffic scenarios. The main novelty of this work, is the use of realistic sensory data input to obtain the observations as input of an iterative multi-player game in a realistic simulator. The game model allows to anticipate reactions of additional vehicles to the movements of the ego-vehicle without using any specific coordination or vehicle-to-vehicle communication. Moreover, direct information from the simulator, such as position or speed of the vehicles is also avoided. <p>The solution of the game is based on cognitive hierarchy reasoning and it uses Monte Carlo reinforcement learning in order to obtain a near-optimal policy towards a specific goal. Moreover, the game proposed is capable of solving different situations using a single policy. The system has been successfully tested and compared with previous techniques using a realistic hybrid simulator, where the ego-vehicle and its sensors are simulated on a 3D simulator and the additional vehicles' behaviour is obtained from a traffic simulator.

- Driving in Dense Traffic with Model-Free Reinforcement Learning

    Author: Saxena, Dhruv Mauria | The Robotics Institute, Carnegie Mellon University
    Author: Bae, Sangjae | University of California, Berkeley
    Author: Nakhaei, Alireza | Honda Research Institute USA
    Author: Fujimura, Kikuo | Honda Research Institute
    Author: Likhachev, Maxim | Carnegie Mellon University
 
    keyword: Autonomous Vehicle Navigation; Autonomous Agents; Sensor-based Control

    Abstract : Traditional planning and control methods could fail to find a feasible trajectory for an autonomous vehicle to execute amongst dense traffic on roads. This is because the obstacle-free volume in spacetime is very small in these scenarios for the vehicle to drive through. However, that does not mean the task is infeasible since human drivers are known to be able to drive amongst dense traffic by leveraging the cooperativeness of other drivers to open a gap. The traditional methods fail to take into account the fact that the actions taken by an agent affect the behaviour of other vehicles on the road. In this work, we rely on the ability of deep reinforcement learning to implicitly model such interactions and learn a continuous control policy over the action space of an autonomous vehicle. The application we consider requires our agent to negotiate and open a gap in the road in order to successfully merge or change lanes. Our policy learns to repeatedly probe into the target road lane while trying to find a safe spot to move in to. We compare against two model-predictive control-based algorithms and show that our policy outperforms them in simulation. As part of this work, we introduce a benchmark for driving in dense traffic for use by the community.

- Enhancing Game-Theoretic Autonomous Car Racing Using Control Barrier Functions

    Author: Notomista, Gennaro | Georgia Institute of Technology
    Author: Wang, Mingyu | Stanford University
    Author: Schwager, Mac | Stanford University
    Author: Egerstedt, Magnus | Georgia Institute of Technology
 
    keyword: Autonomous Vehicle Navigation; Path Planning for Multiple Mobile Robots or Agents; Multi-Robot Systems

    Abstract : In this paper, we consider a two-player racing game, where an autonomous ego vehicle has to be controlled to race against an opponent vehicle, which is either autonomous or human-driven. The approach to control the ego vehicle is based on a Sensitivity-ENhanced NAsh equilibrium seeking (SENNA) method, which uses an iterated best response algorithm in order to optimize for a trajectory in a two-car racing game. This method exploits the interactions between the ego and the opponent vehicle that take place through a collision avoidance constraint. This game-theoretic control method hinges on the ego vehicle having an accurate model and correct knowledge of the state of the opponent vehicle. However, when an accurate model for the opponent vehicle is not available, or the estimation of its state is corrupted by noise, the performance of the approach might be compromised. For this reason, we augment the SENNA algorithm by enforcing Permissive RObust SafeTy (PROST) conditions using control barrier functions. The objective is to successfully overtake or to remain in the front of the opponent vehicle, even when the information about the latter is not fully available. The successful synergy between SENNA and PROST�antithetical to the notable rivalry between the two namesake Formula 1 drivers�is demonstrated through extensive simulated experiments.




- CMTS: An Conditional Multiple Trajectory Synthesizer for Generating Safety-Critical Driving Scenarios

    Author: Ding, Wenhao | Carnegie Mellon University
    Author: Xu, Mengdi | Carnegie Mellon University
    Author: Zhao, Ding | Carnegie Mellon University
 
    keyword: Autonomous Vehicle Navigation; Deep Learning in Robotics and Automation; Intelligent Transportation Systems

    Abstract : Naturalistic driving trajectory generation is crucial for the development of autonomous driving algorithms. However, most of the data is collected in collision-free scenarios leading to the sparsity of the safety-critical cases. When considering safety, testing algorithms in near-miss scenarios that rarely show up in off-the-shelf datasets and are costly to accumulate is a vital part of the evaluation. As a remedy, we propose a safety-critical data synthesizing framework based on variational Bayesian methods and term it as Conditional Multiple Trajectory Synthesizer (CMTS). We extend a generative model to connect safe and collision driving data by representing their distribution in the latent space and use conditional probability to adapt to different maps. Sampling from the mixed distribution enables us to synthesize the safety-critical data not shown in the safe or collision datasets. Experimental results demonstrate that the generated dataset covers many different realistic scenarios, especially the near-misses. We conclude that the use of data generated by CMTS can improve the accuracy of trajectory predictions and autonomous vehicle safety.

- LiDAR Inertial Odometry Aided Robust LiDAR Localization System in Changing City Scenes

    Author: Ding, Wendong | Baidu
    Author: Hou, Shenhua | Baidu
    Author: Gao, Hang | Baidu
    Author: Wan, Guowei | Baidu
    Author: Song, Shiyu | Baidu
 
    keyword: Autonomous Vehicle Navigation; Localization

    Abstract : Environmental fluctuations pose crucial challenges to a localization system in autonomous driving. We present a robust LiDAR localization system that maintains its kinematic estimation in changing urban scenarios by using a dead reckoning solution implemented through a LiDAR inertial odometry. Our localization framework jointly uses information from complementary modalities such as global matching and LiDAR inertial odometry to achieve accurate and smooth localization estimation. To improve the performance of the LiDAR odometry, we incorporate inertial and LiDAR intensity cues into an occupancy grid based LiDAR odometry to enhance frame-to-frame motion and matching estimation. Multi-resolution occupancy grid is implemented yielding a coarse-to-fine approach to balance the odometry's precision and computational requirement. To fuse both the odometry and global matching results, we formulate a MAP estimation problem in a pose graph fusion framework that can be efficiently solved. An effective environmental change detection method is proposed that allows us to know exactly when and what portion of the map requires an update. We comprehensively validate the effectiveness of the proposed approaches using both the Apollo-SouthBay dataset and our internal dataset. The results confirm that our efforts lead to a more robust and accurate localization system, especially in dynamically changing urban scenarios.

- Dynamic Interaction-Aware Scene Understanding for Reinforcement Learning in Autonomous Driving

    Author: Huegle, Maria | University of Freiburg
    Author: Kalweit, Gabriel | University of Freiburg
    Author: Werling, Moritz | Karlsruhe Institute of Technology
    Author: Boedecker, Joschka | University of Freiburg
 
    keyword: Autonomous Vehicle Navigation; Deep Learning in Robotics and Automation; Learning and Adaptive Systems

    Abstract : The common pipeline in autonomous driving systems is highly modular and includes a perception component which extracts lists of surrounding objects and passes these lists to a high-level decision component. In this case, leveraging the benefits of deep reinforcement learning for high-level decision making requires special architectures to deal with multiple variable-length sequences of different object types, such as vehicles, lanes or traffic signs. At the same time, the architecture has to be able to cover interactions between traffic participants in order to find the optimal action to be taken. In this work, we propose the novel Deep Scenes architecture, that can learn complex interaction-aware scene representations based on extensions of either 1) Deep Sets or 2) Graph Convolutional Networks. We present the Graph-Q and DeepScene-Q off-policy reinforcement learning algorithms, both outperforming state-of-the-art methods in evaluations with the publicly available traffic simulator SUMO.

- Interacting Vehicle Trajectory Prediction with Convolutional Recurrent Neural Networks

    Author: Mukherjee, Saptarshi | Heriot Watt University
    Author: Wang, Sen | Edinburgh Centre for Robotics, Heriot-Watt University
    Author: Wallace, Andrew M. | Heriot-Watt University
 
    keyword: Autonomous Vehicle Navigation; Intelligent Transportation Systems

    Abstract : Anticipating the future trajectories of surrounding vehicles is a crucial and challenging task in path planning for autonomous vehicles. In this paper, we propose a novel Convolutional Long Short Term Memory (Conv-LSTM) based neural network architecture to predict future positions of cars using several seconds of historical driving observations. This consists of three parts: 1) Interaction Learning to capture the effect of surrounding cars, 2) Temporal Learning to identify the dependency on past movements and 3) Motion Learning to convert the extracted features from these two modules into future positions. To continuously achieve accurate prediction,we introduce a novel feedback based prediction scheme where the current predicted positions of each car are leveraged to update future instance prediction, encapsulating the surrounding cars' effect on future motion. Experiments on two public datasets demonstrate that the proposed network architecture and feedback based prediction technique in combined effort can match or outperform the state-of-the-art methods for long-term trajectory prediction.

- Navigation Command Matching for Vision-Based Autonomous Driving

    Author: Pan, Yuxin | Xi'an Jiaotong University
    Author: Xue, Jianru | Xi'an Jiaotong University
    Author: Zhang, Pengfei | Xi'an Jiaotong University
    Author: Ouyang, Wanli | The University of Sydney
    Author: Fang, Jianwu | Xian Jiaotong University
    Author: Chen, Xingyu | Laboratory of Visual Cognitive Computing and Intelligent Vehicle
 
    keyword: Autonomous Vehicle Navigation; Deep Learning in Robotics and Automation; Visual-Based Navigation

    Abstract : Learning an optimal policy for autonomous driving task to confront with complex environment is a long-studied challenge. Imitative reinforcement learning is accepted as a promising approach to learn a robust driving policy through expert demonstrations and interactions with environments. However, this model utilizes non-smooth rewards, which have a negative impact on matching between navigation commands and trajectory (state-action pairs), and degrade the generalizability of an agent. Smooth rewards are crucial to discriminate actions generated from sub-optimal policy. In this paper, we propose a navigation command matching (NCM) model to address this issue. There are two key components in NCM, 1) a matching measurer produces smooth navigation rewards that measure matching between navigation commands and trajectory; 2) attention-guided agent performs actions given states where salient regions in RGB images (i.e. roadsides, lane markings and dynamic obstacles) are highlighted to amplify their influence on the final model. We obtain navigation rewards and store transitions to replay buffer after an episode, so NCM is able to discriminate actions generated from sub-optimal policy. Experiments on CARLA driving benchmark show our proposed NCM outperforms previous state-of-the-art models on various tasks in terms of the percentage of successfully completed episodes. Moreover, our model improves generalizability of the agent and obtains good performance even in unseen scenarios.

- GraphRQI: Classifying Driver Behaviors Using Graph Spectrums

    Author: Chandra, Rohan | University of Maryland
    Author: Bhattacharya, Uttaran | UMD College Park
    Author: Mittal, Trisha | University of Maryland, College Park
    Author: Li, Xiaoyu | Cornell University
    Author: Bera, Aniket | University of Maryland
    Author: Manocha, Dinesh | University of Maryland
 
    keyword: Autonomous Vehicle Navigation; Agent-Based Systems

    Abstract : We present a novel algorithm to identify driver behaviors from road-agent trajectories. Our approach assumes that the road agents exhibit a range of driving traits, such as aggressive or conservative driving. Moreover, these traits affect the trajectories of nearby road-agents as well as the interactions between road-agents. We represent these inter-agent interactions using unweighted and undirected traffic graphs. Our algorithm classifies the driver behavior using a supervised learning algorithm by reducing the computation to the spectral analysis of the traffic graph. Moreover, we present a novel eigenvalue algorithm (GraphRQI) to compute the spectrum efficiently. We provide theoretical guarantees for the running time complexity of GraphRQI and show that it is faster than previous methods by 2X. We evaluate the classification accuracy of our approach on traffic videos and autonomous driving datasets corresponding to urban traffic. In practice, our GraphRQI achieves an accuracy improvement of up to 25% over prior driver behavior classification algorithms. We also use our classification algorithm to predict the future trajectories of road-agents.

## Localization

- ROI-Cloud: A Key Region Extraction Method for LiDAR Odometry and Localization

    Author: Zhou, Zhibo | Shanghai Jiao Tong University
    Author: Yang, Ming | Shanghai Jiao Tong University
    Author: Wang, Chunxiang | Shanghai Jiaotong University
    Author: Wang, Bing | Shanghai Jiao Tong University
 
    keyword: Localization; SLAM; Intelligent Transportation Systems

    Abstract :     Abstract�We present a novel key region extraction method of point cloud, ROI-cloud, for LiDAR odometry and localization with autonomous robots. Traditional methods process massive point cloud data in every region within the field of view. In dense urban environments, however, processing redundant and dynamic regions of point cloud is time-consuming and harmful to the results of matching algorithms. In this paper, a voxelized cube set, ROI-cloud, is proposed to solve this problem by exclusively reserving the regions of interest for better point set registration and pose estimation. 3D space is firstly voxelized into weighted cubes. The key idea is to update their weights continually and extract cubes with high importance as key regions. By extracting geometrical features of a LiDAR scan, the importance of each cube is evaluated as a new measurement. With the help of on-board IMU/odometry data as well as new measurements, the weights of cubes are updated recursively through Bayes filtering. Thus, dynamic and redundant point cloud inside cubes with low importance are discarded by means of Monte Carlo sampling. Our method is validated on various datasets, and results indicate that the ROI-cloud improves the existing method in both accuracy and speed.

- To Learn or Not to Learn: Visual Localization from Essential Matrices

    Author: Zhou, Qunjie | Technical University of Munich
    Author: Sattler, Torsten | Chalmers University of Technology
    Author: Pollefeys, Marc | ETH Zurich
    Author: Leal-Taixe, Laura | Technical University of Munich
 
    keyword: Localization; Visual-Based Navigation

    Abstract : Visual localization is the problem of estimating a camera within a scene and a key technology for autonomous robots. State-of-the-art approaches for accurate visual localization use scene-specific representations, resulting in the overhead of constructing these models when applying the techniques to new scenes. Recently, learned approaches based on relative pose estimation have been proposed, carrying the promise of easily adapting to new scenes. However, they are currently significantly less accurate than state-of-the-art approaches. In this paper, we are interested in analyzing this behavior. To this end, we propose a novel framework for visual localization from relative poses. Using a classical feature-based approach within this framework, we show state-of-the-art performance. Replacing the classical approach with learned alternatives at various levels, we then identify the reasons for why deep learned approaches do not perform well. Based on our analysis, we make recommendations for future work.

- Hierarchical Multi-Process Fusion for Visual Place Recognition

    Author: Hausler, Stephen | Queensland University of Technology
    Author: Milford, Michael J | Queensland University of Technology
 
    keyword: Localization; Visual-Based Navigation

    Abstract : Combining multiple complementary techniques together has long been regarded as a way to improve performance. In visual localization, multi-sensor fusion, multi-process fusion of a single sensing modality, and even combinations of different localization techniques have been shown to result in improved performance. However, merely fusing together different localization techniques does not account for the varying performance characteristics of different localization techniques. In this paper we present a novel, hierarchical localization system that explicitly benefits from three varying characteristics of localization techniques: the distribution of their localization hypotheses, their appearance- and viewpoint-invariant properties, and the resulting differences in where in an environment each system works well and fails. We show how two techniques deployed hierarchically work better than in parallel fusion, how combining two different techniques works better than two levels of a single technique, even when the single technique has superior individual performance, and develop two and three-tier hierarchical structures that progressively improve localization performance. Finally, we develop a stacked hierarchical framework where localization hypotheses from techniques with complementary characteristics are concatenated at each layer, significantly improving retention of the correct hypothesis through to the final localization stage.

- Camera Tracking in Lighting Adaptable Maps of Indoor Environments

    Author: Caselitz, Tim | University of Freiburg
    Author: Krawez, Michael | University of Freiburg
    Author: Sundram, Jugesh | Toyota Motor Europe NV/SA
    Author: Van Loock, Mark | Toyota Motor Europe NV/SA
    Author: Burgard, Wolfram | Toyota Research Institute
 
    keyword: Localization; Mapping; RGB-D Perception

    Abstract : Tracking the pose of a camera is at the core of visual localization methods used in many applications. As the observations of a camera are inherently affected by lighting, it has always been a challenge for these methods to cope with varying lighting conditions. Thus far, this issue has mainly been approached with the intent to increase robustness by choosing lighting invariant map representations. In contrast, our work aims at explicitly exploiting lighting effects for camera tracking. To achieve this, we propose a lighting adaptable map representation for indoor environments that allows real-time rendering of the scene illuminated by an arbitrary subset of the lamps contained in the model. Our method for estimating the light setting from the current camera observation enables us to adapt the model according to the lighting conditions present in the scene. As a result, lighting effects like cast shadows do no longer act as disturbances that demand robustness but rather as beneficial features when matching observations against the map. We leverage these capabilities in a direct dense camera tracking approach and demonstrate its performance in real-world experiments in scenes with varying lighting conditions.

- Fast, Compact and Highly Scalable Visual Place Recognition through Sequence-Based Matching of Overloaded Representations

    Author: Garg, Sourav | Queensland University of Technology
    Author: Milford, Michael J | Queensland University of Technology
 
    keyword: Localization; Visual-Based Navigation; Recognition

    Abstract : Visual place recognition algorithms trade off three key characteristics: their storage footprint, their computational requirements, and their resultant performance, often expressed in terms of recall rate. Significant prior work has investigated highly compact place representations, sub-linear computational scaling and sub-linear storage scaling techniques, but have always involved a significant compromise in one or more of these regards, and have only been demonstrated on relatively small datasets. In this paper we present a novel place recognition system which enables for the first time the combination of ultra-compact place representations, near sub-linear storage scaling and extremely lightweight compute requirements. Our approach exploits the inherently sequential nature of much spatial data in the robotics domain and inverts the typical target criteria, through intentionally coarse scalar quantization-based hashing that leads to more collisions but is resolved by sequence-based matching. For the first time, we show how effective place recognition rates can be achieved on a new very large 10 million place dataset, requiring only 8 bytes of storage per place and 37K unitary operations to achieve over 50% recall for matching a sequence of 100 frames, where a conventional state-of-the-art approach both consumes 1300 times more compute and fails catastrophically.

- Vision-Based Multi-MAV Localization with Anonymous Relative Measurements Using Coupled Probabilistic Data Association Filter

    Author: Nguyen, Ty | University of Pennsylvania
    Author: Mohta, Kartik | University of Pennsylvania
    Author: Taylor, Camillo Jose | University of Pennsylvania
    Author: Kumar, Vijay | University of Pennsylvania
 
    keyword: Localization; Aerial Systems: Perception and Autonomy; Swarms

    Abstract : We address the localization of robots in a multi-MAV system where external infrastructure like GPS or motion capture systems may not be available. Our approach lends itself to implementation on platforms with several constraints on size, weight, and power (SWaP). Particularly, our framework fuses the onboard VIO with the anonymous, visual-based robot-to-robot detection to estimate all robot poses in one common frame, addressing three main challenges: 1) the initial configuration of the robot team is unknown, 2) the data association between each vision-based detection and robot targets is unknown, and 3) the vision-based detection yields false negatives, false positives, inaccurate, and provides noisy bearing, distance measurements of other robots. Our approach extends the Coupled Probabilistic Data Association Filter~cite{cpdaf} to cope with nonlinear measurements. We demonstrate the superior performance of our approach over a simple VIO-based method in a simulation with the measurement models statistically modeled using the real experimental data. We also show how onboard sensing, estimation, and control can be used for formation flight.



- UrbanLoco: A Full Sensor Suite Dataset for Mapping and Localization in Urban Scenes

    Author: Wen, Weisong | Hong Kong Polytechnic University
    Author: Zhou, Yiyang | University of California, Berkeley
    Author: Zhang, Guohao | The Hong Kong Polytechnic University
    Author: Fahandezh-Saadi, Saman | University of California, Berkeley
    Author: Bai, Xiwei | Hong Kong Polytechnic University
    Author: Zhan, Wei | Univeristy of California, Berkeley
    Author: Tomizuka, Masayoshi | University of California
    Author: Hsu, Li-ta | Hong Kong Polytechnic University
 
    keyword: Localization; Mapping; Performance Evaluation and Benchmarking

    Abstract : Mapping and localization is a critical module of autonomous driving, and significant achievements have been reached in this field. Beyond Global Navigation Satellite System (GNSS), research in point cloud registration, visual feature matching, and inertia navigation has greatly enhanced the accuracy and robustness of mapping and localization in different scenarios. However, highly urbanized scenes are still challenging: LIDAR- and camera-based methods perform poorly with numerous dynamic objects; the GNSS-based solutions experience signal loss and multipath problems; the inertia measurement units (IMU) suffer from drifting. Unfortunately, current public datasets either do not adequately address this urban challenge or do not provide enough sensor information related to mapping and localization. Here we present UrbanLoco: a mapping/localization dataset collected in highly-urbanized environments with a full sensor-suite. The dataset includes 13 trajectories collected in San Francisco and Hong Kong, covering a total length of over 40 kilometers. Our dataset includes a wide variety of urban terrains: urban canyons, bridges, tunnels, sharp turns, etc. More importantly, our dataset includes information from LIDAR, cameras, IMU, and GNSS receivers. Now the dataset is publicly available through the link in the footnote.

- Map As the Hidden Sensor: Fast Odometry-Based Global Localization

    Author: Peng, Cheng | Univerisyt of Minnesota, Twin Cities
    Author: Weikersdorfer, David | Technische Universitét M�nchen
 
    keyword: Localization; SLAM; Sensor Fusion

    Abstract : Accurate and robust global localization is essential to robotics applications. We propose a novel global localization method that employs the map traversability as a hidden observation. The resulting map-corrected odometry localization is able to provide an accurate belief tensor of the robot state. Our method can be used for blind robots in dark or highly reflective areas. In contrast to odometry drift in long-term, our method using only odometry and the map converges in the long-term. Our method can also be integrated with other sensors to boost the localization performance. The algorithm does not have any initial state assumption and tracks all possible robot states at all times. Therefore, our method is global and is robust in the event of ambiguous observations. We parallel each step of our algorithm such that it can be performed in real-time (up to sim 300 Hz) using GPU. We validate our algorithm in different publicly available floor-plans and show that it is able to converge to the ground truth fast while being robust to ambiguities.

- Joint Human Pose Estimation and Stereo 3D Localization

    Author: Deng, Wenlong | EPFL
    Author: Bertoni, Lorenzo | EPFL
    Author: Kreiss, Sven | EPFL
    Author: Alahi, Alexandre | EPFL
 
    keyword: Localization

    Abstract : We present a new end-to-end trainable Neural Network architecture for stereo imaging that jointly locates and estimates human body poses in 3D, particularly suitable for autonomous vehicles. Our contribution, referred to as Part Spatial Field (PSF), defines a 2D pose for each human in a stereo pair of images and uses a correlation layer with a composite field to associate each left-right pair of joints. Finally, we show that we can train our method with synthetic data only and test it on real-world images (textit{i.e.}, our method is domain invariant). We achieve state-of-the-art results for the 3D localization task on the challenging real-world KITTI dataset.

- Self-Supervised Deep Pose Corrections for Robust Visual Odometry

    Author: Wagstaff, Brandon | University of Toronto
    Author: Peretroukhin, Valentin | University of Toronto
    Author: Kelly, Jonathan | University of Toronto
 
    keyword: Localization; Deep Learning in Robotics and Automation; Visual-Based Navigation

    Abstract : We present a self-supervised deep pose correction (DPC) network that applies pose corrections to a visual odometry estimator to improve its accuracy. Instead of regressing inter-frame pose changes directly, we build on prior work that uses data-driven learning to regress pose corrections that account for systematic errors due to violations of modelling assumptions. Our self-supervised formulation removes any requirement for six-degrees-of-freedom ground truth and, in contrast to expectations, often improves overall navigation accuracy compared to a supervised approach. Through extensive experiments, we show that our self-supervised DPC network can significantly enhance the performance of classical monocular and stereo odometry estimators and substantially out-performs state-of-the-art learning-only approaches.

- Ultra-High-Accuracy Visual Marker for Indoor Precise Positioning

    Author: Tanaka, Hideyuki | National Institute of AIST
 
    keyword: Localization; Automation Technologies for Smart Cities; Service Robots

    Abstract : Indoor positioning technology is essential for indoor mobile robots and drones. However, there has never been a general-purpose technology or infrastructure that enables indoor positioning with an accuracy of less than 10 cm. We have developed an attitude measurement method using multiple dynamic moires with a lenticular lens and developed an ultra-high-accuracy visual marker with an attitude estimation error of less than 0.1 deg. We also developed a calculation method that minimizes the marker position error by reminimizing reprojection error using its good attitude accuracy. We proved that accurate local positioning with a position error of about 1 cm in a marker coordinate system is possible even when a marker is shot from a distance of 10 m. In addition, a demonstration test was performed in a public space, and it was shown that high-accuracy global positioning with a position error of about 10 cm is possible.

- Accurate Position Tracking with a Single UWB Anchor

    Author: Cao, Yanjun | École Polytechnique De Montr�al (Université De Montr�al)
    Author: Yang, Chenhao | University of Tuebingen
    Author: Li, Rui | Institute of Automation, Chinese Academy of Sciences
    Author: Knoll, Alois | Tech. Univ. Muenchen TUM
    Author: Beltrame, Giovanni | Ecole Polytechnique De Montreal
 
    keyword: Localization; Sensor Fusion

    Abstract :  Accurate localization and tracking are a fundamental requirement for robotic applications. Localization systems like GPS, optical tracking, simultaneous localization and mapping (SLAM) are used for daily life activities, research, and commercial applications.	Ultra-wideband (UWB) technology provides another venue to accurately localize devices both indoors and outdoors. In this paper, we study a localization solution with a single UWB anchor, instead of the traditional multi-anchor setup. Besides the challenge of a single UWB ranging source, the only other sensor we require is a low-cost 9 DoF inertial measurement unit (IMU). Under such a configuration, we propose continuous monitoring of UWB range changes to estimate the robot speed when moving on a line. Combining speed estimation with orientation estimation from the IMU sensor, the system becomes temporally observable. We use an Extended Kalman Filter (EKF) to estimate the pose of a robot. With our solution, we can effectively correct the accumulated error and maintain accurate tracking of a moving robot.

- Association-Free Multilateration Based on Times of Arrival

    Author: Frisch, Daniel | Karlsruhe Institute of Technology (KIT)
    Author: Hanebeck, Uwe D. | Karlsruhe Institute of Technology (KIT)
 
    keyword: Localization; Surveillance Systems; Sensor Fusion

    Abstract : Multilateration systems reconstruct the location of a target that transmits electromagnetic or acoustic signals. The employed measurements for localization are the times of arrival (TOAs) of the transmitted signal, measured by a number of spatially distributed receivers at known positions. We present a novel multilateration algorithm to localize multiple targets that transmit indistinguishable signals at unknown times. That is, each receiver measures merely a set of TOAs with no association to the targets. Our method does not need any prior information. Therefore, it can provide uncorrelated, static measurements to be introduced into a separate tracker subsequently, or an initialization routine for multi target trackers.

- Adversarial Feature Disentanglement for Place Recognition across Changing Appearance

    Author: Tang, Li | Zhejiang University
    Author: Wang, Yue | Zhejiang University
    Author: Luo, Qianhui | Zhejiang University
    Author: Ding, Xiaqing | Zhejiang University
    Author: Xiong, Rong | Zhejiang University
 
    keyword: Localization; Deep Learning in Robotics and Automation; SLAM

    Abstract :  When robots move autonomously for long-term, varied appearance such as the transition from day to night and seasonal variation brings challenges to visual place recognition. Defining an appearance condition (e.g. a season, a kind of weather) as a <i>domain</i>, we consider that the desired representation for place recognition (i) should be domain-unrelated so that images from different time can be matched regardless of varied appearance, (ii) should be learned in a self-supervised manner without the need of massive manually labeled data, and (iii) should be able to train among multiple domains in one model to keep limited model complexity. This paper sets to find domain-unrelated features across extremely changing appearance, which can be used as image descriptors to match between images collected at different conditions. We propose to use the adversarial network to disentangle domain-unrelated and domain-related features, which are named <i>place</i> and <i>appearance</i> features respectively. During training, only domain information is needed without requiring manually aligned image sequences. Experiments demonstrated that our method can disentangle place and appearance features in both toy case and images from the real world, and the place features are qualified in place recognition tasks under different appearance conditions. The proposed network is also adaptable to multiple domains without increasing model capacity and shows favorable generalization.

- A Fast and Accurate Solution for Pose Estimation from 3D Correspondences

    Author: Zhou, Lipu | Carnegie Mellon University
    Author: Wang, Shengze | Carnegie Mellon University
    Author: Kaess, Michael | Carnegie Mellon University
 
    keyword: Localization; SLAM; Mapping

    Abstract : Estimating pose from given 3D correspondences, including point-to-point, point-to-line and point-to-plane correspondences, is a fundamental task in computer vision with many applications. We present a fast and accurate solution for the least-squares problem of this task. Previous works mainly focus on studying the way to find the global minimizer of the leastsquares problem. However, existing works that show the ability to achieve the global minimizer are still unsuitable for real-time applications. Furthermore, as one of contributions of this paper, we prove that there exist ambiguous configurations for any number of lines and planes. These configurations have several solutions in theory, which makes the correct solution may come from a local minimizer when the data are with noise. Previous works based on convex optimization which is unable to find local minimizers do not work in the ambiguous configuration. Our algorithm is efficient and able to reveal local minimizers. We employ the Cayley-Gibbs-Rodriguez (CGR) parameterization of the rotation to derive a general rational cost for the three cases of 3D correspondences. The main contribution of this paper is to solve the first-order optimality conditions of the least-squares problem, which are of a complicated rational form. The central idea of our algorithm is to introduce some intermediate unknowns to simplify the problem. Extensive experimental results show that our algorithm is more stable than previous algorithms when

- Ground Texture Based Localization Using Compact Binary Descriptors

    Author: Schmid, Jan Fabian | Robert Bosch GmbH; Goethe University Frankfurt
    Author: Simon, Stephan F. | Robert Bosch GmbH
    Author: Mester, Rudolf | NTNU Trondheim
 
    keyword: Localization; Mapping; SLAM

    Abstract : Ground texture based localization is a promising approach to achieve high-accuracy positioning of vehicles. We present a self-contained method that can be used for global localization as well as for subsequent local localization updates, i.e. it allows a robot to localize without any knowledge of its current whereabouts, but it can also take advantage of a prior pose estimate to reduce computation time significantly. Our method is based on a novel matching strategy, which we call identity matching, that is based on compact binary feature descriptors. Identity matching treats pairs of features as matches only if their descriptors are identical. While other methods for global localization are faster to compute, our method reaches higher localization success rates, and can switch to local localization after the initial localization.

- Reliable Data Association for Feature-Based Vehicle Localization Using Geometric Hashing Methods

    Author: Hofstetter, Isabell | Mercedes-Benz AG
    Author: Sprunk, Michael | Daimler AG
    Author: Ries, Florian | Mercedes-Benz AG
    Author: Haueis, Martin | Mercedes Benz AG
 
    keyword: Localization; Recognition; Autonomous Vehicle Navigation

    Abstract : Reliable data association represents a main challenge of feature-based vehicle localization and is the key to integrity of localization. Independent of the type of features used, incorrect associations between detected and mapped features will provide erroneous position estimates. Only if the uniqueness of a local environment is represented by the features that are stored in the map, reliable and safe localization can be guaranteed. In this work, a new approach based on Geometric Hashing is introduced to the field of data association for feature-based vehicle localization. Without any Information on a prior position, the proposed method allows to efficiently search large map regions for plausible Feature associations. Therefore, odometry and GNSS-based inputs can be neglected, which eliminates the risk of error propagation and enables safe localization. The approach is demonstrated on approximately 10min of data recorded in an urban scenario. Cylindrical objects without distinctive descriptors, which were extracted from LiDAR data, serve as localization features. Experimental results both demonstrate the feasibility as well as limitations of the approach.

- Vehicle Localization Based on Visual Lane Marking and Topological Map Matching

    Author: Asghar, Rabbia | Inria
    Author: Garzon Oviedo, Mario | Inria
    Author: Lussereau, Jerome | INRIA
    Author: Laugier, Christian | INRIA
 
    keyword: Localization; Sensor Fusion; Autonomous Vehicle Navigation

    Abstract : Accurate and reliable localization is crucial to autonomous vehicle navigation and driver assistance systems. This paper presents a novel approach for online vehicle localization in a digital map. Two distinct map matching algorithms are proposed: i) Iterative Closest Point (ICP) based lane level map matching is performed with visual lane tracker and grid map ii) decision-rule based approach is used to perform topological map matching. Results of both the map matching algorithms are fused together with GPS and dead reckoning using Extended Kalman Filter to estimate vehicle's pose relative to the map. The proposed approach has been validated on real life conditions on an equipped vehicle. Detailed analysis of the experimental results show improved localization using the two aforementioned map matching algorithms.

- RISE: A Novel Indoor Visual Place Recogniser

    Author: Sanchez Belenguer, Carlos | Joint Research Centre (JRC) - European Commission
    Author: Wolfart, Erik | European Commission, Joint Research Centre (JRC), Institute For
    Author: Sequeira, Vitor | Joint Research Centre
 
    keyword: Localization; Deep Learning in Robotics and Automation; Recognition

    Abstract : This paper presents a new technique to solve the Indoor Visual Place Recognition problem from the Deep Learning perspective. It consists on an image retrieval approach supported by a novel image similarity metric. Our work uses a 3D laser sensor mounted on a backpack with a calibrated spherical camera i) to generate the data for training the deep neural network and ii) to build a database of geo-referenced images for an environment. The data collection stage is fully automatic and requires no user intervention for labelling. Thanks to the 3D laser measurements and the spherical panoramas, we can efficiently survey large indoor areas in a very short time. The underlying 3D data associated to the map allows us to define the similarity between two training images as the geometric overlap between the observed pixels. We exploit this similarity metric to effectively train a CNN that maps images into compact embeddings. The goal of the training is to ensure that the L2 distance between the embeddings associated to two images is small when they are observing the same place and large when they are observing different places. After the training, similarities between a query image and the geo-referenced images in the database are efficiently retrieved by performing a nearest neighbour search in the embeddings space.

- Beyond Photometric Consistency: Gradient-Based Dissimilarity for Improving Visual Odometry and Stereo Matching

    Author: Quenzel, Jan | University of Bonn
    Author: Rosu, Radu Alexandru | University of Bonn
    Author: L�be, Thomas | University of Bonn
    Author: Stachniss, Cyrill | University of Bonn
    Author: Behnke, Sven | University of Bonn
 
    keyword: Localization; Visual-Based Navigation

    Abstract : Pose estimation and map building are central ingredients of autonomous robots and typically rely on the registration of sensor data. In this paper, we investigate a new metric for registering images that builds upon on the idea of the photometric error. Our approach combines a gradient orientation-based metric with a magnitude-dependent scaling term. We integrate both into stereo estimation as well as visual odometry systems and show clear benefits for typical disparity and direct image registration tasks when using our proposed metric. Our experimental evaluation indicates that our metric leads to more robust and more accurate estimates of the scene depth as well as camera trajectory. Thus, the metric improves camera pose estimation and in turn the mapping capabilities of mobile robots. We believe that a series of existing visual odometry and visual SLAM systems can benefit from the findings reported in this paper.

- ICS: Incremental Constrained Smoothing for State Estimation

    Author: Sodhi, Paloma | Carnegie Mellon University
    Author: Choudhury, Sanjiban | University of Washington
    Author: Mangelson, Joshua | Brigham Young University
    Author: Kaess, Michael | Carnegie Mellon University
 
    keyword: Localization; SLAM; Optimization and Optimal Control

    Abstract : A robot operating in the world constantly receives information about its environment in the form of new measurements at every time step. Smoothing-based estimation methods seek to optimize for the most likely robot state estimate using all measurements up till the current time step. Existing methods solve for this smoothing objective efficiently by framing the problem as that of incremental unconstrained optimization. However, in many cases observed measurements and knowledge of the environment is better modeled as hard constraints derived from real-world physics or dynamics. A key challenge is that the new optimality conditions introduced by the hard constraints break the matrix structure needed for incremental factorization in these incremental optimization methods.<p>Our key insight is that if we leverage primal-dual methods, we can recover a matrix structure amenable to incremental factorization. We propose a framework ICS that combines a primal-dual method like the Augmented Lagrangian with an incremental Gauss Newton approach that reuses previously computed matrix factorizations. We evaluate ICS on a set of simulated and real-world problems involving equality constraints like object contact and inequality constraints like collision avoidance.

- Drone-Aided Localization in LoRa IoT Networks

    Author: Delafontaine, Victor Pierre Guy | Laboratory of Intelligent Systems (LIS), École Polytechnique F�d
    Author: Schiano, Fabrizio | Ecole Polytechnique Federale De Lausanne, EPFL
    Author: Cocco, Giuseppe | Pompeu Fabra University
    Author: Rusu, Alexandru | Swisscom
    Author: Floreano, Dario | Ecole Polytechnique Federal, Lausanne
 
    keyword: Localization; Aerial Systems: Perception and Autonomy; Sensor Networks

    Abstract : Besides being part of the Internet of Things (IoT), drones can play a relevant role in it as enablers. The 3D mobility of UAVs can be exploited to improve node localization in IoT networks for, e.g., search and rescue or goods localization and tracking. One of the widespread IoT communication technologies is Long Range Wide Area Network (LoRaWAN), which allows achieving long communication distances with low power. In this work, we present a drone-aided localization system for LoRa networks in which a UAV is used to improve the estimation of a node's location initially provided by the network. We characterize the relevant parameters of the communication system and use them to develop and test a search algorithm in a realistic simulated scenario. We then move to the full implementation of a real system in which a drone is seamlessly integrated into Swisscom's LoRa network. The drone coordinates with the network with a two-way exchange of information which results in an accurate and fully autonomous localization system. The results obtained in our field tests show a ten-fold improvement in localization precision with respect to the estimation provided by the fixed network. Up to our knowledge, this is the first time a UAV is successfully integrated in a LoRa network to improve its localization accuracy.

- A Fast and Practical Method of Indoor Localization for Resource-Constrained Devices with Limited Sensing

    Author: Wietrzykowski, Jan | Poznan University of Technology
    Author: Skrzypczynski, Piotr | Poznan University of Technology
 
    keyword: Localization; Probability and Statistical Methods; Sensor Fusion

    Abstract : We describe and experimentally demonstrate a practical method for indoor localization using measurements obtained from resource-constrained devices with limited sensing capabilities. We focus on handheld/mobile devices but the method can be useful for a variety of wearable devices. Our system works with sparse WiFi or image-based measurements, avoiding laborious site surveying for dense signal maps and runs in real-time. It uses Conditional Random Fields to infer the most probable sequence of agent positions from a known floor plan, dead reckoning and sparse absolute position estimates. Our solution leverages known topology of the environment by pre-computing allowed motion sequences of an agent, which are then used to constraint the motion inferred from the sensory data. The system is evaluated in a typical office building, demonstrating good accuracy and robustness to sparse, low-quality measurements.


- GN-Net: The Gauss-Newton Loss for Multi-Weather Relocalization

    Author: von Stumberg, Lukas | Technische Universitét M�nchen
    Author: Wenzel, Patrick | Technical University of Munich
    Author: Khan, Qadeer | Technical University of Munich
    Author: Cremers, Daniel | Technical University of Munich
 
    keyword: Localization; Visual Learning; SLAM

    Abstract : Direct SLAM methods have shown exceptional performance on odometry tasks. However, they are susceptible to dynamic lighting and weather changes while also suffering from a bad initialization on large baselines. To overcome this, we propose GN-Net: a network optimized with the novel Gauss Newton loss for training weather invariant deep features, tailored for direct image alignment. Our network can be trained with pixel correspondences between images taken from different sequences. Experiments on both simulated and real-world datasets demonstrate that our approach is more robust against bad initialization, variations in day-time, and weather changes thereby outperforming state-of-the-art direct and indirect methods. Furthermore, we release an evaluation benchmark for relocalization tracking against different types of weather. Our benchmark is available at https://vision.in.tum.de/gn-net.

- A Data-Driven Motion Prior for Continuous-Time Trajectory Estimation on SE(3)

    Author: Wong, Jeremy Nathan | University of Toronto
    Author: Yoon, David Juny | University of Toronto
    Author: Schoellig, Angela P. | University of Toronto
    Author: Barfoot, Timothy | University of Toronto
 
    keyword: Localization; SLAM

    Abstract : Simultaneous trajectory estimation and mapping (STEAM) is a method for continuous-time trajectory estimation in which the trajectory is represented as a Gaussian Process (GP). Previous formulations of STEAM used a GP prior that assumed either white-noise-on-acceleration (WNOA) or white-noise-on-jerk (WNOJ). However, previous work did not provide a principled way to choose the continuous-time motion prior or its parameters on a real robotic system. This paper derives a novel data-driven motion prior where ground truth trajectories of a moving robot are used to train a motion prior that better represents the robot's motion. In this approach, we use a prior where latent accelerations are represented as a GP with a Matern covariance function and draw a connection to the Singer acceleration model. We then formulate a variation of STEAM using this new prior. We train the WNOA, WNOJ, and our new latent-force prior and evaluate their performance in the context of both lidar localization and lidar odometry of a car driving along a 20 km route, where we show improved state estimates compared to the two previous formulations.

- Estimation with Fast Feature Selection in Robot Visual Navigation
 
    Author: Mousavi, Hossein K. | Lehigh University
    Author: Motee, Nader | Lehigh Universitty
 
    keyword: Localization; Visual-Based Navigation; Autonomous Vehicle Navigation

    Abstract : We consider the robot localization problem with sparse visual feature selection. The underlying key property is that contributions of trackable features (landmarks) appear linearly in the information matrix of the corresponding estimation problem. We utilize standard models for motion and vision system using a camera to formulate the feature selection problem over moving finite-time horizons. We propose a scalable randomized sampling algorithm to select more informative features to obtain a certain estimation quality. We provide probabilistic performance guarantees for our method. The time-complexity of our feature selection algorithm is linear in the number of candidate features, which is practically plausible and outperforms existing greedy methods that scale quadratically with the number of candidate features. Our numerical simulations confirm that not only the execution time of our proposed method is comparably less than that of the greedy method, but also the resulting estimation quality is very close to the greedy method.

- A Tightly Coupled VLC-Inertial Localization System by EKF

    Author: Liang, Qing | Hong Kong University of Science and Technology
    Author: Liu, Ming | Hong Kong University of Science and Technology
 
    keyword: Service Robots; Sensor Fusion; Localization

    Abstract : Lightweight global localization is favorable by many resource-constrained platforms working in GPS-denied indoor environments, such as service robots and mobile devices. In recent years, visible light communication (VLC) has emerged as a promising technology that can support global positioning in buildings by reusing the widespread LED luminaries as artificial visual landmarks. In this paper, we propose a novel VLC/IMU integrated system with a tightly coupled formulation by an extended-Kalman filter (EKF) for robust VLC-inertial localization. By tightly fusing the inertial measurements with the visual measurements of LED fiducials, our EKF localizer can provide lightweight real-time accurate global pose estimates, even in LED-shortage situations. We further complete it with a 2-point global pose initialization method that loosely couples the two sensor measurements. We can hence bootstrap our system with two or more LED features observed in one camera frame. The proposed system and method are verified by extensive field experiments using dozens of self-made LED prototypes.

- Localization of Inspection Device Along Belt Conveyors with Multiple Branches Using Deep Neural Networks

    Author: Yasutomi, André Yuji | Hitachi Ltd
    Author: Enoki, Hideo | Hitachi Ltd
 
    keyword: Localization; Manufacturing, Maintenance and Supply Chains; Deep Learning in Robotics and Automation

    Abstract : Regular inspections of belt conveyors are required to prevent the damage of transported objects. Nevertheless, inspections can be troublesome for belt conveyors composed of a plurality of belt lines with multiple branches. To improve the inspection process, an inspection device composed of an inertial measurement unit (IMU) inside a transported object was introduced in our previous study jointly with an algorithm to detect anomalies in the joints of the belt lines. When belt conveying this device for inspection, however, it is required to not only detect the anomaly but also know its position. This study presents a novel method to estimate the position of the inspection device along the belt conveyor using a deep neural network (DNN). The DNN uses the IMU data to detect seven types of features (passage through five types of joints, device stoppage and regular transport), which, when matched to data on a belt conveyor position database, can correctly be translated into positions. Additionally, the proposed method enables the detection of changes of routes along the belt conveyor that occur when a belt line branches into two output streams. To enhance the DNN feature detections, two original algorithms for DNN output post-processing are also introduced. Experiments with a complex belt conveyor demonstrate this method can successfully detect the position of the inspected device more accurately and more cost-effectively than conventional methods.

- Localising PMDs through CNN Based Perception of Urban Streets

    Author: Jayasuriya, Maleen | University of Technology Sydney
    Author: Arukgoda, Janindu | University of Technology Sydney
    Author: Ranasinghe, Ravindra | University of Technology Sydney
    Author: Dissanayake, Gamini | University of Technology Sydney
 
    keyword: Localization; Visual-Based Navigation

    Abstract : The main contribution of this paper is a novel Extended Kalman Filter (EKF) based localisation scheme that fuses two complementary approaches to outdoor vision based localisation. This EKF is aided by a front end consisting of two Convolutional Neural Networks (CNNs) that provide the necessary perceptual information from camera images. The first approach involves a CNN based extraction of information corresponding to artefacts such as curbs, lane markings, and manhole covers to localise on a vector distance transform representation of a binary image of these ground surface boundaries. The second approach involves a CNN based detection of common environmental landmarks such as tree trunks and light poles, which are represented as point features on a sparse map. Utilising CNNs to obtain higher level information about the environment enables this framework to avoid the typical pitfalls of common vision based approaches that use low level hand crafted features for localisation. The EKF framework makes it possible to deal with false positives and missed detections that are inevitable in a practical CNN, to produce a location estimate together with its associated uncertainty. Experiments using a Personal Mobility Device (PMD) driven in typical suburban streets are presented to demonstrate the effectiveness of the proposed localiser.

- The Complex-Step Derivative Approximation on Matrix Lie Groups

    Author: Cossette, Charles Champagne | McGill University
    Author: Walsh, Alex | McGill University
    Author: Forbes, James Richard | McGill University
 
    keyword: Localization; Optimization and Optimal Control; SLAM

    Abstract : The complex-step derivative approximation is a numerical differentiation technique that can achieve analytical accuracy, to machine precision, with a single function evaluation. In this paper, the complex-step derivative approximation is extended to be compatible with elements of matrix Lie groups. As with the standard complex-step derivative, the method is still able to achieve analytical accuracy, up to machine precision, with a single function evaluation. Compared to a central-difference scheme, the proposed complex-step approach is shown to have superior accuracy. The approach is applied to two different pose estimation problems, and is able to recover the same results as an analytical method when available.

- Hybrid Localization Using Model and Learning-Based Methods: Fusion of Monte Carlo and E2E Localizations Via Importance Sampling

    Author: Akai, Naoki | Nagoya University
    Author: Hirayama, Takatsugu | Nagoya University
    Author: Murase, Hiroshi | Nagoya University
 
    keyword: Localization; Deep Learning in Robotics and Automation; Autonomous Vehicle Navigation

    Abstract : This paper proposes a hybrid localization method that fuses Monte Carlo localization (MCL) and convolutional neural network (CNN)-based end-to-end (E2E) localization. MCL is based on particle filter and requires proposal distributions to sample the particles. The proposal distribution is generally predicted using a motion model. However, because the motion model cannot handle unanticipated errors, the predicted distribution is sometimes inaccurate. The use of other ideal proposal distributions, such as the measurement model, can improve robustness against such unanticipated errors. This technique is called importance sampling (IS). However, it is difficult to sample the particles from such ideal distributions because they are not represented in the closed form. Recent works have proved that CNNs with dropout layers represent the posterior distributions over their outputs conditioned on the inputs and the CNN predictions are equivalent to sampling the outputs from the posterior. Therefore, the proposed method utilizes a CNN to sample the particles and fuses them with MCL via IS. Consequently, the advantages of both MCL and E2E localization can be simultaneously leveraged while preventing their disadvantages. Experiments demonstrate that the proposed method can smoothly estimate the robot pose, similar to the model-based method, and quickly re-localize it from the failures, similar to the learning-based method.

- Measurement Scheduling for Cooperative Localization in Resource-Constrained Conditions

    Author: Yan, Qi | Shanghai Jiao Tong University
    Author: Jiang, Li | Shanghai Jiao Tong University
    Author: Kia, Solmaz | Uinversity of California Irvine
 
    keyword: Localization; Networked Robots; Multi-Robot Systems

    Abstract : This paper studies the measurement scheduling problem for a group of N mobile robots moving on a flat surface that are performing cooperative localization (CL). We consider a scenario in which due to the limited on-board resources such as battery life and communication bandwidth only a given number of relative measurements per robot are allowed at observation and update stage. Optimal selection of which teammates a robot should take a relative measurement from such that the updated joint localization uncertainty of the team is minimized is an NP-hard problem. In this paper, we propose a suboptimal greedy approach that allows each robot to choose its landmark robots locally in polynomial time. Our method, unlike the known results in the literature, does not assume the full-observability of CL algorithm. Moreover, it does not require inter-robot communication at the scheduling stage. That is, there is no need for the robots to collaborate to carry out the landmark robot selections. We discuss the application of our method in the context of a state-of-the-art decentralized CL algorithm and demonstrate its effectiveness through numerical simulations. Even though our solution does not come with rigorous performance guarantees, its low computational cost along with no communication requirement makes it an appealing solution for operations with resource-constrained robots.

- Quantifying Robot Localization Safety: A New Integrity Monitoring Method for Fixed-Lag Smoothing

    Author: Abdul Hafez, Osama | Illinois Institute of Technology
    Author: Duenas Arana, Guillermo | Illinois Institute of Technology
    Author: Joerger, Mathieu | Virginia Tech
    Author: Spenko, Matthew | Illinois Institute of Technology
 
    keyword: Localization; Autonomous Vehicle Navigation; Probability and Statistical Methods

    Abstract : Localization safety, or integrity risk, is the probability of undetected localization failures and a common aviation performance metric used to verify a minimum accuracy requirement. As autonomous robots become more common, applying integrity risk metrics will be necessary to verify localization performance. This paper introduces a new method, solution separation, to quantify landmark-based mobile robot localization safety for fixed-lag smoothing estimators and compares it's computation time and fault detection capabilities to a chi-squared integrity monitoring method. Results show that solution separation is more computationally efficient and results in a tighter upper-bound on integrity risk when few measurements are included, which makes it the method of choice for lightweight, safety-critical applications such as UAVs. Conversely, chi-squared requires more computing resources but performs better when more measurements are included, making the method more appropriate for high performance computing platforms such as autonomous vehicles.

- Visual Localization with Google Earth Images for Robust Global Pose Estimation of UAVs

    Author: Patel, Bhavit | University of Toronto
    Author: Barfoot, Timothy | University of Toronto
    Author: Schoellig, Angela P. | University of Toronto
 
    keyword: Localization; Field Robots; Aerial Systems: Perception and Autonomy

    Abstract : We estimate the global pose of a multirotor UAV by visually localizing images captured during a flight with Google Earth images pre-rendered from known poses. We metrically localize real images with georeferenced rendered images using a dense mutual information technique to allow accurate global pose estimation in outdoor GPS-denied environments. We show the ability to consistently localize throughout a sunny summer day despite major lighting changes while demonstrating that a typical feature-based localizer struggles under the same conditions. Successful image registrations are used as measurements in a filtering framework to apply corrections to the pose estimated by a gimballed visual odometry pipeline. We achieve less than 1 metre and 1 degree RMSE on a 303 metre flight and less than 3 metres and 3 degrees RMSE on six 1132 metre flights as low as 36 metres above ground level conducted at different times of the day from sunrise to sunset.

- Relax and Recover: Guaranteed Range-Only Continuous Localization

    Author: Pacholska, Michalina | EPFL
    Author: D�mbgen, Frederike | EPFL
    Author: Scholefield, Adam | EPFL
 
    keyword: Localization; Range Sensing; Optimization and Optimal Control

    Abstract : Range-only localization has applications as diverse as underwater navigation, drone tracking and indoor localization. While the theoretical foundations of lateration�range-only localization for static points�are well understood, there is a lack of understanding when it comes to localizing a moving device. As most interesting applications in robotics involve moving objects, we study the theory of trajectory recovery. This problem has received a lot of attention; however, state-of-the-art methods are of a probabilistic or heuristic nature and not well suited for guaranteeing trajectory recovery. In this letter, we pose trajectory recovery as a quadratic problem and show that we can relax it to a linear form, which admits a closed-form solution. We provide necessary and sufficient recovery conditions and in particular show that trajectory recovery can be guaranteed when the number of measurements is proportional to the trajectory complexity. Finally, we apply our reconstruction algorithm to simulated and real-world data.

- SPRINT: Subgraph Place Recognition for Intelligent Transportation

    Author: Latif, Yasir | University of Adelaide
    Author: Doan, Anh-Dzung | The University of Adelaide
    Author: Chin, Tat-Jun | The University of Adelaide
    Author: Reid, Ian | University of Adelaide
 
    keyword: Localization; SLAM

    Abstract : Place recognition is an important problem in mobile robotics that allows a robot to localize itself using image data alone. Recent methods have shown good performance for place recognition under varying environmental conditions by exploiting sequential nature of the incoming data. Using k nearest neighbours based image retrieval as the backend, and exploiting the structure of the image acquisition process which introduces temporal relations between images in the database, the location of possible matches can be restricted to a subset of all the images seen so far. We show that when using Hidden Markov Models for inference, the original problem space can be restricted to a significantly smaller subspace by exploiting these properties of the problem, significantly reducing the inference time. This is important if we want to carry out place recognition over database containing millions of images. We show large scale experiments using publicly sourced data that show the computational performance of the proposed method under varying environmental conditions.

- OneShot Global Localization: Instant LiDAR-Visual Pose Estimation

    Author: Ratz, Sebastian | ETH Zurich, Sevensense Robotics AG
    Author: Dymczyk, Marcin Tomasz | ETH Zurich, Autonomous Systems Lab
    Author: Siegwart, Roland | ETH Zurich
    Author: Dub�, Renaud | ETH Zurich
 
    keyword: Localization; Deep Learning in Robotics and Automation; RGB-D Perception

    Abstract : Globally localizing in a given map is a crucial ability for robots to perform a wide range of autonomous navigation tasks. This paper presents OneShot - a global localization algorithm that uses only a single 3D LiDAR scan at a time, while outperforming approaches based on integrating a sequence of point clouds. Our approach, which does not require the robot to move, relies on learning-based descriptors of point cloud segments and computes the full 6 degree-of-freedom pose in a map. The segments are extracted from the current LiDAR scan and are matched against a database using the computed descriptors. Candidate matches are then verified with a geometric consistency test. We additionally present a strategy to further improve the performance of the segment descriptors by augmenting them with visual information provided by a camera. For this purpose, a custom-tailored neural network architecture is proposed. We demonstrate that our LiDAR-only approach outperforms a state-of-the-art baseline on a sequence of the KITTI dataset and also evaluate its performance on the challenging NCLT dataset. Finally, we show that fusing in visual information boosts segment retrieval rates by up to 26% compared to LiDAR-only description.

- Relocalization on Submaps: Multi-Session Mapping for Planetary Rovers Equipped with Stereo Cameras

    Author: Giubilato, Riccardo | University of Padova
    Author: Vayugundla, Mallikarjuna | DLR (German Aerospace Center)
    Author: Schuster, Martin J. | German Aerospace Center (DLR)
    Author: Stuerzl, Wolfgang | DLR, Institute of Robotics and Mechantronics
    Author: Wedler, Armin | DLR - German Aerospace Center
    Author: Triebel, Rudolph | German Aerospace Center (DLR)
    Author: Debei, Stefano | Université Degli Studi Di Padova
 
    keyword: Localization; Space Robotics and Automation; Mapping

    Abstract : To enable long term exploration of extreme environments such as planetary surfaces, heterogeneous robotic teams need the ability to localize themselves on previously built maps. While the Localization and Mapping problem for single sessions can be efficiently solved with many state of the art solutions, place recognition in natural environments still poses great challenges for the perception system of a robotic agent. In this paper we propose a relocalization pipeline which exploits both 3D and visual information from stereo cameras to detect matches across local point clouds of multiple SLAM sessions. Our solution is based on a Bag of Binary Words scheme where binarized SHOT descriptors are enriched with visual cues to recall in a fast and efficient way previously visited places. The proposed relocalization scheme is validated on challenging datasets captured using a planetary rover prototype on Mount Etna, designated as a Moon analogue environment

- DeepTIO: A Deep Thermal-Inertial Odometry with Visual Hallucination

    Author: Saputra, Muhamad Risqi U. | University of Oxford
    Author: Porto Buarque de Gusm�o, Pedro | University of Oxford
    Author: Lu, Chris Xiaoxuan | University of Oxford
    Author: Almalioglu, Yasin | The University of Oxford
    Author: Rosa, Stefano | University of Oxford
    Author: Chen, Changhao | University of Oxford
    Author: Wahlstrom, Johan | University of Oxford
    Author: Wang, Wei | University of Oxford
    Author: Markham, Andrew | Oxford University
    Author: Trigoni, Niki | University of Oxford
 
    keyword: Localization; Deep Learning in Robotics and Automation; Sensor Fusion

    Abstract : Visual odometry shows excellent performance in a wide range of environments. However, in visually-denied scenarios (e.g. heavy smoke or darkness), pose estimates degrade or even fail. Thermal cameras are commonly used for perception and inspection when the environment has low visibility. However, their use in odometry estimation is hampered by the lack of robust visual features. In part, this is as a result of the sensor measuring the ambient temperature profile rather than scene appearance and geometry. To overcome this issue, we propose a Deep Neural Network model for thermal-inertial odometry (DeepTIO) by incorporating a visual hallucination network to provide the thermal network with complementary information. The hallucination network is taught to predict fake visual features from thermal images by using Huber loss. We also employ selective fusion to attentively fuse the features from three different modalities, i.e thermal, hallucination, and inertial features. Extensive experiments are performed in hand-held and mobile robot data in benign and smoke-filled environments, showing the efficacy of the proposed model.

- RSL-Net: Localising in Satellite Images from a Radar on the Ground

    Author: Tang, Tim Yuqing | University of Oxford
    Author: De Martini, Daniele | University of Oxford
    Author: Barnes, Dan | University of Oxford
    Author: Newman, Paul | Oxford University
 
    keyword: Localization; Autonomous Vehicle Navigation; Deep Learning in Robotics and Automation

    Abstract : This paper is about localising a vehicle in an overhead image using FMCW radar mounted on a ground vehicle. FMCW radar offers extraordinary promise and efficacy for vehicle localisation. It is impervious to all weather types and lighting conditions. However the complexity of the interactions between millimetre radar wave and the physical environment makes it a challenging domain. Infrastructure-free large-scale radar-based localisation is in its infancy. Typically here a map is built and suitable techniques, compatible with the nature of sensor, are brought to bear. In this work we eschew the need for a radar-based map; instead we simply use an overhead image -- a resource readily available everywhere. This paper introduces a method that not only naturally deals with the complexity of the signal type but does so in the context of cross modal processing.


- Kidnapped Radar: Topological Radar Localisation Using Rotationally-Invariant Metric Learning

    Author: Saftescu, Stefan | University of Oxford
    Author: Gadd, Matthew | University of Oxford
    Author: De Martini, Daniele | University of Oxford
    Author: Barnes, Dan | University of Oxford
    Author: Newman, Paul | Oxford University
 
    keyword: Localization; Mapping; Deep Learning in Robotics and Automation

    Abstract : This paper presents a system for robust, large-scale topological localisation using Frequency-Modulated Continuous-Wave (FMCW) scanning radar. We learn a metric space for embedding polar radar scans using CNN and VLAD architectures traditionally applied to the visual domain. However, we tailor the feature extraction for more suitability to the polar nature of radar scan formation using cylindrical convolutions, anti-aliasing blurring, and azimuth-wise max-pooling; all in order to bolster the rotational invariance. The enforced metric space is then used to encode a reference trajectory, serving as a map, which is queried for nearest neighbours (NN) for recognition of places at run-time. We demonstrate the performance of our topological localisation system over the course of many repeat forays using the largest radar-focused mobile autonomy dataset released to date, totalling 280 km of urban driving, a small portion of which we also use to learn the weights of the modified architecture. As this work represents a novel application for FMCW radar, we analyse the utility of the proposed method via a comprehensive set of metrics which provide insight into the efficacy when used in a realistic system, showing improved performance over the root architecture even in the face of random rotational perturbation.

- Global Visual Localization in LiDAR-Maps through Shared 2D-3D Embedding Space

    Author: Cattaneo, Daniele | University of Freiburg
    Author: Vaghi, Matteo | Université Degli Studi Di Milano - Bicocca
    Author: Fontana, Simone | Univ. of Milano Bicocca
    Author: Ballardini, Augusto Luis | Universidad De Alcal�
    Author: Sorrenti, Domenico G. | Université Di Milano - Bicocca
 
    keyword: Localization; Deep Learning in Robotics and Automation; Sensor Fusion

    Abstract : Global localization is an important and widely studied problem for many robotic applications. Place recognition approaches can be exploited to solve this task, <i>e.g.</i>, in the autonomous driving field. While most vision-based approaches match an image <i>w.r.t.</i> an image database, global visual localization within LiDAR-maps remains fairly unexplored, even though the path toward high definition 3D maps, produced mainly from LiDARs, is clear. In this work we leverage Deep Neural Network (DNN) approaches to create a shared embedding space between images and LiDAR-maps, allowing for image to 3D-LiDAR place recognition. We trained a 2D and a 3D DNN that create embeddings, respectively from images and from point clouds, that are close to each other whether they refer to the same place. An extensive experimental activity is presented to assess the effectiveness of the approach <i>w.r.t.</i> different learning paradigms, network architectures, and loss functions. All the evaluations have been performed using the Oxford Robotcar Dataset, which encompasses a wide range of weather and light conditions.

- Unsupervised Learning Methods for Visual Place Recognition in Discretely and Continuously Changing Environments

    Author: Schubert, Stefan | Chemnitz University of Technology
    Author: Neubert, Peer | Chemnitz University of Technology
    Author: Protzel, Peter | Chemnitz University of Technology
 
    keyword: Localization; SLAM; Visual-Based Navigation

    Abstract : Visual place recognition in changing environments is the problem of finding matchings between two sets of observations, a query set and a reference set, despite severe appearance changes. Recently, image comparison using CNN-based descriptors showed very promising results. However, existing experiments from the literature typically assume a single distinctive condition within each set (e.g., reference: day, query: night). We demonstrate that as soon as the conditions change within one set (e.g., reference: day,	query: traversal daytime-dusk-night-dawn), different places under the same condition can suddenly look more similar than same places under different conditions and state-of-the-art approaches like CNN-based descriptors fail. This paper discusses this practically very important problem of in-sequence condition changes and defines a hierarchy of problem setups from (1) no in-sequence changes, (2) discrete in-sequence changes, to (3) continuous in-sequence changes. We will experimentally evaluate the effect of these changes on two state-of-the-art CNN-descriptors. Our experiments emphasize the importance of statistical standardization of descriptors and shows its limitations in case of continuous changes. To address this practically most relevant setup, we investigate and experimentally evaluate the application of unsupervised learning methods using two available PCA-based approaches and propose a novel clustering-based extension of the statistical normalization.

- LOL: Lidar-Only Odometry and Localization in 3D Point Cloud Maps

    Author: Rozenberszki, D�vid | MTA SZTAKI
    Author: Majdik, Andras | Hungarian Academy of Sciences
 
    keyword: Localization; Range Sensing; Computer Vision for Transportation

    Abstract : In this paper we deal with the problem of odometry and localization for Lidar-equipped vehicles driving in urban environments, where a premade target map exists to localize against. In our problem formulation, to correct the accumulated drift of the Lidar-only odometry we apply a place recognition method to detect geometrically similar locations between the online 3D point cloud and the a priori offline map. In the proposed system, we integrate a state-of-the-art Lidar-only odometry algorithm with a recently proposed 3D point segment matching method by complementing their advantages. Also, we propose additional enhancements in order to reduce the number of false matches between the online point cloud and the target map, and to refine the position estimation error whenever a good match is detected. We demonstrate the utility of the proposed LOL system on several Kitti datasets of different lengths and environments, where the relocalization accuracy and the precision of the vehicle's trajectory were significantly improved in every case, while still being able to maintain real-time performance.

- Localising Faster: Efficient and Precise Lidar-Based Robot Localisation in Large-Scale Environments

    Author: Sun, Li | University of Oxford
    Author: Adolfsson, Daniel | Örebro University
    Author: Magnusson, Martin | Örebro University
    Author: Andreasson, Henrik | Örebro University
    Author: Posner, Ingmar | Oxford University
    Author: Duckett, Tom | University of Lincoln
 
    keyword: Localization; Deep Learning in Robotics and Automation

    Abstract : This paper proposes a novel approach for global localisation of mobile robots in large-scale environments. Our method leverages learning-based localisation and filtering-based localisation, to localise the robot efficiently and precisely through seeding Monte Carlo Localisation (MCL) with a deep-learned distribution. In particular, a fast localisation system rapidly estimates the 6-DOF pose through a deep-probabilistic model (Gaussian Process Regression with a deep kernel), then a precise recursive estimator refines the estimated robot pose according to the geometric alignment. More importantly, the Gaussian method (i.e. deep probabilistic localisation) and non-Gaussian method (i.e. MCL) can be integrated naturally via importance sampling. Consequently, the two systems can be integrated seamlessly and mutually benefit from each other. To verify the proposed framework, we provide a case study in large-scale localisation with a 3D lidar sensor. Our experiments on the Michigan NCLT long-term dataset show that the proposed method is able to localise the robot in 1.94 s on average (median of 0.8 s) with precision 0.75 m in a largescale environment of approximately 0.5 km2.

- Set-Membership State Estimation by Solving Data Association

    Author: Rohou, Simon | ENSTA Bretagne
    Author: Desrochers, Benoit | ENSTA-Bretagne
    Author: Jaulin, Luc | ENSTA-Bretagne
 
    keyword: Localization; Autonomous Vehicle Navigation; Marine Robotics

    Abstract : This paper deals with the localization problem of a robot in an environment made of indistinguishable landmarks, and assuming the initial position of the vehicle is unknown. This scenario is typically encountered in underwater applications for which landmarks such as rocks all look alike. Furthermore, the position of the robot may be lost during a diving phase, which obliges us to consider unknown initial position. We propose a deterministic approach to solve simultaneously the problems of data association and state estimation, without combinatorial explosion. The efficiency of the method is shown on an actual experiment involving an underwater robot and sonar data.

## Learning from Demonstration

- Benchmark for Skill Learning from Demonstration: Impact of User Experience, Task Complexity, and Start Configuration on Performance

    Author: Rana, Muhammad Asif | Georgia Institute of Technology
    Author: Chen, Daphne | Georgia Institute of Technology
    Author: Williams, Jacob | Georgia Institute of Technology
    Author: Chu, Vivian | Georgia Institute of Technology
    Author: Ahmadzadeh, S. Reza | University of Massachusetts Lowell
    Author: Chernova, Sonia | Georgia Institute of Technology
 
    keyword: Learning from Demonstration

    Abstract : We contribute a study benchmarking the performance of multiple motion-based learning from demonstration approaches. Given the number and diversity of existing methods, it is critical that comprehensive empirical studies be performed comparing the relative strengths of these techniques. In particular, we evaluate four approaches based on properties an end user may desire for real-world tasks. To perform this evaluation, we collected data from nine participants, across four manipulation tasks. The resulting demonstrations were used to train 180 task models and evaluated on 720 task reproductions on a physical robot. Our results detail how i) complexity of the task, ii) the expertise of the human demonstrator, and iii) the starting configuration of the robot affect task performance. The collected dataset of demonstrations, robot executions, and evaluations are publicly available. Research insights and guidelines are also provided to guide future research and deployment choices about these approaches.

- MPC-Net: A First Principles Guided Policy Search

    Author: Carius, Jan | ETH Zurich
    Author: Farshidian, Farbod | ETH Zurich
    Author: Hutter, Marco | ETH Zurich
 
    keyword: Learning from Demonstration; Legged Robots; Optimization and Optimal Control

    Abstract : We present an Imitation Learning approach for the control of dynamical systems with a known model. Our policy search method is guided by solutions from MPC. Typical policy search methods of this kind minimize a distance metric between the guiding demonstrations and the learned policy. Our loss function, however, corresponds to the minimization of the control Hamiltonian, which derives from the principle of optimality. Therefore, our algorithm directly attempts to solve the optimality conditions with a parameterized class of control laws. Additionally, the proposed loss function explicitly encodes the constraints of the optimal control problem and we provide numerical evidence that its minimization achieves improved constraint satisfaction. We train a mixture-of-expert neural network architecture for controlling a quadrupedal robot and show that this policy structure is well suited for such multimodal systems. The learned policy can successfully stabilize different gaits on the real walking robot from less than 10 min of demonstration data.

- Robot Programming without Coding

    Author: Lentini, Gianluca | University of Pisa
    Author: Grioli, Giorgio | Istituto Italiano Di Tecnologia
    Author: Catalano, Manuel Giuseppe | Istituto Italiano Di Tecnologia
    Author: Bicchi, Antonio | Université Di Pisa
 
    keyword: Learning from Demonstration; Natural Machine Motion; Learning and Adaptive Systems

    Abstract : An approach toward intuitive and easy robot programming, consists to transfer skills from humans to machines, through demonstration. A vast literature exists on learning from multiple demonstrations. This paper, on the other hand, tackles the problem of providing all needed information to execute a certain task by resorting to one single demonstration - hence, a problem closer to programming than to learning. We use wearable consumer devices - but no keyboard nor coding - as programming tools, to let the programmer tele-operate the robot, which in turn records the most salient features and affordances from the object, environment, robot, and human. To enable this goal we combine off-the-shelf soft-articulated robotic components with the framework of Dynamic Movement Primitives, which we contribute to extend to generalize human trajectories and impedance regulation skills. This framework enables to teach robot quickly and in a intuitive way without coding. Experimental tests have been performed on a dual-arm system composed by two 7-dofs collaborative robots equipped with anthropomorphic end-effectors. Experiments show the functionality of the framework and verify the effectiveness of the impedance extension.

- Learning Robust Task Priorities and Gains for Control of Redundant Robots

    Author: Penco, Luigi | INRIA
    Author: Mingo Hoffman, Enrico | Fondazione Istituto Italiano Di Tecnologia
    Author: Modugno, Valerio | Sapienza Université Di Roma
    Author: Gomes, Waldez | INRIA
    Author: Mouret, Jean-Baptiste | Inria
    Author: Ivaldi, Serena | INRIA
 
    keyword: Learning from Demonstration; Humanoid Robots

    Abstract : Generating complex movements in redundant robots like humanoids is usually done by means of multi-task controllers based on quadratic programming, where a multitude of tasks is organized according to strict or soft priorities. Time-consuming tuning and expertise are required to choose suitable task priorities, and to optimize their gains. Here, we automatically learn the controller configuration (soft and strict task priorities and Convergence Gains), looking for solutions that track a variety of desired task trajectories efficiently while preserving the robot's balance. We use multi-objective optimization to compare and choose among Pareto-optimal solutions that represent a trade-off of performance and robustness and can be transferred onto the real robot. We experimentally validate our method by learning a control configuration for the iCub humanoid, to perform different whole-body tasks, such as picking up objects, reaching and opening doors.

- Planning with Uncertain Specifications (PUnS)

    Author: Shah, Ankit Jayesh | Massachusetts Institute of Technology
    Author: Li, Shen | MIT
    Author: Shah, Julie A. | MIT
 
    keyword: Learning from Demonstration; AI-Based Methods

    Abstract : Reward engineering is crucial to high performance in reinforcement learning systems. Prior research into reward design has largely focused on Markovian functions representing the reward. While there has been research into expressing non-Markov rewards as linear temporal logic (LTL) formulas, this has focused on task specifications directly defined by the user. However, in many real-world applications, task specifications are ambiguous, and can only be expressed as a belief over LTL formulas. In this paper, we introduce planning with uncertain specifications (PUnS), a novel formulation that addresses the challenge posed by non-Markovian specifications expressed as beliefs over LTL formulas. We present four criteria that capture the semantics of satisfying a belief over specifications for different applications, and analyze the qualitative implications of these criteria within a synthetic domain. We demonstrate the existence of an equivalent Markov decision process (MDP) for any instance of PUnS. Finally, we demonstrate our approach on the real-world task of setting a dinner table automatically with a robot that inferred task specifications from human demonstrations.

- Predictive Modeling of Periodic Behavior for Human-Robot Symbiotic Walking

    Author: Clark, Geoffrey | ASU
    Author: Campbell, Joseph | Arizona State University
    Author: Rezayat sorkhabadi, Seyed Mostafa | Arizona State University
    Author: Zhang, Wenlong | Arizona State University
    Author: Ben Amor, Heni | Arizona State University
 
    keyword: Learning from Demonstration; Physical Human-Robot Interaction

    Abstract : We propose in this paper Periodic Interaction Primitives - a probabilistic framework that can be used to learn compact models of periodic behavior. Our approach extends existing formulations of Interaction Primitives to periodic movement regimes, i.e., walking. We show that this model is particularly well-suited for learning data-driven, customized models of human walking, which can then be used for generating predictions over future states or for inferring latent, biomechanical variables. We also demonstrate how the same framework can be used to learn controllers for a robotic prosthesis using an imitation learning approach. Results in experiments with human participants indicate that Periodic Interaction Primitives efficiently generate predictions and ankle angle control signals for a robotic prosthetic ankle, with MAE of 2.21&#9702;in 0.0008s per inference. Performance degrades gracefully in the presence of noise or sensor fall outs. Compared to alternatives, this algorithm functions 20 times faster and performed 4.5 times more accurately on test subjects.

- Adaptive Curriculum Generation from Demonstrations for Sim-To-Real Visuomotor Control

    Author: Hermann, Lukas | University of Freiburg
    Author: Argus, Maximilian | University of Freiburg
    Author: Eitel, Andreas | University of Freiburg
    Author: Amiranashvili, Artemij | University of Freiburg
    Author: Burgard, Wolfram | Toyota Research Institute
    Author: Brox, Thomas | University of Freiburg
 
    keyword: Learning from Demonstration; Deep Learning in Robotics and Automation; Perception for Grasping and Manipulation

    Abstract : We propose Adaptive Curriculum Generation from demonstrations (ACGD) for reinforcement learning in the presence of sparse rewards. Rather than designing shaped reward functions, ACGD adaptively sets the appropriate task difficulty for the learner by controlling where to sample from the demonstration trajectories and which set of simulation parameters to use. We show that training vision-based control policies in simulation while gradually increasing the difficulty of the task via ACGD improves the policy transfer to the real world. The degree of domain randomization is also gradually increased through the task difficulty. We demonstrate zero-shot transfer for two real-world manipulation tasks: pick-and-stow and block stacking.

- Accept Synthetic Objects As Real: End-To-End Training of Attentive Deep Visuomotor Policies for Manipulation in Clutter

    Author: Abolghasemi, Pooya | University of Central Florida
    Author: B�l�ni, Ladislau | University of Central Florida
 
    keyword: Learning from Demonstration; Deep Learning in Robotics and Automation; Perception for Grasping and Manipulation

    Abstract : Recent research demonstrated that it is feasible to end-to-end train multi-task deep visuomotor policies for robotic manipulation using variations of learning from demonstration (LfD) and reinforcement learning (RL). In this paper, we extend the capabilities of end-to-end LfD architectures to object manipulation in clutter. We start by introducing a data augmentation procedure called Accept Synthetic Objects as Real (ASOR). Using ASOR we develop two network architectures: implicit attention ASOR-IA and explicit attention ASOR-EA. Both architectures use the same training data (demonstrations in uncluttered environments) as previous approaches. Experimental results show that ASOR-IA and ASOR-EA succeed in a significant fraction of trials in cluttered environments where previous approaches never succeed. In addition, we find that both ASOR-IA and ASOR-EA outperform previous approaches even in uncluttered environments, with ASOR-EA performing better even in clutter compared to the previous best baseline in an uncluttered environment.

- A Probabilistic Framework for Imitating Human Race Driver Behavior

    Author: L�ckel, Stefan | TU Darmstadt, Porsche AG
    Author: Peters, Jan | Technische Universitét Darmstadt
    Author: van Vliet, Peter | Porsche AG
 
    keyword: Learning from Demonstration; Autonomous Vehicle Navigation

    Abstract : Understanding and modeling human driver behavior is crucial for advanced vehicle development. However, unique driving styles, inconsistent behavior, and complex decision processes render it a challenging task, and existing approaches often lack variability or robustness. To approach this problem, we propose Probabilistic Modeling of Driver behavior (ProMoD), a modular framework which splits the task of driver behavior modeling into multiple modules. A global target trajectory distribution is learned with Probabilistic Movement Primitives, clothoids are utilized for local path generation, and the corresponding choice of actions is performed by a neural network. Experiments in a simulated car racing setting show considerable advantages in imitation accuracy and robustness compared to other imitation learning algorithms. The modular architecture of the proposed framework facilitates straightforward extensibility in driving line adaptation and sequencing of multiple movement primitives for future research.

- Learning of Exception Strategies in Assembly Tasks

    Author: Nemec, Bojan | Jozef Stefan Institute
    Author: Simoni&#269;, Mihael | Jo�ef Stefan Institute
    Author: Ude, Ales | Jozef Stefan Institute
 
    keyword: Learning from Demonstration; Learning and Adaptive Systems; Intelligent and Flexible Manufacturing

    Abstract : Assembly tasks performed with a robot often fail due to unforeseen situations, regardless of the fact that we carefully learned and optimized the assembly policy. This problem is even more present in humanoid robots acting in an unstructured environment where it is not possible to anticipate all factors that might lead to the failure of the given task. In this work, we propose a concurrent LfD framework, which associates demonstrated exception strategies to the given context. Whenever a failure occurs, the proposed algorithm generalizes past experience regarding the current context and generates an appropriate policy that solves the assembly issue. For this purpose, we applied PCA on force/torque data, which generates low dimensional descriptor of the current context. The proposed framework was validated in a peg-in-hole (PiH) task using Franka-Emika Panda robot.

- A Framework for Learning from Demonstration with Minimal Human Effort

    Author: Rigter, Marc | University of Oxford
    Author: Lacerda, Bruno | University of Oxford
    Author: Hawes, Nick | University of Oxford
 
    keyword: Learning from Demonstration; Human-Centered Robotics; Telerobotics and Teleoperation

    Abstract : We consider robot learning in the context of shared autonomy, where control of the system can switch between a human teleoperator and autonomous control. In this setting we address reinforcement learning, and learning from demonstration, where there is a cost associated with human time. This cost represents the human time required to teleoperate the robot, or recover the robot from failures. For each episode, the agent must choose between requesting human teleoperation, or using one of its autonomous controllers. In our approach, we learn to predict the success probability for each controller, given the initial state of an episode. This is used in a contextual multi-armed bandit algorithm to choose the controller for the episode. Furthermore, an autonomous controller is learnt from demonstrations and reinforcement learning so that the system becomes increasingly autonomous with more experience. We show that our approach to controller selection reduces the human cost to perform two robotics tasks.

- Learning Constraints from Locally-Optimal Demonstrations under Cost Function Uncertainty

    Author: Chou, Glen | University of Michigan
    Author: Ozay, Necmiye | Univ. of Michigan
    Author: Berenson, Dmitry | University of Michigan
 
    keyword: Learning from Demonstration

    Abstract : We present an algorithm for learning parametric constraints from locally-optimal demonstrations, where the cost function being optimized is uncertain to the learner. Our method uses the Karush-Kuhn-Tucker (KKT) optimality conditions of the demonstrations within a mixed integer linear program (MILP) to learn constraints which are consistent with the local optimality of the demonstrations, by either using a known constraint parameterization or by incrementally growing a parameterization that is consistent with the demonstrations. We provide theoretical guarantees on the conservativeness of the recovered safe/unsafe sets and analyze the limits of constraint learnability when using locally-optimal demonstrations. We evaluate our method on high-dimensional constraints and systems by learning constraints for 7-DOF arm and quadrotor examples, show that it outperforms competing constraint-learning approaches, and can be effectively used to plan new constraint-satisfying trajectories in the environment.

- Gershgorin Loss Stabilizes the Recurrent Neural Network Compartment of an End-To-End Robot Learning Scheme

    Author: Lechner, Mathias | IST Austria
    Author: Hasani, Ramin | TU Wien
    Author: Rus, Daniela | MIT
    Author: Grosu, Radu | TU Wien
 
    keyword: Learning from Demonstration; Deep Learning in Robotics and Automation; Model Learning for Control

    Abstract : Traditional robotic control suits require profound task-specific knowledge for designing, building and testing control software. The rise of Deep Learning has enabled end-to-end solutions to be learned entirely from data, requiring minimal knowledge about the application area. We design a learning scheme to train end-to-end linear dynamical systems (LDS)s by gradient descent in imitation learning robotic domains. We introduce a new regularization loss component together with a learning algorithm that improves the stability of the learned autonomous system, by forcing the eigenvalues of the internal state updates of an LDS to be negative reals. We evaluate our approach on a series of real-life and simulated robotic experiments, in comparison to linear and nonlinear Recurrent Neural Network (RNN) architectures. Our results show that our stabilizing method significantly improves test performance of LDS, enabling such linear models to match the performance of contemporary nonlinear RNN architectures. A video of the obstacle avoidance performance of our method on a mobile robot, in unseen environments, compared to other methods can be viewed at https://youtu.be/mhEsCoNao5E.

- Mini-Batched Online Incremental Learning through Supervisory Teleoperation with Kinesthetic Coupling

    Author: Latifee, Hiba | Korea Advanced Institute of Science and Technology
    Author: Pervez, Affan | Technical University of Munich
    Author: Ryu, Jee-Hwan | Korea Advanced Institute of Science and Technology
    Author: Lee, Dongheui | Technical University of Munich
 
    keyword: Learning from Demonstration; Telerobotics and Teleoperation; Haptics and Haptic Interfaces

    Abstract : We propose an online incremental learning approach through teleoperation which allows an operator to partially modify a learned model, whenever it is necessary, during task execution. Compared to conventional incremental learning approaches, the proposed approach is applicable for teleoperation-based teaching and it needs only partial demonstration without any need to obstruct the task execution. Dynamic     Authority distribution and kinesthetic coupling between the operator and the agent helps the operator to correctly perceive the exact instance where modification needs to be asserted in the agent's behaviour online using partial trajectory. For this, we propose a variation of the Expectation-Maximization algorithm for updating original model through mini batches of the modified partial trajectory. The proposed approach reduces human workload and latency for a rhythmic peg-in-hole teleoperation task where online partial modification is required during the task operation.

- Recurrent Neural Network Control of a Hybrid Dynamical Transfemoral Prosthesis with EdgeDRNN Accelerator

    Author: Gao, Chang | University of Zurich and ETH Zurich
    Author: Gehlhar, Rachel | California Institute of Technology
    Author: Ames, Aaron | Caltech
    Author: Liu, Shih-Chii | University of Zurich and ETH Zurich
    Author: Delbruck, Tobi | Institute of Neuroinformatics, University of Zurich/ETH
 
    keyword: Learning from Demonstration; Prosthetics and Exoskeletons

    Abstract : Lower leg prostheses could improve the life quality of amputees by increasing comfort and reducing energy to locomote, but currently control methods are limited in modulating behaviors based upon the human's experience. This paper describes the first steps toward learning complex controllers for dynamical robotic assistive devices. We provide the first example of behavioral cloning to control a powered transfemoral prostheses using a Gated Recurrent Unit (GRU) based recurrent neural network (RNN) running on a custom hardware accelerator that exploits temporal sparsity. The RNN is trained on data collected from the original prosthesis controller. The RNN inference is realized by a novel EdgeDRNN accelerator in real-time. Experimental results show that the RNN can replace the nominal PD controller to realize end-to-end control of the AMPRO3 prosthetic leg walking on flat ground and unforeseen slopes with comparable tracking accuracy. EdgeDRNN computes the RNN about 240 times faster than real time, opening the possibility of running larger networks for more complex tasks in the future. Implementing an RNN on this real-time dynamical system with impacts sets the ground work to incorporate other learned elements of the human-prosthesis system into prosthesis control.

- Cross-Context Visual Imitation Learning from Demonstrations

    Author: Yang, Shuo | Shandong University
    Author: Zhang, Wei | Shandong University
    Author: Lu, Weizhi | Shandong University
    Author: Wang, Hesheng | Shanghai Jiao Tong University
    Author: Li, Yibin | Shandong University
 
    keyword: Learning from Demonstration; Model Learning for Control; Grasping

    Abstract : Imitation learning enables robots to learn a task by simply watching the demonstration of the task. Current imitation learning methods usually require the learner and demonstrator to occur in the same context. This limits their scalability to practical applications. In this paper, we propose a more general imitation learning method which allows the learner and the demonstrator to come from different contexts, such as different viewpoints, backgrounds, and object positions and appearances. Specifically, we design a robotic system consisting of three models: context translation model, depth prediction model and multi-modal inverse dynamics model. First, the context translation model translates the demonstration to the context of learner from a different context. Then combining the color observation and depth observation as inputs, the inverse model maps the multi-modal observations into actions to reproduce the demonstration, where the depth observation is provided by a depth prediction model. By performing the block stacking tasks both in simulation and real world, we prove the cross-context learning advantage of the proposed robotic system over other systems.

- Improving Generalisation in Learning Assistance by Demonstration for Smart Wheelchairs

    Author: Schettino, Vinicius | Imperial College London
    Author: Demiris, Yiannis | Imperial College London
 
    keyword: Learning from Demonstration; Physically Assistive Devices; Virtual Reality and Interfaces

    Abstract : Learning Assistance by Demonstration (LAD) is concerned with using demonstrations of a human agent to teach a robot how to assist another human. The concept has previously been used with smart wheelchairs to provide customised assistance to individuals with driving difficulties. A basic premise of this technique is that the learned assistive policy should be able to generalise to environments different than the ones used for training; but this has not been tested before. In this work we evaluate the assistive power and the generalisation capability of LAD using our custom teleoperation and learning system for smart wheelchairs, while seeking to improve it by experimenting with different combinations of dimensionality reduction techniques and machine learning models. Using Autoencoders to reduce the dimension of laser-scan data and a Gaussian Process as the learning model, we achieved a 23% improvement in prediction performance against the combination used by the latest work on the field. Using this model to assist a driver exposed to a simulated disability, we observed a 9.8% reduction in track completion times when compared to driving without assistance.

- Analyzing the Suitability of Cost Functions for Explaining and Imitating Human Driving Behavior Based on Inverse Reinforcement Learning

    Author: Naumann, Maximilian | FZI Research Center for Information Technology
    Author: Sun, Liting | University of California, Berkeley
    Author: Zhan, Wei | Univeristy of California, Berkeley
    Author: Tomizuka, Masayoshi | University of California
 
    keyword: Learning from Demonstration; Motion and Path Planning; Autonomous Vehicle Navigation

    Abstract : Autonomous vehicles are sharing the road with human drivers. In order to facilitate interactive driving and cooperative behavior in dense traffic, a thorough understanding and representation of other traffic participants' behavior are necessary. Cost functions (or reward functions) have been widely used to describe the behavior of human drivers since they can not only explicitly incorporate the rationality of human drivers and the theory of mind (TOM), but also share similarity with the motion planning problem of autonomous vehicles. Hence, more human-like driving behavior and comprehensible trajectories can be generated to enable safer interaction and cooperation. However, the selection of cost functions in different driving scenarios is not trivial, and there is no systematic summary and analysis for cost function selection and learning from a variety of driving scenarios. <p>In this work, we aim to investigate to what extent cost functions are suitable for explaining and imitating human driving behavior. Further, we focus on how cost functions differ from each other in different driving scenarios. Towards this goal, we first comprehensively review existing cost function structures in literature. Based on that, we point out required conditions for demonstrations to be suitable for inverse reinforcement learning (IRL). Finally, we use IRL to explore suitable features and learn representative cost functions from human driven trajectories in three different scenarios.

 


- A Linearly Constrained Nonparametric Framework for Imitation Learning

    Author: Huang, Yanlong | University of Leeds
    Author: Caldwell, Darwin G. | Istituto Italiano Di Tecnologia
 
    keyword: Learning from Demonstration

    Abstract : In recent years, a myriad of advanced results have been reported in the community of imitation learning, ranging from parametric to non-parametric, probabilistic to non-probabilistic and Bayesian to frequentist approaches. Meanwhile, ample applications (e.g., grasping tasks and human-robot collaborations) further show the applicability of imitation learning in a wide range of domains. While numerous literature is dedicated to the learning of human skills in unconstrained environments, the problem of learning constrained motor skills, however, has not received equal attention. In fact, constrained skills exist widely in robotic systems. For instance, when a robot is demanded to write letters on a board, its end-effector trajectory must comply with the plane constraint from the board. In this paper, we propose linearly constrained kernelized movement primitives (LC-KMP) to tackle the problem of imitation learning with linear constraints. Specifically, we propose to exploit the probabilistic properties of multiple demonstrations, and subsequently incorporate them into a linearly constrained optimization problem, which finally leads to a non-parametric solution. In addition, a connection between our framework and the classical model predictive control is provided. Several examples including simulated writing and locomotion tasks are presented to show the effectiveness of our framework.

- An Energy-Based Approach to Ensure the Stability of Learned Dynamical Systems

    Author: Saveriano, Matteo | University of Innsbruck
 
    keyword: Learning from Demonstration; Learning and Adaptive Systems

    Abstract : Non-linear dynamical systems represent a compact, flexible, and robust tool for real-time motion generation. The effectiveness on dynamical systems relies on their ability to accurately represent stable motions. Several approaches have been proposed to learn stable and accurate motions from demonstration. Some approaches work by separating accuracy and stability into two learning problems, which increases the number of open parameters and the overall training time. Alternative solutions exploit single-step learning but restrict the applicability to one regression technique. This paper presents a single-step approach to learn stable and accurate motions that work with any regression technique. The approach makes energy considerations on the learned dynamics to stabilize the system at run-time while introducing small deviations from the demonstrated motion. Since the initial value of the energy injected into the system affects the reproduction accuracy, it is estimated from training data using an efficient procedure. Experiments on a real robot and comparisons on a public benchmark show the effectiveness of the proposed approach.

- IRIS: Implicit Reinforcement without Interaction at Scale for Learning Control from Offline Robot Manipulation Data

    Author: Mandlekar, Ajay Uday | Stanford University
    Author: Ramos, Fabio | University of Sydney, NVIDIA
    Author: Boots, Byron | University of Washington
    Author: Savarese, Silvio | Stanford University
    Author: Fei-Fei, Li | Stanford University
    Author: Garg, Animesh | University of Toronto
    Author: Fox, Dieter | University of Washington
 
    keyword: Learning from Demonstration; Deep Learning in Robotics and Automation; Learning and Adaptive Systems

    Abstract : Learning from offline task demonstrations is a problem of great interest in robotics. For simple short-horizon manipulation tasks with modest variation in task instances, offline learning from a small set of demonstrations can produce controllers that successfully solve the task. However, leveraging a fixed batch of data can be problematic for larger datasets and longer-horizon tasks with greater variation. The data can exhibit substantial diversity and consist of suboptimal solution approaches. In this paper, we propose Implicit Reinforcement without Interaction at Scale (IRIS), a novel framework for learning from large-scale demonstration datasets. IRIS factorizes the control problem into a goal-conditioned low-level controller that imitates short demonstration sequences and a high-level goal selection mechanism that sets goals for the low-level and selectively combines parts of suboptimal solutions leading to more successful task completions. We evaluate IRIS across three datasets, including the RoboTurk Cans dataset collected by humans via crowdsourcing, and show that performant policies can be learned from purely offline learning.

- Geometry-Aware Dynamic Movement Primitives

    Author: Abu-Dakka, Fares | Aalto University
    Author: Kyrki, Ville | Aalto University
 
    keyword: Learning from Demonstration; Motion Control of Manipulators; Industrial Robots

    Abstract : In many robot control problems, factors such as stiffness and damping matrices and manipulability ellipsoids are naturally represented as symmetric positive definite (SPD) matrices, which capture the specific geometric characteristics of those factors. Typical learned skill models such as dynamic movement primitives (DMPs) can not, however, be directly employed with quantities expressed as SPD matrices as they are limited to data in Euclidean space. In this paper, we propose a novel and mathematically principled framework that uses Riemannian metrics to reformulate DMPs such that the resulting formulation can operate with SPD data in the SPD manifold. Evaluation of the approach demonstrates that beneficial properties of DMPs such as change of the goal during operation apply also to the proposed formulation.

- Learning a Pile Loading Controller from Demonstrations

    Author: Yang, Wenyan | Tampere University
    Author: Strokina, Nataliya | Tampere University of Technology
    Author: Serbenyuk, Nikolay | Tampere University
    Author: Ghabcheloo, Reza | Tampere University of Technology
    Author: Kamarainen, Joni-Kristian | Tampere University of Technology
 
    keyword: Learning from Demonstration; Computer Vision for Automation; Robotics in Construction

    Abstract : This work introduces a learning-based pile loading controller for autonomous robotic wheel loaders. Controller parameters are learnt from a small number of demonstrations for which low level sensor (boom angle, bucket angle and hy- drostatic driving pressure), egocentric video frames and control signals are recorded. Application specific deep visual features are learnt from demonstrations using a Siamese network architecture and a combination of cross-entropy and contrastive loss. The controller is based on a Random Forest (RF) regressor that provides robustness against changes in field conditions (loading distance, soil type, weather and illumination). The controller is deployed to a real autonomous robotic wheel loader and it outperforms prior art with a clear margin.

- Learning Navigation Costs from Demonstration in Partially Observable Environments

    Author: Wang, Tianyu | University of California, San Diego
    Author: Dhiman, Vikas | University of Michigan
    Author: Atanasov, Nikolay | University of California, San Diego
 
    keyword: Learning from Demonstration; Autonomous Vehicle Navigation; Model Learning for Control

    Abstract : This paper focuses on inverse reinforcement learning (IRL) to enable safe and efficient autonomous navigation in unknown partially observable environments. The objective is to infer a cost function that explains expert-demonstrated navigation behavior while relying only on the observations and state-control trajectory used by the expert. We develop a cost function representation composed of two parts: a probabilistic occupancy encoder, with recurrent dependence on the observation sequence, and a cost encoder, defined over the occupancy features. The representation parameters are optimized by differentiating the error between demonstrated controls and a control policy computed from the cost encoder. Such differentiation is typically computed by dynamic programming through the value function over the whole state space. We observe that this is inefficient in large partially observable environments because most states are unexplored. Instead, we rely on a closed-form subgradient of the cost-to-go obtained only over a subset of promising states via an efficient motion-planning algorithm such as A* or RRT. Our experiments show that our model exceeds the accuracy of baseline IRL algorithms in robot navigation tasks, while substantially improving the efficiency of training and test-time inference.


## Medical Robots and Systems

- Design of a Percutaneous MRI-Guided Needle Robot with Soft Fluid-Driven Actuator

    Author: He, Zhuoliang | The University of Hong Kong
    Author: Dong, Ziyang | The University of Hong Kong
    Author: Fang, Ge | The University of Hong Kong
    Author: Ho, Justin Di-Lang | The University of Hong Kong
    Author: Cheung, Chim Lee | The University of Hong Kong
    Author: Chang, Hing-Chiu | The University of Hong Kong
    Author: Chong, Ching-Ning | The Chinese University of Hong Kong
    Author: Chan, Ying-Kuen | The Chinese University of Hong Kong
    Author: Chan, Tat-Ming | Prince of Wales Hospital
    Author: Kwok, Ka-Wai | The University of Hong Kong
 
    keyword: Medical Robots and Systems; Soft Robot Applications; Mechanism Design

    Abstract : Percutaneous ablation is a standard therapy for most cases of hepatocellular carcinoma (HCC), which is a general type of primary liver cancer. Magnetic resonance imaging (MRI) offers high-contrast images of soft tissue to monitor the ablation procedure. However, the success of MRI-guided ablation still depends on precise intra-tumor probe placement and skin insertion positioning, both of which require highly experienced operators, and can induce inter-operator variability in ablation results. In this letter, we present a semi-automated robotic system for MRI-guided percutaneous needle procedures. The compact and lightweight design enables the direct fixture of robot on the patient body and simultaneous needle targeting at multiple locations with several robots. Accurate (0.89 - 0.31 mm) needle navigation is achieved by incorporating soft fluid-driven actuators with feedback control and stiffness modulation capabilities. The 3D location of the needle guide is reconfirmed by wireless MR tracking coils. The performance of the robotic platform, such as stiffness, needle positioning accuracy and frequency response was experimentally evaluated. Negligible interference to MR imaging was also validated by an MR compatibility test.

- SCADE: Simultaneous Sensor Calibration and Deformation Estimation of FBG-Equipped Unmodeled Continuum Manipulators (I)

    Author: Alambeigi, Farshid | University of Texas at Austin
    Author: Aghajani Pedram, Sahba | University of California, Los Angeles
    Author: Jason L., Speyer | Department of Mechanical and Aerospace Engineering, University O
    Author: Rosen, Jacob | &#8203;University of California, Los Angeles
    Author: Iordachita, Ioan Iulian | Johns Hopkins University
    Author: Taylor, Russell H. | The Johns Hopkins University
    Author: Armand, Mehran | Johns Hopkins University Applied Physics Laboratory
 
    keyword: Medical Robots and Systems; Sensor Fusion; Flexible Robots

    Abstract : We present a novel stochastic algorithm called simultaneous sensor calibration and deformation estimation(SCADE) to address the problem of modeling deformation behavior of a generic continuum manipulator (CM) in free and obstructed environments. In SCADE, using a	novel mathematical formulation, we introduce a priori model-independent filtering algorithm to fuse the continuous and inaccurate	measurements of an embedded sensor (e.g., magnetic or	piezoelectric sensors) with an intermittent but accurate data of an external imaging system(e.g., optical	trackers or cameras). The	main motivation of this study is the crucial need of obtaining an accurate shape/position estimation of a CM utilized in a surgical intervention.	In these robotic procedures,	the CM is typically equipped with an embedded sensing unit while an external imaging modality (e.g.,ultrasound or a fluoroscopy machine) is also available in	the surgical site. The results of two different set of prior experiments in	free and obstructed environments were used to evaluate the efficacy of SCADE algorithm. The experiments was performed with a CM specifically designed for orthopaedic interventions and equipped with an inaccurate fiber Bragg grating (FBG) ESU and an overhead camera.

- Novel Optimization-Based Design and Surgical Evaluation of a Treaded Robotic Capsule Colonoscope (I)

    Author: Formosa, Gregory | University of Colorado at Boulder
    Author: Prendergast, Joseph Micah | University of Colorado at Boulder
    Author: Edmundowicz, Steven | University of Colorado Anschutz Medical Campus
    Author: Rentschler, Mark | University of Colorado at Boulder
 
    keyword: Medical Robots and Systems; Product Design, Development and Prototyping; Wheeled Robots

    Abstract : Robotic capsule endoscopes (RCEs) are being widely investigated to improve the state of various endoscopy procedures. This article presents the novel design of a multi-DOF sensor-enabled RCE for colonoscopies (Endoculus) and evaluates porcine in vivo and ex vivo performance. The novelty of the design includes a custom �double-worm� drive that removes axial gear forces while reducing radial moments, and the full parameterization of gear geometries allows for size minimization via an optimization routine over design constraints. Two independently controlled motors drive micro-pillared treads above and below the device allowing for two-degrees of freedom (2-DOF) skid-steering, even in a collapsed lumen. The Endoculus contains all functionality of a traditional endoscope: a camera, adjustable light emitting diodes (LEDs), channels for insufflation and irrigation, and a tool port for endoscopy instruments (e.g., forceps, snares, etc.). Additionally, the Endoculus carries an inertial measurement unit, magnetometer, motor encoders, and motor current sensors to aid in future autonomy strategies. Porcine surgical evaluation demonstrated locomotion up to 40 mm/s on the colon mucosa, 2-DOF steering, the ability to traverse haustral folds, and functionality of endoscopy tools. This platform will enable future validation of feedback control, localization, and mapping algorithms in the unconventional in vivo environment.

- Generative Localisation with Uncertainty Estimation through Video-CT Data for Bronchoscopic Biopsy

    Author: Zhao, Cheng | University of Oxford
    Author: Shen, Mali | The Hamlyn Centre for Robotic Surgery, Imperial College London
    Author: Sun, Li | University of Sheffield
    Author: Yang, Guang-Zhong | Shanghai Jiao Tong University
 
    keyword: Medical Robots and Systems

    Abstract : Robot-assisted endobronchial intervention requires accurate localisation based on both intra- and pre-operative data. Most existing methods achieve this by registering 2D videos with 3D CT models according to a defined similarity metric with local features. Instead, we formulate the bronchoscopic localisation as a learning-based global localisation using deep neural networks. The proposed network consists of two generative architectures and one auxiliary learning component. The cycle generative architecture bridges the domain variance between the real bronchoscopic videos and virtual views derived from pre-operative CT data so that the proposed approach can be trained through a large number of generated virtual images but deployed through real images. The auxiliary learning architecture leverages complementary relative pose regression to constrain the search space, ensuring consistent global pose predictions. Most importantly, the uncertainty of each global pose is obtained through variational inference by sampling within the learned underlying probability distribution. Detailed validation results demonstrate the localisation accuracy with reasonable uncertainty achieved and its potential clinical value.

- Internet of Things (IoT)-Based Collaborative Control of a Redundant Manipulator for Teleoperated Minimally Invasive Surgeries

    Author: Su, Hang | Politecnico Di Milano
    Author: Ovur, Salih Ertug | Politecnico Di Milano
    Author: Li, Zhijun | University of Science and Technology of China
    Author: Hu, Yingbai | Technische Universitét M�nchen
    Author: Li, Jiehao | Beijing Institute of Technology
    Author: Knoll, Alois | Tech. Univ. Muenchen TUM
    Author: Ferrigno, Giancarlo | Politecnico Di Milano
    Author: De Momi, Elena | Politecnico Di Milano
 
    keyword: Medical Robots and Systems; Cognitive Human-Robot Interaction; Redundant Robots

    Abstract : In this paper, an Internet of Things-based human-robot collaborative control scheme is developed in Robot-assisted Minimally Invasive Surgery scenario. A hierarchical operational space formulation is designed to exploit the redundancies of the 7-DoFs redundant manipulator to handle multiple operational tasks based on their priority levels, such as guaranteeing a remote center of motion constraint and avoiding collision with a swivel motion without influencing the undergoing surgical operation. Furthermore, the concept of the Internet of Robotic Things is exploited to facilitate the best action of the robot in human-robot interaction. Instead of utilizing compliant swivel motion, HTC VIVE PRO controllers, used as the Internet of Things technology, is adopted to detect the collision. A virtual force is applied to the robot elbow, enabling a smooth swivel motion for human-robot interaction. The effectiveness of the proposed strategy is validated using experiments performed on a patient phantom in a lab setup environment, with a KUKA LWR4+ slave robot and a SIGMA 7 master manipulator. By comparison with previous works, the results show improved performances in terms of the accuracy of the RCM constraint and surgical tip.

- Design and Prototyping of a Bio-Inspired Kinematic Sensing Suit for the Shoulder Joint: Precursor to a Multi-DoF Shoulder Exosuit

    Author: Varghese, Rejin John | Imperial College London
    Author: Lo, Benny Ping Lai | Imperial College London
    Author: Yang, Guang-Zhong | Shanghai Jiao Tong University
 
    keyword: Medical Robots and Systems; Prosthetics and Exoskeletons; Biomimetics

    Abstract : Soft wearable robots represent a promising new design paradigm for rehabilitation and active assistance applications. Their compliant nature makes them ideal for complex joints, but intuitive control of these robots require robust and compliant sensing mechanisms. In this work, we introduce the sensing framework for a multiple degrees-of-freedom shoulder exosuit capable of sensing the kinematics of the joint. The proposed sensing system is inspired by the body's embodied kinematic sensing, and the organisation of muscles and muscle synergies responsible for shoulder movements. A motion-capture-based evaluation study of the developed framework confirmed conformance with the behaviour of the muscles that inspired its routing. This validation of the tendon-routing hypothesis allows for it to be extended to the actuation framework of the exosuit in the future. The sensor-to-joint-space mapping is based on multivariate multiple regression and derived using an Artificial Neural Network. Evaluation of the derived mapping achieved root mean square error of approximately 5.43<sup>o</sup> and approximately 3.65<sup>o</sup> for the azimuth and elevation joint angles measured over 29,500 frames (4+ minutes) of motion-capture data.

- LaryngoTORS: A Novel Cable-Driven Parallel Robotic System for Transoral Laser Phonosurgery

    Author: Zhao, Ming | Imperial College London
    Author: Oude Vrielink, Timo Joric Corman | Imperial College London
    Author: Kogkas, Alexandros | Imperial College London
    Author: Runciman, Mark | Imperial College London
    Author: Elson, Daniel | Imperial College London
    Author: Mylonas, George | Imperial College London
 
    keyword: Medical Robots and Systems

    Abstract : Transoral laser phonosurgery is a commonly used surgical procedure in which a laser beam is used to perform incision, ablation or photocoagulation of laryngeal tissues. Two techniques are commonly practised: free beam and fiber delivery. For free beam delivery, a laser scanner is integrated into a surgical microscope to provide an accurate laser scanning pattern. This approach can only be used under direct line of sight, which is uncomfortable for the surgeon during prolonged operations, the manipulability is poor and extensive training is required. In contrast, in the fiber delivery technique, a flexible fiber is used to transmit the laser beam and therefore does not require a direct line of sight. However, this can only achieve manual level accuracy, repeatability and velocity and does not allow for pattern scanning. This work presents the LaryngoTORS, a robotic system that aims at overcoming the current limitations of the two techniques by using a cable-driven parallel robotic mechanism for controlling the end tip of the laser fiber. The robotic mechanism is attached at the end of a curved laryngeal blade and allows generation of pattern or free-path scanning. Scanning paths have been performed, exhibiting a root-mean-square error of 0.054�0.028 mm at velocity 0.5 mm/s, with repeatability error of 0.027�0.020 mm. Ex vivo tests on chicken tissue have been carried out. The results have demonstrated the LaryngoTORS is able to overcome limitations of current clinical methods

- Online Disturbance Estimation for Improving Kinematic Accuracy in Continuum Manipulators

    Author: Campisano, Federico | Vanderbilt University
    Author: Remirez, Andria | Vanderbilt University
    Author: Cal�, Simone | University of Leeds
    Author: Chandler, James Henry | University of Leeds
    Author: Obstein, Keith | Vanderbilt University
    Author: Webster III, Robert James | Vanderbilt University
    Author: Valdastri, Pietro | University of Leeds
 
    keyword: Medical Robots and Systems; Modeling, Control, and Learning for Soft Robots; Flexible Robots

    Abstract : Continuum manipulators are flexible robots which undergo continuous deformation as they are actuated. To describe the elastic deformation of such robots, kinematic models have been developed and successfully applied to a large variety of designs and to various levels of constitutive stiffness. Independent of the design, kinematic models need to be calibrated to best describe the deformation of the manipulator. However, even after calibration, unmodeled effects such as friction, nonlinear elastic and/or spatially varying material properties as well as manufacturing imprecision reduce the accuracy of these models. In this paper, we present a method for improving the accuracy of kinematic models of continuum manipulators through the incorporation of orientation sensor feedback. We achieve this through the use of a ``disturbance wrench", which is used to compensate for these unmodeled effects, and is continuously estimated based on orientation sensor feedback as the robot moves through its workspace. The presented method is applied to the HydroJet, a waterjet-actuated soft continuum manipulator, and shows an average a 40% reduction in RMS position and orientation error in the two most common types of kinematic models for continuum manipulators, a Cosserat rod model and a pseudo-rigid body model.

- Permanent Magnet-Based Localization for Growing Robots in Medical Applications

    Author: Watson, Connor | University of California, San Diego
    Author: Morimoto, Tania | University of California San Diego
 
    keyword: Medical Robots and Systems; Surgical Robotics: Steerable Catheters/Needles; Modeling, Control, and Learning for Soft Robots

    Abstract : Growing robots that achieve locomotion by extending from their tip, are inherently compliant and can safely navigate through constrained environments that prove challenging for traditional robots. However, the same compliance and tip-extension mechanism that enables this ability, also leads directly to challenges in their shape estimation and control. In this paper, we present a low-cost, wireless, permanent magnet-based method for localizing the tip of these robots. A permanent magnet is placed at the robot tip, and an array of magneto-inductive sensors is used to measure the change in magnetic field as the robot moves through its workspace. We develop an approach to localization that combines analytical and machine learning techniques and show that it outperforms existing methods. We also measure the position error over a 500 mm x 500 mm workspace with different magnet sizes to show that this approach can accommodate growing robots of different scales. Lastly, we show that our localization method is suitable for tracking the tip of a growing robot by deploying a 12 mm robot through different, constrained environments. Our method achieves position and orientation errors of 3.0+/-1.1~mm and 6.5+/-5.4 degrees in the planar case and 4.3+/-2.3 mm, 3.9+/-3.0 degrees, and 3.8+/-3.5 degrees in the 5-DOF setting.

- An Ergonomic Shared Workspace Analysis Framework for the Optimal Placement of a Compact Master Control Console

    Author: Zhang, Dandan | Imperial College London
    Author: Liu, Jindong | Imperial College London
    Author: Gao, Anzhu | Shanghai Jiao Tong University
    Author: Yang, Guang-Zhong | Shanghai Jiao Tong University
 
    keyword: Medical Robots and Systems; Surgical Robotics: Laparoscopy; Human Factors and Human-in-the-Loop

    Abstract : Master-Slave control is commonly used for Robot-Assisted Minimally Invasive Surgery (RAMIS). The configuration, as well as the placement of the master manipulators, can influence the remote control performance. An ergonomic shared workspace analysis framework is proposed in this paper. Combined with the workspace of the master manipulators and the human arms, the human-robot interaction workspace can be generated. The optimal master robot placement can be determined based on three criteria: 1) interaction workspace volume, 2) interaction workspace quality, and 3) intuitiveness for slave robot control. Experimental verification of the platform is conducted on a da Vinci Research Kit (dVRK). An in-house compact master manipulator (Hamlyn CRM) is used as the master robot and the da Vinci robot is used as the slave robot. Comparisons are made between with and without using design optimization to validate the effectiveness of ergonomic shared workspace analysis. Results indicate that the proposed ergonomic shared workspace analysis can improve the performance of teleoperation in terms of task completion time and the number of clutching required during operation.

- Virtual Fixture Assistance for Suturing in Robot-Aided Pediatric Endoscopic Surgery

    Author: Marques Marinho, Murilo | The University of Tokyo
    Author: Ishida, Hisashi | The University of Tokyo
    Author: Harada, Kanako | The University of Tokyo
    Author: Deie, Kyoichi | The University of Tokyo Hospital
    Author: Mitsuishi, Mamoru | The University of Tokyo
 
    keyword: Medical Robots and Systems; Kinematics; Collision Avoidance

    Abstract : The limited workspace in pediatric endoscopic surgery makes surgical suturing one of the most difficult tasks. During suturing, surgeons have to prevent collisions between instruments and also collisions with the surrounding tissues. Surgical robots have been shown to be effective in adult laparoscopy, but assistance for suturing in constrained workspaces has not been yet fully explored. In this letter, we propose guidance virtual fixtures to enhance the performance and the safety of suturing while generating the required task constraints using constrained optimization and Cartesian force feedback. We propose two guidance methods: looping virtual fixtures and a trajectory guidance cylinder, that are based on dynamic geometric elements. In simulations and experiments with a physical robot, we show that the proposed methods increase precision and safety in-vitro.

- Design, Modeling, and Control of a Compact SMA-Actuated MR-Conditional Steerable Neurosurgical Robot

    Author: Shao, Shicong | The Chinese University of Hong Kong
    Author: Sun, Botian | Peking University
    Author: Ding, Qingpeng | The Chinese University of Hong Kong
    Author: Yan, Wanquan | The Chinese University of Hong Kong
    Author: Zheng, Wenjia | The Chinese University of Hong Kong
    Author: Yan, Kim | The Chinese University of Hong Kong
    Author: Hong, Yilun | The Chinese University of Hong Kong
    Author: Cheng, Shing Shin | The Chinese University of Hong Kong
 
    keyword: Medical Robots and Systems; Mechanism Design; Tendon/Wire Mechanism

    Abstract : The paper presents a compact shape memory alloy (SMA)-actuated magnetic resonance (MR)-conditional neurosurgical robotic system. It consists of a 2-degree of freedom (DoF) cable-driven steerable end effector, an antagonistic SMA springs-based actuation module, and a quick-connect module, packaged into a single integrated device measuring 305 mm length - 76 mm diameter. The system is also highly adaptable, such that it could operate a cable-driven end effector up to a maximum of 4-DoFs and its length can be easily modified due to the acrylic plate-based modular construction. In addition to the kinematics of the robotic end effector and the SMA constitutive model, we also present the antagonistic SMA springs model under the known tension and cable displacement from the robotic end effector. We performed extensive characterization experiments to obtain SMA model parameters and integrated a feedforward component in our controller to achieve improved tracking of a sinusoidal reference up to 80� bending angle amplitude and 100 s period. Lastly, proof-of-concept robot demonstrations were performed in a gel phantom and in the MRI that confirmed the robot motion capability in the brain and MRI compatibility of the robot.

- Constrained-Space Optimization and Reinforcement Learning for Complex Tasks

    Author: Tsai, Ya-Yen | Imperial College London
    Author: Xiao, Bo | Imperial College London
    Author: Johns, Edward | Imperial College London
    Author: Yang, Guang-Zhong | Shanghai Jiao Tong University
 
    keyword: Medical Robots and Systems; Learning from Demonstration

    Abstract : Learning from Demonstration is increasingly used for transferring operator manipulation skills to robots. In practice, it is important to cater for limited data and imperfect human demonstrations, as well as underlying safety constraints. This paper presents a constrained-space optimization and reinforcement learning scheme for managing complex tasks. Through interactions within the constrained space, the reinforcement learning agent is trained to optimize the manipulation skills according to a defined reward function. After learning, the optimal policy is derived from the well-trained reinforcement learning agent, which is then implemented to guide the robot to conduct tasks that are similar to the experts' demonstrations. The effectiveness of the proposed method is verified with a robotic suturing task, demonstrating that the learned policy outperformed the experts' demonstrations in terms of the smoothness of the joint motion and end-effector trajectories, as well as the overall task completion time.

- Automatic Design of Compliant Surgical Forceps with Adaptive Grasping Functions

    Author: Sun, Yilun | Technical University of Munich
    Author: Liu, Yuqing | Technical University of Munich
    Author: Xu, Lingji | Technical University of Munich
    Author: Zou, Yunzhe | Technical Universty of Munich
    Author: Faragasso, Angela | The University of Tokyo
    Author: Lueth, Tim C. | Technical University of Munich
 
    keyword: Medical Robots and Systems; Mechanism Design; Surgical Robotics: Laparoscopy

    Abstract : In this paper, we present a novel method for achieving automatic design of compliant surgical forceps with adaptive grasping functions. Compliant forceps are much easier to assemble and sterilize than conventional rigid-joint forceps, hence their use is spreading from traditional open surgery to robot-assisted minimally invasive applications. However, many compliant forceps still perform stiff grasping, and thus can damage sensitive organs and tissues during the operation. Adaptive grasping function is therefore required for safe manipulation of vulnerable structures. Currently, it is difficult and time consuming to use empirical methods for designing adaptive compliant forceps for different surgical robotic applications. To cope with this problem, we developed a topology-optimization-based method able to synthesize adaptive compliant forceps automatically. Simulation and experimental tests were conducted to evaluate the adaptive grasping function of designed surgical forceps. The results demonstrated that the developed method greatly simplifies the design process and makes it possible to efficiently realize task-specific compliant forceps.

- A Parametric Grasping Methodology for Multi-Manual Interactions in Real-Time Dynamic Simulations

    Author: Munawar, Adnan | Johns Hopkins University
    Author: Srishankar, Nishan | Worcester Polytechnic Institute
    Author: Fichera, Loris | Worcester Polytechnic Institute
    Author: Fischer, Gregory Scott | Worcester Polytechnic Institute, WPI
 
    keyword: Medical Robots and Systems; Contact Modeling; Simulation and Animation

    Abstract : Interactive simulators are used in several important applications which include the training simulators for teleoperated robotic laparoscopic surgery. While state-of-art simulators are capable of rendering realistic visuals and accurate dynamics, grasping is often implemented using kinematic simplification techniques that prevent truly multi-manual manipulation, which is often an important requirement of the actual task. Realistic grasping and manipulation in simulation is a challenging problem due to the constraints imposed by the implementation of rigid-body dynamics and collision computation techniques in state-of-the-art physics libraries. We present a penalty based parametric approach to achieve multi-manual grasping and manipulation of complex objects at arbitrary postures in a real-time dynamic simulation. This approach is demonstrated by accomplishing multi-manual tasks modeled after realistic scenarios, which include the grasping and manipulation of a two-handed screwdriver task and the manipulation of a deformable thread.
- PCA-Based Visual Servoing Using Optical Coherence Tomography

    Author: Dahroug, Bassem | Femto-St
    Author: Tamadazte, Brahim | Univ. Bourgogne Franche-Comt�, CNRS
    Author: Andreff, Nicolas | Université De Franche Comt�
 
    keyword: Medical Robots and Systems; Computer Vision for Medical Robotics; Visual Servoing

    Abstract : This article deals with the development of a vision-based control law to achieve high-accuracy automatic six degrees of freedom (DoF) positioning tasks. The objective of this work is to be able to replace a biological sample under an optical device for a non-invasive depth examination at any given time (i.e., performing repetitive and accurate optical characterizations of the sample). The optical examination, also called optical biopsy, is performed thanks to an optical coherence tomography (OCT) system. The OCT device is used to perform a 3-dimensional optical biopsy, and as a sensor to control the robot motion during the repositioning process. The proposed visual servoing controller uses the 3D pose of the studied biological sample estimated directly from the C-scan OCT images using a Principal Component Analysis (PCA)~framework.<p>The proposed materials and methods were experimentally validated using a spectral-domain OCT and a 6-DoF robotic platform. The obtained results have demonstrated the pertinence of such methods which offer a positioning accuracy around 0.052pm0.03~mm (mean error pm standard deviation) for linear errors and 0.41pm0.16^circ for angular ones over a 8 times 9 times 3.5~mm^3 workspace.

- A Tele-Operated Microsurgical Forceps-Driver with a Variable Stiffness Haptic Feedback Master Device

    Author: Park, Sungwoo | Korea University, Korea Institute of Science and Technology
    Author: Jang, Namseon | Korea Institute of Science and Technology
    Author: Ihn, Yong Seok | Korea Institute of Science and Technology
    Author: Yang, Sungwook | Korea Institute of Science and Technology
    Author: Jeong, Jinwoo | Korea Institute of Science and Technology
    Author: Yim, Sehyuk | KIST
    Author: Oh, Sang-Rok | KIST
    Author: Kim, Keehoon | POSTECH, Pohang University of Science and Technology
    Author: Hwang, Donghyun | Korea Institute of Science and Technology
 
    keyword: Medical Robots and Systems; Haptics and Haptic Interfaces; Grippers and Other End-Effectors

    Abstract : We develop a surgical forceps-driver and a haptic feedback master device that could be applied to a tele-operated microsurgical robotic system for peripheral nerve surgery. Considering that the neurological damage could occur to the peripheral nerve when an excessive force is applied to the nerve tissue, we aim to implement the forceps-driver with precision gripping-force control and the master device capable of providing haptic feedback. For this aim, a high-precision tiny force sensor is fabricated and embedded into the forceps-driver for gripping-force measurement. And, we develop a novel master device handled by surgeon's thumb and forefinger. As a kind of a variable stiffness module, it functions to generate the forceps-drive operation command according to a surgeon's pinching motion and to display haptic feedback by varying the stiffness based on the gripping-force measured from the slave device. Thus, the surgeon can tele-operate the forceps-driver intuitively as well as feel the gripped-object by proprioceptive haptic feedback. In the performance evaluation experiments for the master-slave system, the gripping-force measurement capacity of the forceps-driver and the stiffness variation range of the master device are investigated as about 4 N with a resolution of 0.03 N and about 3.6 N/mm with a resolution of 0.025 N/mm, respectively.

- Hysteresis Compensator with Learning-Based Hybrid Joint Angle Estimation for Flexible Surgery Robots

    Author: Baek, DongHoon | KAIST
    Author: Seo, JuHwan | KAIST(Korea Advanced Institute of Science and Technology)
    Author: Kim, Joonhwan | Korea Advanced Institute of Science and Technology(KAIST)
    Author: Kwon, Dong-Soo | KAIST
 
    keyword: Medical Robots and Systems; Deep Learning in Robotics and Automation; Tendon/Wire Mechanism

    Abstract : Hysteresis causes difficulties in precisely controlling motion of flexible surgery robots and degrades the surgical performance. In order to reduce hysteresis, model-based feed-forward and feedback-based methods using endoscopic cameras have been suggested. However, model-based methods show limited performance when the sheath configuration is deformed. Although feedback-based methods maintain their performance regardless of the changing sheath configuration, these methods are limited in practical situations where the surgical instruments are obscured by surgical debris, such as blood and tissues. In this paper, a hysteresis compensation method using learning-based hybrid joint angle estimation (LBHJAE) is proposed to address both of these situations. This hybrid method combines image-based joint angle estimation (IBJAE) and kinematic-based joint angle estimation (KBJAE) using a Kalman filter. The proposed method can estimate an actual joint angle of a surgical instrument as well as reduce its hysteresis both in the face of partial obscuration and in different sheath configurations. We use a flexible surgery robot, K-FLEX, to evaluate our approach. The results indicate that the proposed method has effective performance in reducing hysteresis.

- Towards FBG-Based Shape Sensing for Micro-Scale and Meso-Scale Continuum Robots with Large Deflection

    Author: Chitalia, Yash | Georgia Institute of Technology
    Author: Deaton, Nancy Joanna | Georgia Institute of Technology
    Author: Jeong, Seokhwan | Georgia Institute of Technology
    Author: Rahman, Nahian | Georgia Institute of Technology
    Author: Desai, Jaydev P. | Georgia Institute of Technology
 
    keyword: Medical Robots and Systems; Surgical Robotics: Steerable Catheters/Needles; Mechanism Design

    Abstract : Endovascular and endoscopic surgical procedures require micro-scale and meso-scale continuum robotic tools to navigate complex anatomical structures. In numerous studies, fiber Bragg grating (FBG) based shape sensing has been used for measuring the deflection of continuum robots on larger scales, but has proved to be a challenge for micro-scale and meso-scale robots with large deflections. In this paper, we have developed a sensor by mounting an FBG fiber within a micromachined nitinol tube whose neutral axis is shifted to one side due to the machining. This shifting of the neutral axis allows the FBG core to experience compressive strain when the tube bends. The fabrication method of the sensor has been explicitly detailed and the sensor has been tested with two tendon-driven micro-scale and meso-scale continuum robots with outer diameters of 0.41 mm and 1.93 mm respectively. The compact sensor allows repeatable and reliable estimates of the shape of both scales of robots with minimal hysteresis. We propose an analytical model to derive the curvature of the robot joints from FBG fiber strain and a static model that relates joint curvature to the tendon force. Finally, as proof-of-concept, we demonstrate the feasibility of our sensor assembly by combining tendon force feedback and the FBG strain feedback to generate reliable estimates of joint angles for the meso-scale robot.

- Agile 3D-Navigation of a Helical Magnetic Swimmer

    Author: Julien, Leclerc | University of Houston
    Author: Zhao, Haoran | University of Houston
    Author: Bao, Daniel | University of Houston
    Author: Becker, Aaron | University of Houston
    Author: Ghosn, Mohamad | Houston Methodist DeBakey Heart and Vascular Center
    Author: Shah, Dipan J. | Houston Methodist DeBakey Heart &amp; Vascular Center
 
    keyword: Medical Robots and Systems

    Abstract : Rotating miniature magnetic swimmers are devices that could navigate within the bloodstream to access remote locations of the body and perform minimally invasive procedures. The rotational movement could be used, for example, to abrade a pulmonary embolus. Some regions, such as the heart, are challenging to navigate. Cardiac and respiratory motions of the heart combined with a fast and variable blood flow necessitate a highly agile swimmer. This swimmer should minimize contact with the walls of the blood vessels and the cardiac structures to mitigate the risk of complications. This paper presents experimental tests of a millimeter-scale magnetic helical swimmer navigating in a blood-mimicking solution and describes its turning capabilities. The step-out frequency and the position error were measured for different values of turn radius. The paper also introduces rapid movements that increase the swimmer's agility and demonstrates these experimentally on a complex 3D trajectory.

- Two Shank-Mounted IMUs-Based Gait Analysis and Classification for Neurological Disease Patients

    Author: Wang, Lei | Zhejiang University
    Author: Sun, Yun | The First Affiliated Hospital of Zhejiang University
    Author: Li, Qingguo | Queen's University
    Author: Liu, Tao | Zhejiang University
    Author: Yi, Jingang | Rutgers University
 
    keyword: Medical Robots and Systems; Human-Centered Automation

    Abstract : Automatic gait measurement and analysis is an enabling tool for intelligent healthcare and robotics-assisted rehabilitation. This paper proposes a novel two shank-mounted inertial measurement units (IMU)-based method on gait analysis and classification for three different neurological diseases. The IMU-based gait analysis and design aims to be applied in personal daily activities and environment for remote diagnosis and rehabilitation guidance. In the design, eight spatial-temporal and kinematic gait parameters are extracted from two shank-mounted IMUs. A support vector machine-based classifier is developed to classify four types of gait patterns with different neurological diseases (healthy control, peripheral neuropathy, post-stroke and Parkinson's disease). A total of 49 subjects are recruited and 93.9% of them are assigned to the right group after the leave-one-subject-out cross validation. The results demonstrate that the proposed IMU-based gait parameters and classifier are capable of differentiating the four types of gait patterns. The analysis and design have great potentials for use in clinical applications.

- An Open-Source Framework for Rapid Development of Interactive Soft-Body Simulations for Real-Time Training

    Author: Munawar, Adnan | Johns Hopkins University
    Author: Srishankar, Nishan | Worcester Polytechnic Institute
    Author: Fischer, Gregory Scott | Worcester Polytechnic Institute, WPI
 
    keyword: Medical Robots and Systems; Simulation and Animation; Software, Middleware and Programming Environments

    Abstract : We present an open-source framework that provides a low barrier to entry for real-time simulation, visualization, and interactive manipulation of user-specifiable soft-bodies, environments, and robots (using a human-readable front-end interface). The simulated soft-bodies can be interacted by a variety of input interface devices including commercially available haptic devices, game controllers, and the Master Tele-Manipulators (MTMs) of the da Vinci Research Kit (dVRK) with real-time haptic feedback. We propose this framework for carrying out multi-user training, user-studies, and improving the control strategies for manipulation problems. In this paper, we present the associated challenges to the development of such a framework and our proposed solutions. We also demonstrate the performance of this framework with examples of soft-body manipulation and interaction with various input devices.

- Towards 5-DoF Control of an Untethered Magnetic Millirobot Via MRI Gradient Coils

    Author: Erin, Onder | Carnegie Mellon University, Max Planck Institute
    Author: Antonelli, Dario | La Sapienza University of Rome
    Author: Tiryaki, Mehmet Efe | Max Plank Institute for Intelligent Systems
    Author: Sitti, Metin | Max-Planck Institute for Intelligent Systems
 
    keyword: Medical Robots and Systems; Micro/Nano Robots; Optimization and Optimal Control

    Abstract : Electromagnetic field gradients generated by magnetic resonance imaging (MRI) devices pave the way to power untethered magnetic robots remotely. This innovative use of MRI devices allows exerting magnetic pulling forces on untethered magnetic robots, which could be used for navigation, diagnosis, drug delivery and therapeutic procedures inside a human body. So far, MRI-powered untethered magnetic robots lack simultaneous position and orientation control inside three-dimensional (3D) fluids, and therefore, their control has been limited to 3-DoF position control. In this paper, we present a path-planning-based 5-DoF control algorithm to steer and control an MRI-powered untethered robot's position and orientation simultaneously in 3D workspaces in fluids. Even though the simulation results show that the proposed optimal controller can successfully control the robot for 5-DoF, in the experiments, we observe a reduced 5-DoF controllability due to the robot manufacturing errors, which result in pitch angle to remain at around the neutral pitching angle at the steady state. The proposed controller was evaluated to track four different paths (linear, planar-horizontal, planar-vertical and 3D paths) generated by 3D Bezier curves. The worst-case path-tracking error was observed for 3D path-following experiments. For this case, the position-tracking error was

- The ARMM System - Autonomous Steering of Magnetically-Actuated Catheters: Towards Endovascular Applications

    Author: Heunis, Christoff Marthinus | University of Twente
    Author: Wotte, Yannik P | University of Twente
    Author: Sikorski, Jakub | University of Twente
    Author: Phillips Furtado, Guilherme | University of Twente
    Author: Misra, Sarthak | University of Twente
 
    keyword: Medical Robots and Systems; Surgical Robotics: Steerable Catheters/Needles; Surgical Robotics: Planning

    Abstract : Positioning conventional endovascular catheters is not without risk, and there is a multitude of complications that are associated with their use in manual surgical interventions. By utilizing surgical manipulators, the efficacy of remote-controlled catheters can be investigated in vivo. However, technical challenges, such as the duration of catheterizations, accurate positioning at target sites, and consistent imaging of these catheters using nonhazardous modalities, still exist. In this paper, we propose the integration of multiple sub-systems in order to extend the clinical feasibility of an autonomous surgical system designed to address these challenges. The system handles the full synchronization of co-operating manipulators that both actuate a clinical tool. The experiments within this study are conducted within a clinically-relevant workspace and inside a gelatinous phantom that represents a life-size human torso. A catheter is positioned using magnetic actuation and proportional-integral (PI) control in conjunction with real-time ultrasound images. Our results indicate an average error between the tracked catheter tip and target positions of 2.09�0.49 mm. The median procedure time to reach targets is 32.6 s. We expect that our system will provide a step towards collaborative manipulators employing mobile electromagnets, and possibly improve autonomous catheterization procedures within endovascular surgeries.

- Automatic Normal Positioning of Robotic Ultrasound Probe Based Only on Confidence Map Optimization and Force Measurement

    Author: Jiang, Zhongliang | Technische Universitat Munchen
    Author: Grimm, Matthias | TU Munich
    Author: Zhou, Mingchuan | Technische Universitét M�nchen
    Author: Esteban, Javier | Technische Universitét M�nchen
    Author: Simson, Walter | Technical University Munich
    Author: Zahnd, Guillaume | TUM
    Author: Navab, Nassir | TU Munich
 
    keyword: Medical Robots and Systems; Force and Tactile Sensing

    Abstract : Acquiring good image quality is one of the main challenges for fully-automatic robot-assisted ultrasound systems (RUSS). The presented method aims at overcoming this challenge for orthopedic applications by optimizing the orientation of the robotic ultrasound (US) probe, i.e. aligning the US probe to the tissue's surface normal at the point of contact in order to improve sound propagation within the tissue. We first optimize the in-plane orientation of the probe by analyzing the confidence map of the US image. We then carry out a fan motion and analyze the resulting forces estimated from joint torques to align the central axis of the probe to the normal within the plane orthogonal to the initial image plane. This results in the final 3D alignment of the probe's main axis with the normal to the anatomical surface at the point of contact without using external sensors for surface reconstruction or localizing the point of contact in an anatomical atlas. The algorithm is evaluated both on a phantom and on human tissues. The mean absolute angular difference (�STD) between true and estimated normal on stationary phantom, forearm, upper arm and lower back was 3.1 �1.0, 3.7�1.7, 5.3�1.3 and 6.9�3.5. In comparison, six human operators obtained errors of 3.2�1.7 deg on the phantom. Hence the method is able to automatically position the probe normal to the scanned tissue at the point of contact and the point of contact and thus improve the quality of automatically acquired US images.

- A Semi-Autonomous Stereotactic Brain Biopsy Robot with Enhanced Safety

    Author: Minxin, Ye | The Chinese University of HongKong
    Author: Li, Weibing | The Chinese University of Hong Kong
    Author: Chan, Tat-Ming | Prince of Wales Hospital
    Author: Chiu, Philip, Wai-yan | Chinese University of Hong Kong
    Author: Li, Zheng | The Chinese University of Hong Kong
 
    keyword: Medical Robots and Systems; Surgical Robotics: Steerable Catheters/Needles; Kinematics

    Abstract : In stereotactic brain biopsy, operating the needle accurately and taking the biopsy specimen safely are two major challenges for ensuring the success of the surgical procedure. Considering this fact, surgical robots offering high accuracy and precision have been developed for neurosurgery including brain biopsy. Typical brain biopsy robots are only commanded to adjust the needle's pose before inserting the needle manually by a neurosurgeon. In the literature, there exists no robotic system that is competent to complete the needle insertion task autonomously. To move a step forward, a novel biopsy module for brain biopsy is first designed and fabricated in this paper. The biopsy module can be automated to complete a series of tasks such as inserting the needle, generating and controlling the aspiration pressure for specimen acquisition, and rotating the cannula for side-cutting. The biopsy module is further integrated with a cost-effective and lightweight UR5 robot and an optical tracking system to improve the autonomy, leading to a stereotactic neuronavigation system. Kinematic relationships of the involved elements are established via a calibration process. A quadratic programming based approach equipped with a virtual potential field method is implemented to safely control the robot with joint-limit avoidance and obstacle avoidance capabilities. The experimentation of the brain biopsy robot is performed, demonstrating that the developed robotic system has potential applicab

- Magnetically Steered Robotic Insertion of Cochlear-Implant Electrode Arrays: System Integration and First-In-Cadaver Results

    Author: Bruns, Trevor | Vanderbilt University
    Author: Riojas, Katherine | Vanderbilt University
    Author: Ropella, Dominick | Vanderbilt University
    Author: Cavilla, Matt | University of Utah
    Author: Petruska, Andrew J. | Colorado School of Mines
    Author: Freeman, Michael | Vanderbilt University Medical Center
    Author: Labadie, Robert F | Vanderbilt University
    Author: Abbott, Jake | University of Utah
    Author: Webster III, Robert James | Vanderbilt University
 
    keyword: Medical Robots and Systems

    Abstract : Cochlear-implant electrode arrays (EAs) must be inserted accurately and precisely to avoid damaging the delicate anatomical structures of the inner ear. It has previously been shown on the benchtop that using magnetic fields to steer magnet-tipped EAs during insertion reduces insertion forces, which correlate with insertion errors and damage to internal cochlear structures. This paper presents several advancements toward the goal of deploying magnetic steering of cochlear-implant EAs in the operating room. In particular, we integrate image guidance with patient-specific insertion vectors, we incorporate a new nonmagnetic insertion tool, and we use an electromagnetic source, which provides programmable control over the generated field. The electromagnet is safer than prior permanent-magnet approaches in two ways: it eliminates motion of the field source relative to the patient's head and creates a field-free source in the power-off state. Using this system, we demonstrate system feasibility by magnetically steering EAs into a cadaver cochlea for the first time. We show that magnetic steering decreases average insertion forces, in comparison to manual insertions and to image-guided robotic insertions alone.

- Magnetic Sensor Based Topographic Localization for Automatic Dislocation of Ingested Button Battery

    Author: Liu, Jialun | The University of Sheffield
    Author: Sugiyama, Hironari | Nagaoka University of Technology
    Author: Nakayama, Tadachika | Nagaoka University of Technology
    Author: Miyashita, Shuhei | University of Sheffield
 
    keyword: Medical Robots and Systems; Localization; Micro/Nano Robots

    Abstract : A button battery accidentally ingested by a toddler or small child can cause severe damage to the stomach within a short period of time. Once a battery lands on the surface of the esophagus or stomach, it can run a current in the tissue and induce a chemical reaction resulting in injury. Following our previous work where we presented an ingestible magnetic robot for button battery retrieval, this study presents a remotely achieved novel localization method of a button battery with commonly available magnetic sensors (Hall-effect sensors). By applying a direct magnetic field to the button battery using an electromagnetic coil, the battery is magnetized, and hence it becomes able to be sensed by Hall-effect sensors. Using a trilateration method, we were able to detect the locations of an LR44 button battery and other ferromagnetic materials at variable distances. Additional four electromagnetic coils were used to autonomously navigate a magnet-containing capsule to dislocate the battery from the affected site.

- A Fully Actuated Body-Mounted Robotic Assistant for MRI-Guided Low Back Pain Injection

    Author: Li, Gang | Johns Hopkins University
    Author: Patel, Niravkumar | Johs Hopkins University
    Author: Liu, Weiqiang | Johns Hopkins University
    Author: Wu, Di | Johns Hopkins University
    Author: Sharma, Karun | Sheikh Zayed Institute for Pediatric Surgical Innovation, Childr
    Author: Cleary, Kevin | Children's National Medical Center
    Author: Fritz, Jan | John Hopkins
    Author: Iordachita, Ioan Iulian | Johns Hopkins University
 
    keyword: Medical Robots and Systems; Mechanism Design

    Abstract : This paper reports the development of a fully actuated body-mounted robotic assistant for MRI-guided low back pain injection. The robot is designed with a 4-DOF needle alignment module and a 2-DOF remotely actuated needle driver module. The 6-DOF fully actuated robot can operate inside the scanner during imaging; hence, minimizing the need of moving the patient in or out of the scanner during the procedure, and thus potentially reducing the procedure time and streamlining the workflow. The robot is built with a lightweight and compact profile that could be mounted directly on the patient's lower back via straps; therefore, attenuating the effect of patient motion by moving with the patient. The novel remote actuation design of the needle driver module with beaded chain transmission can reduce the weight and profile on the patient, as well as minimize the imaging degradation caused by the actuation electronics. The free space positioning accuracy of the system was evaluated with an optical tracking system, demonstrating the mean absolute errors (MAE) of the tip position to be 0.99�0.46mm and orientation to be 0.99�0.65&#9702;. Qualitative imaging quality evaluation was performed on a human volunteer, revealing minimal visible image degradation that should not affect the procedure. The mounting stability of the system was assessed on a human volunteer, indicating the 3D position variation of target movement with respect to the robot frame to be less than 0.7mm.

- Fault Tolerant Control in Shape-Changing Internal Robots

    Author: Balasubramanian, Lavanya | University of Sheffield
    Author: Wray, Tom | University of Sheffield
    Author: Damian, Dana | University of Sheffield
 
    keyword: Medical Robots and Systems; Flexible Robots; Failure Detection and Recovery

    Abstract : It is known that the interior of the human body is one of the most adverse environments for a foreign body, such as an in vivo robot, and vice-versa. As robots operating in vivo are increasingly recognized for their capabilities and potential for improved therapies, it is important to ensure their safety, especially for long term treatments when little supervision can be provided. We introduce an implantable robot that is flexible, extendable and symmetric, thus changing shape and size. This design allows the implementation of an effective fault tolerant control, with features such as physical polling for fault diagnosis, retraction and redundancy-based control switching at fault. We demonstrate the fault-tolerant capabilities for an implantable robot that elongates tubular tissues by applying tension to the tissue. In benchtop tests, we show a reduction of the fault risks by at least 83%. The study provides a valuable methodology to enhance safety and efficacy of implantable and surgical robots, and thus to accelerate their adoption.

- Evaluation of Increasing Camera Baseline on Depth Perception in Surgical Robotics

    Author: Avinash, Apeksha | University of British Columbia
    Author: Abdelaal, Alaa Eldin | University of British Columbia
    Author: Salcudean, Septimiu E. | University of British Columbia
 
    keyword: Medical Robots and Systems; Telerobotics and Teleoperation; Performance Evaluation and Benchmarking

    Abstract : In this paper, we evaluate the effect of increasing camera baselines on depth perception in robot-assisted surgery. Restricted by the diameter of the surgical trocar through which they are inserted, current clinical stereo endoscopes have a fixed baseline of 5.5 mm. To overcome this restriction, we propose using a stereoscopic "pickup" camera with a side-firing design that allows for larger baselines. We conducted a user study with baselines of 10 mm, 15 mm, 20 mm, and 30 mm to evaluate the effect of increasing baseline on depth perception when used with the da Vinci surgical system. Subjects (N=28) were recruited and asked to rank differently sized poles, mounted at a distance of 200 mm from the cameras, according to their increasing order of height when viewed under different baseline conditions. The results showed that subjects performed better as the baseline was increased with the best performance at a 20 mm baseline. This preliminary proof-of-concept study shows that there is opportunity to improve depth perception in robot-assisted surgical systems with a change in endoscope design philosophy. In this paper, we present this change with our side-firing "pickup" camera and its flexible baseline design. Ultimately, this serves as the first step towards an adaptive baseline camera design that maximizes depth perception in surgery.

- Toward Autonomous Robotic Micro-Suturing Using Optical Coherence Tomography Calibration and Path Planning

    Author: Tian, Yuan | Duke University
    Author: Draelos, Mark | Duke University
    Author: Tang, Gao | University of Illinois at Urbana-Champaign
    Author: Qian, Ruobing | Duke University
    Author: Kuo, Anthony | Duke University
    Author: Izatt, Joseph | Duke University
    Author: Hauser, Kris | University of Illinois at Urbana-Champaign
 
    keyword: Medical Robots and Systems; Calibration and Identification

    Abstract : Robotic automation has the potential to assist human surgeons in performing suturing tasks in microsurgery, and in order to do so a robot must be able to guide a needle with sub-millimeter precision through soft tissue. This paper presents a robotic suturing system that uses 3D optical coherence tomography (OCT) system for imaging feedback. Calibration of the robot-OCT and robot-needle transforms, wound detection, keypoint identification, and path planning are all performed automatically. The calibration method handles pose uncertainty when the needle is grasped using a variant of iterative closest points. The path planner uses the identified wound shape to calculate needle entry and exit points to yield an evenly-matched wound shape after closure. Experiments on tissue phantoms and animal tissue demonstrate that the system can pass a suture needle through wounds with 0.194mm overall accuracy in achieving the planned entry and exit points.

- Improved Multiple Objects Tracking Based Autonomous Simultaneous Magnetic Actuation &amp; Localization for WCE

    Author: Xu, Yangxin | The Chinese University of Hong Kong
    Author: Li, Keyu | The Chinese University of Hong Kong
    Author: Zhao, Ziqi | The Chinese University of Hong Kong
    Author: Meng, Max Q.-H. | The Chinese University of Hong Kong
 
    keyword: Medical Robots and Systems

    Abstract : Wireless Capsule Endoscopy (WCE) has the advantage of reducing the invasiveness and pain of gastrointestinal examinations. In this work, we propose a system aimed at autonomously accelerating and locating the WCE inside the intestine for clinical applications. A rotating magnet controlled by a robotic arm is placed outside the patient's body to actuate the capsule with an internal magnetic ring, and the magnetic fields of the two sources are measured by an external sensor array. The original Multiple Objects Tracking method is improved by combining Normal Vector Fitting, Bezier Curve Gradient, and Spherical Linear Interpolation to estimate the 6-D pose of the WCE from a 5-D pose sequence. In order to close the actuation-localization loop, a strategy is presented to react to different states of the capsule. The proposed method is validated via experiments on phantoms as well as on animal intestines. The localization of the capsule shows an accuracy of 3.5mm in position and 9.4 degrees in orientation, and the average update frequency of the estimated 6-D pose reaches 25Hz.
- Towards Bimanual Vein Cannulation: Preliminary Study of a Bimanual Robotic System with a Dual Force Constraints Controller

    Author: He, Changyan | Beihang University
    Author: Ebrahimi, Ali | Johns Hopkins University
    Author: Yang, Emily | Johns Hopkins University
    Author: Urias, Muller | Wilmer Eye Institute
    Author: Yang, Yang | Beijing University of Aerosnautics and Astronautics
    Author: Gehlbach, Peter | Johns Hopkins Medical Institute
    Author: Iordachita, Ioan Iulian | Johns Hopkins University
 
    keyword: Medical Robots and Systems; Force Control; Motion Control of Manipulators

    Abstract : Retinal vein cannulation is a promising approach for treating retinal vein occlusion. The approach remains largely unexploited clinically due to surgeon limitations in detecting interaction forces between surgical tools and retinal tissue. In this paper, a dual force constraint controller for robot-assisted retinal surgery was presented to keep the tool-to-vessel forces and tool-to-sclera forces below prescribed thresholds. A cannulation tool and forceps with dual force-sensing capability were developed and used to measure force information fed into the robot controller, which was implemented on existing Steady Hand Eye Robot platforms. The robotic system facilitates retinal vein cannulation by allowing a user to grasp the target vessel with the forceps and then enter the vessel with the cannula. The system was evaluated on an eye phantom. The results showed that, while the eyeball was subjected to rotational disturbances, the proposed controller actuates the robotic manipulators to maintain the average tool-to-vessel force at 10.9 mN and 13.1 mN and the average tool-to-sclera force at 38.1 mN and 41.2 mN for the cannula and the forcpes, respectively. Such small tool-to-tissue forces are acceptable to avoid retinal tissue injury. Additionally, two clinicians participated in a preliminary user study of the bimanual cannulation demonstrating that the operation time and tool-to-tissue forces are significantly decreased with the robotic system as compared to freehand performance.

- Evaluation of a Combined Grip of Pinch and Power Grips in Manipulating a Master Manipulator

    Author: Jeong, Solmon | Tokyo Institute of Technology
    Author: Tadano, Kotaro | Tokyo Institute of Technology
 
    keyword: Medical Robots and Systems; Human-Centered Robotics

    Abstract : In conventional robotic surgery, the manipulating methods exhibit limitations that are strongly related to the advantages and disadvantages of a pinch grip and power grip. The context of this study is focused on the introduction of a combined grip to compensate for such restraints. In particular, this study proposed the combined-grip-handle scheme on a master manipulator. In this framework, the position of fingertips was designed to be adjustable in distance and direction to allow for a pinch grip motion around the holding axis of a power grip motion. A ring-bar experiment applying the master-slave scheme was conducted with the master manipulator under several manipulating conditions of the combined grip and the conventional gripping types. Results for using the combined grip demonstrated that the combined grip showed better performance on the positioning operation, compared with the conventional gripping types

- Contact Stability Analysis of Magnetically-Actuated Robotic Catheter under Surface Motion

    Author: Hao, Ran | Case Western Reserve University
    Author: Greigarn, Tipakorn | Case Western Reserve University
    Author: Cavusoglu, M. Cenk | Case Western Reserve University
 
    keyword: Medical Robots and Systems; Surgical Robotics: Steerable Catheters/Needles

    Abstract : Contact force quality is one of the most critical factors for safe and effective lesion formation during cardiac ablation. The contact force and contact stability plays important roles in determining the lesion size and creating a gap-free lesion. In this paper, the contact stability of a novel magnetic resonance imaging (MRI)-actuated robotic catheter under tissue surface motion is studied. The robotic catheter is modeled using a pseudo-rigid-body model, and the contact model under surface constraint is provided. Two contact force control schemes to improve the contact stability of the catheter under heart surface motions are proposed and their performance are evaluated in simulation.

- Fast and Accurate Intracorporeal Targeting through an Anatomical Orifice Exhibiting Unknown Behavior

    Author: Chalard, R�mi | Université Pierre Et Marie Curie (UPMC)
    Author: Reversat, David | Université Pierre Et Marie Curie
    Author: Morel, Guillaume | Sorbonne Université, CNRS, INSERM
    Author: Vitrani, Marie-Aude | Univ. Pierre Et Marie Curie - Paris6
 
    keyword: Medical Robots and Systems; Robust/Adaptive Control of Robotic Systems; Surgical Robotics: Laparoscopy

    Abstract : Surgery may involve precise instrument tip positioning in a minimally invasive way. During these operations, the instrument is inserted in the body through an orifice. The movements of the instrument are constrained by interaction forces arising at the orifice level. The physical constraints may drastically vary depending on the patient's anatomy. This introduces uncertainties that challenge the positioning task for a robot. Indeed, it raises an antagonism: On one side, the required precision appeals for a rigid behavior. On the other side, forces applied at the entry point should be limited, which requires softness. In this paper we choose to minimize forces at the orifice by using a passive ball joint wrist to manipulate the instrument. From a control perspective, this leads to consider the task as a 3 DOF wrist center positioning problem, whose softness can be achieved through conventional low impedance control. However, positioning the wrist center, even with a high static precision, does not allow to achieve a high precision of the instrument tip positioning when the orifice behavior is not known. To cope with this problem, we implement a controller that servos the tip position by commanding the wrist position. In order to deal with uncertainties, we exploit an adaptive control scheme that identifies in real-time the unknown mapping between the wrist velocity and the tip velocity. Both simulations and in vitro experimental results show the efficiency of the control law.

- Robotic Swarm Control for Precise and On-Demand Embolization

    Author: Luo, Mengxi | University of Toronto
    Author: Law, Junhui | University of Toronto
    Author: Wang, Xian | University of Toronto
    Author: Xin, Liming | University of Toronto
    Author: Shan, Guanqiao | University of Toronto
    Author: Badiwala, Mitesh | University of Toronto
    Author: Huang, Xi | The Hospital for Sick Children (SickKids)
    Author: Sun, Yu | University of Toronto
 
    keyword: Medical Robots and Systems; Micro/Nano Robots; Automation in Life Sciences: Biotechnology, Pharmaceutical and Health Care

    Abstract : Existing approaches for robotic control of magnetic swarms are not capable of generating magnetic aggregates precisely in an arbitrarily specified target region in a fluidic flow environment. Such a swarm control capability is demanded by medical applications such as clinical embolization (i.e., localized clogging of blood vessels). This paper presents a new magnetic swarm control strategy to generate aggregates only in a specified target region under fluidic flow. Within the target region, the magnetic field generates sufficiently large magnetic forces among magnetic particles to maintain the aggregates' integrity at the junctions of blood vessels. In contrast, unintended aggregates outside the target region are disassembled by fluidic shear. The aggregation control approach achieved a mean absolute error of 0.15 mm in positioning a target region and a mean absolute error of 0.30 mm in controlling the target region's radius. With thrombin coating, 1 �m magnetic particles were controlled to perform embolization both in vitro (using microfluidic channel networks) and ex vivo (using porcine tissue). Experiments proved the effectiveness of the swarm control technique for on-demand, targeted embolization.

- Bilateral Teleoperation Control of a Redundant Manipulator with an RCM Kinematic Constraint

    Author: Su, Hang | Politecnico Di Milano
    Author: Schmirander, Yunus | Politecnico Di Milano
    Author: Li, Zhijun | University of Science and Technology of China
    Author: Zhou, Xuanyi | Central South University
    Author: Ferrigno, Giancarlo | Politecnico Di Milano
    Author: De Momi, Elena | Politecnico Di Milano
 
    keyword: Medical Robots and Systems; Telerobotics and Teleoperation; Haptics and Haptic Interfaces

    Abstract : In this paper, a bilateral teleoperation control of a serial robot manipulator, which guarantees a Remote Center of Motion (RCM) constraint in its kinematic level, is developed. A two-layered approach based on the energy tank model is proposed to achieve haptic feedback on the end effector with a pedal switch. The redundancy of the manipulator is exploited to maintain the RCM constraint using the decoupled Cartesian Admittance Control. Transparency and stability of the proposed bilateral teleoperation are demonstrated using a KUKA LWR4+ serial robot and a Sigma 7 haptic manipulator with an RCM constraint in augmented reality. The results prove that the control can achieve not only the bilateral teleoperation but also maintain the RCM constraint.

## Legged Robots

- An Open Torque-Controlled Modular Robot Architecture for Legged Locomotion Research

    Author: Grimminger, Felix | Max Planck Institute for Intelligent Systems
    Author: Meduri, Avadesh | New York University
    Author: Khadiv, Majid | Max Planck Institute for Intelligent Systems
    Author: Viereck, Julian | Max Planck Institute for Intelligent Systems
    Author: W�thrich, Manuel | Max-Planck-Institute for Intelligent Systems
    Author: Naveau, Maximilien | LAAS/CNRS
    Author: Berenz, Vincent | Max Planck Institute for Intelligent Systems
    Author: Heim, Steve | Max Planck Institute for Intelligent Systems
    Author: Widmaier, Felix | Max-Planck Institute for Intelligent Systems
    Author: Flayols, Thomas | LAAS, CNRS
    Author: Fiene, Jonathan | Max Planck Institute for Intelligent Systems
    Author: Badri-Spröwitz, Alexander | Max Planck Institute for Intelligent Systems
    Author: Righetti, Ludovic | New York University
 
    keyword: Legged Robots; Compliance and Impedance Control; Mechanism Design

    Abstract : We present a new open-source torque-controlled legged robot system, with a low-cost and low-complexity actuator module at its core. It consists of a high-torque brushless DC motor and a low-gear-ratio transmission suitable for impedance and force control. We also present a novel foot contact sensor suitable for legged locomotion with hard impacts. A 2.2 kg quadruped robot with a large range of motion is assembled from eight identical actuator modules and four lower legs with foot contact sensors. Leveraging standard plastic 3D printing and off-the-shelf parts results in a lightweight and inexpensive robot, allowing for rapid distribution and duplication within the research community. We systematically characterize the achieved impedance at the foot in both static and dynamic scenarios, and measure a maximum dimensionless leg stiffness of 10.8 without active damping, which is comparable to the leg stiffness of a running human. Finally, to demonstrate the capabilities of the quadruped, we present a novel controller which combines feedforward contact forces computed from a kino-dynamic optimizer with impedance control of the center of mass and base orientation. The controller can regulate complex motions while being robust to environmental uncertainty.

- Passive Quadrupedal Gait Synchronization for Extra Robotic Legs Using a Dynamically Coupled Double Rimless Wheel Model

    Author: Gonzalez, Daniel | United States Military Academy at West Point
    Author: Asada, Harry | MIT
 
    keyword: Passive Walking; Physical Human-Robot Interaction; Dynamics

    Abstract : The Extra Robotic Legs (XRL) system is a robotic augmentation worn by a human operator consisting of two articulated robot legs that walk with the operator and help bear a heavy backpack payload. It is desirable for the Human-XRL quadruped system to walk with the rear legs lead the front by 25% of the gait period, minimizing the energy lost from foot impacts while maximizing balance stability. Unlike quadrupedal robots, the XRL cannot command the human's limbs to coordinate quadrupedal locomotion. Using a pair of Rimless Wheel models, it is shown that the systems coupled with a spring and damper converge to the desired 25% phase difference. A Poincare return map was generated using numerical simulation to examine the convergence properties to different coupler design parameters, and initial conditions. The Dynamically Coupled Double Rimless Wheel system was physically realized with a spring and dashpot chosen from the theoretical results, and initial experiments indicate that the desired synchronization properties may be achieved within several steps using this set of passive components alone.

- Optimal Fast Entrainment Waveform for Indirectly Controlled Limit Cycle Walker against External Disturbances

    Author: Li, Longchuan | Ritsumeikan University
    Author: Tokuda, Isao | Ritsumeikan University
    Author: Asano, Fumihiko | Japan Advanced Institute of Science and Technology
 
    keyword: Legged Robots; Underactuated Robots; Dynamics

    Abstract : After occasional perturbation, it is crucial to spontaneously control the limit cycle walking so that it quickly returns to its closed orbit in phase space. Otherwise, its stability can not be sufficiently guaranteed if the speed of recovery is slow while successive perturbation is applied. The accumulated deviation may eventually drive the phase outside the basin of attraction, leading to failure of the walking. In this sense, a control law that quickly recovers the disturbed phase before encountering the following perturbations is indispensable. With this consideration, here we analytically derive an optimal fast entrainment waveform that maximizes the speed of phase recovery based on phase reduction theory. Our theoretical method is numerically evaluated using a limit cycle walker, which is indirectly controlled by the oscillation of a wobbling mass via entrainment effect. The obtained waveform is used as the desired trajectory of the wobbling motion. The simulation results show that the waveform we derived achieves the best performance among all candidates. Our method helps to enhance the stability of limit cycle walking.

- GaitMesh: Controller-Aware Navigation Meshes for Long-Range Legged Locomotion Planning in Multi-Layered Environments

    Author: Brandao, Martim | University of Oxford
    Author: Aladag, Omer Burak | Sabanci University
    Author: Havoutis, Ioannis | University of Oxford
 
    keyword: Legged Robots; Autonomous Vehicle Navigation; Motion and Path Planning

    Abstract : Long-range locomotion planning is an important problem for the deployment of legged robots to real scenarios. Current methods used for legged locomotion planning often do not exploit the flexibility of legged robots, and do not scale well with environment size. In this paper we propose the use of navigation meshes for deployment in large-scale multi-floor sites. We leverage this representation to improve long-term locomotion plans in terms of success rates, path costs and reasoning about which gait-controller to use when. We show that NavMeshes have higher planning success rates than sampling-based planners, but are 400x faster to construct and at least 100x faster to plan with. The performance gap further increases when considering multi-floor environments. We present both a procedure for building controller-aware NavMeshes and a full navigation system that adapts to changes to the environment. We demonstrate the capabilities of the system in simulation experiments and in field trials at a real-world oil rig facility.

- Mechanical Shock Propagation Reduction in Robot Legs

    Author: Singh, Bajwa Roodra Pratap | Italian Institute of Technology
    Author: Featherstone, Roy | Istituto Italiano Di Tecnologia
 
    keyword: Legged Robots; Mechanism Design; Dynamics

    Abstract : This paper shows how the mass distribution in a robot's leg affects the propagation of mechanical shocks from the foot to the torso. An example is given of a leg design that propagates no shock at all; and a formula is given for the propagation of shock in a general robot leg, modelled as a chain of rigid bodies, assuming that the foot makes a point contact when it strikes the ground.

- Guided Constrained Policy Optimization for Dynamic Quadrupedal Robot Locomotion

    Author: Gangapurwala, Siddhant | University of Oxford
    Author: Mitchell, Alexander Luis | University of Oxford
    Author: Havoutis, Ioannis | University of Oxford
 
    keyword: Legged Robots; Deep Learning in Robotics and Automation; Control Architectures and Programming

    Abstract : Deep reinforcement learning (RL) uses model-free techniques to optimize task-specific control policies. Despite having emerged as a promising approach for complex problems, RL is still hard to use reliably for real world applications. Apart from challenges such as precise reward function tuning, inaccurate sensing and actuation, and non-deterministic response, existing RL methods do not guarantee behavior within required safety constraints that are crucial for real robot scenarios. In this regard, we introduce guided constrained policy optimization (GCPO), an RL framework based upon our implementation of constrained proximal policy optimization (CPPO) for tracking base velocity commands while following the defined constraints. We also introduce schemes which encourage state recovery into constrained regions in case of constraint violations. We present experimental results of our training method and test it on the real ANYmal quadruped robot. We compare our approach against the unconstrained RL method and show that guided constrained RL offers faster convergence close to the desired optimum resulting in an optimal, yet physically feasible, robotic control behavior without the need for precise reward function tuning.

- MPC-Based Controller with Terrain Insight for Dynamic Legged Locomotion

    Author: Villarreal Maga�a, Octavio Antonio | Istituto Italiano Di Tecnologia
    Author: Barasuol, Victor | Istituto Italiano Di Tecnologia
    Author: Wensing, Patrick M. | University of Notre Dame
    Author: Caldwell, Darwin G. | Istituto Italiano Di Tecnologia
    Author: Semini, Claudio | Istituto Italiano Di Tecnologia
 
    keyword: Legged Robots; Optimization and Optimal Control; Dynamics

    Abstract : We present a novel control strategy for dynamic legged locomotion in complex scenarios, that considers information about the morphology of the terrain in contexts when only on-board mapping and computation are available. The strategy is built on top of two main elements: first a contact sequence task that provides safe foothold locations based on a convolutional neural network to perform fast and continuous evaluation of the terrain in search of safe foothold locations; then a model predictive controller that considers the foothold locations given by the contact sequence task to optimize target ground reaction forces. We assess the performance of our strategy through simulations of the hydraulically actuated quadruped robot HyQReal traversing rough terrain under realistic on-board sensing conditions.

- An Adaptive Supervisory Control Approach to Dynamic Locomotion under Parametric Uncertainty

    Author: Chand, Prem | University of Delaware
    Author: Veer, Sushant | Princeton University
    Author: Poulakakis, Ioannis | University of Delaware
 
    keyword: Legged Robots; Robust/Adaptive Control of Robotic Systems; Humanoid and Bipedal Locomotion

    Abstract : This paper presents an adaptive control scheme for robotic systems that operate in the face of--potentially large--structured uncertainty. The proposed adaptive controller employs an on-line supervisor that utilizes logic-based switching among a finite set of controllers to identify uncertain parameters, and adapt the behavior of the system based on a current estimate of their value. To achieve this, the adaptive control approach in this paper combines on-line parameter estimation and feedback control while avoiding some of the inherent difficulties of classical adaptive control strategies. Furthermore, the proposed supervisory control architecture is modular as it relies on established `off-the-shelf' feedback control law and estimator design approaches, instead of customizing the overall design to the specific requirements of an adaptive control algorithm. We demonstrate the efficacy of the method on the problem of a dynamically-walking bipedal robot delivering a payload of unknown mass, and show that, by switching to the controller that is the `best' according to a current estimate of the uncertainty, the system maintains a low energy cost during its operation.

- Joint Space Position/Torque Hybrid Control of the Quadruped Robot for Locomotion and Push Reaction

    Author: Sim, Okkee | KAIST
    Author: Jeong, Hyobin | KAIST
    Author: Oh, Jaesung | KAIST
    Author: Lee, Moonyoung | Korea Advanced Institute of Science and Technology
    Author: Lee, Kang Kyu | KAIST Hubolab
    Author: Park, Hae-Won | Korea Advanced Institute of Science and Technology
    Author: Oh, Jun Ho | Korea Advanced Inst. of Sci. and Tech
 
    keyword: Legged Robots; Motion Control; Dynamics

    Abstract : This paper proposes a novel algorithm for joint space position/torque hybrid control of a mammal-type quadruped robot. With this control algorithm, the robot demonstrated both dynamic locomotion and push reaction abilities without the need for torque control in the ab/ad joints. Based on the tipping and slipping condition of the legged robot, we showed that reaction to a typical push in the horizontal direction does not require full contact-force-control in the frontal plane. Furthermore, we showed that position/torque hybrid control in Cartesian space is directly applicable to joint space hybrid control due to the joint configuration of the quadruped robot. We conducted experiments on our legged robot platform to verify the performance of our hybrid control algorithm. With this approach, the robot displayed stability while walking and reacting to external push disturbances.

- Improved Performance on Moving-Mass Hopping Robots with Parallel Elasticity

    Author: Ambrose, Eric | California Institute of Technology
    Author: Ames, Aaron | Caltech
 
    keyword: Legged Robots

    Abstract : Robotic Hopping is challenging from the perspective of both modeling the dynamics as well as the mechanical design due to the short period of ground contact in which to actuate on the world. Previous work has demonstrated stable hopping on a moving-mass robot, wherein a single spring was utilized below the body of the robot. This paper finds that the addition of a spring in parallel to the actuator greatly improves the performance of moving mass hopping robots. This is demonstrated through the design of a novel one-dimensional hopping robot. For this robot, a rigorous trajectory optimization method is developed using hybrid systems models with experimentally tuned parameters. Simulation results are used to study the effects of a parallel spring on energetic efficiency, stability, and hopping effort. We find that the double-spring model had 2.5x better energy efficiency than the single-spring model, and was able to hop using 40% less peak force from the actuator. Furthermore, the double-spring model produces stable hopping without the need for stabilizing controllers. These concepts are demonstrated experimentally on a novel hopping robot, wherein hop heights up to 40cm were achieved with comparable efficiency and stability.

- Vision Aided Dynamic Exploration of Unstructured Terrain with a Small-Scale Quadruped Robot

    Author: Kim, Donghyun | Massachusetts Institute of Technology
    Author: Carballo, Daniel | MIT
    Author: Di Carlo, Jared | Massachusetts Institute of Technology
    Author: Katz, Benjamin | Massachusetts Institute of Technology
    Author: Bledt, Gerardo | Massachusetts Institute of Technology (MIT)
    Author: Lim, Bryan Wei Tern | Massachusetts Institute of Technology
    Author: Kim, Sangbae | Massachusetts Institute of Technology
 
    keyword: Legged Robots; Autonomous Vehicle Navigation; Underactuated Robots

    Abstract : Legged robots have been highlighted as promising mobile platforms for disaster response and rescue scenar- ios because of their rough terrain locomotion capability. In cluttered environments, small robots are desirable as they can maneuver through small gaps, narrow paths, or tunnels. However small robots have their own set of difficulties such as limited space for sensors, limited obstacle clearance, and scaled- down walking speed. In this paper, we extensively address these difficulties via effective sensor integration and exploitation of dynamic locomotion and jumping. We integrate two Intel RealSense sensors into the MIT Mini-Cheetah, a 0.3 m tall, 9 kg quadruped robot. Simple and effective filtering and evaluation algorithms are used for foothold adjustment and obstacle avoidance. We showcase the exploration of highly irregular terrain using dynamic trotting and jumping with the small- scale, fully sensorized Mini-Cheetah quadruped robot.

- Reactive Support Polygon Adaptation for the Hybrid Legged-Wheeled CENTAURO Robot

    Author: Kamedula, Malgorzata | Istituto Italiano Di Tecnologia
    Author: Tsagarakis, Nikos | Istituto Italiano Di Tecnologia
 
    keyword: Legged Robots; Wheeled Robots; Motion Control

    Abstract : The need for robots operating in the real-world has sparked interest in hybrid locomotion that combines the versatile legged mobility with a simpler wheeled motion. The use of legged-wheeled robots in complex real-world scenarios requires controllers that will capitalise on this flexibility.<p>In this work, a reactive control scheme that exploits wheels steering and robot articulated legs is proposed to continuously adjust the robot support polygon (SP) in response to unknown disturbances. The designed cartesian-space control is expressed in the joint-space to account for the hardware limits. To tackle the non-holonomy in the joint-space model, the linear velocity/acceleration-based model is developed for the general legged-wheeled platform and applied to resolve the SP adaptation of a platform with steerable wheels. The proposed control is experimentally verified on the CENTAURO robot, demonstrating the SP adjustment when external disturbances are applied.


- Reliable Trajectories for Dynamic Quadrupeds Using Analytical Costs and Learned Initializations

    Author: Melon, Oliwier Aleksander | University of Oxford
    Author: Geisert, Mathieu | University of Oxford
    Author: Surovik, David | University of Oxford
    Author: Havoutis, Ioannis | University of Oxford
    Author: Fallon, Maurice | University of Oxford
 
    keyword: Legged Robots; Optimization and Optimal Control; Deep Learning in Robotics and Automation

    Abstract : Dynamic traversal of uneven terrain is a major objective in the field of legged robotics. The most recent model predictive control approaches for these systems can generate robust dynamic motion of short duration; however, planning over a longer time horizon may be necessary when navigating complex terrain. A recently-developed framework, Trajectory Optimization for Walking Robots (TOWR), computes such plans but does not guarantee their reliability on real platforms, under uncertainty and perturbations. We extend TOWR with analytical costs to generate trajectories that a state-of-the-art whole-body tracking controller can successfully execute. To reduce online computation time, we implement a learning-based scheme for initialization of the nonlinear program based on offline experience. The execution of trajectories as long as 16 footsteps and 5.5 s over different terrains by a real quadruped demonstrates the effectiveness of the approach on hardware. This work builds toward an online system which can efficiently and robustly replan dynamic trajectories.

- On the Hardware Feasibility of Nonlinear Trajectory Optimization for Legged Locomotion Based on a Simplified Dynamics

    Author: Bratta, Angelo | Istituto Italiano Di Tecnologia
    Author: Orsolino, Romeo | University of Oxford
    Author: Focchi, Michele | Fondazione Istituto Italiano Di Tecnologia
    Author: Barasuol, Victor | Istituto Italiano Di Tecnologia
    Author: Muscolo, Giovanni Gerardo | Politecnico Di Torino
    Author: Semini, Claudio | Istituto Italiano Di Tecnologia
 
    keyword: Legged Robots; Optimization and Optimal Control; Dynamics

    Abstract : Simplified models are useful to increase the com- putational efficiency of a motion planning algorithm, but their lack of accuracy have to be managed. We propose two feasibility constraints to be included in a Single Rigid Body Dynamics- based trajectory optimizer in order to obtain robust motions in challenging terrain. The first one finds an approximate relation- ship between joint-torque limits and admissible contact forces, without requiring the joint positions. The second one proposes a leg model to prevent leg collision with the environment. Such constraints have been included in a simplified nonlinear non- convex trajectory optimization problem. We demonstrate the feasibility of the resulting motion plans both in simulation and on the Hydraulically actuated Quadruped (HyQ) robot, considering experiments on an irregular terrain.

- Agile Legged-Wheeled Reconfigurable Navigation Planner Applied on the CENTAURO Robot

    Author: Raghavan, Vignesh Sushrutha | Istituto Italiano Di Tecnologia
    Author: Kanoulas, Dimitrios | University College London
    Author: Caldwell, Darwin G. | Istituto Italiano Di Tecnologia
    Author: Tsagarakis, Nikos | Istituto Italiano Di Tecnologia
 
    keyword: Motion and Path Planning; Visual-Based Navigation; Legged Robots

    Abstract : Hybrid legged-wheeled robots such as the CENTAURO, are capable of varying their footprint polygon to carry out various agile motions. This property can be advantageous for wheeled-only planning in cluttered spaces, which is our focus. In this paper, we present an improved algorithm that builds upon our previously introduced preliminary footprint varying A* planner, which was based on the rectangular symmetry of the foot support polygon. In particular, we introduce a Theta* based planner with trapezium-like search, which aims to further reduce the limitations imposed upon the wheeled-only navigation of the CENTAURO robot by the low-dimensional search space, maintaining the real-time computational efficiency. The method is tested on the simulated and real full-size CENTAURO robot in cluttered environments.

- Bounded Haptic Teleoperation of a Quadruped Robot's Foot Posture for Sensing and Manipulation

    Author: Xin, Guiyang | The University of Edinburgh
    Author: Smith, Joshua | University of Edinburgh
    Author: Rytz, David | Oxford
    Author: Wolfslag, Wouter | University of Edinburgh
    Author: Lin, Hsiu-Chin | McGIll University
    Author: Mistry, Michael | University of Edinburgh
 
    keyword: Legged Robots; Motion Control; Haptics and Haptic Interfaces

    Abstract : This paper presents a control framework to teleoperate a quadruped robot's foot for operator-guided haptic exploration of the environment. Since one leg of a quadruped robot typically only has 3 actuated degrees of freedom (DoFs), the torso is employed to assist foot posture control via a hierarchical whole-body controller. The foot and torso postures are controlled by two analytical Cartesian impedance controllers cascaded by a null space projector. The contact forces acting on supporting feet are optimized by quadratic programming (QP). The foot's Cartesian impedance controller may also estimate contact forces from trajectory tracking errors, and relay the force-feedback to the operator. A 7D haptic joystick, Sigma.7, transmits motion commands to the quadruped robot ANYmal, and renders the force feedback. Furthermore, the joystick's motion is bounded by mapping the foot's feasible force polytope constrained by the friction cones and torque limits in order to prevent the operator from driving the robot to slipping or falling over. Experimental results demonstrate the efficiency of the proposed framework.

- Pinbot: A Walking Robot with Locking Pin Arrays for Passive Adaptability to Rough Terrains

    Author: Noh, Seonghoon | Yale University
    Author: Dollar, Aaron | Yale University
 
    keyword: Legged Robots; Underactuated Robots; Mechanism Design

    Abstract : To date, many control strategies for legged robots have been proposed for stable locomotion over rough and unstructured terrains. However, these approaches require sensing information throughout locomotion, which may be noisy or unavailable at times. An alternative solution to rough terrain locomotion is a legged robot design that can passively adapt to the variations in the terrain without requiring knowledge of them. This paper presents one such solution in the design of a walking robot that employs pin array mechanisms to passively adapt to rough terrains. The pins are passively dropped over the terrain to conform to its variations and then locked to provide a statically stable stance. Locomotion is achieved with parallel four-bar linkages that swing forward the platforms in an alternating manner. Experimental evaluation of the robot demonstrates that the pin arrays enable legged locomotion over rough terrains under open-loop control.

- Planning for the Unexpected: Explicitly Optimizing Motions for Ground Uncertainty in Running

    Author: Green, Kevin | Oregon State University
    Author: Hatton, Ross | Oregon State University
    Author: Hurst, Jonathan | Oregon State University
 
    keyword: Legged Robots; Optimization and Optimal Control; Robust/Adaptive Control of Robotic Systems

    Abstract : We propose a method to generate actuation plans for a reduced order, dynamic model of bipedal running. This method explicitly enforces robustness to ground uncertainty. The plan generated is not a fixed body trajectory that is aggressively stabilized: instead, the plan interacts with the passive dynamics of the reduced order model to create emergent robustness. The goal is to create plans for legged robots that will be robust to imperfect perception of the environment, and to work with dynamics that are too complex to optimize in real-time. Working within this dynamic model of legged locomotion, we optimize a set of disturbance cases together with the nominal case, all with linked inputs. The input linking is nontrivial due to the hybrid dynamics of the running model but our solution is effective and has analytical gradients. The optimization procedure proposed is significantly slower than a standard trajectory optimization, but results in robust gaits that reject disturbances extremely effectively without any replanning required.
- On the Efficient Control of Series-Parallel Compliant Articulated Robots

    Author: Amara, Vishnu Dev | Istituto Italiano Di Tecnologia
    Author: Malzahn, J�rn | Istituto Italiano Di Tecnologia
    Author: Ren, Zeyu | Istituto Italiano Di Tecnologia
    Author: Roozing, Wesley | University of Twente
    Author: Tsagarakis, Nikos | Istituto Italiano Di Tecnologia
 
    keyword: Legged Robots; Energy and Environment-Aware Automation; Optimization and Optimal Control

    Abstract : The paper applies optimal control to investigate the efficacy of distinct torque distribution strategies on a redundant robot that combines the potential of asymmetric series-parallel compliant actuation branches and multi-articulation. An optimization based controller that can accommodate various quadratic cost functions to perform the non-trivial torque distribution among the dissimilar actuators is contrived. Three candidate criteria are composed and their performance during periodic squat motions are compared. From one set of experiments, it is learnt that by minimizing a criterion that takes into account the actuator hardware specifications, the gravity-driven phases can be lengthened. Thereby, the particular criterion results in slightly better performance than when adopting a strategy that maximizes the torque allocation to the higher efficiency actuators. Another set of experiments performed across a range of frequencies provide valuable insights such as the efficacy of maximum utilization of the highly-efficient but slow actuators decreases progressively at high frequencies.

- Preintegrated Velocity Bias Estimation to Overcome Contact Nonlinearities in Legged Robot Odometry

    Author: Wisth, David | University of Oxford
    Author: Camurri, Marco | University of Oxford
    Author: Fallon, Maurice | University of Oxford
 
    keyword: Legged Robots; Sensor Fusion; Visual-Based Navigation

    Abstract : In this paper, we present a novel factor graph formulation to estimate the pose and velocity of a quadruped robot on slippery and deformable terrains. The factor graph includes a new type of preintegrated velocity factor that incorporates velocity inputs from leg odometry. To accommodate for leg odometry drift, we extend the robot's state vector with a bias term for this preintegrated velocity factor. This term incorporates all the effects of unmodeled uncertainties at the contact point, such as slippery or deformable grounds and leg flexibility. The bias term can be accurately estimated thanks to the tight fusion of the preintegrated velocity factor with stereo vision and IMU factors, without which it would be unobservable. The system has been validated on several scenarios that involve dynamic motions of the ANYmal robot on loose rocks, slopes and muddy ground. We demonstrate a 26% improvement of relative pose error compared to our previous work and 52% compared to a state-of-the-art proprioceptive state estimator.

- Optimized Foothold Planning and Posture Searching for Energy-Efficient Quadruped Locomotion Over Challenging Terrains

    Author: Chen, Lu | Peng Cheng Laboratory (PCL) , Shenzhen, China
    Author: Ye, Shusheng | The Chinese University of Hong Kong (CUHK), Shenzhen, China
    Author: Sun, Caiming | The Chinese University of Hong Kong, Shenzhen
    Author: Zhang, Aidong | The Chinese University of Hong Kong, Shenzhen
    Author: Deng, Ganyu | The Chinese University of Hong Kong, Shenzhen
    Author: Liao, Tianjiao | The Chinese University of Hong Kong, Shenzhen
 
    keyword: Legged Robots; Energy and Environment-Aware Automation

    Abstract : Energy-efficient locomotion is of primary importance for legged robot to extend operation time in practical applications. This paper presents an approach to achieve energy-efficient locomotion for a quadrupedal robot walking over challenging terrains. Firstly, we optimize the nominal stance parameters based on the analysis of leg torque distribution. Secondly, we proposed the foothold planner and the center of gravity (COG) trajectory planner working together to guide the robot to place its standing legs in an energy-saving stance posture. We have validated the effectiveness of our method on a real quadrupedal robot in experiments including autonomously walking on plain ground and climbing stairs.

- Extracting Legged Locomotion Heuristics with Regularized Predictive Control

    Author: Bledt, Gerardo | Massachusetts Institute of Technology (MIT)
    Author: Kim, Sangbae | Massachusetts Institute of Technology
 
    keyword: Legged Robots

    Abstract : Optimization based predictive control is a powerful tool that has improved the ability of legged robots to execute dynamic maneuvers and traverse increasingly difficult terrains. However, it is often challenging and unintuitive to design meaningful cost functions and build high-fidelity models while adhering to timing restrictions. A novel framework to extract and design principled regularization heuristics for legged locomotion optimization control is presented. By allowing a simulation to fully explore the cost space offline, certain states and actions can be constrained or isolated. Data is fit with simple models relating the desired commands, optimal control actions, and robot states to identify new heuristic candidates. Basic parameter learning and adaptation laws are then applied to the models online. This method extracts simple, but powerful heuristics that can approximate complex dynamics and account for errors stemming from model simplifications and parameter uncertainty without the loss of physical intuition while generalizing the parameter tuning process. Results on the Mini Cheetah robot verify the increased capabilities due to the newly extracted heuristics without any modification to the controller structure or gains.

- Learning Generalizable Locomotion Skills with Hierarchical Reinforcement Learning

    Author: Li, Tianyu | Facebook
    Author: Lambert, Nathan | University of California, Berkeley
    Author: Calandra, Roberto | Facebook
    Author: Meier, Franziska | Facebook
    Author: Rai, Akshara | Facebook AI Research
 
    keyword: Legged Robots; AI-Based Methods; Model Learning for Control

    Abstract : Learning to locomote to arbitrary goals on hardware remains a challenging problem for reinforcement learning. In this paper, we present a hierarchical learning framework that improves sample-efficiency and generalizability of locomotion skills on real-world robots. Our approach divides the problem of goal-oriented locomotion into two sub-problems: learning diverse primitives skills, and using model-based planning to sequence these skills. We parametrize our primitives as cyclic movements, improving sample-efficiency of learning on a 18 degrees of freedom robot. Then, we learn coarse dynamics models over primitive cycles and use them in a model predictive control framework. This allows us to learn to walk to arbitrary goals up to 12m away, after about two hours of training from scratch on hardware. Our results on a Daisy hexapod hardware and simulation demonstrate the efficacy of our approach at reaching distant targets, in different environments and with sensory noise.

- SoRX: A Soft Pneumatic Hexapedal Robot to Traverse Rough, Steep, and Unstable Terrain

    Author: Liu, Zhichao | University of California, Riverside
    Author: Lu, Zhouyu | University of California, Riverside
    Author: Karydis, Konstantinos | University of California, Riverside
 
    keyword: Legged Robots; Soft Robot Applications; Soft Robot Materials and Design

    Abstract : Soft robotics technology creates new ways for legged robots to interact with and adapt to their environment. In this paper we develop i) a new 2-degree-of-freedom soft pneumatic actuator, and ii) a novel soft robotic hexapedal robot called SoRX that leverages the new actuators. Simulation and physical testing confirm that the proposed actuator can generate cyclic foot trajectories that are appropriate for legged locomotion. Consistent with other hexapedal robots (and animals), SoRX employs an alternating tripod gait to propel itself forward. Experiments reveal that SoRX can reach forward speeds of up to 0.44 body lengths per second, or equivalently 101 mm/s. With a size of 230 mm length, 140 mm width and 100 mm height, and weight of 650 grams, SoRX is among the fastest tethered soft pneumatically-actuated legged robots to date. The motion capabilities of SoRX are evaluated through five experiments: running, step climbing, and traversing rough terrain, steep terrain, and unstable terrain. Experimental results show that SoRX is able to operate over challenging terrains in open-loop control and by following the same alternating tripod gait across all experimental cases.

- Probe-Before-Step Walking Strategy for Multi-Legged Robots on Terrain with Risk of Collapse

    Author: Tennakoon, Eranda | Queensland University of Technology
    Author: Peynot, Thierry | Queensland University of Technology (QUT)
    Author: Roberts, Jonathan | Queensland University of Technology
    Author: Kottege, Navinda | CSIRO
 
    keyword: Legged Robots; Failure Detection and Recovery; Robot Safety

    Abstract : Multi-legged robots are effective at traversing rough terrain. However, terrains that include collapsible footholds (i.e. regions that can collapse when stepped on) remain a significant challenge, especially since such situations can be extremely difficult to anticipate using only exteroceptive sensing. State-of-the-art methods typically use various stabilisation techniques to regain balance and counter changing footholds. However, these methods are likely to fail if safe footholds are sparse and spread out or if the robot does not respond quickly enough after a foothold collapse. This paper presents a novel method for multi-legged robots to probe and test the terrain for collapses using its legs while walking. The proposed method improves on existing terrain probing approaches, and integrates the probing action into a walking cycle. A follow-the-leader strategy with a suitable gait and stance is presented and implemented on a hexapod robot. The proposed method is experimentally validated, demonstrating the robot can safely traverse terrain containing collapsible footholds.

- An Augmented Kinematic Model for the Cartesian Control of the Hybrid Wheeled-Legged Quadrupedal Robot CENTAURO

    Author: Laurenzi, Arturo | Istituto Italiano Di Tecnologia
    Author: Mingo Hoffman, Enrico | Fondazione Istituto Italiano Di Tecnologia
    Author: Parigi Polverini, Matteo | Istituto Italiano Di Tecnologia (IIT)
    Author: Tsagarakis, Nikos | Istituto Italiano Di Tecnologia
 
    keyword: Wheeled Robots; Motion Control; Legged Robots

    Abstract : This work deals with the kinematic control of Centauro, a highly redundant, hybrid wheeled-legged robot designed at Istituto Italiano di Tecnologia (IIT). Given its full wheeled mobility as allowed by its four independently steerable wheels, the choice of some local frame (in addition to the global world) is required in order to express tasks that are naturally defined in a robot-centric fashion. In this work, we show that trivially selecting such a frame as the robot trunk leads to sub-optimal results in terms of motion capabilities; as main contribution, we therefore propose a comparative analysis among three different choices of local frame, and demonstrate that in order to retain all advantages from the whole-body control domain, the kinematic model of the robot must be augmented with an additional virtual frame, which proves to be a useful choice of local frame, enabling e.g. the automatic adaptation of the trunk posture under constraint activation. The resulting Cartesian controller is finally validated by means of an extensive experimental session on the real hardware.

- Precision Robotic Leaping and Landing Using Stance-Phase Balance

    Author: Yim, Justin K. | University of California, Berkeley
    Author: Singh, Bajwa Roodra Pratap | Italian Institute of Technology
    Author: Wang, Eric K. | University of California, Berkeley
    Author: Featherstone, Roy | Istituto Italiano Di Tecnologia
    Author: Fearing, Ronald | University of California at Berkeley
 
    keyword: Legged Robots

    Abstract : Prior work has addressed the control of continuous jumping by setting touchdown angle in flight, but greater precision can be obtained by using liftoff angle in stance to direct individual leaps. We demonstrate targeted leaping and landing on a narrow foot with a small, single leg hopping robot, Salto-1P. Accurate and reliable leaping and landing are achieved by the combination of stance-phase balance control based on angular momentum, a launch trajectory that stabilizes the robot at a desired launch angle, and an approximate expression for selecting touchdown angle before landing. Furthermore, dynamic transitions between standing, hopping, and standing again are now possible in a robot with a narrow foot. We also present approximate bounds on acceptable velocity estimate and angle errors outside of which balanced landing is no longer possible. Compared to a prior Spring Loaded Inverted Pendulum (SLIP)-like gait, the jump distance standard deviation is reduced from 9.2 cm to 1.6 cm for particular jumps, now enabling precise jumps to narrow targets.

- STANCE: Locomotion Adaptation Over Soft Terrain (I)

    Author: Fahmi, Shamel | Istituto Italiano Di Tecnologia
    Author: Focchi, Michele | Fondazione Istituto Italiano Di Tecnologia
    Author: Radulescu, Andreea | Dyson Technology Ltd
    Author: Fink, Geoff | Istituto Italiano Di Tecnologia
    Author: Barasuol, Victor | Istituto Italiano Di Tecnologia
    Author: Semini, Claudio | Istituto Italiano Di Tecnologia
 
    keyword: Legged Robots; Compliance and Impedance Control; Optimization and Optimal Control

    Abstract : Whole-Body Control (WBC) has emerged as an important framework in locomotion control for legged robots. However, most WBC frameworks fail to generalize beyond rigid terrains. Legged locomotion over soft terrain is difficult due to the presence of unmodeled contact dynamics that WBCs do not account for. This introduces uncertainty in locomotion and affects the stability and performance of the system. In this paper, we propose a novel soft terrain adaptation algorithm called STANCE: Soft Terrain Adaptation and Compliance Estimation. STANCE consists of a WBC that exploits the knowledge of the terrain to generate an optimal solution that is contact consistent and an online terrain compliance estimator that provides the WBC with terrain knowledge. We validated STANCE both in simulation and experiment on the Hydraulically actuated Quadruped (HyQ) robot, and we compared it against the state of the art WBC. We demonstrated the capabilities of STANCE with multiple terrains of different compliances, aggressive maneuvers, different forward velocities, and external disturbances. STANCE allowed HyQ to adapt online to terrains with different compliances (rigid and soft) without pre-tuning. HyQ was able to successfully deal with the transition between different terrains and showed the ability to differentiate between compliances under each foot.

- Rolling in the Deep - Hybrid Locomotion for Wheeled-Legged Robots Using Online Trajectory Optimization

    Author: Bjelonic, Marko | ETH Zurich
    Author: Sekoor Lakshmana Sankar, Prajish Kumar | Technische Universiteit Delft
    Author: Bellicoso, C. Dario | ETH Zurich
    Author: Vallery, Heike | TU Delft
    Author: Hutter, Marco | ETH Zurich
 
    keyword: Legged Robots; Wheeled Robots; Optimization and Optimal Control

    Abstract : Wheeled-legged robots have the potential for highly agile and versatile locomotion. The combination of legs and wheels might be a solution for any real-world application requiring rapid, and long-distance mobility skills on challenging terrain. In this paper, we present an online trajectory optimization framework for wheeled quadrupedal robots capable of executing hybrid walking-driving locomotion strategies. By breaking down the optimization problem into a wheel and base trajectory planning, locomotion planning for high dimensional wheeled-legged robots becomes more tractable, can be solved in real-time on-board in a model predictive control fashion, and becomes robust against unpredicted disturbances. The reference motions are tracked by a hierarchical whole-body controller that sends torque commands to the robot. Our approach is verified on a quadrupedal robot with non-steerable wheels attached to its legs. The robot performs hybrid locomotion with a great variety of gait sequences on rough terrain. Besides, we validated the robotic platform at the Defense Advanced Research Projects Agency (DARPA) Subterranean Challenge, where the robot rapidly mapped, navigated and explored dynamic underground environments.







- Optimal Landing Strategy for Two-Mass Hopping Leg with Natural Dynamics

    Author: Lee, Chan | DGIST (Daegu Gyeongbuk Institute of Science and Technology)
    Author: Oh, Sehoon | DGIST (Daegu Gyeongbuk Institute of Science and Technology)
 
    keyword: Legged Robots; Compliance and Impedance Control; Humanoid and Bipedal Locomotion

    Abstract : It is necessary for a robotic leg to behave like a spring to realize a periodic hopping, since it can be efficient and does not require complicated control algorithm. However, the impact force makes the realization of periodic hopping more challenging. In this paper, an optimal landing strategy for a hopping leg is proposed, which can realize continuous hopping motion only by natural dynamics. The proposed strategy can reduce the foot landing velocity to zero and thus minimize the impact force. The formulation to derive the optimal condition is derived theoretically based on two-mass leg model, and its effectiveness is verified through various simulations and experiments using a series elastic actuator-driven robot leg.

- From Bipedal Walking to Quadrupedal Locomotion: Full-Body Dynamics Decomposition for Rapid Gait Generation

    Author: Ma, Wenlong | Caltech
    Author: Ames, Aaron | Caltech
 
    keyword: Legged Robots; Humanoid and Bipedal Locomotion; Optimization and Optimal Control

    Abstract : This paper systematically decomposes a quadrupedal robot into bipeds to rapidly generate walking gaits and then recomposes these gaits to obtain quadrupedal locomotion. We begin by decomposing the full-order, nonlinear and hybrid dynamics of a three-dimensional quadrupedal robot, including its continuous and discrete dynamics, into two bipedal systems that are subject to external forces. Using the hybrid zero dynamics (HZD) framework, gaits for these bipedal robots can be rapidly generated (on the order of seconds) along with corresponding controllers. The decomposition is achieved in such a way that the bipedal walking gaits and controllers can be composed to yield dynamic walking gaits for the original quadrupedal robot --- the result is the rapid generation of dynamic quadruped gaits utilizing the full-order dynamics. This methodology is demonstrated through the rapid generation (3.96 seconds on average) of four stepping-in-place gaits and one diagonally symmetric ambling gait at 0.35 m/s on a quadrupedal robot --- the Vision 60, with 36 state variables and 12 control inputs --- both in simulation and through outdoor experiments. This suggested a new approach for fast quadrupedal trajectory planning using full-body dynamics, without the need for empirical model simplification, wherein methods from dynamic bipedal walking can be directly applied to quadrupeds.

- Posture Control for a Low-Cost Commercially-Available Hexapod Robot

    Author: Tikam, Mayur | CSIR South Africa
    Author: Withey, Daniel | CSIR
    Author: Theron, Nicolaas Johannes | University of Pretoria
 
    keyword: Legged Robots; Force Control; Motion Control

    Abstract : Posture control for legged robots has been widely developed on custom-designed robotic platforms, with little work being done on commercially-available robots despite their potential as low-cost research platforms. This paper presents the implementation of a Walking Posture Control system on a commercially-available hexapod robot which utilizes low-cost joint actuators without torque control capabilities. The hierarchical control system employs Virtual Model Control with simple foot force distribution and a novel, position-based Foot Force Controller that enables direct force control during the leg's stance phase and active compliance control during the swing phase. Ground truth measurements in experimental tests, obtained with a Vicon motion capture system, demonstrate the improvement to posture made by the control system on uneven terrain, with the results comparing favorably to those obtained in similar tests on more sophisticated, custom-designed platforms.

- DeepGait: Planning and Control of Quadrupedal Gaits Using Deep Reinforcement Learning

    Author: Tsounis, Vassilios | ETH Zurich
    Author: Alge, Mitja | ETH Zurich
    Author: Lee, Joonho | ETH Zurich Robotic Systems Laboratory
    Author: Farshidian, Farbod | ETH Zurich
    Author: Hutter, Marco | ETH Zurich
 
    keyword: Legged Robots; Deep Learning in Robotics and Automation; Motion and Path Planning

    Abstract : This paper addresses the problem of legged locomotion in non-flat terrain. As legged robots such as quadrupeds are to be deployed in terrains with geometries which are difficult to model and predict, the need arises to equip them with the capability to generalize well to unforeseen situations. In this work, we propose a novel technique for training neural-network policies for terrain-aware locomotion, which combines state-of-the-art methods for model-based motion planning and reinforcement learning. Our approach is centered on formulating Markov decision processes using the evaluation of dynamic feasibility criteria in place of physical simulation. We thus employ policy-gradient methods to independently train policies which respectively plan and execute foothold and base motions in 3D environments using both proprioceptive and exteroceptive measurements. We apply our method within a challenging suite of simulated terrain scenarios which contain features such as narrow bridges, gaps and stepping-stones, and train policies which succeed in locomoting effectively in all cases.

- The Soft-Landing Problem: Minimizing Energy Loss by a Legged Robot Impacting Yielding Terrain

    Author: Lynch, Daniel | Northwestern University
    Author: Lynch, Kevin | Northwestern University
    Author: Umbanhowar, Paul | Northwestern University
 
    keyword: Legged Robots; Compliance and Impedance Control; Optimization and Optimal Control

    Abstract : Enabling robots to walk and run on yielding terrain is vital to endeavors ranging from disaster response to extraterrestrial exploration. While dynamic legged locomotion on rigid ground is challenging enough, yielding terrain presents additional challenges such as ground deformation which dissipates energy. In this paper, we examine the soft-landing problem: given some impact momentum, bring the robot to rest while minimizing foot penetration depth. To gain insight into properties of penetration depth-minimizing control policies, we formulate a constrained optimal control problem and obtain a bang-bang open-loop force profile. Motivated by examples from biology and recent advances in legged robotics, we also examine impedance-control solutions to the soft-landing problem. Through simulations and experiments, we find that optimal impedance reduces penetration depth nearly as much as the open-loop force profile, while remaining robust to model uncertainty. Lastly, we discuss the relevance of this work to minimum-cost-of-transport locomotion for several actuator design choices.

- A Computational Framework for Designing Skilled Legged-Wheeled Robots

    Author: Geilinger, Moritz | ETH Zurich
    Author: Winberg, Sebastian | ETH Zurich
    Author: Coros, Stelian | Carnegie Mellon University
 
    keyword: Legged Robots; Motion and Path Planning; Wheeled Robots

    Abstract : Legged-wheeled robots promise versatile, fast and efficient mobile capabilities. To unleash their full potential, however, such hybrid robots need to be designed in a way that promotes the rich, full-body motions required for novel locomotion modes. This paper discusses the computational framework we have used to create a new type of legged robot which, when equipped with different types of end-effectors, is capable of an array of interesting locomotory behaviors, including walking, roll-walking, roller-blading, and ice-skating. We show that this computational framework, which builds on a design system we recently introduced in the computer graphics community, can accurately predict the way in which different design decisions affect the robot's ability to move, thus serving as an important tool in engineering new types of mobile robots. We also propose a novel warm-starting method which leverages ideas from numerical continuation to drastically improve convergence rates for the trajectory optimization routine we employ to generate optimal motions.

## Multi-Robot Systems

- Optimal Perimeter Guarding with Heterogeneous Robot Teams: Complexity Analysis and Effective Algorithms

    Author: Feng, Si Wei | Rutgers University
    Author: Yu, Jingjin | Rutgers University
 
    keyword: Multi-Robot Systems; Optimization and Optimal Control; Surveillance Systems

    Abstract : We perform structural and algorithmic studies of significantly generalized versions of the optimal perimeter guarding (OPG) problem. As compared with the original OPG where robots are uniform, in this paper, many mobile robots with heterogeneous sensing capabilities are to be deployed to optimally guard a set of one-dimensional segments. Two complimentary formulations are investigated where one limits the number of available robots (OPGLR) and the other seeks to minimize the total deployment cost (OPGMC). In contrast to the original OPG which admits low-polynomial time solutions, both OPGLR and OPGMC are computationally intractable with OPGLR being strongly NP-hard. Nevertheless, we develop fairly scalable pseudo-polynomial time algorithms for practical, fixed-parameter subcase of OPGLR; we also develop pseudo-polynomial time algorithm for general OPGMC and polynomial time algorithm for the fixed-parameter OPGMC case. The applicability and effectiveness of selected algorithms are demonstrated through extensive numerical experiments.

- Spatial Scheduling of Informative Meetings for Multi-Agent Persistent Coverage

    Author: Haksar, Ravi N. | Stanford University
    Author: Trimpe, Sebastian | Max Planck Institute for Intelligent Systems
    Author: Schwager, Mac | Stanford University
 
    keyword: Multi-Robot Systems; Path Planning for Multiple Mobile Robots or Agents; Distributed Robot Systems

    Abstract : In this work, we develop a novel decentralized coordination algorithm for a team of autonomous unmanned aerial vehicles (UAVs) to surveil an aggressive forest wildfire. For dangerous environmental processes that occur over very large areas, like forest wildfires, multi-agent systems cannot rely on long-range communication networks. Therefore, our framework is formulated for very restrictive communication constraints: UAVs are only able to communicate when they are physically close to each other. To accommodate this constraint, the UAVs schedule a time and place to meet in the future to guarantee that they will be able to meet up again and share their belief of the wildfire state. In contrast with prior work, we allow for a discrete time, discrete space Markov model with a large state space as well as restrictive communication constraints. We demonstrate the effectiveness of our approach using simulations of a wildfire model that has 10^{298} total states.

- Simultaneous Policy and Discrete Communication Learning for Multi-Agent Cooperation

    Author: Freed, Benjamin | Carnegie Mellon University
    Author: Sartoretti, Guillaume Adrien | National University of Singapore (NUS)
    Author: Choset, Howie | Carnegie Mellon University
 
    keyword: Multi-Robot Systems; Deep Learning in Robotics and Automation; Distributed Robot Systems

    Abstract : Decentralized multi-agent reinforcement learning has been demonstrated to be an effective solution to large multi-agent control problems. However, agents typically can only make decisions based on local information, resulting in suboptimal performance in partially-observable settings. The addition of a communication channel overcomes this limitation by allowing agents to exchange information. Existing approaches, however, have required agent output size to scale exponentially with the number of message bits, and have been slow to converge to satisfactory policies due to the added difficulty of learning message selection. We propose an independent bitwise message policy parameterization that allows agent output size to scale linearly with information content. Additionally, we leverage aspects of the environment structure to derive a novel policy gradient estimator that is both unbiased and has a lower variance message gradient contribution than typical policy gradient estimators. We evaluate the impact of these two contributions on a collaborative multi-agent robot navigation problem, in which information must be exchanged among agents. We find that both significantly improve sample efficiency and result in improved final policies, and demonstrate the applicability of these techniques by deploying the learned policies on physical robots.

- Cooperative Team Strategies for Multi-Player Perimeter-Defense Games

    Author: Shishika, Daigo | University of Pennsylvania
    Author: Paulos, James | University of Pennsylvania
    Author: Kumar, Vijay | University of Pennsylvania, School of Engineering and Applied Sc
 
    keyword: Multi-Robot Systems; Cooperating Robots

    Abstract : This paper studies a variant of the multi-player reach-avoid game played between intruders and defenders with applications to perimeter defense. The intruder team tries to score by sending as many intruders as possible to the target area, while the defender team tries to minimize this score by intercepting them. Finding the optimal strategies of the game is challenging due to the high dimensionality of the joint state space. Existing works have proposed approximation methods to reduce the design of the defense strategy into assignment problems, however, they suffer from either suboptimal defender performance or computational complexity. Based on a novel decomposition method, this paper proposes a scalable (polynomial-time) assignment algorithm that accommodates cooperative behaviors and outperforms the existing defense strategies. For a certain class of initial configurations, we derive the exact score by showing that the lower bound provided by the intruder team matches the upper bound provided by the defender team, which also proves the optimality of the team strategies.

- Multirobot Symmetric Formations for Gradient and Hessian Estimation with Application to Source Seeking (I)

    Author: Bri��n Arranz, Lara | CEA Tech
    Author: Renzaglia, Alessandro | INRIA
    Author: Schenato, Luca | University of Padova
 
    keyword: Cooperating Robots; Networked Robots; Marine Robotics

    Abstract : This paper deals with the problem of estimating in a collaborative way the gradient and the Hessian matrix of an unknown signal via noisy measurements collected by a group of robots. We propose symmetric formations with a reduced number of robots for both the two-dimensional (2-D) and the three-dimensional (3-D) cases, such that the gradient and Hessian of the signal are estimated at the center of the formation via simple computation on local quantities independently of the orientation of the formation. If only gradient information is required, the proposed formations are suit- able for mobile robots that need to move in circular motion. We also provide explicit bounds for the approximation error and for the noise perturbation that can be used to optimally scale the formation radius. Numerical simulations illustrate the performance of the proposed strategy for source seeking against alternative solutions available in the literature and show how Hessian estimation can provide faster convergence even in the presence of noisy measurements.

- Multi-Robot Path Deconfliction through Prioritization by Path Prospects

    Author: Wu, Wenying | University of Cambridge
    Author: Bhattacharya, Subhrajit | Lehigh University
    Author: Prorok, Amanda | University of Cambridge
 
    keyword: Multi-Robot Systems; Distributed Robot Systems; Path Planning for Multiple Mobile Robots or Agents

    Abstract : This work deals with the problem of planning conflict-free paths for mobile robots in cluttered environments. Since centralized, coupled planning algorithms are computationally intractable for large numbers of robots, we consider decoupled planning, in which robots plan their paths sequentially in order of priority. Choosing how to prioritize the robots is a key consideration. State-of-the-art prioritization heuristics, however, do not model the coupling between a robot's mobility and its environment. This is particularly relevant when prioritizing between robots with different degrees of mobility. In this paper, we propose a prioritization rule that can be computed online by each robot independently, and that provides consistent, conflict-free path plans. Our innovation is to formalize a robot's path prospects to reach its goal from its current location. To this end, we consider the number of homology classes of trajectories, which capture distinct prospects of paths for each robot. This measure is used as a prioritization rule, whenever any robots enter negotiation to deconflict path plans. We perform simulations with heterogeneous robot teams and compare our method to five benchmarks. Our method achieves the highest success rate, and strikes a good balance between makespan and flowtime objectives.

- Cooperative Aerial-Ground Multi-Robot System for Automated Construction Tasks

    Author: Krizmancic, Marko | University of Zagreb, Faculty of Electrical Engineering and Comp
    Author: Arbanas, Barbara | University of Zagreb, Faculty of Electrical Engineering and Comp
    Author: Petrovic, Tamara | Univ. of Zagreb
    Author: Petric, Frano | University of Zagreb, Faculty of Electrical Engineering and Comp
    Author: Bogdan, Stjepan | University of Zagreb
 
    keyword: Multi-Robot Systems; Planning, Scheduling and Coordination; Robotics in Construction

    Abstract : In this paper, we study a cooperative aerial-ground robotic team and its application to the task of automated construction. We propose a solution for planning and coordinating the mission of constructing a wall with a predefined structure for a heterogeneous system consisting of one mobile robot and up to three unmanned aerial vehicles. The wall consists of bricks of various weights and sizes, some of which need to be transported using multiple robots simultaneously. To that end, we use hierarchical task representation to specify interrelationships between mission subtasks and employ effective scheduling and coordination mechanism, inspired by Generalized Partial Global Planning. We evaluate the performance of the method under different optimization criteria and validate the solution in the realistic Gazebo simulation environment.

- A Connectivity-Prediction Algorithm and Its Application in Active Cooperative Localization for Multi-Robot Systems

    Author: Zhang, Liang | Harbin Institute of Technology, Swiss Federal Institute of Techn
    Author: Zhang, Zexu | Harbin Institute of Technology
    Author: Siegwart, Roland | ETH Zurich
    Author: Chung, Jen Jen | Eidgen�ssische Technische Hochschule Zurich
 
    keyword: Multi-Robot Systems; Path Planning for Multiple Mobile Robots or Agents; Localization

    Abstract : This paper presents a method for predicting the probability of future connectivity between mobile robots with range-limited communication. In particular, we focus on its application to active motion planning for cooperative localization (CL). The probability of connection is modeled by the distribution of quadratic forms in random normal variables and is computed by the infinite power series expansion theorem. A finite-term approximation is made to realize the computational feasibility and three more modifications are designed to handle the adverse impacts introduced by the omission of the higher order series terms. On the basis of this algorithm, an active and CL problem with leader-follower architecture is then reformulated into a Markov Decision Process (MDP) with a one-step planning horizon, and the optimal motion strategy is generated by minimizing the expected cost of the MDP. Extensive simulations and comparisons are presented to show the effectiveness and efficiency of both the proposed prediction algorithm and the MDP model.

- Multi-Agent Formation Control Based on Distributed Estimation with Prescribed Performance

    Author: Stamouli, Charis | NTUA
    Author: Bechlioulis, Charalampos | National Technical University of Athens
    Author: Kyriakopoulos, Kostas | National Technical Univ. of Athens
 
    keyword: Multi-Robot Systems; Distributed Robot Systems; Autonomous Agents

    Abstract : We consider the distributed simultaneous estimation and formation control problem for swarms of identical mobile agents with limited communication, sensing and computation capabilities. In particular, we develop a novel scalable algorithm that encodes the formation specifications of the swarm via geometric moment statistics, which are estimated by a distributed scheme with prescribed performance guarantees. Based on the locally available information, each agent calculates an estimate of the global formation statistics, which is then employed by its local motion controller, thus creating a feedback interconnection between the estimator and the controller. The proposed scheme guarantees convergence of the global formation statistics to the desired values, while decoupling the estimation performance from the control performance. Moreover, a minimum allowable inter-agent distance can be predetermined so that inter-agent collision avoidance is achieved. Finally, simulation paradigms are provided to validate the approach.

- Optimization-Based Distributed Flocking Control for Multiple Rigid Bodies

    Author: Ibuki, Tatsuya | Tokyo Institute of Technology
    Author: Wilson, Sean | Georgia Institute of Technology
    Author: Yamauchi, Junya | Tokyo Institute of Technology
    Author: Fujita, Masayuki | Tokyo Institute of Technology
    Author: Egerstedt, Magnus | Georgia Institute of Technology
 
    keyword: Multi-Robot Systems; Optimization and Optimal Control; Swarms

    Abstract : This paper considers distributed flocking control on the Special Euclidean group for networked rigid bodies. The method captures the three flocking rules proposed by Reynolds: cohesion; alignment; and separation. The proposed controller is based only on relative pose (position and attitude) information with respect to neighboring rigid bodies so that it can be implemented in a fully distributed manner using only local sensors. The flocking algorithm is moreover based on pose synchronization methods for the cohesion/alignment rules and achieves safe separation distances through the application of control barrier functions. The control input for each rigid body is chosen by solving a distributed optimization problem with constraints for pose synchronization and collision avoidance. Here, the inherent conflict between cohesion and separation is explicitly handled by relaxing the position synchronization constraint. The effectiveness of the proposed flocking algorithm is demonstrated via simulation and hardware experiments.

- Behavior Mixing with Minimum Global and Subgroup Connectivity Maintenance for Large-Scale Multi-Robot Systems

    Author: Luo, Wenhao | Carnegie Mellon University
    Author: Yi, Sha | Carnegie Mellon University
    Author: Sycara, Katia | Carnegie Mellon University
 
    keyword: Multi-Robot Systems; Networked Robots; Autonomous Agents

    Abstract : In many cases the multi-robot systems are desired to execute simultaneously multiple behaviors with different controllers, and sequences of behaviors in real time, which we call textit{behavior mixing}. Behavior mixing is accomplished when different subgroups of the overall robot team change their controllers to collectively achieve given tasks while maintaining connectivity within and across subgroups in one connected communication graph. In this paper, we present a provably minimum connectivity maintenance framework to ensure the subgroups and overall robot team stay connected at all times while providing the highest freedom for behavior mixing. In particular, we propose a real-time distributed Minimum Connectivity Constraint Spanning Tree (MCCST) algorithm to select the minimum inter-robot connectivity constraints preserving subgroup and global connectivity that are textit{least likely to be violated} by the original controllers. With the employed safety and connectivity barrier certificates for the activated connectivity constraints and collision avoidance, the behavior mixing controllers are thus minimally modified from the original controllers. We demonstrate the effectiveness and scalability of our approach via simulations of up to 100 robots with multiple behaviors.


- CAPRICORN: Communication Aware Place Recognition Using Interpretable Constellations of Objects in Robot Networks

    Author: Ramtoula, Benjamin | École Polytechnique De Montréal, École Polytechnique Fédérale De
    Author: de Azambuja, Ricardo | University of Plymouth
    Author: Beltrame, Giovanni | Ecole Polytechnique De Montreal
 
    keyword: Multi-Robot Systems; Distributed Robot Systems; SLAM

    Abstract : Using multiple robots for exploring and mapping environments can provide improved robustness and performance, but it can be difficult to implement. In particular, limited communication bandwidth is a considerable constraint when a robot needs to determine if it has visited a location that was previously explored by another robot, as it requires for robots to share descriptions of places they have visited. One way to compress this description is to use constellations, groups of 3D points that correspond to the estimate of a set of relative object positions. Constellations maintain the same pattern from different viewpoints and can be robust to illumination changes or dynamic elements. We present a method to extract from these constellations compact spatial and semantic descriptors of the objects in a scene. We use this representation in a 2-step decentralized loop closure verification: first, we distribute the compact semantic descriptors to determine which other robots might have seen scenes with similar objects; then we query matching robots with the full constellation to validate the match using geometric information. The proposed method requires less memory, is more interpretable than global image descriptors, and could be useful for other tasks and interactions with the environment. We validate our system's performance on a TUM RGB-D SLAM sequence and show its benefits in terms of bandwidth requirements.

- Online Planning for Quadrotor Teams in 3-D Workspaces Via Reachability Analysis on Invariant Geometric Trees

    Author: Desai, Arjav Ashesh | Carnegie Mellon University
    Author: Michael, Nathan | Carnegie Mellon University
 
    keyword: Multi-Robot Systems; Motion and Path Planning; Planning, Scheduling and Coordination

    Abstract : We consider the kinodynamic multi-robot planning problem in cluttered 3-D workspaces. Reachability analysis on position invariant geometric trees is leveraged to find kinodynamically feasible trajectories for the multi-robot team from potentially non-stationary initial states. The key contribution of our approach is that a collision-free geometric solution guarantees a kinodynamically feasible, safe solution without additional refinement. Simulation results with up-to 40 robots and hardware results with 5 robots suggest the viability of the proposed approach for online planning and replanning for large teams of aerial robots in cluttered 3-D workspaces.

- Decentralized Visual-Inertial-UWB Fusion for Relative State Estimation of Aerial Swarm

    Author: Xu, Hao | HKUST
    Author: Wang, Luqi | HKUST
    Author: Zhang, Yichen | The Hong Kong University of Science and Technology
    Author: Qiu, Kejie | The Hong Kong University of Science and Technology
    Author: Shen, Shaojie | Hong Kong University of Science and Technology
 
    keyword: Multi-Robot Systems; Aerial Systems: Perception and Autonomy; Swarms

    Abstract : The collaboration of unmanned aerial vehicles (UAVs) has become a popular research topic for its practicability in multiple scenarios. The collaboration of multiple UAVs, which is also known as aerial swarm is a highly complex system, which still lacks a state-of-art decentralized relative state estimation method. In this paper, we present a novel fully decentralized visual-inertial-UWB fusion framework for relative state estimation and demonstrate the practicability by performing extensive aerial swarm flight experiments. The comparison result with ground truth data from the motion capture system shows the centimeter-level precision which outperforms all the Ultra-WideBand (UWB) and even vision based method. The system is not limited by the field of view (FoV) of the camera or Global Positioning System (GPS), meanwhile on account of its estimation consistency, we believe that the proposed relative state estimation framework has the potential to be prevalently adopted by aerial swarm applications in different scenarios in multiple scales.

- Synthesis of a Time-Varying Communication Network by Robot Teams with Information Propagation Guarantees

    Author: Yu, Xi | University of Pennsylvania
    Author: Hsieh, M. Ani | University of Pennsylvania
 
    keyword: Multi-Robot Systems; Networked Robots; Distributed Robot Systems

    Abstract : We present a distributed control and coordination strategy to enable a swarm of mobile robots to form an intermittently connected communication network while monitoring an environment. In particular, we consider the scenario where robots are tasked to patrol a collection of perimeters within a workspace and are only able to communicate with one another when they move into each other's communication range as they move along their respective perimeters. We show how intermittent connectivity can be achieved as each robot synchronizes its speed with robots moving along neighboring perimeters. By ensuring future rendezvous between robot pairs, the team forms a time-varying communication network where information can be successfully transmitted between any pair of robots within some finite period of time. We show how the proposed strategy guarantees a tau-connected network for some finite tau&gt;0 and provide bounds on the time needed to propagate information throughout the network. Simulations are presented to show the feasibility of our strategy and the validity of our approach.

- DC-CAPT: Concurrent Assignment and Planning of Trajectories for Dubins Cars

    Author: Whitzer, Michael | University of Pennsylvania
    Author: Shishika, Daigo | University of Pennsylvania
    Author: Thakur, Dinesh | University of Pennsylvania
    Author: Kumar, Vijay | University of Pennsylvania, School of Engineering and Applied Sc
    Author: Prorok, Amanda | University of Cambridge
 
    keyword: Multi-Robot Systems

    Abstract : We present an algorithm for the concurrent assignment and planning of collision-free trajectories (DC-CAPT) for robots whose kinematics can be modeled as Dubins cars, i.e., robots constrained in terms of their initial orientation and their minimum turning radius. Coupling the assignment and trajectory planning subproblems allows for a computationally tractable solution. This solution is guaranteed to be collision-free through the use of a single constraint: the start and goal locations have separation distance greater than some threshold. We derive this separation distance by extending a prior work that assumed holonomic robots. We demonstrate the validity of our approach, and show its efficacy through simulations and experiments where groups of robots executing Dubins curves travel to their assigned goal locations without collisions.

- An Adversarial Approach to Private Flocking in Mobile Robot Teams

    Author: Zheng, Hehui | University of Cambridge
    Author: Panerati, Jacopo | Polytechnique Montreal
    Author: Beltrame, Giovanni | Ecole Polytechnique De Montreal
    Author: Prorok, Amanda | University of Cambridge
 
    keyword: Multi-Robot Systems

    Abstract : Privacy is an important facet of defence against adversaries. In this letter, we introduce the problem of private flocking. We consider a team of mobile robots flocking in the presence of an adversary, who is able to observe all robots' trajectories, and who is interested in identifying the leader. We present a method that generates private flocking controllers that hide the identity of the leader robot. Our approach towards privacy leverages a data-driven adversarial co-optimization scheme. We design a mechanism that optimizes flocking control parameters, such that leader inference is hindered. As the flocking performance improves, we succes- sively train an adversarial discriminator that tries to infer the identity of the leader robot. To evaluate the performance of our co-optimization scheme, we investigate different classes of reference trajectories. Although it is reasonable to assume that there is an inherent trade-off between flocking performance and privacy, our results demonstrate that we are able to achieve high flocking performance and simultaneously reduce the risk of revealing the leader.


- Subspace Projectors for State-Constrained Multi-Robot Consensus

    Author: Morbidi, Fabio | Université De Picardie Jules Verne
 
    keyword: Multi-Robot Systems; Distributed Robot Systems; Cooperating Robots

    Abstract : In this paper, we study the state-constrained consensus problem and introduce a new family of distributed algorithms based on subspace projection methods which are simple to implement and which preserve, under some suitable conditions, the consensus value of the original discrete-time agreement protocol. The proposed theory is supported by extensive numerical experiments for the constrained 2D rendezvous of single-integrator robots.

- Multi-Agent Task Allocation Using Cross-Entropy Temporal Logic Optimization

    Author: Banks, Christopher | Georgia Institute of Technology
    Author: Wilson, Sean | Georgia Institute of Technology
    Author: Coogan, Samuel | Georgia Tech
    Author: Egerstedt, Magnus | Georgia Institute of Technology
 
    keyword: Multi-Robot Systems; Formal Methods in Robotics and Automation; Aerial Systems: Applications

    Abstract : In this paper, we propose a graph-based search method to optimally allocate tasks to a team of robots given a global task specification. In particular, we define these agents as discrete transition systems. In order to allocate tasks to the team of robots, we decompose finite linear temporal logic (LTL) specifications and consider agent specific cost functions. We propose to use the stochastic optimization technique, cross entropy, to optimize over this cost function. The multi-agent task allocation cross-entropy (MTAC-E) algorithm is developed to determine both when it is optimal to switch to a new agent to complete a task and minimize the costs associated with individual agent trajectories. The proposed algorithm is verified in simulation and experimental results are included.

- Adaptive Task Allocation for Heterogeneous Multi-Robot Teams with Evolving and Unknown Robot Capabilities

    Author: Emam, Yousef | Mr
    Author: Mayya, Siddharth | University of Pennsylvania
    Author: Notomista, Gennaro | Georgia Institute of Technology
    Author: Bohannon, Addison | CCDC Army Research Laboratory
    Author: Egerstedt, Magnus | Georgia Institute of Technology
 
    keyword: Multi-Robot Systems; Networked Robots; Learning and Adaptive Systems

    Abstract : For multi-robot teams with heterogeneous capabilities, typical task allocation methods assign tasks to robots based on the suitability of the robots to perform certain tasks as well as the requirements of the task itself. However, in real-world deployments of robot teams, the suitability of a robot might be unknown prior to deployment, or might vary due to changing environmental conditions. This paper presents an adaptive task allocation and task execution framework which allows individual robots to prioritize among tasks while explicitly taking into account their efficacy at performing the tasks---the parameters of which might be unknown before deployment and/or might vary over time. Such a specialization parameter---encoding the effectiveness of a given robot towards a task---is updated on-the-fly, allowing our algorithm to reassign tasks among robots with the aim of executing them. The developed framework requires no explicit model of the changing environment or of the unknown robot capabilities---it only takes into account the progress made by the robots at completing the tasks. Simulations and experiments demonstrate the efficacy of the proposed approach during variations in environmental conditions and when robot capabilities are unknown before deployment.

- Mobile Wireless Network Infrastructure on Demand

    Author: Mox, Daniel | University of Pennsylvania
    Author: Calvo-Fullana, Miguel | University of Pennsylvania
    Author: Gerasimenko, Mikhail | Tampere University
    Author: Fink, Jonathan | US Army Research Laborator
    Author: Kumar, Vijay | University of Pennsylvania
    Author: Ribeiro, Alejandro | University of Pennsylvania
 
    keyword: Multi-Robot Systems; Networked Robots

    Abstract : In this work, we introduce Mobile Wireless Infrastructure on Demand: a framework for providing wireless connectivity to multi-robot teams via autonomously reconfiguring ad-hoc networks. In many cases, previous multi-agent systems either assumed the availability of existing communication infrastructure or were required to create a network in addition to completing their objective. Instead our system explicitly assumes the responsibility of creating and sustaining a wireless network capable of satisfying end-to-end communication requirements of a team of agents, called the task team, performing an arbitrary objective. To accomplish this goal, we propose a joint optimization framework that alternates between finding optimal network routes to support data flows between the task agents and improving the performance of the network by repositioning a collection of mobile relay nodes referred to as the network team. We demonstrate our approach with simulations and experiments wherein wireless connectivity is provided to patrolling task agents.

- Monitoring Over the Long Term: Intermittent Deployment and Sensing Strategies for Multi-Robot Teams

    Author: Liu, Jun | Virginia Tech
    Author: Williams, Ryan | Virginia Polytechnic Institute and State University
 
    keyword: Multi-Robot Systems

    Abstract : In this paper, we formulate and solve the intermittent deployment problem, which yields strategies that couple when heterogeneous robots should sense an environmental process, with where a deployed team should sense in the environment. As a motivation, suppose that a spatiotemporal process is slowly evolving and must be monitored by a multi-robot team, e.g., UAVs monitoring pasturelands in a precision agriculture context. In such a case, an intermittent deployment strategy is necessary as persistent deployment or monitoring is not cost-efficient for a slowly evolving process. At the same time, the problem of where to sense once deployed must be solved as process observations yield useful feedback for determining effective future deployment and monitoring decisions. In this context, we model the environmental process to be monitored as a spatiotemporal Gaussian process with mutual information as a measurement criterion. To make the sensing resource-efficient, we demonstrate how to use matroid constraints to impose a diverse set of homogeneous and heterogeneous constraints. In addition, to reflect the cost-sensitive nature of real-world applications, we apply budgets on the cost of deployed heterogeneous robot teams. To solve the resulting problem, we exploit the theories of submodular optimization and matroids and present a greedy algorithm with bounds on sub-optimality. Finally, Monte Carlo simulations demonstrate the correctness of the proposed method.

- Multi-Robot Coordination for Estimation and Coverage of Unknown Spatial Fields

    Author: Benevento, Alessia | University of Salento
    Author: Santos, Mar�a | Georgia Institute of Technology
    Author: Notarstefano, Giuseppe | University of Bologna
    Author: Paynabar, Kamran | Georgia Tech
    Author: Bloch, Matthieu | Georgia Institute of Technology
    Author: Egerstedt, Magnus | Georgia Institute of Technology
 
    keyword: Multi-Robot Systems; Learning and Adaptive Systems; Optimization and Optimal Control

    Abstract : We present an algorithm for multi-robot coverage of an initially unknown spatial scalar field characterized by a density function, whereby a team of robots simultaneously estimates and optimizes its coverage of the density function over the domain. The proposed algorithm borrows powerful concepts from Bayesian Optimization with Gaussian Processes that, when combined with control laws to achieve centroidal Voronoi tessellation, give rise to an adaptive sequential sampling method to explore and cover the domain. The crux of the approach is to apply a control law using a surrogate function of the true density function, which is then successively refined as robots gather more samples for estimation. The performance of the algorithm is justified theoretically under slightly idealized assumptions, by demonstrating asymptotic no-regret with respect to the coverage obtained with a known density function. The performance is also evaluated in simulation and on the Robotarium with small teams of robots, confirming the good performance suggested by the theoretical analysis.

- Dense R-Robust Formations on Lattices
 
    Author: Guerrero-Bonilla, Luis | KTH Royal Institute of Technology
    Author: Salda�a, David | Lehigh University
    Author: Kumar, Vijay | University of Pennsylvania
 
    keyword: Multi-Robot Systems; Networked Robots; Cooperating Robots

    Abstract : Robot networks are susceptible to fail under the presence of malicious or defective robots. Resilient networks in the literature require high connectivity and large communication ranges, leading to high energy consumption in the communication network. This paper presents robot formations with guaranteed resiliency that use smaller communication ranges than previous results in the literature. The formations can be built on triangular and square lattices in the plane, and cubic lattices in the three-dimensional space. We support our theoretical framework with simulations.

- Optimizing Topologies for Probabilistically Secure Multi-Robot Systems

    Author: Wehbe, Remy | Virginia Tech
    Author: Williams, Ryan | Virginia Polytechnic Institute and State University
 
    keyword: Multi-Robot Systems; Networked Robots; Distributed Robot Systems

    Abstract : In this paper, we optimize the interaction graph of a multi-robot system (MRS) by maximizing its probability of security while requiring the MRS to have the fewest edges possible. Edges that represent robot interactions exist according to a probability distribution and security is defined using the control theoretic notion of left invertibility. To compute an optimal solution to our problem, we first start by reducing our problem to a variation of the rooted k-connections problem using three graph transformations. Then, we apply a weighted matroid intersection algorithm (WMIA) on matroids defined on the edge set of the interaction graph. Although the optimal solution can be found in polynomial time, MRSs are dynamic and their topologies may change faster than the rate at which the optimal security solution can be found. To cope with dynamic behavior, we present two heuristics that relax optimality but execute with much lower time complexity. Finally, we validate our results through Monte Carlo simulations.

- Efficient Communication in Large Multi-Robot Networks

    Author: Dutta, Ayan | University of North Florida
    Author: Ghosh, Anirban | University of North Florida
    Author: Sisley, Stephen | University of North Florida
    Author: Kreidl, Patrick | University of North Florida
 
    keyword: Multi-Robot Systems; Planning, Scheduling and Coordination

    Abstract : To achieve coordination in a multi-robot system, the robots typically resort to some form of communication among each other. In most of the multi-robot coordination frameworks, high-level coordination strategies are studied but "how" the ground-level communication takes place, is assumed to be taken care of by another program. In this paper, we study the communication routing problem for large multi-robot systems where the robots have limited communication ranges. The objective is to send a message from a robot to another in the network, routed through a low number of other robots. To this end, we propose a communication model between any pair of robots using peer-to-peer radio communication. Our proposed model is generic to any type of message and guarantees a low hop routing between any pair of robots in this network. These help the robots to exchange large messages (e.g., multispectral images) in a short amount of time. Results show that our proposed approach easily scales up to 1000 robots while drastically reducing the space complexity for maintaining the network information.

- CyPhyHouse: A Programming, Simulation, and Deployment Toolchain for Heterogeneous Distributed Coordination

    Author: Ghosh, Ritwika | University of Illinois at Urbana-Champaign
    Author: Jansch-Porto, Joao Paulo | University of Illinois at Urbana-Champaign
    Author: Hsieh, Chiao | University of Illinois at Urbana-Champaign
    Author: Gosse, Amelia | University of Illinois at Urbana-Champaign
    Author: Jiang, Minghao | University of Illinois at Urbana-Champaign
    Author: Taylor, Hebron | University of Illinois at Urbana-Champaign
    Author: Du, Peter | University of Illinois at Urbana Champaign
    Author: Mitra, Sayan | University of Ilinois, Urbana Champagne
    Author: Dullerud, Geir E. | University of Illinois
 
    keyword: Multi-Robot Systems; Autonomous Agents; Distributed Robot Systems

    Abstract : Programming languages, libraries, and development tools have transformed the application development processes for mobile computing and machine learning. This paper introduces CyPhyHouse---a toolchain that aims to provide similar programming, debugging, and deployment benefits for distributed mobile robotic applications. Users can develop hardware-agnostic, distributed applications using the high-level, event-driven Koord programming language, without requiring expertise in controller design or distributed network protocols. The modular, platform-independent middleware of CyPhyHouse implements these functionalities using standard algorithms for path planning (RRT), control (MPC), mutual exclusion, etc. A high-fidelity, scalable, multi-threaded simulator for Koord applications is developed to simulate the same application code for dozens of heterogeneous agents. The same compiled code can also be deployed on heterogeneous mobile platforms. The effectiveness of CyPhyHouse in improving the design cycles is explicitly illustrated in a robotic testbed through development, simulation, and deployment of a distributed task allocation application on in-house ground and aerial vehicles.

- Chance Constrained Simultaneous Path Planning and Task Assignment for Multiple Robots with Stochastic Path Costs

    Author: Yang, Fan | Stony Brook University
    Author: Chakraborty, Nilanjan | Stony Brook University
 
    keyword: Multi-Robot Systems; Optimization and Optimal Control; Planning, Scheduling and Coordination

    Abstract : We present a novel algorithm for simultaneous task assignment and path planning on a graph (or roadmap) with stochastic edge costs. In this problem, the initially unassigned robots and tasks are located at known positions in a roadmap. We want to assign a unique task to each robot and compute a path for the robot to go to its assigned task location. Given the mean and variance of travel cost of each edge, our goal is to develop algorithms that, with high probability, the total path cost of the robot team is below a minimum value in any realization of the stochastic travel costs. We formulate the problem as a chance-constrained simultaneous task assignment and path planning problem (CC-STAP). We prove that the optimal solution of CC-STAP can be obtained by solving a sequence of deterministic simultaneous task assignment and path planning problems in which the travel cost is a linear combination of mean and variance of the edge cost. We show that the deterministic problem can be solved in two steps. In the first step, robots compute the shortest paths to the task locations and in the second step, the robots solve a linear assignment problem with the costs obtained in the first step. We also propose a distributed algorithm that solves CC-STAP near-optimally. We present simulation results on randomly generated networks and data to demonstrate that our algorithm is scalable with the number of robots (or tasks) and the size of the network.

- Optimal Topology Selection for Stable Coordination of Asymmetrically Interacting Multi-Robot Systems

    Author: Mukherjee, Pratik | Virginia Polytechnic Institute and State University
    Author: Santilli, Matteo | Université Degli Studi Roma Tre
    Author: Gasparri, Andrea | Université Degli Studi Roma Tre
    Author: Williams, Ryan | Virginia Polytechnic Institute and State University
 
    keyword: Multi-Robot Systems; Optimization and Optimal Control

    Abstract : In this paper, we address the problem of optimal topology selection for stable coordination of multi-robot systems with asymmetric interactions. This problem arises naturally for multi-robot systems that	interact based on sensing, e.g., with limited field of view (FOV) cameras. From our previous efforts on motion control in such settings, we have shown that not all interaction topologies yield stable coordinated	motion	when asymmetry exists. At	the same time, not all robot-to-robot	interactions are of equal quality,	and thus we seek to optimize asymmetric interaction topologies subject to the constraint that the topology yields stable multi-robot motion. In this context, we formulate an optimal	topology selection problem (OTSP)	as a mixed integer semidefinite programming (MISDP) problem to compute optimal topologies that yield stable coordinated motion.Simulation results are provided to corroborate the effectiveness of the proposed OTSP formulation.


- Representing Multi-Robot Structure through Multimodal Graph Embedding for the Selection of Robot Teams

    Author: Reily, Brian | Colorado School of Mines
    Author: Reardon, Christopher M. | U.S. Army Research Laboratory
    Author: Zhang, Hao | Colorado School of Mines
 
    keyword: Multi-Robot Systems; Swarms

    Abstract : Multi-robot systems of increasing size and complexity are used to solve large-scale problems, such as area exploration and search and rescue. A key decision in human-robot teaming is dividing a multi-robot system into teams to address separate issues or to accomplish a task over a large area. In order to address the problem of selecting teams in a multi-robot system, we propose a new multimodal graph embedding method to construct a unified representation that fuses multiple information modalities to describe and divide a multi-robot system. The relationship modalities are encoded as directed graphs that can encode asymmetrical relationships, which are embedded into a unified representation for each robot. Then, the constructed multimodal representation is used to determine teams based upon unsupervised learning. We perform experiments to evaluate our approach on expert-defined team formations, large-scale simulated multi-robot systems, and a system of physical robots. Experimental results show that our method successfully decides correct teams based on the multifaceted internal structures describing multi-robot systems, and outperforms baseline methods based upon only one mode of information, as well as other graph embedding-based division methods.

- MAMS-A*: Multi-Agent Multi-Scale A*

    Author: Lim, Jaein | Georgia Institute of Technology
    Author: Tsiotras, Panagiotis | Georgia Tech
 
    keyword: Multi-Robot Systems; Motion and Path Planning

    Abstract : We present a multi-scale forward search algorithm for distributed agents to solve single-query shortest path planning problems. Each agent first builds a representation of its own search space of the common environment as a multi-resolution graph, it communicates with the other agents the result of its local search, and it uses received information from other agents to refine its own graph and update the local inconsistency conditions. As a result, all agents attain a common subgraph that includes a provably optimal path in the most informative graph available among all agents, if one exists, without necessarily communicating the entire graph. We prove the completeness and optimality of the proposed algorithm, and present numerical results supporting the advantages of the proposed approach.

- Connectivity Maintenance: Global and Optimized Approach through Control Barrier Functions

    Author: Capelli, Beatrice | University of Modena and Reggio Emilia
    Author: Sabattini, Lorenzo | University of Modena and Reggio Emilia
 
    keyword: Multi-Robot Systems; Networked Robots

    Abstract : Connectivity maintenance is an essential aspect to consider while controlling a multi-robot system. In general, a multi-robot system should be connected to obtain a certain common objective. Connectivity must be kept regardless of the control strategy or the objective of the multi-robot system. Two main methods exist for connectivity maintenance: keep the initial connections (local connectivity) or allow modifications to the initial connections, but always keeping the overall system connected (global connectivity). In this paper we present a method that allows, at the same time, to maintain global connectivity and to implement the desired control strategy (e.g., consensus, formation control, coverage), all in an optimized fashion. For this purpose, we defined and implemented a Control Barrier Function that can incorporate constraints and objectives. We provide a mathematical proof of the method, and we demonstrate its versatility with simulations of different applications.

- Controller Synthesis for Infinitesimally Shape-Similar Formations

    Author: Buckley, Ian | Georgia Institute of Technology
    Author: Egerstedt, Magnus | Georgia Institute of Technology
 
    keyword: Multi-Robot Systems; Networked Robots

    Abstract : The interplay between network topology and the interaction modalities of a multi-robot team fundamentally impact the types of formations that can be achieved. To explore the trade-offs between network structure and the sensing and communication capabilities of individual robots, this paper applies controller synthesis to formation control of infinitesimally shape-similar frameworks, for which maintaining the relative angles between robots ensures invariance of the framework to translation, rotation, and uniform scaling. Beginning with the development of a controller for the sole purpose of maintaining the formation, the controller-synthesis approach is introduced as a mechanism for incorporating user-designated objectives while ensuring that the formation is maintained. Both centralized and decentralized formulations of the synthesized controller are presented, the resulting sensing and communication requirements are discussed, and the method is demonstrated on a team of differential-drive robots.

- A Distributed Source Term Estimation Algorithm for Multi-Robot Systems

    Author: Rahbar, Faezeh | EPFL
    Author: Martinoli, Alcherio | EPFL
 
    keyword: Multi-Robot Systems; Autonomous Agents; Planning, Scheduling and Coordination

    Abstract : Finding sources of airborne chemicals with mobile sensing systems finds applications in safety, security, and emergency situations related to medical, domestic, and environmental domains. Given the often critical nature of all the applications, it is important to reduce the amount of time necessary to accomplish this task through intelligent systems and algorithms. In this paper, we extend a previously presented algorithm based on source term estimation for odor source localization for homogeneous multi-robot systems. By gradually increasing the level of coordination among multiple mobile robots, we study the benefits of a distributed system on reducing the amount of time and resources necessary to achieve the task at hand. The method has been evaluated systematically through high-fidelity simulations and in a wind tunnel emulating realistic and repeatable conditions in different coordination scenarios and with different number of robots.

- Weighted Buffered Voronoi Cells for Distributed Semi-Cooperative Behavior

    Author: Pierson, Alyssa | Massachusetts Institute of Technology
    Author: Schwarting, Wilko | Massachusetts Institute of Technology (MIT)
    Author: Karaman, Sertac | Massachusetts Institute of Technology
    Author: Rus, Daniela | MIT
 
    keyword: Multi-Robot Systems; Collision Avoidance; Path Planning for Multiple Mobile Robots or Agents

    Abstract : This paper introduces the Weighted Buffered Voronoi tessellation, which allows us to define distributed, semi-cooperative multi-agent navigation policies with guarantees on collision avoidance. We generate the Voronoi cells with dynamic weights that bias the boundary towards the agent with the lower relative weight while always maintaining a buffered distance between two agents. By incorporating agent weights, we can encode selfish or prioritized behavior among agents, where a more selfish agent will have a larger relative cell over less selfish agents. We consider this semi-cooperative since agents do not cooperate in symmetric ways. Furthermore, when all agents start in a collision-free configuration and plan their control actions within their cells, we prove that no agents will collide. Simulations demonstrate the performance of our algorithm for agents navigating to goal locations in a position-swapping game. We observe that agents with more egoistic weights consistently travel shorter paths to their goal than more altruistic agents.
- Collaborative Multi-Robot Localization in Natural Terrain

    Author: Wiktor, Adam | Stanford University
    Author: Rock, Stephen | Stanford
 
    keyword: Multi-Robot Systems; Localization; Sensor Fusion

    Abstract : This paper presents a novel filter architecture that allows a team of vehicles to collaboratively localize using Terrain Relative Navigation (TRN). The work explores several causes of measurement correlation that preclude the use of traditional estimators, and proposes an estimator structure that eliminates one source of measurement correlation while properly incorporating others through the use of Covariance Intersection. The result is a consistent estimator that is able to augment proven TRN techniques with multi-robot information, significantly improving localization for vehicles in uninformative terrain. The approach is demonstrated using field data from an Autonomous Underwater Vehicle (AUV) navigating with TRN in Monterey Bay and simulated inter-vehicle range measurements. In addition, a Monte Carlo simulation was used to quantify the algorithm's performance on one example mission. Monte Carlo results show that a vehicle operating in uninformative terrain has 62% lower localization error when fusing range measurements to two converged AUVs than it would using standard TRN.

- Multi-Robot Control Using Coverage Over Time-Varying Non-Convex Domains

    Author: Xu, Xiaotian | University of Maryland, College Park
    Author: Diaz-Mercado, Yancy | University of Maryland
 
    keyword: Multi-Robot Systems; Path Planning for Multiple Mobile Robots or Agents

    Abstract : This paper addresses the problem of a domain becoming non-convex while using coverage control of a multirobot system over time-varying domains. When the domain moves around in the workspace, its motion and the presence of obstacles might cause it to deform into some non-convex shape, and the robot team should act in a coordinating manner to maintain coverage. The proposed solution is based on a framework for constructing a diffeomorphism to transform a non-convex coverage problem into a convex one. A control law is developed to capture the effects of time variations (e.g., from a time-varying density, time-varying convex hull of the domain and time-varying diffeomorphism) in the system. Analytic expressions of each term in the control law are found for uniform density case. A simulation and robotic implementation are used to validate the proposed algorithm.

- Efficient Large-Scale Multi-Drone Delivery Using Transit Networks

    Author: Choudhury, Shushman | Stanford University
    Author: Solovey, Kiril | Stanford University
    Author: Kochenderfer, Mykel | Stanford University
    Author: Pavone, Marco | Stanford University
 
    keyword: Multi-Robot Systems; Intelligent Transportation Systems; Planning, Scheduling and Coordination

    Abstract : We consider the problem of controlling a large fleet of drones to deliver packages simultaneously across broad urban areas. To conserve energy, drones hop between public transit vehicles (e.g., buses and trams). We design a comprehensive algorithmic framework that strives to minimize the maximum time to complete any delivery. We address the multifaceted complexity of the problem through a two-layer approach. First, the upper layer assigns drones to package delivery sequences with a near-optimal polynomial-time task allocation algorithm. Then, the lower layer executes the allocation by periodically routing the fleet over the transit network while employing efficient bounded-suboptimal multi-agent pathfinding techniques tailored to our setting. Experiments demonstrate the efficiency of our approach on settings with up to 200 drones, 5000 packages, and transit networks with up to 8000 stops in San Francisco and Washington DC. Our results show that the framework computes solutions within a few seconds (up to 2 minutes at most) on commodity hardware, and that drones travel up to 450% of their flight range with public transit.

- Resilience in Multi-Robot Target Tracking through Reconfiguration

    Author: Ramachandran, Ragesh Kumar | University Southern California
    Author: Fronda, Nicole | University of Southern California
    Author: Sukhatme, Gaurav | University of Southern California
 
    keyword: Multi-Robot Systems; Cooperating Robots; Sensor Networks

    Abstract : We address the problem of maintaining resource availability in a networked multi-robot system performing distributed target tracking. In our model, robots are equipped with sensing and computational resources enabling them to track a target's position using a Distributed Kalman Filter (DKF). We use the trace of each robot's sensor measurement noise covariance matrix as a measure of sensing quality. When a robot's sensing quality deteriorates, the systems communication graph is modified by adding edges such that the robot with deteriorating sensor quality may share information with other robots to improve the team's target tracking ability. This computation is performed centrally and is designed to work without a large change in the number of active communication links. We propose two mixed integer semi-definite programming formulations (an �agent-centric� strategy and a �team-centric� strategy) to achieve this goal. We implement both formulations and a greedy strategy in simulation and show that the team- centric strategy outperforms the agent-centric and greedy strategies.

- Teleoperation of Multi-Robot Systems to Relax Topological Constraints

    Author: Sabattini, Lorenzo | University of Modena and Reggio Emilia
    Author: Capelli, Beatrice | University of Modena and Reggio Emilia
    Author: Fantuzzi, Cesare | Université Di Modena E Reggio Emilia
    Author: Secchi, Cristian | Univ. of Modena &amp; Reggio Emilia
 
    keyword: Multi-Robot Systems; Telerobotics and Teleoperation

    Abstract : Multi-robot systems are able to achieve common objectives exchanging information among each other. This is possible exploiting a communication structure, usually modeled as a graph, whose topological properties (such as connectivity) are very relevant in the overall performance of the multi-robot system. When considering mobile robots, such properties can change over time: robots are then controlled to preserve them, thus guaranteeing the possibility, for the overall system, to achieve its goals. This, however, implies limitations on the possible motion patterns of the robots, thus reducing the flexibility of the overall multi-robot system. In this paper we introduce teleoperation as a means to reduce these limitations, allowing temporary violations of topological properties, with the aim of increasing the flexibility of the multi-robot system.

- Eciton Robotica: Design and Algorithms for an Adaptive Self-Assembling Soft Robot Collective

    Author: Malley, Melinda | Harvard University
    Author: Haghighat, Bahar | EPFL
    Author: Houel, Lucie | Ecole Polytechnique Federale De Lausanne (EPFL),
    Author: Nagpal, Radhika | Harvard University
 
    keyword: Multi-Robot Systems; Swarms; Biologically-Inspired Robots

    Abstract : Social insects successfully create bridges, rafts, nests and other structures out of their own bodies and do so with no centralized control system, simply by following local rules. For example, while traversing rough terrain, army ants (genus Eciton) build bridges which grow and dissolve in response to local traffic. Because these self-assembled structures incorporate smart, flexible materials (i.e. ant bodies) and emerge from local behavior, the bridges are adaptive and dynamic. With the goal of realizing robotic collectives with similar features, we designed a hardware system, Eciton robotica, consisting of flexible robots that can climb over each other to assemble compliant structures and communicate locally using vibration. In simulation, we demonstrate self-assembly of structures: using only local rules and information, robots build and dissolve bridges in response to local traffic and varying terrain. Unlike previous self-assembling robotic systems that focused on lattice-based structures and predetermined shapes, our system takes a new approach where soft robots attach to create amorphous structures whose final self-assembled shape can adapt to the needs of the group.

## Modeling, Control, and Learning for Soft Robots

- Learning Robotic Assembly Tasks with Lower Dimensional Systems by Leveraging Softness and Environmental Constraints

    Author: Hamaya, Masashi | OMRON SINIC X Corporation
    Author: Lee, Robert | Australian Centre for Robotic Vision
    Author: Tanaka, Kazutoshi | OMRON SINIC X Corporation
    Author: von Drigalski, Felix Wolf Hans Erich | OMRON SINIC X Corporation
    Author: Nakashima, Chisato | OMRON Corp
    Author: Shibata, Yoshiya | OMRON Corpration
    Author: Ijiri, Yoshihisa | OMRON Corp
 
    keyword: Soft Robot Applications; Modeling, Control, and Learning for Soft Robots; Compliant Assembly

    Abstract : In this study, we present a novel control framework for assembly tasks with a soft robot. Typically, existing hard robots require high frequency controllers and precise force/torque sensors for assembly tasks. The resulting robot system is complex, entailing large amounts of engineering and maintenance. Physical softness allows the robot to interact with the environment easily. We expect soft robots to perform assembly tasks without the need for high frequency force/torque controllers and sensors. However, specific data-driven approaches are needed to deal with complex models involving nonlinearity and hysteresis. If we were to apply these approaches directly, we would be required to collect very large amounts of training data. To solve this problem, we argue that by leveraging softness and environmental constraints, a robot can complete tasks in lower dimensional state and action spaces, which could greatly facilitate the exploration of appropriate assembly skills. Then, we apply a highly efficient model-based reinforcement learning method to lower dimensional systems. To verify our method, we perform a simulation for peg-in-hole tasks. The results show that our method learns the appropriate skills faster than an approach that does not consider lower dimensional systems. Moreover, we demonstrate that our method works on a real robot equipped with a compliant module on the wrist.

- Titan: A Parallel Asynchronous Library for Multi-Agent and Soft-Body Robotics Using NVIDIA CUDA

    Author: Austin, Jacob | Columbia University
    Author: Corrales-Fatou, Rafael | Imperial College London
    Author: Wyetzner, Sofia | Columbia University
    Author: Lipson, Hod | Columbia University
 
    keyword: Software, Middleware and Programming Environments; Modeling, Control, and Learning for Soft Robots; Simulation and Animation

    Abstract : While most robotics simulation libraries are built for low-dimensional and intrinsically serial tasks, soft-body and multi-agent robotics have created a demand for simulation environments that can model many interacting bodies in parallel. Despite the increasing interest in these fields, no existing simulation library addresses the challenge of providing a unified, highly-parallelized, GPU-accelerated interface for simulating large robotic systems. Titan is a versatile CUDA-based C++ robotics simulation library that employs a novel asynchronous computing model for GPU-accelerated simulations of robotics primitives. The innovative GPU architecture design permits simultaneous optimization and control on the CPU while the GPU runs asynchronously, enabling rapid topology optimization and reinforcement learning iterations. Kinematics are solved with a massively parallel integration scheme that incorporates constraints and environmental forces. We report dramatically improved performance over CPU baselines, simulating as many as 300 million primitive updates per second, while allowing flexibility for a wide range of research applications. We present several applications of Titan to high-performance simulations of soft-body and multi-agent robots.

- Motion Planning with Competency-Aware Transition Models for Underactuated Adaptive Hands

    Author: Sintov, Avishai | Tel-Aviv University
    Author: Kimmel, Andrew | Rutgers University
    Author: Bekris, Kostas E. | Rutgers, the State University of New Jersey
    Author: Boularias, Abdeslam | Rutgers University
 
    keyword: Modeling, Control, and Learning for Soft Robots; Dexterous Manipulation; Motion and Path Planning

    Abstract : Underactuated adaptive hands simplifying grasping tasks but it can be difficult to model their interactions with objects during in-hand manipulation. Learned data-driven models, however, have been recently shown to be efficient in motion planning and control of such hands. Still, the accuracy of the models is limited even with the addition of more data. This becomes important for long horizon predictions where errors are accumulated along the length of the path. Instead of throwing more data into learning the transition model, this work proposes to rather invest a portion of the training data in a {it critic} model. The critic is trained to estimate the error of the transition model given a state and a sequence of future actions, along with information of past actions. The critic is used to reformulate the cost function of an asymptotically optimal motion planner. Given the critic, the planner directs planned paths to less erroneous regions in the state space. The approach is evaluated against standard planning on simulated and real underactuated hands. The results show that it outperforms an alternative where all the available data is used for training the transition model, without a critic.

- Learning to Walk a Tripod Mobile Robot Using Nonlinear Soft Vibration Actuators with Entropy Adaptive Reinforcement Learning

    Author: Kim, Jae In | Seoul National University
    Author: Hong, Mineui | Seoul National University
    Author: Lee, Kyungjae | Seoul National University
    Author: Kim, DongWook | Seoul National University
    Author: Park, Yong-Lae | Seoul National University
    Author: Oh, Songhwai | Seoul National University
 
    keyword: Modeling, Control, and Learning for Soft Robots; Hydraulic/Pneumatic Actuators; Motion and Path Planning

    Abstract : Soft mobile robots have shown great potential in unstructured and confined environments by taking advantage of their excellent adaptability and high dexterity. However, there are several issues to be addressed in terms of actuating speed and controllability of soft robots. In this paper, a new vibration actuator is proposed using the nonlinear stiffness characteristic of the hyper-elastic material in order to make the actuator vibrate continuously, and an advanced soft mobile robot is presented which has a high degree of freedom of movement. However, since the dynamics model of a soft mobile robot is generally intractable, it is difficult to design a controller for the robot. In this regard, we present a method to train a controller, using<p>our novel reinforcement learning (RL) algorithm called adaptive soft actor-critic (ASAC). ASAC gradually reduces a parameter called the entropy temperature, which regulates the entropy of the control policy.</p><p>By doing so, the proposed method can narrow down the search space during the training, and reduce the duration of the demanding data collection processes in the real-world experiment. For the verification</p><p>of the robustness and controllability of our robot and RL algorithm, zig-zagging path tracking and obstacle avoidance experiments were conducted, and the robot successfully finished the missions with only an hour of training time.

- Time Generalization of Trajectories Learned on Articulated Soft Robots

    Author: Angelini, Franco | University of Pisa
    Author: Mengacci, Riccardo | Université Di Pisa
    Author: Della Santina, Cosimo | Massachusetts Institute of Technology
    Author: Catalano, Manuel Giuseppe | Istituto Italiano Di Tecnologia
    Author: Garabini, Manolo | Université Di Pisa
    Author: Bicchi, Antonio | Université Di Pisa
    Author: Grioli, Giorgio | Istituto Italiano Di Tecnologia
 
    keyword: Natural Machine Motion; Motion Control; Flexible Robots

    Abstract : To avoid feedback-related stiffening of articulated soft robots, a substantive feedforward contribution is crucial. However, obtaining reliable feedforward actions requires very accurate models, which are not always available for soft robots. Learning-based approaches are a promising solution to the problem. They proved to be an effective strategy achieving good tracking performance, while preserving the system intrinsic compliance. Nevertheless, learning methods require rich data sets, and issues of scalability and generalization still remain to be solved. This paper proposes a method to generalize learned control actions to execute a desired trajectory with different velocities - with the ultimate goal of making these learning-based architectures sample efficient. More specifically, we prove that the knowledge of how to execute a same trajectory at five different speeds is necessary and sufficient to execute the same trajectory at any velocity - without any knowledge of the model. We also give a simple constructive way to calculate this new feedforward action. The effectiveness of the proposed technique is validated in extensive simulation on a Baxter robot with soft springs playing a drum, and experimentally on a VSA double pendulum performing swinging motions.

- A Probabilistic Model-Based Online Learning Optimal Control Algorithm for Soft Pneumatic Actuators

    Author: Tang, ZhiQiang | The Chinese University of Hong Kong
    Author: Heung, Ho Lam | The Chinese University of Hong Kong
    Author: Tong, Kai Yu | The Chinese University of Hong Kong
    Author: Li, Zheng | The Chinese University of Hong Kong
 
    keyword: Modeling, Control, and Learning for Soft Robots; Model Learning for Control; Optimization and Optimal Control

    Abstract : Soft robots are increasingly being employed in different fields and various designs are created to satisfy relevant requirements. The wide ranges of design bring challenges to soft robotic control in that a unified control framework is difficult to derive. Traditional model-driven approaches for soft robots are usually design-specific which highly depend on specific design structures. Our approach to such challenges involves a probabilistic model that learns a mapping from the soft actuator states and controls to the next states. Then an optimal control policy is derived by minimizing a cost function based on the probabilistic model. We demonstrate the efficiency of our approach through simulations with parameter analysis and real-robot experiments involving three different designs of soft pneumatic actuators. Comparisons with previous model-based controllers are also provided to show advantages of the proposed method. Overall, this work provides a promising design-independent control approach for the soft robotics community.

- Rigid-Soft Interactive Learning for Robust Grasping

    Author: Yang, Linhan | Southern University of Science and Technology
    Author: Wan, Fang | Ancora Spring Inc
    Author: Wang, Haokun | Southern University of Science and Technology
    Author: Liu, Xiaobo | Southern University of Science and Technology
    Author: Liu, Yujia | The University of Hong Kong
    Author: Pan, Jia | University of Hong Kong
    Author: Song, Chaoyang | Southern University of Science and Technology
 
    keyword: Modeling, Control, and Learning for Soft Robots; Grasping; Multifingered Hands

    Abstract : Inspired by widely used soft fingers on grasping, we propose a method of rigid-soft interactive learning, aiming at reducing the time of data collection. In this paper, we classify the interaction categories into Rigid-Rigid, Rigid-Soft, Soft-Rigid according to the interaction surface between grippers and target objects. We find experimental evidence that the interaction types between grippers and target objects play an essential role in the learning methods. We use soft, stuffed toys for training, instead of everyday objects, to reduce the integration complexity and computational burden and exploit such rigid-soft interaction by changing the gripper fingers to the soft ones when dealing with rigid, daily-life items such as the Yale-CMU-Berkeley (YCB) objects. With a small data collection of 5K picking attempts in total, our results suggest that such Rigid-Soft and Soft-Rigid interactions are transferable. Moreover, the combination of different grasp types shows better performance on the grasping test. We achieve the best grasping performance at 97.5% for easy YCB objects and 81.3% for difficult YCB objects while using a precise grasp with a two-soft-finger gripper to collect training data and power grasp with a four-soft-finger gripper to test.

- Model and Data Based Approaches to the Control of Tensegrity Robots

    Author: Wang, Ran | Texas A&amp;M University
    Author: Goyal, Raman | Texas A&amp;M University
    Author: Chakravorty, Suman | Texas A&amp;M University
    Author: Skelton, Robert | Texas A&amp;M University
 
    keyword: Modeling, Control, and Learning for Soft Robots; Optimization and Optimal Control; Motion and Path Planning

    Abstract : This paper proposes two approaches to control the shape of the structure or the position of the end effector for a soft-robotic application. The first approach is a model based approach where the non-linear dynamics of the tensegrity system is used to regulate position, velocity and acceleration to the specified reference trajectory. The formulation uses state feedback to obtain the solution for the control (tension in the strings) as a linear programming problem. The other model-free approach is a novel decoupled data based control (D2C) which first optimizes a deterministic open-loop trajectory using a blackbox (no actual model) simulation model and then develops a linear quadratic regulator around the linearized open-loop trajectory. A 2-dimensional tensegrity robotic reacher is used to compare the results for both the approaches for a given cost function. The D2C approach is also used to study two more complex tensegrity examples whose dynamics is difficult to model analytically.

- Stiffness Imaging with a Continuum Appendage: Real-Time Shape and Tip Force Estimation from Base Load Readings

    Author: Sadati, Seyedmohammadhadi | King's College London
    Author: Shiva, Ali | King's College London
    Author: Herzig, Nicolas | University of Sheffield
    Author: Rucker, Caleb | University of Tennessee
    Author: Hauser, Helmut | University of Bristol
    Author: Walker, Ian | Clemson University
    Author: Bergeles, Christos | King's College London
    Author: Althoefer, Kaspar | Queen Mary University of London
    Author: Nanayakkara, Thrishantha | Imperial College London
 
    keyword: Modeling, Control, and Learning for Soft Robots; Soft Robot Applications; Medical Robots and Systems

    Abstract : In this paper, we propose benefiting from load readings at the base of a continuum appendage for real-time forward integration of Cosserat rod model with application in configuration and tip load estimation. The application of this method is successfully tested for stiffness imaging of a soft tissue, using a 3-DOF hydraulically actuated braided continuum appendage. Multiple probing runs with different actuation pressures are used for mapping the tissue surface shape and directional linear stiffness, as well as detecting non-homogeneous regions, e.g. a hard nodule embedded in a soft silicon tissue phantom. Readings from a 6-axis force sensor at the tip is used for comparison and verification. As a result, the tip force is estimated with 0.016-0.037 N (7-20%) mean error in the probing and 0.02-0.1 N (6-12%) in the indentation direction, 0.17 mm (14%) mean error is achieved in estimating the surface profile, and 3.415 [N/m] (10-16%) mean error is observed in evaluating tissue directional stiffness, depending on the appendage actuation. We observed that if the appendage bends against the slider motion (toward the probing direction), it provides better horizontal stiffness estimation and better estimation in the perpendicular direction is achieved when it bends toward the slider motion (against the probing direction). In comparison with a rigid probe, &#8776; 10 times smaller stiffness and &#8776; 7 times larger mean standard deviation values were observed.

- Sim-To-Real Transfer Learning Approach for Tracking Multi-DOF Ankle Motions Using Soft Strain Sensors

    Author: Park, Hyunkyu | Korea Advanced Institute of Science and Technology
    Author: Cho, Junhwi | KAIST
    Author: Park, Junghoon | KAIST
    Author: Na, Youngjin | Sookmyung Women's University
    Author: Kim, Jung | KAIST
 
    keyword: Modeling, Control, and Learning for Soft Robots; Soft Sensors and Actuators; Soft Robot Applications

    Abstract : A data-driven approach has recently been investigated for identifying human joint angles by means of soft strain sensors because of the corresponding modeling difficulty. However, this approach commonly incurs a high computational burden due to the voluminous amount of data required and the time-series-oriented network architecture. Moreover, the nature of soft sensors makes the problem worse due to the inherent nonlinearity and hysteresis of the material. In this study, we developed a novel wearable sensing brace design for measuring multiple degrees of freedom (DOFs) ankle motions to minimize hysteresis and to improve the measurement repeatability and developed a computationally efficient calibration method based on sim-to-real transfer learning. By attaching the soft sensors to shin links rather than directly to the ankle joint, the effects of external disturbances during joint motions were minimized. To calibrate the sensors to body motions, transfer learning was used based on the results from musculoskeletal simulation(OpenSim) and sensor data. The average tracking error for ankle motions using the proposed method was found to be 12.02� for five healthy subjects, while the direct deep neural network approach showed an error of 17.88�. The proposed method could be used to calibrate the soft sensors with 1000 times faster training spee d while maintaining comparable tracking accuracy with a smaller amount of data.

- Model-Based Pose Control of Inflatable Eversion Robot with Variable Stiffness

    Author: Ataka, Ahmad | Queen Mary University of London
    Author: Abrar, Taqi | Queen Mary University of London
    Author: Putzu, Fabrizio | Queen Mary University of London
    Author: Godaba, Hareesh | Queen Mary University of London
    Author: Althoefer, Kaspar | Queen Mary University of London
 
    keyword: Modeling, Control, and Learning for Soft Robots; Soft Robot Applications; Motion Control

    Abstract : Plant-inspired inflatable eversion robots with their tip growing behaviour have recently emerged. Because they extend from the tip, eversion robots are particularly suitable for applications that require reaching into remote places through narrow openings. Besides, they can vary their structural stiffness. Despite these essential properties which make the eversion robot a promising candidate for applications involving cluttered environments and tight spaces, controlling their motion especially laterally has not been investigated in depth. In this paper, we present a new approach based on model-based kinematics to control the eversion robot's tip position and orientation. Our control approach is based on Euler-Bernoulli beam theory which takes into account the effect of the internal inflation pressure to model each robot bending segment for various conditions of structural stiffness. We determined the parameters of our bending model by performing a least-square technique based on the pressure-bending data acquired from an experimental study. The model is then used to develop a pose controller for the tip of our eversion robot. Experimental results show that the proposed control strategy is capable of guiding the tip of the eversion robot to reach a desired position and orientation whilst varying its structural stiffness.

- Learning to Control Reconfigurable Staged Soft Arms

    Author: Nicolai, Austin | Oregon State University
    Author: Olson, Gina | Oregon State University
    Author: Menguc, Yigit | Facebook Reality Labs
    Author: Hollinger, Geoffrey | Oregon State University
 
    keyword: Modeling, Control, and Learning for Soft Robots; Deep Learning in Robotics and Automation

    Abstract : In this work, we present a novel approach for modeling, and classifying between, the system load states introduced when constructing staged soft arm configurations. Through a two stage approach: (1) an LSTM calibration routine is used to identify the current load state then (2) a control input generation step combines a generalized quasistatic model with the learned load model. Our experiments show that accounting for system load allows us to more accurately control tapered arm configurations. We analyze the performance of our method using soft robotic actuators and show it is capable of classifying between different arm configurations at a rate greater than 95%. Additionally, our method is capable of reducing the end-effector error of quasistatic model only control to within 1 cm of our controller baseline.

- Open-Loop Position Control in Collaborative, Modular Variable-Stiffness-Link (VSL) Robots

    Author: Gandarias, Juan M. | University of Malaga
    Author: Wang, Yongjing | University College London
    Author: Stilli, Agostino | University College London
    Author: Garc�a-Cerezo, Alfonso | University of Malaga
    Author: Gomez de Gabriel, Jesus Manuel | Universidad De Malaga
    Author: Wurdemann, Helge Arne | University College London
 
    keyword: Modeling, Control, and Learning for Soft Robots; Soft Robot Materials and Design; Deep Learning in Robotics and Automation

    Abstract : Collaborative robots open up new avenues in the field of industrial robotics and physical Human-Robot Interaction (pHRI) as they are suitable to work in close approximation with humans. The integration and control of variable stiffness elements allow inherently safe interaction: Apart from notable work on Variable Stiffness Actuators, the concept of Variable-Stiffness-Link (VSL) manipulators promises safety improvements in cases of unintentional physical collision. However, position control of these type of robotic manipulators is challenging for critical task-oriented motions. In this paper, we propose a hybrid, learning based kinematic modelling approach to improve the performance of traditional open-loop position controllers for a modular, collaborative VSL robot. We show that our approach improves the performance of traditional open-loop position controllers for robots with VSL and compensates for position errors, in particular, for lower stiffness values inside the links: Using our upgraded and modular robot, two experiments have been carried out to evaluate the behaviour of the robot during task-oriented motions. Results show that traditional model-based kinematics are not able to accurately control the position of the end-effector: the position error increases with higher loads and lower pressures inside the VSLs. On the other hand, we demonstrate that, using our approach, the VSL robot can outperform the position control compared to a robotic manipulator with 3D print

-  Control of a Silicone Soft Tripod Robot Via Uncertainty Compensation

    Author: Zheng, Gang | INRIA

- Control Oriented Modeling of Soft Robots: The Polynomial Curvature Case

    Author: Della Santina, Cosimo | Massachusetts Institute of Technology
    Author: Rus, Daniela | MIT
 
    keyword: Modeling, Control, and Learning for Soft Robots; Motion Control; Dynamics

    Abstract : The complex nature of soft robot dynamics calls for the development of models specifically tailored on the control application. In this paper we take a first step in this direction, by proposing a dynamic model for slender soft robots taking into account the fully infinite-dimensional dynamical structure of the system. We also contextually introduce a strategy to approximate this model at any level of detail through a finite dimensional system. First, we analyze the main mathematical properties of this model, in the case of lightweight and non lightweight soft robots. Then, we prove that using the constant term of curvature as control output produces a minimum phase system, in this way providing the theoretical support that existing curvature control techniques lack, and at the same time opening up to the use of advanced nonlinear control techniques. Finally, we propose a new controller, the PD-poly, which exploits information on high order deformations, to achieve zero steady state regulation error in presence of gravity and generic non constant curvature conditions.

- Modeling and Analysis of SMA Actuator Embedded in Stretchable Coolant Vascular Pursuing Artificial Muscles

    Author: Jeong, Jaeyeon | Korea Advanced Institute of Science Ane Technology
    Author: Park, Cheol Hoon | Korea Institute of Machinery &amp; Materials
    Author: Kyung, Ki-Uk | Korea Advanced Institute of Science &amp; Technology (KAIST)
 
    keyword: Modeling, Control, and Learning for Soft Robots; Soft Sensors and Actuators

    Abstract : This paper proposes a muscle-like SMA (Shape Memory Alloy) actuator with an active cooling system for efficient response. An SMA coil spring is embedded into a stretchable coolant vascular for soften structure of robots. In order to design a flexible, lightweight, and fast-response soft actuator with the SMA coil spring and coolant circulation system, a modeling based approach has been conducted. Analysis of coolant effects has been conducted in aspects of heating speed, cooling speed, and energy consumption based on both theoretical and empirical studies. From thermomechanical and heat transfer model between SMA and coolant, the actuation times in the case of heating and cooling phase have been estimated. From experimental results, Mineral oil is selected as the optimal coolant, and the maximum actuation frequency was measured as 0.5Hz for 40% contraction lifting 1kg.

- Distributed Proprioception of 3D Configuration in Soft, Sensorized Robots Via Deep Learning

    Author: Truby, Ryan Landon | Massachusetts Institute of Technology
    Author: Della Santina, Cosimo | Massachusetts Institute of Technology
    Author: Rus, Daniela | MIT
 
    keyword: Modeling, Control, and Learning for Soft Robots; Soft Sensors and Actuators; Soft Robot Materials and Design

    Abstract : Creating soft robots with sophisticated, autonomous capabilities requires these systems to possess reliable, on-line proprioception of 3D configuration through integrated soft sensors. We introduce a framework for predicting the 3D configuration of a soft robot via deep learning using feedback provided by a soft, proprioceptive sensor skin. Our framework introduces a kirigami-enabled strategy for rapidly sensorizing soft robots using off-the-shelf materials, a general kinematic description for soft robot geometry, and an investigation of neural network designs for predicting soft robot configuration. Even with hysteretic, non-monotonic feedback from the soft piezoresistive sensors, recurrent neural networks show potential for predicting our new kinematic parameters and, in turn, the soft robot's configuration. One trained neural network closely predicts steady-state configuration during operation, though complete dynamic behavior is not fully captured. We validate our methods on a soft robotic arm with 12 discrete actuators and 12 proprioceptive strain sensors. As an essential advance in soft robotic perception, we anticipate our framework will open new avenues towards closed loop control in soft robotics.


- Stable Tool-Use with Flexible Musculoskeletal Hands by Learning the Predictive Model of Sensor State Transition

    Author: Kawaharazuka, Kento | The University of Tokyo
    Author: Tsuzuki, Kei | University of Tokyo
    Author: Onitsuka, Moritaka | The University of Tokyo
    Author: Asano, Yuki | The University of Tokyo
    Author: Okada, Kei | The University of Tokyo
    Author: Kawasaki, Koji | The University of Tokyo
    Author: Inaba, Masayuki | The University of Tokyo
 
    keyword: Modeling, Control, and Learning for Soft Robots; Biomimetics; Tendon/Wire Mechanism

    Abstract : The flexible under-actuated musculoskeletal hand is superior in its adaptability and impact resistance. On the other hand, since the relationship between sensors and actuators cannot be uniquely determined, almost all its controls are based on feedforward controls. When grasping and using a tool, the contact state of the hand gradually changes due to the inertia of the tool or impact of action, and the initial contact state is hardly kept. In this study, we propose a system that trains the predictive network of sensor state transition using the actual robot sensor information, and keeps the initial contact state by a feedback control using the network. We conduct experiments of hammer hitting, vacuuming, and brooming, and verify the effectiveness of this study.

- Learning to Transfer Dynamic Models of Underactuated Soft Robotic Hands

    Author: Schramm, Liam | Rutgers University
    Author: Sintov, Avishai | Tel-Aviv University
    Author: Boularias, Abdeslam | Rutgers University
 
    keyword: Modeling, Control, and Learning for Soft Robots; Learning and Adaptive Systems; Model Learning for Control

    Abstract : Transfer learning is a popular approach to bypassing data limitations in one domain by leveraging data from another domain. This is especially useful in robotics, as it allows practitioners to reduce data collection with physical robots, which can be time-consuming and cause wear and tear. The most common way of doing this with neural networks is to take an existing neural network, and simply train it more with new data. However, we show that in some situations this can lead to significantly worse performance than simply using the transferred model without adaptation. We find that a major cause of these problems is that models trained on small amounts of data can have chaotic or divergent behavior in some regions. We derive an upper bound on the Lyapunov exponent of a trained transition model, and demonstrate two approaches that make use of this insight. Both show significant improvement over traditional fine-tuning. Experiments performed on real underactuated soft robotic hands clearly demonstrate the capability to transfer a dynamic model from one hand to another.

- Periodic Movement Learning in a Soft-Robotic Arm

    Author: Oikonomou, Paris | National Technical University of Athens (NTUA)
    Author: Khamassi, Mehdi | Cnrs / Upmc
    Author: Tzafestas, Costas S. | ICCS - Inst of Communication and Computer Systems
 
    keyword: Modeling, Control, and Learning for Soft Robots

    Abstract : In this paper we introduce a novel technique that aims to dynamically control a modular bio-inspired soft-robotic arm in order to perform cyclic rhythmic patterns. Oscillatory signals are produced at the actuator's level by a central pattern generator (CPG), resulting in the generation of a periodic motion by the robot's end-effector. The proposed controller is based on a model-free neurodynamic scheme and is assigned with the task of training a policy that computes the parameters of the CPG model which generates a trajectory with desired features. The proposed methodology is first evaluated with a simulation model, which successfully reproduces the trained targets. Then experiments are also conducted using the real robot. Both procedures validate the efficiency of the learning architecture to successfully complete these tasks.

- An Input Observer-Based Stiffness Estimation Approach for Flexible Robot Joints

    Author: Fagiolini, Adriano | University of Palermo
    Author: Trumic, Maja | University of Palermo
    Author: Jovanovic, Kosta | University of Belgrade, Serbia
 
    keyword: Modeling, Control, and Learning for Soft Robots; Physical Human-Robot Interaction; Flexible Robots

    Abstract : This paper addresses the stiffness estimation prob- lem for flexible robot joints, driven by variable stiffness actua- tors in antagonistic setups. Due to the difficulties of achieving consistent production of these actuators and the time-varying nature of their internal flexible elements, which are subject to plastic deformation over time, it is currently a challenge to precisely determine the total flexibility torque applied to a robot's joint and the corresponding joint stiffness. Herein, by considering the flexibility torque acting on each motor as an unknown signal and building upon Unknown Input Observer theory, a solution for electrically-driven actuators is proposed, which consists of a linear estimator requiring only knowledge about the positions of the joints and the motors as well as the drive's dynamic parameters. Beyond its linearity advantage, another appealing feature of the solution is the lack of need for torque and velocity sensors. The presented approach is first verified via simulations and then successfully tested on an experimental setup, comprising bidirectional antagonistic variable stiffness actuators.

- Fast Model-Based Contact Patch and Pose Estimation for Highly Deformable Dense-Geometry Tactile Sensors

    Author: Kuppuswamy, Naveen | Toyota Research Institute
    Author: Castro, Alejandro | Toyota Research Institute
    Author: Phillips-Grafflin, Calder | Toyota Research Institute
    Author: Alspach, Alex | Toyota Research Institute
    Author: Tedrake, Russ | Massachusetts Institute of Technology
 
    keyword: Modeling, Control, and Learning for Soft Robots; Perception for Grasping and Manipulation; Force and Tactile Sensing

    Abstract : Modeling deformable contact is a well-known problem in soft robotics and is particularly challenging for compliant interfaces that permit large deformations. We present a model for the behavior of a highly deformable dense geometry sensor in its interaction with objects; the forward model predicts the elastic deformation of a mesh given the pose and geometry of a contacting rigid object. We use this model to develop a fast approximation to solve the inverse problem: estimating the contact patch when the sensor is deformed by arbitrary objects. This inverse model can be easily identified through experiments and is formulated as a sparse Quadratic Program (QP) that can be solved efficiently online. The proposed model serves as the first stage of a pose estimation pipeline for robot manipulation. We demonstrate the proposed inverse model through real-time estimation of contact patches on a contact-rich manipulation problem in which oversized fingers screw a nut onto a bolt, and as part of a complete pipeline for pose-estimation and tracking based on the Iterative Closest Point (ICP) algorithm. Our results demonstrate a path towards realizing soft robots with highly compliant surfaces that perform complex real-world manipulation tasks.

- Mechanism and Model of a Soft Robot for Head Stabilization in Cancer Radiation Therapy

    Author: Ogunmolu, Olalekan | The University of Pennsylvania
    Author: Liu, Xinmin | University of Chicago
    Author: Gans, Nicholas (Nick) | University Texas at Arlington
    Author: Wiersma, Rodney | University of Chicago
 
    keyword: Modeling, Control, and Learning for Soft Robots; Soft Robot Applications; Medical Robots and Systems

    Abstract : We present a parallel robot mechanism and the constitutive laws that govern the deformation of its constituent soft actuators. Our ultimate goal is the real-time motion-correction of a patient's head deviation from a target pose where the soft actuators control the position of the patient's cranial region on a treatment machine. We describe the mechanism, derive the stress-strain constitutive laws for the individual actuators and the inverse kinematics that prescribes a given deformation, and then present simulation results that validate our mathematical formulation. Our results demonstrate deformations consistent with our radially symmetric displacement formulation under a finite elastic deformation framework.

## Manipulation

- Grasping Unknown Objects by Coupling Deep Reinforcement Learning, Generative Adversarial Networks, and Visual Servoing

    Author: Pedersen, Ole-Magnus | NTNU - Norwegian University of Technology and Science
    Author: Misimi, Ekrem | SINTEF Ocean
    Author: Chaumette, Francois | Inria Rennes-Bretagne Atlantique
 
    keyword: Deep Learning in Robotics and Automation; Perception for Grasping and Manipulation; Visual Servoing

    Abstract : In this paper, we propose a novel approach for transferring a deep reinforcement learning (DRL) grasping agent from simulation to a real robot, without fine tuning in the real world. The approach utilises a CycleGAN to close the reality gap between the simulated and real environments, in a reverse real-to-sim manner, effectively "tricking" the agent into believing it is still in the simulator. Furthermore, a visual servoing (VS) grasping task is added to correct for inaccurate agent gripper pose estimations derived from deep learning. The proposed approach is evaluated by means of real grasping experiments, achieving a success rate of 83 % on previously seen objects, and the same success rate for previously unseen, semi-compliant objects. The robustness of the approach is demonstrated by comparing it with two baselines, DRL plus CycleGAN, and VS only. The results clearly show that our approach outperforms both baselines.

- Incorporating Motion Planning Feasibility Considerations During Task-Agent Assignment to Perform Complex Tasks Using Mobile-Manipulators

    Author: Kabir, Ariyan M | University of Southern California
    Author: Thakar, Shantanu | University of Southern California
    Author: Bhatt, Prahar | University of Southern California
    Author: Malhan, Rishi | University of Southern California
    Author: Rajendran, Pradeep | University of Southern California
    Author: Shah, Brual C. | University of Southern California
    Author: Gupta, Satyandra K. | University of Southern California
 
    keyword: Task Planning; Mobile Manipulation; Motion and Path Planning

    Abstract : Multi-arm mobile manipulators can be represented as a combination of multiple robotic agents from the perspective of task-assignment and motion planning. Depending upon the task, agents might collaborate or work independently. Integrating motion planning with task-agent assignment is a computationally slow process as infeasible assignments can only be detected through expensive motion planning queries. We present three speed-up techniques for addressing this problem- (1) spatial constraint checking using conservative surrogates for motion planners, (2) instantiating symbolic conditions for pruning infeasible assignments, and (3) efficiently caching and reusing previously generated motion plans. We show that the developed method is useful for real-world operations that require complex interaction and coordination among high-DOF robotic agents.

- Learning to Scaffold the Development of Robotic Manipulation Skills

    Author: Shao, Lin | Stanford University
    Author: Migimatsu, Toki | Stanford University
    Author: Bohg, Jeannette | Stanford University
 
    keyword: Intelligent and Flexible Manufacturing; Learning and Adaptive Systems; Deep Learning in Robotics and Automation

    Abstract : Learning contact-rich, robotic manipulation skills is a challenging problem due to the high-dimensionality of the state and action space as well as uncertainty from noisy sensors and inaccurate motor control. To combat these factors and achieve more robust manipulation, humans are actively exploiting contact constraints in the environment. By adopting a similar strategy, robots can also achieve more robust manipulation. In this paper, we enable a robot to autonomously modify its environment and thereby discover how to ease manipulation skill learning. Specifically, we provide the robot with fixtures that it can freely place within the environment. These fixtures provide hard constraints that limit the outcome of robot actions. Thereby, they funnel uncertainty from perception and motor control and scaffold manipulation skill learning. We propose a learning system that consist of two learning loops. In the outer loop, the robot positions the fixture in the workspace. In the inner loop, the robot learns a manipulation skill and after a fixed number of episodes, returns the reward to the outer loop. Thereby, the robot is incentivised to place the fixture such that the inner loop quickly achieves a high reward. We demonstrate our framework both in simulation and the real world on three tasks: peg insertion, wrench manipulation and shallow-depth insertion. We show that manipulation skill learning is dramatically sped up through this way of scaffolding.

- Online Replanning in Belief Space for Partially Observable Task and Motion Problems

    Author: Garrett, Caelan | Massachusetts Institute of Technology
    Author: Paxton, Chris | NVIDIA Research
    Author: Lozano-Perez, Tomas | MIT
    Author: Kaelbling, Leslie | MIT
    Author: Fox, Dieter | University of Washington
 
    keyword: Task Planning; Manipulation Planning; Mobile Manipulation

    Abstract : To solve multi-step manipulation tasks in the real world, an autonomous robot must take actions to observe its environment and react to unexpected observations. This may require opening a drawer to observe its contents or moving an object out of the way to examine the space behind it. Upon receiving a new observation, the robot must update its belief about the world and compute a new plan of action. In this work, we present an online planning and execution system for robots faced with these challenges. We perform deterministic cost-sensitive planning in the space of hybrid belief states to select likely-to-succeed observation actions and continuous control actions. After execution and observation, we replan using our new state estimate. We initially enforce that planner reuses the structure of the unexecuted tail of the last plan. This both improves planning efficiency and ensures that the overall policy does not undo its progress towards achieving the goal. Our approach is able to efficiently solve partially observable problems both in simulation and in a real-world kitchen.

- An Automated Dynamic-Balancing-Inspection Scheme for Wheel Machining

    Author: Hao, Tieng | National Cheng Kung University
    Author: Li, Yu-Yong | National Cheng Kung University
    Author: Tseng, Kuang-Ping | National Cheng Kung University
    Author: Yang, Haw-Ching | National Kaohsiung Univ. of Sci. and Tech
    Author: Cheng, Fan-Tien | National Cheng Kung University
 
    keyword: Intelligent and Flexible Manufacturing

    Abstract : Wheel balance plays an important role in vehicle safety. The existing inspection method for wheel balance mainly relies on the off-machine measurement technique, which is time- and manpower-consuming as the worldwide requirement of the automated production system gradually increases. However, the multi-unbalance causes are difficult to identify due to complex machine structures; and the low signal-noise-ratio between wheel and machine vibration makes traditional handcrafted features difficult to detect wheel unbalance. To overcome these two problems, this paper proposes to a Dynamic-Balancing-Inspection (DBI) scheme which integrates steps of data collection, data preprocessing, ensemble average of Convolution Neural Network (CNN) based models with well-tailored filters and activation functions, to automatically uncover critical information from frequency data and provide a reliable total inspection method. The application of the wheel balance from a practical CNC-machine is adopted to illustrate the performance of the DBI approach.

- Faster Confined Space Manufacturing Teleoperation through Dynamic Autonomy with Task Dynamics Imitation Learning

    Author: Owan, Parker | University of Washington
    Author: Garbini, Joseph | U. of Washington
    Author: Devasia, Santosh | University of Washington
 
    keyword: Intelligent and Flexible Manufacturing; Human Performance Augmentation; Learning and Adaptive Systems

    Abstract : Confined space manufacturing tasks, such as cleaning pilot holes prior to installing fasteners during aircraft wing assembly, currently require human experts to be inside ergonomically-challenging environments. Small rapidly deployable robots can substantially improve manufacturing safety and productivity. However, relatively rapid full automation remains elusive due to high-level of uncertainty in the environment, lack of cost-effective programming for low volume production, and difficulty of deploying adequate number of sensors in the confined space. Moreover, currently, teleoperation with typical levels of training and limited transparency of hardware is too slow for manufacturing applications, requiring experts to spend more time for each task to achieve the same cleaning quality. In this context, the main contribution of this article is to reduce cycle times for remote manufacturing by learning statistical dynamic autonomy from higher quality expert demonstrations in an ideal offline scenario. During the task, to keep cycle times low, the dynamic autonomy imitates the faster expert demonstrations when certain, and employs the slower human teleoperation when uncertain. A user study (n=8) with an experimental robot platform shows that for the same cleaning quality, the dynamic autonomy reduces process completion time by 54.0% and human operator energy expenditure by 80.5% as compared with teleoperation without dynamic autonomy.

- Learning Precise 3D Manipulation from Multiple Uncalibrated Cameras

    Author: Akinola, Iretiayo | Columbia University
    Author: Varley, Jacob | Google
    Author: Kalashnikov, Dmitry | Google Brain
 
    keyword: Deep Learning in Robotics and Automation; Perception for Grasping and Manipulation; RGB-D Perception

    Abstract : In this work, we present an effective end-to-end learning approach for solving precision tasks that are 3D in nature. Our method learns to accomplish these tasks using multiple statically placed but uncalibrated RGB camera views without building an explicit 3D representation such as a pointcloud or voxel grid. This multi-camera approach achieves superior task performance on difficult stacking and insertion tasks compared to single-view baselines. Single view robotic agents struggle from occlusion and challenges in estimating relative poses between points of interest. Operating off explicit 3D representations from multiple depth sensors is often complicated by challenges in camera calibration, obtaining depth maps due to object properties such as reflective surfaces, and slower inference speeds over 3D representations compared to 2D images. Our use of static but uncalibrated cameras does not require camera-robot or camera-camera calibration and is robust to sensor dropout making it easy to setup and resilient to the loss of camera-views after deployment.

- Surfing on an Uncertain Edge: Precision Cutting of Soft Tissue Using Torque-Based Medium Classification

    Author: Straizys, Arturas | University of Edinburgh
    Author: Burke, Michael | University of Edinburgh
    Author: Ramamoorthy, Subramanian | The University of Edinburgh
 
    keyword: Learning and Adaptive Systems

    Abstract : Precision cutting of soft-tissue remains a challenging problem in robotics, due to the complex and unpredictable mechanical behaviour of tissue under manipulation. Here, we consider the challenge of cutting along the boundary between two soft mediums, a problem that is made extremely difficult due to visibility constraints, which means that the precise location of the cutting trajectory is typically unknown. This paper introduces a novel strategy to address this task, using a binary medium classifier trained using joint torque measurements, and a closed loop control law that relies on an error signal compactly encoded in the decision boundary of the classifier. We illustrate this on a grapefruit cutting task, successfully modulating a nominal trajectory fit using dynamic movement primitives to follow the boundary between grapefruit pulp and peel using torque based medium classification. Results show that this control strategy is successful in 72 % of attempts in contrast to control using a nominal trajectory, which only succeeds in 50 % of attempts.

- Dynamic Cloth Manipulation with Deep Reinforcement Learning

    Author: Jangir, Rishabh | Institut De Robòtica I Informàtica Industrial, CSIC-UPC
    Author: Aleny�, Guillem | CSIC-UPC
    Author: Torras, Carme | Csic - Upc
 
    keyword: Deep Learning in Robotics and Automation; Motion Control of Manipulators; Manipulation Planning

    Abstract : In this paper we present a Deep Reinforcement Learning approach to solve dynamic cloth manipulation tasks. Differing from the case of rigid objects, we stress that the followed trajectory (including speed and acceleration) has a decisive influence on the final state of cloth, which can greatly vary even if the positions reached by the grasped points are the same. We explore how goal positions for non-grasped points can be attained through learning adequate trajectories for the grasped points. Our approach uses few demonstrations to improve control policy learning, and a sparse reward approach to avoid engineering complex reward functions. Since perception of textiles is challenging, we also study different state representations to assess the minimum observation space required for learning to succeed. Finally, we compare different combinations of control policy encodings, demonstrations, and sparse reward learning techniques, and show that our proposed approach can learn dynamic cloth manipulation in an efficient way, i.e., using a reduced observation space, a few demonstrations, and a sparse reward.

- Learning to Combine Primitive Skills: A Step towards Versatile Robotic Manipulation

    Author: Strudel, Robin | INRIA Paris
    Author: Pashevich, Alexander | INRIA Grenoble Rhone-Alpes
    Author: Kalevatykh, Igor | INRIA
    Author: Laptev, Ivan | INRIA
    Author: Sivic, Josef | INRIA, Ecole Normale Supérieure, Paris, France
    Author: Schmid, Cordelia | Inria
 
    keyword: Deep Learning in Robotics and Automation; Learning and Adaptive Systems; Visual Learning

    Abstract : Manipulation tasks such as preparing a meal or assembling furniture remain highly challenging for robotics and vision. Traditional task and motion planning (TAMP) methods can solve complex tasks but require full state observability and are not adapted to dynamic scene changes. Recent learning methods can operate directly on visual inputs but typically require many demonstrations and/or task-specific reward engineering. In this work we aim to overcome previous limitations and propose a reinforcement learning (RL) approach to task planning that learns to combine primitive skills. First, compared to previous learning methods, our approach requires neither intermediate rewards nor complete task demonstrations during training. Second, we demonstrate the versatility of our vision-based task planning in challenging settings with temporary occlusions and dynamic scene changes. Third, we propose an efficient training of basic skills from few synthetic demonstrations by exploring recent CNN architectures and data augmentation. Notably, while all of our policies are learned on visual inputs in simulated environments, we demonstrate the successful transfer and high success rates when applying such policies to manipulation tasks on a real UR5 robotic arm.

- Learning to Assemble: Estimating 6D Poses for Robotic Object-Object Manipulation

    Author: Stevsic, Stefan | ETH Zurich
    Author: Christen, Sammy | ETH Zurich
    Author: Hilliges, Otmar | ETH Zurich
 
    keyword: Deep Learning in Robotics and Automation; Perception for Grasping and Manipulation; Computer Vision for Automation

    Abstract : In this paper we propose a robotic vision task with the goal of enabling robots to execute complex assembly tasks in unstructured environments using a camera as the primary sensing device. We formulate the task as an instance of 6D pose estimation of template geometries, to which manipulation objects should be connected. In contrast to the standard 6D pose estimation task, this requires reasoning about local geometry that is surrounded by arbitrary context, such as a power outlet embedded into a wall. We propose a deep learning based approach to solve this task alongside a novel dataset that will enable future work in this direction and can serve as a benchmark. We experimentally show that state-of-the-art 6D pose estimation methods alone are not sufficient to solve the task but that our training procedure significantly improves the performance of deep learning techniques in this context.

- Learning Affordance Space in Physical World for Vision-Based Robotic Object Manipulation

    Author: Wu, Huadong | Sun Yat-Sen University
    Author: Zhang, Zhanpeng | SenseTime Group Limited
    Author: Cheng, Hui | Sun Yat-Sen University
    Author: Yang, Kai | Sun Yat-Sen University
    Author: Liu, Jiaming | Sensetime
    Author: Guo, Ziying | Sun Yat-Sen University
 
    keyword: Deep Learning in Robotics and Automation; Computer Vision for Automation; Perception for Grasping and Manipulation

    Abstract : What is a proper representation for objects in manipulation? What would human try to perceive when manipulating a new object in a new environment? In fact, instead of focusing on the texture and illumination, human can infer the "affordance" of the objects from vision. Here "affordance" describes the object's intrinsic property that affords a particular type of manipulation. In this work, we investigate whether such affordance can be learned by a deep neural network. In particular, we propose an Affordance Space Perception Network (ASPN) that takes an image as input and outputs an affordance map. Different from existing works that infer the pixel-wise probability affordance map in image space, our affordance is defined in the real world space, thus eliminates the need of hand-eye calibration. In addition, we extend the representation ability of affordance by defining it in a 3D affordance space and propose a novel training strategy to improve the performance. Trained purely with simulation data, ASPN can achieve significant performance in the real world. It is a task-agnostic framework and can handle different objects, scenes and viewpoints. Extensive real-world experiments demonstrate the accuracy and robustness of our approach. We achieve the success rates of 94.2% for singular-object pushing and 92.4% for multiple-object pushing. We achieve the success rates of 97.2% for singular-object grasping and 95.4% for multiple-object grasping, which outperform current SotA methods.

## Sensor Fusion

- LiStereo: Generate Dense Depth Maps from LIDAR and Stereo Imagery

    Author: Junming, Zhang | University of Michigan
    Author: Srinivasan Ramanagopal, Manikandasriram | University of Michigan
    Author: Vasudevan, Ram | University of Michigan
    Author: Johnson-Roberson, Matthew | University of Michigan
 
    keyword: Sensor Fusion; Computer Vision for Transportation; RGB-D Perception

    Abstract : An accurate depth map of the environment is critical to the safe operation of autonomous robots and vehicles. Currently, either light detection and ranging (LIDAR) or stereo matching algorithms are used to acquire such depth information. However, a high-resolution LIDAR is expensive and produces sparse depth map at large range; stereo matching algorithms are able to generate denser depth maps but are typically less accurate than LIDAR at long range. This paper combines these approaches together to generate high-quality dense depth maps. Unlike previous approaches that are trained using ground-truth labels, the proposed model adopts a self-supervised training process. Experiments show that the proposed method is able to generate high-quality dense depth maps and performs robustly even with low-resolution inputs. This shows the potential to reduce the cost by using LIDARs with lower resolution in concert with stereo systems while maintaining high resolution.

- Monocular Visual-Inertial Odometry in Low-Textured Environments with Smooth Gradients: A Fully Dense Direct Filtering Approach

    Author: Hardt-Stremayr, Alexander | Alpen-Adria-Universitét Klagenfurt
    Author: Weiss, Stephan | Universitét Klagenfurt
 
    keyword: Sensor Fusion; Visual-Based Navigation; Computer Vision for Other Robotic Applications

    Abstract : State of the art visual-inertial odometry approaches suffer from the requirement of high gradients and sufficient visual texture. Even direct photometric approaches select a subset of the image with high-gradient areas and ignore smooth gradients or generally low-textured areas. In this work, we show that taking all image information (i.e. every single pixel) enables visual-inertial odometry even on areas with very low texture and smooth gradients, inherently interpolating and estimating the scene with no texture based on its informative surrounding. This information propagation is only possible as we estimate all states and their uncertainties (robot pose, extrinsic sensor calibration, and scene depth) jointly in a fully dense filter framework. Our complexity reduction approach enables real-time execution despite the large size of the state vector. Compared to our previous basic feasibility study on this topic, this work includes higher order covariance propagation and improved state handling for a significant performance gain, thorough comparisons to state-of-the-art algorithms, larger mapping components with uncertainty, self-calibration capability, and real-data tests.

- Gated Recurrent Fusion to Learn Driving Behaviour from Temporal Multimodal Data

    Author: Lakshmi Narayanan, Athmanarayanan | Honda Research Institute
    Author: Siravuru, Avinash | Carnegie Mellon University
    Author: Dariush, Behzad | Honda Research Institute USA
 
    keyword: Sensor Fusion; Intelligent Transportation Systems; Computer Vision for Transportation

    Abstract : The Tactical Driver Behavior modeling problem requires an understanding of driver actions in complicated urban scenarios from rich multimodal signals including video, LiDAR and CAN signal data streams. However, the majority of deep learning research is focused either on learning the vehicle/environment state (sensor fusion) or the driver policy (from temporal data), but not both. Learning both tasks jointly offers the richest distillation of knowledge but presents challenges in the formulation and successful training. In this work, we propose promising first steps in this direction. Inspired by the gating mechanisms in Long Short-Term Memory units (LSTMs), we propose Gated Recurrent Fusion Units (GRFU) that learn fusion weighting and temporal weighting simultaneously. We demonstrate it's superior performance over multimodal and temporal baselines in supervised regression and classification tasks, all in the realm of autonomous navigation. On tactical driver behavior classification using Honda Driving Dataset (HDD), we report 10% improvement in mean Average Precision (mAP) score, and similarly, for steering angle regression on TORCS dataset, we note a 20% drop in Mean Squared Error (MSE) over the state-of-the-art.

- Cooperative Visual-Inertial Odometry: Analysis of Singularities, Degeneracies and Minimal Cases

    Author: Martinelli, Agostino | INRIA Grenoble-Rhone-Alpes
 
    keyword: Sensor Fusion; Visual-Based Navigation; Distributed Robot Systems

    Abstract : This paper provides an exhaustive analysis of all the singularities and minimal cases in cooperative visual-inertial odometry. Specifically, the case of two agents is analysed. As in the case of a single agent (addressed in [1]) and in the case of other computer vision problems, the key of the analysis is the establishment of an equivalence between the cooperative visual-inertial odometry problem and a Polynomial Equation System (PES). In the case of a single agent, the PES consists of linear equations and a single polynomial of second degree. In the case of two agents, the number of second degree equations becomes three and, also in this case, a complete analytic solution can be obtained [2]. The power of the analytic solution is twofold. From one side, it allows us to determine the state without the need of an initialization. From another side, it provides fundamental insights into all the structural properties of the problem. This paper focuses on this latter issue. Specifically, we obtain all the minimal cases and singularities depending on the number of camera images and the relative trajectory between the agents. The problem, when non singular, can have up to eight distinct solutions. The usefulness of this analysis is illustrated with simulations. In particular, we show quantitatively how the performance of the state estimation worsens near a singularity.

- A Lightweight and Accurate Localization Algorithm Using Multiple Inertial Measurement Units

    Author: Zhang, Ming | Alibaba Incorporation
    Author: Xu, Xiangyu | Alibaba Inc
    Author: Chen, Yiming | Alibaba Group
    Author: Li, Mingyang | Alibaba
 
    keyword: Sensor Fusion; Localization; SLAM

    Abstract : This paper proposes a novel inertial-aided localization approach by fusing information from multiple inertial measurement units (IMUs) and exteroceptive sensors. IMU is a low-cost motion sensor which provides measurements on angular velocity and gravity compensated linear acceleration of a moving platform, and widely used in modern localization systems. To date, most existing inertial-aided localization methods exploit only one single IMU. While the single-IMU localization yields acceptable accuracy and robustness for different use cases, the overall performance can be further improved by using multiple IMUs. To this end, we propose a lightweight and accurate algorithm for fusing measurements from multiple IMUs and exteroceptive sensors, which is able to obtain noticeable performance gain without incurring additional computational cost. To achieve this, we first probabilistically map measurements from all IMUs onto a virtual IMU. This step is performed by stochastic estimation with least-square estimators and probabilistic marginalization of inter-IMU rotational accelerations. Subsequently, the propagation model for both state and error state of the virtual IMU is also derived, which enables the use of the classical filter-based or optimization-based sensor fusion algorithms for localization. Finally, results from both simulation and real-world tests are provided, which demonstrate that the proposed algorithm outperforms competing algorithms by noticeable margins.

- Accelerating the Estimation of Metabolic Cost Using Signal Derivatives: Implications for Optimization and Evaluation of Wearable Robots (I)

    Author: Ingraham, Kimberly | University of Michigan
    Author: Rouse, Elliott | University of Michigan / (Google) X
    Author: Remy, C. David | University of Stuttgart
 
    keyword: Sensor Fusion; Rehabilitation Robotics; Optimization and Optimal Control

    Abstract : Body-in-the-loop optimization algorithms use real-time estimates of metabolic cost to iteratively tune the actuation profile of a robotic assistive device (e.g., an exoskeleton) to minimize the wearer's energetic cost. To translate these algorithms outside the laboratory environment, we need to obtain estimates of metabolic energy cost quickly, accurately, and with unobtrusive equipment. We have previously shown that we can estimate metabolic cost using physiological signals collected from portable, wearable sensors (e.g., accelerometers or EMG). However, these estimates are still dynamically delayed. Inspired by model-based estimation techniques, in this article we show that including signal derivatives in a black-box estimation process improves both the magnitude and speed of predicting instantaneous metabolic cost from wearable sensors when the input signals are dynamically delayed. These performance improvements were observed during the transient phase of an activity, while steady state performance remained unchanged. This article provides a practical foundation for improving the speed of predicting metabolic energy cost for wearable robotics applications.

- Deep Depth Fusion for Black, Transparent, Re&#64258;ective and Texture-Less Objects

    Author: Chai, Chun-Yu | National Chiao Tung University
    Author: Wu, Yu-Po | National Chiao Tung University
    Author: Tsao, Shiao-Li | National Chiao Tung University
 
    keyword: Sensor Fusion; RGB-D Perception; Perception for Grasping and Manipulation

    Abstract : Structured-light and stereo cameras, which are widely used to construct point clouds for robotic applications, have different limitations on estimating depth values. Structured-light cameras fail in black, transparent, and reflective objects, which influence the light path; stereo cameras fail in texture-less objects.<p>In this work, we propose a depth fusion model that complements these two types of methods to generate high-quality point clouds for short-range robotic applications. The model first determines the fusion weights from the two input depth images and then refines the fused depth using color features.</p><p>We construct a dataset containing the aforementioned challenging objects and report the performance of our proposed model. The results reveal that our method reduces the average L1 distance on depth prediction by 75% and 52% compared with the original depth output of the structured-light camera and the stereo model, respectively. A direct improvement on the Iterative Closest Point (ICP) algorithm can be achieved by using the refined depth images output from our method.

- LiDAR-Enhanced Structure-From-Motion

    Author: Zhen, Weikun | Carnegie Mellon University
    Author: Hu, Yaoyu | Carnegie Mellon University
    Author: Yu, Huai | Wuhan University
    Author: Scherer, Sebastian | Carnegie Mellon University
 
    keyword: Sensor Fusion; Range Sensing; Mapping

    Abstract : Although Structure-from-Motion (SfM) as a maturing technique has been widely used in many applications, state-of-the-art SfM algorithms are still not robust enough in certain situations. For example, images for inspection purposes are often taken in close distance to obtain detailed textures, which will result in less overlap between images and thus decrease the accuracy of estimated motion. In this paper, we propose a LiDAR-enhanced SfM pipeline that jointly processes data from a rotating LiDAR and a stereo camera pair to estimate sensor motions. We show that incorporating LiDAR helps to effectively reject falsely matched images and significantly reduce the motion drift in large scale environments. Experiments are conducted in different environments to test the performance of the proposed pipeline and comparison results with the state-of-the-art SfM algorithms are reported.

- Low Latency and Low-Level Sensor Fusion for Automotive Use-Cases

    Author: Pollach, Matthias | Technical University Munich
    Author: Schiegg, Felix | Technische Universitét M�nchen
    Author: Knoll, Alois | Tech. Univ. Muenchen TUM
 
    keyword: Sensor Fusion; Object Detection, Segmentation and Categorization; Sensor Networks

    Abstract : This work proposes a probabilistic low level automotive sensor fusion approach using LiDAR, RADAR and camera data. The method is stateless and directly operates on associated data from all sensor modalities. Tracking is not used, in order to reduce the object detection latency and create existence hypotheses per frame. The probabilistic fusion uses input from 3D and 2D space. An association method using a combination of overlap and distance metrics, avoiding the need for sensor synchronization is proposed. A Bayesian network executes the sensor fusion. The proposed approach is compared with a state of the art fusion system, which is using multiple sensors of the same modality and relies on tracking for object detection. Evaluation was done using low level sensor data recorded in an urban environment. The test results show that the low level sensor fusion reduces the object detection latency.

- Spatiotemporal Camera-LiDAR Calibration: A Targetless and Structureless Approach

    Author: Park, Chanoh | CSIRO, QUT
    Author: Moghadam, Peyman | CSIRO
    Author: Kim, Soohwan | CSIRO
    Author: Sridharan, Sridha | Queensland University of Technology
    Author: Fookes, Clinton | Queensland University of Technology
 
    keyword: Sensor Fusion; SLAM

    Abstract : The demand for multimodal sensing systems for robotics is growing due to the increase in robustness, reliability and accuracy offered by these systems. These systems also need to be spatially and temporally co-registered to be effective. In this paper, we propose a targetless and structureless spatiotemporal camera-LiDAR calibration method. Our method combines a closed-form solution with a modified structureless bundle adjustment where the coarse-to-fine approach does not require an initial guess on the spatiotemporal parameters. Also, as 3D features (structure) are calculated from triangulation only, there is no need to have a calibration target or to match 2D features with the 3D point cloud which provides flexibility in the calibration process and sensor configuration. We demonstrate the accuracy and robustness of the proposed method through both simulation and real data experiments using multiple sensor payload configurations mounted to hand-held, aerial and legged robot systems. Also, qualitative results are given in the form of a colorized point cloud visualization.

- Robot-Assisted and Wearable Sensor-Mediated Autonomous Gait Analysis

    Author: Zhang, Huanghe | Stevens Institute of Technology
    Author: Chen, Zhuo | Stevens Institute of Technology
    Author: Zanotto, Damiano | Stevens Institute of Technology
    Author: Guo, Yi | Stevens Institute of Technology
 
    keyword: Sensor Fusion; Physically Assistive Devices; Robot Companions

    Abstract : In this paper, we propose an autonomous gait analysis system consisting of a mobile robot and custom-engineered instrumented insoles. The robot is equipped with an on-board RGB-D sensor, the insoles feature inertial sensors and force sensitive resistors. This system is motivated by the need of a robot companion to engage older adults in walking exercises. Support vector regression (SVR) models were developed to extract accurate estimates of fundamental kinematic gait parameters (i.e., stride length, velocity, foot clearance, and step length), from data collected with the robot's on-board RGB-D sensor and with the instrumented insoles during straight walking and turning tasks. The accuracy of each model was validated against ground-truth data measured by an optical motion capture system with N=10 subjects. Results suggest that the combined use of wearable and robot's sensors yields more accurate gait estimates than either sub-system used independently. Additionally, SVR models are robust to inter-subject variability and type of walking task (i.e., straight walking vs. turning), thereby making it unnecessary to collect subject-specific or task-specific training data for the models. These findings indicate the potential of the synergistic use of autonomous mobile robots and wearable sensors for accurate out-of-the-lab gait analysis.

- Gaussian Process Preintegration for Inertial-Aided State Estimation

    Author: Le Gentil, Cedric | University of Technology Sydney
    Author: Vidal-Calleja, Teresa A. | University of Technology Sydney
    Author: Huang, Shoudong | University of Technology, Sydney
 
    keyword: Sensor Fusion; SLAM; Localization

    Abstract : In this paper, we present Gaussian Process Preintegration, a preintegration theory based on continuous representations of inertial measurements. A novel use of linear operators on Gaussian Process kernels is employed to generate the proposed Gaussian Preintegrated Measurements (GPMs). This formulation allows the analytical integration of inertial signals on any time interval. Consequently, GPMs are especially suited for asynchronous inertial-aided estimation frameworks. Unlike discrete preintegration approaches, the proposed method does not rely on any explicit motion-model and does not suffer from numerical integration noise. Additionally, we provide the analytical derivation of the Jacobians involved in the first-order expansion for postintegration bias and inter-sensor time-shift correction. We benchmarked the proposed method against existing preintegration methods on simulated data. Our experiments show that GPMs produce the most accurate results and their computation time allows close-to-real-time operations. We validated the suitability of GPMs for inertial-aided estimation by integrating them into a lidar-inertial localisation and mapping framework.

- A Code for Unscented Kalman Filtering on Manifolds (UKF-M)

    Author: Brossard, Martin | Mines ParisTech
    Author: Barrau, Axel | Safran
    Author: Bonnabel, Silvere | Mines ParisTech
 
    keyword: Sensor Fusion; Localization; Wheeled Robots

    Abstract : The present paper introduces a novel methodology for Unscented Kalman Filtering (UKF) on manifolds that extends previous work by the     Authors on UKF on Lie groups. Beyond filtering performance, the main interests of the approach are its versatility, as the method applies to numerous state estimation problems, and its simplicity of implementation for practitioners not being necessarily familiar with manifolds and Lie groups. We have developed the method on two independent open-source Python and Matlab frameworks we call UKF-M, for quickly implementing and testing the approach. The online repositories contain tutorials, documentation, and various relevant robotics examples that the user can readily reproduce and then adapt, for fast prototyping and benchmarking. The code is available at https://github.com/CAOR-MINES-ParisTech/ukfm.

- Efficient and Precise Sensor Fusion for Non-Linear Systems with Out-Of-Sequence Measurements by Example of Mobile Robotics

    Author: B�hmler, Pascal | Karlsruhe Institute of Technology
    Author: Dziedzitz, Paul Jonathan | Karlsruhe Institute of Technology
    Author: Hopfgarten, Patric | Karlsruher Institut F�r Technologie
    Author: Specker, Thomas | Robert Bosch GmbH
    Author: Lange, Ralph | Robert Bosch GmbH
 
    keyword: Sensor Fusion; Localization

    Abstract : For most applications in mobile robotics, precise state estimation is essential. Typically, the state estimation is based on the fusion of data from different sensors. In practice, these sensors differ in their characteristics and measurements are available to the sensor fusion algorithm only with delay. Based on a brief survey of sensor fusion approaches that consider delayed and out-of-sequence availability of measurements, suitable approaches for applications in mobile robotics are identified. In a consumer robot use-case, experiments show that the estimation is biased if delayed availability of measurements is not considered appropriately. However, if delays are considered in the fusion process, the estimation bias is reduced to almost zero and in consequence, the estimation performance is distinctly improved. Two computational favorable approximative methods are described and provide almost the same accuracy as - theoretically optimal - brute-force filter recalculation at much lower and well-distributed computational costs.

- UNO: Uncertainty-Aware Noisy-Or Multimodal Fusion for Unanticipated Input Degradation

    Author: Tian, Junjiao | Georgia Institute of Technology
    Author: Cheung, Wesley | Georgia Institute of Technology
    Author: Glaser, Nathaniel | Georgia Institute of Technology
    Author: Liu, Yen-Cheng | Georgia Tech
    Author: Kira, Zsolt | Georgia Institute of Technology
 
    keyword: Sensor Fusion; RGB-D Perception; Semantic Scene Understanding

    Abstract : The fusion of multiple sensor modalities, especially through deep learning architectures, has been an active area of study. However, an under-explored aspect of such work is whether the methods can be robust to degradation across their input modalities, especially when they must generalize to degradation not seen during training. In this work, we propose an uncertainty-aware fusion scheme to effectively fuse inputs that might suffer from a range of known and unknown degradation. Specifically, we analyze a number of uncertainty measures, each of which captures a different aspect of uncertainty, and we propose a novel way to fuse degraded inputs by scaling modality-specific output softmax probabilities. We additionally propose a novel data-dependent spatial temperature scaling method to complement these existing uncertainty measures. Finally, we integrate the uncertainty-scaled output from each modality using a probabilistic noisy-or fusion method. In a photo-realistic simulation environment (AirSim), we show that our method achieves significantly better results on a semantic segmentation task, as compared to state-of-art fusion architectures, on a range of degradation (e.g. fog, snow, frost, and various other types of noise), some of which are unknown during training.

- Intermittent GPS-Aided VIO: Online Initialization and Calibration

    Author: Lee, Woosik | University of Delaware
    Author: Eckenhoff, Kevin | University of Delaware
    Author: Geneva, Patrick | University of Delaware
    Author: Huang, Guoquan | University of Delaware
 
    keyword: Sensor Fusion; Localization; SLAM

    Abstract : In this paper, we present an efficient and robust GPS-aided visual inertial odometry (GPS-VIO) system that fuses IMU-camera data with intermittent GPS measurements. To perform sensor fusion, spatiotemporal sensor calibration and initialization of the transform between the sensor reference frames are required. We propose an online calibration method for both the GPS-IMU extrinsics and time offset as well as a reference frame initialization procedure that is robust to GPS sensor noise. In addition, we prove the existence of four unobservable directions of the GPS-VIO system when estimating in the VIO reference frame, and advocate a state transformation to the GPS reference frame for full observability. We extensively evaluate the proposed approach in Monte-Carlo simulations where we investigate the system's robustness to different levels of GPS noise and loss of GPS signal, and additionally study the hyper-parameters used in the initialization procedure. Finally, the proposed system is validated in a large-scale real-world experiment.

- A Mathematical Framework for IMU Error Propagation with Applications to Preintegration

    Author: Barrau, Axel | Safran
    Author: Bonnabel, Silvere | Mines ParisTech
 
    keyword: Sensor Fusion; Localization; SLAM

    Abstract : To fuse information from inertial measurement units (IMU) with other sensors one needs an accurate model for IMU error propagations in terms of position, velocity and orientation, a triplet we call extended pose.	In this paper we leverage a nontrivial result, namely log-linearity of inertial navigation equations based on the recently introduced Lie group SE_2(3), to	transpose the recent methodology of Barfoot and Furgale for associating uncertainty with poses (position, orientation) of SE(3) when using noisy wheel speeds, to the case of extended poses (position, velocity, orientation) of SE_2(3) when using noisy IMUs. Besides, our approach to extended poses combined with log-linearity property allows revisiting the theory of preintegration on manifolds and reaching a further theoretic level in this field. We show exact preintegration formulas that account for rotating earth, that is, centrifugal force and Coriolis effect,	may be derived as a byproduct.

- Radar-Inertial Ego-Velocity Estimation for Visually DegradedEnvironments

    Author: Kramer, Andrew | University of Colorado Boulder
    Author: Stahoviak, Carl | University of Colorado Boulder
    Author: Santamaria-Navarro, Angel | NASA Jet Propulsion Laboratory, Caltech
    Author: Heckman, Christoffer | University of Colorado at Boulder
    Author: Agha-mohammadi, Ali-akbar | NASA-JPL, Caltech
 
    keyword: Sensor Fusion; Aerial Systems: Perception and Autonomy; Field Robots

    Abstract : We present an approach for estimating the body-frame velocity of a mobile robot. We combine measurements from a millimeter-wave radar-on-a-chip sensor and an inertial measurement unit (IMU) in a batch optimization over a sliding window of recent measurements. The sensor suite employed is lightweight, low-power, and is invariant to ambient lighting conditions. This makes the proposed approach an attractive solution for platforms with limitations around payload and longevity, such as aerial vehicles conducting autonomous exploration in perceptually degraded operating conditions, including subterranean environments. We compare our radar-inertial velocity estimates to those from a visual-inertial (VI) approach. We show the accuracy of our method is comparable to VI in conditions favorable to VI, and far exceeds the accuracy of VI when conditions deteriorate.

- Observability Analysis of Flight State Estimation for UAVs and Experimental Validation

    Author: Huang, Peng | Technische Universitét Dresden
    Author: Meyr, Heinrich | Barkhausen Institut
    Author: D�rpinghaus, Meik | Technische Universitét Dresden
    Author: Fettweis, Gerhard | Technische Universitét Dresden
 
    keyword: Sensor Fusion; Autonomous Vehicle Navigation; Aerial Systems: Mechanics and Control

    Abstract : UAVs require reliable, cost-efficient onboard flight state estimation that achieves high accuracy and robustness to perturbation. We analyze a multi-sensor extended Kalman filter (EKF) based on the work by Leutenegger. The EKF uses measurements from a MEMS-based inertial system, static and dynamic pressure sensors as well as GPS. As opposed to other implementations we do not use a magnetic sensor because the weak magnetic field of the earth is subject to disturbances. Observability of the state is a necessary condition for the EKF to work. In this paper, we demonstrate that the system state is observable - which is in contrast to statements in the literature - if the random nature of the air mass is taken into account. Therefore, we carry out an in-depth observability analysis based on a singular value decomposition (SVD). The numerical SVD delivers a wealth of information regarding the observable (sub)spaces. We validated the theoretical findings based on sensor data recorded in test flights on a glider. Most importantly, we demonstrate that the EKF works. It is capable of absorbing large perturbations in the wind state variable converging to the undisturbed estimates.

- OpenVINS: A Research Platform for Visual-Inertial Estimation

    Author: Geneva, Patrick | University of Delaware
    Author: Eckenhoff, Kevin | University of Delaware
    Author: Lee, Woosik | University of Delaware
    Author: Yang, Yulin | University of Delaware
    Author: Huang, Guoquan | University of Delaware
 
    keyword: Sensor Fusion; Localization; SLAM

    Abstract : In this paper, we present an open platform, termed OpenVINS, for visual-inertial estimation research for both the academic community and practitioners from industry. The open sourced codebase provides a foundation for researchers and engineers to quickly start developing new capabilities for their visual-inertial systems. This codebase has out of the box support for commonly desired visual-inertial estimation features, which include: (i) on-manifold sliding window Kalman filter, (ii) online camera intrinsic and extrinsic calibration, (iii) camera to inertial sensor time offset calibration, (iv) SLAM landmarks with different representations and consistent First-Estimates Jacobian (FEJ) treatments, (v) modular type system for state management, (vi) extendable visual-inertial system simulator, and (vii) extensive toolbox for algorithm evaluation. Moreover, we have also focused on detailed documentation and theoretical derivations to support rapid development and research, which are greatly lacked in the current open sourced algorithms. Finally, we perform comprehensive validation of the proposed OpenVINS against state-of-the-art open sourced algorithms, showing its competing estimation performance.

- Decentralized Collaborative State Estimation for Aided Inertial Navigation

    Author: Jung, Roland | Alpen-Adria-Universitét Klagenfurt
    Author: Brommer, Christian | Alpen Adria University
    Author: Weiss, Stephan | Universitét Klagenfurt
 
    keyword: Sensor Fusion; Cooperating Robots; Localization

    Abstract : In this paper, we present a Quaternion-based Error-State Extended Kalman Filter (Q-ESEKF) based on IMU propagation with an extension for Collaborative State Estimation (CSE) and a communication complexity of O(1) (in terms of required communication links). Our approach combines a versatile filter formulation with the concept of CSE, allowing independent state estimation on each of the agents and at the same time leveraging and statistically maintaining interdependencies between agents, after joint measurements and communication (i.e. relative position measurements) occur. We discuss the development of the overall framework and the probabilistic (re-)initialization of the agent's states upon initial or recurring joint observations. Our approach is evaluated in a simulation framework on two prominent benchmark datasets in 3D.

- Analytic Combined IMU Integration (ACI^2) for Visual Inertial Navigation

    Author: Yang, Yulin | University of Delaware
    Author: Wisely Babu, Benzun Pious | Robert Bosch Research &amp; Technology Center, North America
    Author: Chen, Chuchu | University of Delaware
    Author: Huang, Guoquan | University of Delaware
    Author: Ren, Liu | Robert Bosch North America Research Technology Center
 
    keyword: Sensor Fusion; SLAM; Localization

    Abstract : Batch optimization based inertial measurement unit (IMU) and vision sensor fusion enables high rate localization for many robotics tasks. However, it remains a challenge to ensure that the batch optimization is computationally efficient while being consistent for high rate IMU measurements without marginalization. In this paper, we derive inspiration from maximum likelihood estimation with partial-fixed estimates to provide a unified approach for handing both IMU pre-integration and time-offset calibration. We present a novel modularized analytic combined IMU integrator (ACI^2) with derivations for integration, Jabcobians and covariances estimation. To simplify our derivation we also prove that the right Jacobians for Hamilton quaterions and SO(3) are equivalent. Finally, we also present a time offset calibrator that operates by fixing the linearization point for a given time offset. This reduces re-integration of the IMU measurements and thus improve efficiency. The proposed ACI^2 and time offset calibration is verified by intensive Monte-Carlo simulations generated from real world datasets. A proof-of-concept real world experiment is also conducted to verify the proposed ACI^2 estimator.

- Second-Order Kinematics for Floating-Base Robots Using the Redundant Acceleration Feedback of an Artificial Sensory Skin

    Author: Leboutet, Quentin | Technical University of Munich
    Author: Guadarrama-Olvera, Julio Rogelio | Technical University of Munich
    Author: Bergner, Florian | Technical University of Munich
    Author: Cheng, Gordon | Technical University of Munich
 
    keyword: Sensor Fusion; Sensor Networks; Kinematics

    Abstract : In this work, we propose a new estimation method for second-order kinematics for floating-base robots, based on highly redundant distributed inertial feedback. The linear acceleration of each robot link is measured at multiple points using a multimodal, self-configuring and self-calibrating artificial skin. The proposed algorithm is two-fold: i) the skin acceleration data is fused at the link level for state dimensionality reduction; ii) the estimated values are then fused limb-wise with data from the joint encoders and the main inertial measurement unit (IMU), using a Sigma-point Kalman filter. In this manner, it is possible to estimate the joint velocities and accelerations while avoiding the lag and noise amplification phenomena associated with conventional numerical derivation approaches. Experiments performed on the right arm and torso of a REEM-C humanoid robot, demonstrate the consistency of the proposed estimation method.

- Clock-Based Time Synchronization for an Event-Based Camera Dataset Acquisition Platform

    Author: Osadcuks, Vitalijs | Latvia University of Life Sciences and Technologies, Faculty Of
    Author: Pudzs, Mihails | Riga Technical University
    Author: Zujevs, Andrejs | Riga Technical University
    Author: Pecka, Aldis | Latvia University of Life Sciences and Technologies
    Author: Ardavs, Arturs | Riga Technical University
 
    keyword: Sensor Fusion; Neurorobotics; Robotics in Agriculture and Forestry

    Abstract : The Dynamic Visual Sensor is considered to be a next-generation vision sensor. Since event-based vision is in its early stage of development, a small number of datasets has been created during the last decade. Dataset creation is motivated by the need for real data from one or many sensors. Temporal accuracy of data in such datasets is crucially important since the events have high temporal resolution measured in microseconds and, during an algorithm evaluation task, such type of visual data is usually fused with data from other types of sensors. The main aim of our research is to achieve the most accurate possible time synchronization between an event camera, LIDAR, and ambient environment sensors during a session of data acquisition. All the mentioned sensors as well as a stereo and a monocular camera were installed on a mobile robotic platform. In this work, a time synchronization architecture and algorithm are proposed for time synchronization with an implementation example on a PIC32 microcontroller. The overall time synchronization approach is scalable for other sensors where there is a need for accurate time synchronization between many nodes. The evaluation results of the proposed solution are reported and discussed in the paper.

## Compliance and Impedance Control
- Hierarchical Impedance-Based Tracking Control of Kinematically Redundant Robots (I)

    Author: Dietrich, Alexander | German Aerospace Center (DLR)
    Author: Ott, Christian | German Aerospace Center (DLR)
 
    keyword: Compliance and Impedance Control; Redundant Robots; Force Control

    Abstract : The control of a robot in its task space is a standard approach nowadays. If the system is kinematically redundant with respect to this goal, one can even execute additional subtasks simultaneously. By utilizing null space projections, for example, the whole stack of tasks can be implemented within a strict task hierarchy following the order of priority. One of the most common methods to track multiple task-space trajectories at the same time is to feedback-linearize the system and dynamically decouple all involved subtasks, which finally yields exponential stability of the desired equilibrium. Here, we provide a hierarchical multi-objective controller for trajectory tracking that ensures both asymptotic stability of the equilibrium and a desired contact impedance at the same time. In contrast to the state of the art in prioritized multi-objective control, feedback of the external forces can be avoided and the natural inertia of the robot is preserved. The controller is evaluated in simulations and on a standard lightweight robot with torque interface. The approach is predestined for precise trajectory tracking where dedicated and robust physical-interaction compliance is crucial at the same time.

- Position-Based Impedance Control of a 2-DOF Compliant Manipulator for a Facade Cleaning Operation

    Author: Kim, Taegyun | Yeungnam University
    Author: Yoo, Sungkeun | Seoul National University
    Author: Kim, Hwa Soo | Kyonggi University
    Author: Seo, TaeWon | Hanyang University
 
    keyword: Compliance and Impedance Control; Force Control; Service Robots

    Abstract : This paper presents the design of a compliant manipulator using a series elastic actuator (SEA) and a mechanism for precisely measuring the force acting on the contact part of the manipulator without using a force sensor. It is important to maintain a constant contact force between the compliant manipulator and the wall in order to guarantee cleaning performance, and the ball screw mechanism is used to adapt to changes in the distance and the angle. Position-based impedance control is used to maintain a constant contact force when the manipulator interacts with the wall of the building, and the results confirm that the system stability is guaranteed when using SEA, regardless of the variation in the actual stiffness of the manipulator. The results of extensive experimentation using the test bench demonstrate the force tracking performance against various types of wall changes using the stiff wet-type cleaning manipulator. The results indicate that the stiffness of SEA affects the force tracking performance and system stability under the condition of the manipulator and environment interaction, and that the system stability and control performance can be improved by applying a robust force measurement mechanism to noise.

- Robust, Locally Guided Peg-In-Hole with Impedance-Controlled Robots

    Author: Nottensteiner, Korbinian | German Aerospace Center (DLR)
    Author: Stulp, Freek | DLR - Deutsches Zentrum F�r Luft Und Raumfahrt E.V
    Author: Albu-Sch�ffer, Alin | DLR - German Aerospace Center
 
    keyword: Compliant Assembly; Force and Tactile Sensing; Reactive and Sensor-Based Planning

    Abstract : We present an approach for the autonomous, robust execution of peg-in-hole assembly tasks. We build on a sampling-based state estimation framework, in which samples are weighted according to their consistency with the position and joint torque measurements. The key idea is to reuse these samples in a motion generation step, where they are assigned a second task-specific weight. The algorithm thereby guides the peg towards the goal along the configuration space. An advantage of the approach is that the user only needs to provide: the geometry of the objects as mesh data, as well as a rough estimate of the object poses in the workspace, and a desired goal state. Another advantage is that the local, online nature of our algorithm leads to robust behavior under uncertainty. The approach is validated in the case of our robotic setup and under varying uncertainties for the classical peg-in-hole problem subject to two different geometries.

- Model-Free Friction Observers for Flexible Joint Robots with Torque Measurements (I)

    Author: Kim, Min Jun | DLR
    Author: Beck, Fabian | German Aerospace Center (DLR)
    Author: Ott, Christian | German Aerospace Center (DLR)
    Author: Albu-Sch�ffer, Alin | DLR - German Aerospace Center
 
    keyword: Compliance and Impedance Control; Robust/Adaptive Control of Robotic Systems; Physical Human-Robot Interaction

    Abstract : This paper tackles a friction compensation problem without using a friction model. The unique feature of the proposed friction observer is that the nominal motor-side signal is fed back into the controller instead of the measured signal. By doing so, asymptotic stability and passivity of the controller are maintained. Another advantage of the proposed observer is that it provides a clear understanding for the stiction compensation which is hard to be captured in model-free approaches. This allows to design observers that do not overcompensate for the stiction. The proposed scheme is validated through simulations and experiments.

- Necessary and Sufficient Conditions for the Passivity of Impedance Rendering with Velocity-Sourced Series Elastic Actuation (I)

    Author: Tosun, Fatih Emre | Sabanci University
    Author: Patoglu, Volkan | Sabanci University
 
    keyword: Compliance and Impedance Control; Physical Human-Robot Interaction; Haptics and Haptic Interfaces

    Abstract : Series Elastic Actuation (SEA) has become prevalent in applications involving physical human-robot interaction as it provides considerable advantages over traditional stiff actuators in terms of stability robustness and force control fidelity. Several impedance control architectures have been proposed for SEA.<p>Among these alternatives, the cascaded controller with an inner- most velocity loop, an intermediate torque loop and an outer-most</p><p>impedance loop is particularly favoured for its simplicity, robust- ness, and performance. In this paper, we derive the necessary</p><p>and sufficient conditions for passively rendering null impedance and virtual springs with this cascade-controller architecture.</p><p>Based on the newly established conditions, we provide non- conservative passivity design guidelines to haptically display these</p><p>two impedance models, which serve as the basic building blocks of various virtual environments, while ensuring the safety of interaction. We also demonstrate the importance of including physical damping in the actuator model for deriving the passivity conditions, when integrators are utilized. In particular, we prove the unintuitive adversary effect of physical damping on the passivity of the system by noting that the damping term reduces the system Z-width as well as introducing an extra passivity constraint. Finally, we experimentally validate our theoretical results using a SEA brake pedal.

- Design of Spatial Admittance for Force-Guided Assembly of Polyhedral Parts in Single Point Frictional Contact

    Author: Huang, Shuguang | Marquette University
    Author: Schimmels, Joseph | Marquette University
 
    keyword: Compliant Assembly; Compliance and Impedance Control

    Abstract : This paper identifies conditions for designing the appropriate spatial admittance to achieve reliable force-guided assembly of polyhedral parts for cases in which a single frictional contact occurs between the two parts.	This work is an extension of previous work in which frictionless contact was considered. This paper presents a way to characterize friction without solving a set of complicated non-linear equations. We show that, by modifying the error reduction function and evaluating the function bounds associated with friction, the procedures developed for frictionless contact apply to the frictional cases. Thus, for bounded misalignments, if an admittance satisfies the misalignment-reducing conditions at a finite number of contact configurations, then the admittance will also satisfy the conditions at all intermediate configurations for any value of friction less than the specified upper bound.

- Model Predictive Impedance Control

    Author: Bednarczyk, Maciej | ICube Laboratory, University of Strasbourg, Strasbourg
    Author: Omran, Hassan | ICube Laboratory, University of Strasbourg, Strasbourg
    Author: Bayle, Bernard | University of Strasbourg
 
    keyword: Compliance and Impedance Control; Optimization and Optimal Control

    Abstract : Robots are more and more often designed in order to perform tasks in synergy with human operators. In this context, a current research focus for collaborative robotics lies in the design of high-performance control solutions, which ensure security in spite of unmodeled external forces. The present work provides a method based on Model Predictive Control (MPC) to allow compliant behavior when interacting with an environment, while respecting practical robotic constraints. The study shows in particular how to define the impedance control problem as a MPC problem. The approach is validated with an experimental setup including a collaborative robot. The obtained results emphasize the ability of this control strategy to solve constraints like speed, energy or jerk limits, which have a direct impact on the operator's security during human-robot compliant interactions.

- Kinematic Modeling and Compliance Modulation of Redundant Manipulators under Bracing Constraints

    Author: Johnston, Garrison | Vanderbilt University
    Author: Orekhov, Andrew | Vanderbilt University
    Author: Simaan, Nabil | Vanderbilt University
 
    keyword: Compliance and Impedance Control; Redundant Robots; Kinematics

    Abstract : Collaborative robots should ideally use low torque actuators for passive safety reasons. However, some applications require these collaborative robots to reach deep into confined spaces while assisting a human operator in physically demanding tasks. In this paper, we consider the use of in-situ collaborative robots (ISCRs) that balance the conflicting demands of passive safety dictating low torque actuation and the need to reach into deep confined spaces. We consider the judicious use of bracing as a possible solution to these conflicting demands and present a modeling framework that takes into account the constrained kinematics and the effect of bracing on the end-effector compliance. We then define a redundancy resolution framework that minimizes the directional compliance of the end-effector while maximizing end-effector dexterity. Kinematic simulation results show that the redundancy resolution strategy successfully decreases compliance and improves kinematic conditioning while satisfying the constraints imposed by the bracing task. Applications of this modeling framework can support future research on the choice of bracing locations and support the formation of an admittance control framework for collaborative control of ISCRs under bracing constraints. Such robots can benefit workers in the future by reducing the physiological burdens that contribute to musculoskeletal injury.

- Successive Stiffness Increment and Time Domain Passivity Approach for Stable High Bandwidth Control of Series Elastic Actuator

    Author: Lee, ChanIl | Korea Advanced Institute of Science and Technology
    Author: Kim, Do-Hyeong | KAIST
    Author: Singh, Harsimran | DLR German Aerospace Center
    Author: Ryu, Jee-Hwan | Korea Advanced Institute of Science and Technology
 
    keyword: Compliance and Impedance Control; Physical Human-Robot Interaction; Flexible Robots

    Abstract : For safe human-robot interaction, various type of flexible manipulators have been developed. Especially series elastic actuator (SEA) based manipulators have been getting huge attention since the elastic element of SEA prevents people from injury when undesirable collision happens. Moreover, it improves system durability by absorbing impact force, which could damage actuators. However, the elastic element inside SEA manipulator causes low system bandwidth which limits the speed performance of conventional impedance control approaches. To alleviate the low bandwidth issue of impedance controlled SEA while guaranteeing system stability, we implement Time Domain Passivity Approach (TDPA) and Successive Stiffness Increment (SSI) approach, which was invented in haptic and teleoperation domain. Impedance controlled SEA is reformulated as a two-port electrical circuit network for implementing TDPA. In addition, a pair of input and output power conjugate variable, dominating the system passivity is identified for implementing SSI approach. Experimental results showed that TDPA and SSI approach can render the stiffness of the impedance controller, which decides the bandwidth, upto 350 kN/m without any stability issue, while normal impedance controller only render upto 120 kN/m. Although both of the approaches significantly increased the bandwidth of the impedance controlled SEA, TDPA slightly outperformed in stability, and SSI outperformed in tracking.

- Arm-Hand Motion-Force Coordination for Physical Interactions with Non-Flat Surfaces Using Dynamical Systems: Toward Compliant Robotic Massage

    Author: Khoramshahi, Mahdi | EPFL
    Author: Henriks, Gustav | EPFL
    Author: Naef, Aileen | EPFL
    Author: Mirrazavi Salehian, Seyed Sina | EPFL
    Author: Kim, Joonyoung | Samsung Research
    Author: Billard, Aude | EPFL
 
    keyword: Compliance and Impedance Control; Reactive and Sensor-Based Planning; Manipulation Planning

    Abstract : Many manipulation tasks require coordinated motions for arm and fingers. Complexity increases when the task requires to control for the force at contact against a non-flat surface; This becomes even more challenging when this contact is done on a human. All these challenges are regrouped when one, for instance, massages a human limb. When massaging, the robotic arm is required to continuously adapt its orientation and distance to the limb while the robot fingers exert desired patterns of forces and motion on the skin surface. To address these challenges, we adopt a Dynamical System (DS) approach that offers a unified motion-force control approach and enables to easily coordinate multiple degrees of freedom. As each human limb may slightly differ, we learn a model of the surface using support vector regression (SVR) which enable us to obtain a distance-to-surface mapping. The gradient of this mapping, along with the DS, generates the desired motions for the interaction with the surface. A DS-based impedance control for the robotic fingers allows to control separately for force along the normal direction of the surface while moving in the tangential plane. We validate our approach using the KUKA IIWA robotic arm and Allegro robotic hand for massaging a mannequin arm covered with a skin-like material. Our results show the effectiveness of our approach; especially the robustness toward uncertainties for shape and the given location of the surface.

- A Control Scheme with a Novel DMP-Robot Coupling Achieving Compliance and Tracking Accuracy under Unknown Task Dynamics and Model Uncertainties

    Author: Vlachos, Konstantinos | Aristotle University of Thessaloniki
    Author: Doulgeri, Zoe | Aristotle University of Thessaloniki
 
    keyword: Compliance and Impedance Control; Motion Control

    Abstract : A control scheme consisting of a novel coupling of a DMP based virtual reference with a low stiffness controlled robot is proposed. The overall system is proved to achieve superior tracking of a DMP encoded trajectory and accurate target reaching with respect to the conventional scheme under the presence of constant and periodic disturbances owing to unknown task dynamics and robot model uncertainties. It further preserves the desired compliance under contact forces that may arise in human interventions and collisions. Results in simulations and experiments validate the theoretical findings.

- A Bio-Signal Enhanced Adaptive Impedance Controller for Lower Limb Exoskeleton

    Author: Xia, Linqing | Chinese Academy of Sciences
    Author: Feng, Yachun | Shenzhen Institutes of Advanced Technology, Chinese Academy of Sc
    Author: Chen, Fan | Shenzhen Institutes of Advanced Technology, Chinese Academy of S
    Author: Wu, Xinyu | CAS
 
    keyword: Compliance and Impedance Control; Wearable Robots; Robust/Adaptive Control of Robotic Systems

    Abstract : The problem of human-exoskeleton interaction with uncertain dynamical parameters remains an open-ended research area. It requires an elaborate control strategy design of the exoskeleton to accommodate complex and unpredictable human body movements. In this paper, we proposed a novel control approach for the lower limb exoskeleton to realize its task of assisting the human operator walking. The main challenge of this study was to determine the human lower extremity dynamics, such as the joint torque. For this purpose, we developed a neural network-based torque estimation method. It can predict the joint torques of humans with surface electromyogram signals (sEMG). Then an RBF neural network enhanced adaptive impedance controller is employed to ensure exoskeleton track desired motion trajectory of a human operator. Algorithm performance is evaluated with two healthy subjects and the rehabilitation lower-limb exoskeleton developed by Shenzhen Institutes of Advanced Technology (SIAT).

## Visual Learning
- Vid2Param: Modelling of Dynamics Parameters from Video

    Author: Asenov, Martin | The University of Edinburgh
    Author: Burke, Michael | University of Edinburgh
    Author: Angelov, Daniel | University of Edinburgh
    Author: Davchev, Todor Bozhinov | University of Edinburgh
    Author: Subr, Kartic | The University of Edinburgh
    Author: Ramamoorthy, Subramanian | The University of Edinburgh
 
    keyword: Visual Learning; Sensor-based Control; Motion and Path Planning

    Abstract : Videos provide a rich source of information, but it is generally hard to extract dynamical parameters of interest. Inferring those parameters from a video stream would be beneficial for physical reasoning. Robots performing tasks in dynamic environments would benefit greatly from understanding the underlying environment motion, in order to make future predictions and to synthesize effective control policies that use this inductive bias. Online physical reasoning is therefore a fundamental requirement for robust autonomous agents. When the dynamics involves multiple modes (due to contacts or interactions between objects) and sensing must proceed directly from a rich sensory stream such as video, then traditional methods for system identification may not be well suited. We propose an approach wherein fast parameter estimation can be achieved directly from video. We integrate a physically based dynamics model with a recurrent variational autoencoder, by introducing an additional loss to enforce desired constraints. The model, which we call Vid2Param, can be trained entirely in simulation, in an end-to-end manner with domain randomization, to perform online system identification, and make probabilistic forward predictions of parameters of interest. This enables the resulting model to encode parameters such as position, velocity, restitution, air drag and other physical properties of the system.

- Safe Robot Navigation Via Multi-Modal Anomaly Detection

    Author: Wellhausen, Lorenz | ETH Zurich
    Author: Ranftl, Rene | Intel
    Author: Hutter, Marco | ETH Zurich
 
    keyword: Visual Learning; Visual-Based Navigation; Deep Learning in Robotics and Automation

    Abstract : Navigation in natural outdoor environments requires a robust and reliable traversability classification method to handle the plethora of situations a robot can encounter. Binary classification algorithms perform well in their native domain but tend to provide overconfident predictions when presented with out-of-distribution samples, which can lead to catastrophic failure when navigating unknown environments. We propose to overcome this issue by using anomaly detection on multi-modal images for traversability classification, which is easily scalable by training in a self-supervised fashion from robot experience. In this work, we evaluate multiple anomaly detection methods with a combination of uni- and multi-modal images in their performance on data from different environmental conditions. Our results show that an approach using a feature extractor and normalizing flow with an input of RGB, depth and surface normals performs best. It achieves over 95% area under the ROC curve and is robust to out-of-distribution samples.

- MAVRIC: Morphology-Agnostic Visual Robotic Control

    Author: Yang, Brian | University of California, Berkeley
    Author: Jayaraman, Dinesh | Facebook AI Research and University of Pennsylvania
    Author: Berseth, Glen | University of British Columbia
    Author: Efros, Alexei A. | Carnegie Mellon University
    Author: Levine, Sergey | UC Berkeley
 
    keyword: Visual Learning; Visual Tracking; Visual Servoing

    Abstract : Existing approaches for visuomotor robotic control typically require characterizing the robot in advance by calibrating the camera or performing system identification. We propose MAVRIC, an approach that works with minimal prior knowledge of the robot's morphology, and requires only a camera view containing the robot and its environment and an unknown control interface. MAVRIC revolves around a mutual information-based method for self-recognition, which discovers visual "control points" on the robot body within a few seconds of exploratory interaction, and these control points in turn are then used for visual servoing. MAVRIC can control robots with imprecise actuation, no proprioceptive feedback, unknown morphologies including novel tools, unknown camera poses, and even unsteady handheld cameras. We demonstrate our method on visually-guided 3D point reaching, trajectory following, and robot-to-robot imitation. Project website: https://bit.ly/386j2fi.

- MFuseNet: Robust Depth Estimation with Learned Multiscopic Fusion

    Author: Yuan, Weihao | Hong Kong University of Science and Technology
    Author: Fan, Rui | The Hong Kong University of Science and Technology
    Author: Wang, Michael Yu | Hong Kong University of Science &amp; Technology
    Author: Chen, Qifeng | HKUST
 
    keyword: Visual Learning; Deep Learning in Robotics and Automation; Computer Vision for Automation

    Abstract : We design a multiscopic vision system that utilizes a low-cost monocular RGB camera to acquire accurate depth estimation. Unlike multi-view stereo with images captured at unconstrained camera poses, the proposed system controls the motion of a camera to capture a sequence of images in horizontally or vertically aligned positions with the same parallax. In this system, we propose a new heuristic method and a robust learning-based method to fuse multiple cost volumes between the reference image and its surrounding images. To obtain training data, we build a synthetic dataset with multiscopic images. The experiments on the real-world Middlebury dataset and real robot demonstration show that our multiscopic vision system outperforms traditional two-frame stereo matching methods in depth estimation. Our code and dataset are available at https://sites.google.com/view/multiscopic.

- Deceiving Image-To-Image Translation Networks for Autonomous Driving with Adversarial Perturbations

    Author: Wang, Lin | KAIST
    Author: Cho, Wonjune | KAIST
    Author: Yoon, Kuk-Jin | KAIST
 
    keyword: Visual Learning; Computer Vision for Automation; Deep Learning in Robotics and Automation

    Abstract : Deep neural networks (DNNs) have achieved impressive performance on handling computer vision problems, however, it has been found that DNNs are vulnerable to adversarial examples. For such reason, adversarial perturbations have been recently studied in several respects. However, most previous works have focused on image classification tasks, and it has never been studied regarding adversarial perturbations on Image-to-image (Im2Im) translation tasks, showing great success in handling paired and/or unpaired mapping problems in the field of autonomous driving and robotics. This paper examines different types of adversarial perturbations that can fool Im2Im frameworks for autonomous driving purposes. We propose both quasi-physical and digital adversarial perturbations that can make Im2Im models yield unexpected results. We then empirically analyze these perturbations and show that they generalize well under both paired for image synthesis and unpaired settings for style transfer. We also validate that there exist some perturbation thresholds over which the Im2Im mapping is disrupted or impossible. The existence of these perturbations reveals that there exist crucial weaknesses in Im2Im models. Lastly, we show that our methods illustrate how perturbations affect the quality of outputs, pioneering the improvement of the robustness of current SOTA networks for autonomous driving.

- Self-Supervised Learning of State Estimation for Manipulating Deformable Linear Objects

    Author: Yan, Mengyuan | Stanford University
    Author: Zhu, Yilin | Stanford University
    Author: Jin, Ning | Stanford University
    Author: Bohg, Jeannette | Stanford University
 
    keyword: Visual Learning; Deep Learning in Robotics and Automation; Perception for Grasping and Manipulation

    Abstract : We demonstrate model-based, visual robot manipulation of linear deformable objects. Our approach is based on a state-space representation of the physical system. This choice has multiple advantages, including the ease of incorporating physics priors in the dynamics model and perception model, and the ease of planning manipulation actions. In addition, physical states can naturally represent object instances of different appearances. Therefore, dynamics in the state space generalizes across visually different settings, in contrast to dynamics learned in pixel space or latent space, where such generalization is not guaranteed. Challenges in taking the state-space approach are the estimation of the high-dimensional state of a deformable object from raw images, where annotations are very expensive on real data, and finding a dynamics model that is both accurate, generalizable, and efficient to compute. We are the first to demonstrate self-supervised training of rope state estimation on real images. We propose a novel self-supervising learning objective, which is generalizable across a wide range of visual appearances. With estimated rope states, we train a fast and differentiable neural network dynamics model that encodes the physics of mass-spring systems. Our method has a higher accuracy in predicting future states compared to models in pixel space, while only using 3% of training data. Our approach also achieves more efficient manipulation, both in simulation and on real robot

- Self-Supervised Correspondence in Visuomotor Policy Learning

    Author: Florence, Peter | MIT
    Author: Manuelli, Lucas | Massachusetts Institute of Technology
    Author: Tedrake, Russ | Massachusetts Institute of Technology
 
    keyword: Visual Learning; Perception for Grasping and Manipulation; Deep Learning in Robotics and Automation

    Abstract : In this paper we explore using self-supervised correspondence for improving the generalization performance and sample efficiency of visuomotor policy learning. Prior work has primarily used approaches such as autoencoding, pose-based losses, and end-to-end policy optimization in order to train the visual portion of visuomotor policies. We instead propose an approach using self-supervised dense visual correspondence training, and show this enables visuomotor policy learning with surprisingly high generalization performance with modest amounts of data: using imitation learning, we demonstrate extensive hardware validation on challenging manipulation tasks with as few as 50 demonstrations. Our learned policies can generalize across classes of objects, react to deformable object configurations, and manipulate textureless symmetrical objects in a variety of backgrounds, all with closed-loop, real-time vision-based policies. Simulated imitation learning experiments suggest that correspondence training offers sample complexity and generalization benefits compared to autoencoding and end-to-end training.

- Differentiable Mapping Networks: Learning Structured Map Representations for Sparse Visual Localization

    Author: Karkus, Peter | National University of Singapore
    Author: Angelova, Anelia | Google Research
    Author: Vanhoucke, Vincent | Google Research
    Author: Jonschkowski, Rico | Google
 
    keyword: Visual Learning; Deep Learning in Robotics and Automation

    Abstract : Mapping and localization, preferably from a small number of observations, are fundamental tasks in robotics. We address these tasks by combining spatial structure (differentiable mapping) and end-to-end learning in a novel neural network architecture: the Differentiable Mapping Network (DMN). The DMN constructs a spatially structured view-embedding map and uses it for subsequent visual localization with a particle filter. Since the DMN architecture is end-to-end differentiable, we can jointly learn the map representation and localization using gradient descent. We apply the DMN to sparse visual localization, where a robot needs to localize in a new environment with respect to a small number of images from known viewpoints. We evaluate the DMN using simulated environments and a challenging real-world Street View dataset. We find that the DMN learns effective map representations for visual localization. The benefit of spatial structure increases with larger environments, more viewpoints for mapping, and when training data is scarce. Project website: https://sites.google.com/view/differentiable-mapping.

- Attentive Task-Net: Self Supervised Task-Attention Network for Imitation Learning Using Video Demonstration

    Author: Ramachandruni, Kartik | TCS Innovation Labs
    Author: Vankadari, Madhu Babu | TCS
    Author: Majumder, Anima | Tata Consultancy Services
    Author: Dutta, Samrat | TCS Research and Innovation
    Author: Swagat, Kumar | Tata Consultancy Services
 
    keyword: Visual Learning; Learning and Adaptive Systems; Deep Learning in Robotics and Automation

    Abstract : This paper proposes an end-to-end self-supervised feature representation network named Attentive Task-Net or AT-Net for video-based task imitation. The proposed AT-Net incorporates a novel multi-level spatial attention module to highlight spatial features corresponding to the intended task demonstrated by the expert. The neural connections in AT-Net ensure the relevant information in the demonstration is amplified and the irrelevant information is suppressed while learning task-specific feature embeddings. This is achieved by a weighted combination of multiple intermediate feature maps of the input image at different stages of the CNN pipeline. The weights of the combination are given by the compatibility scores, predicted by the attention module for respective feature maps. The AT-Net is trained using a metric learning loss which aims to decrease the distance between the feature representations of concurrent frames from multiple view points and increase the distance between temporally consecutive frames. The AT-Net features are then used to formulate a reinforcement learning problem for task imitation. Through experiments on the publicly available Multi-view pouring dataset, it is demonstrated that the output of the attention module highlights the task-specific objects while suppressing the rest of the background. The efficacy of the proposed method is further validated by qualitative and quantitative comparison with a state-of-the-art technique along with ablations.

- OpenLORIS-Object: A Robotic Vision Dataset and Benchmark for Lifelong Deep Learning

    Author: She, Qi | Intel Labs
    Author: Feng, Fan | City University of Hong Kong
    Author: Hao, Xinyue | Beijing University of Posts and Telecommunications
    Author: Yang, Qihan | City University of Hong Kong
    Author: Lan, Chuanlin | Wuhan University
    Author: Lomonaco, Vincenzo | University of Bologna
    Author: Shi, Xuesong | Intel
    Author: Wang, Zhengwei | Dublin City University
    Author: Guo, Yao | Imperial College London
    Author: Zhang, Yimin | Intel Corporation
    Author: Qiao, Fei | Tsinghua University
    Author: Chan, Rosa H. M. | City University of Hong Kong
 
    keyword: Visual Learning; Learning and Adaptive Systems; RGB-D Perception

    Abstract : The recent breakthroughs in computer vision have benefited from the availability of large representative datasets (e.g. ImageNet and COCO) for training. Yet, robotic vision poses unique challenges for applying visual algorithms developed from these standard computer vision datasets due to their implicit assumption over non-varying distributions for a fixed set of tasks. Fully retraining models each time a new task becomes available is infeasible due to computational, storage and sometimes privacy issues, while naive incremental strategies have been shown to suffer from catastrophic forgetting. It is crucial for the robots to operate continuously under open-set and detrimental conditions with adaptive visual perceptual systems, where lifelong learning is a fundamental capability. However, very few datasets and benchmarks are available to evaluate and compare emerging techniques. To fill this gap, we provide a new lifelong robotic vision dataset (�OpenLORIS-Object�). The dataset embeds the challenges faced by a robot in the real-life application and provides new benchmarks for validating lifelong object recognition algorithms. Moreover, we have provided a testbed of 9 state-of-the-art lifelong learning algorithms. Each of them involves 48 tasks with 4 evaluation metrics over the OpenLORIS-Object dataset. The results demonstrate that the object recognition task in the ever-changing difficulty environments is not solved.

- Unsupervised Depth Completion from Visual Inertial Odometry

    Author: Wong, Alex | University of California Los Angeles
    Author: Fei, Xiaohan | University of California, Los Angeles
    Author: Tsuei, Stephanie | University of California, Los Angeles
    Author: Soatto, Stefano | University of California, Los Angeles
 
    keyword: Visual Learning; Sensor Fusion

    Abstract : We describe a method to infer dense depth from camera motion and sparse depth as estimated using a visual-inertial odometry system. Unlike other scenarios using point clouds from lidar or structured light sensors, we only have a few hundred to a few thousand points, insufficient to inform the topology of the scene. Counter to current trends of end-to-end learning, our method first constructs a piecewise planar scaffolding of the scene, and then uses it to infer dense depth using the image along with the sparse points. We use a predictive cross-modal criterion, akin to ``self-supervision,'' measuring photometric consistency across time, forward-backward pose consistency, and geometric compatibility with the sparse point cloud. We also present the first visual-inertial + depth dataset, which we hope will foster additional exploration into combining the complementary strengths of visual and inertial sensors. To compare our method to prior work, we adopt the unsupervised KITTI depth completion benchmark, where we achieve state-of-the-art performance with significantly fewer parameters.

- Geometric Pretraining for Monocular Depth Estimation

    Author: Wang, Kaixuan | Hong Kong University of Science and Technology
    Author: Chen, Yao | ByteDance Inc
    Author: Guo, Hengkai | ByteDance AI Lab
    Author: Wen, Linfu | ByteDance AI Lab
    Author: Shen, Shaojie | Hong Kong University of Science and Technology
 
    keyword: Visual Learning; Learning and Adaptive Systems; Deep Learning in Robotics and Automation

    Abstract : ImageNet-pretrained networks have been widely used in transfer learning for monocular depth estimation. These pretrained networks are trained with classification losses that only semantic information is exploited while spatial information is ignored. However, both semantic and spatial information is important for per-pixel depth estimation. In this paper, we design a novel self-supervised geometric pretraining task that is tailored for monocular depth estimation using uncalibrated videos. The designed task decouples the structure information from input videos by a simple yet effective conditional autoencoder-decoder structure. Using almost unlimited videos from the internet, networks are pretrained to capture a variety of structures of the scene and can be easily transferred to depth estimation tasks using calibrated images. Extensive experiments are used to demonstrate that the proposed geometric-pretrained networks perform better than ImageNet-pretrained networks in terms of accuracy, few-shot learning and generalization ability. With the same learning method, geometric-transferred networks achieve new state-of-the-art results by a large margin. Pretrained networks will be open source soon.

## Soft Sensors and Actuators

- Active Acoustic Contact Sensing for Soft Pneumatic Actuators

    Author: Zöller, Gabriel Donald | TU Berlin
    Author: Wall, Vincent | TU Berlin
    Author: Brock, Oliver | Technische Universitét Berlin
 
    keyword: Soft Sensors and Actuators; Force and Tactile Sensing

    Abstract : We present an active acoustic sensor that turns soft pneumatic actuators into contact sensors. The whole surface of the actuator becomes a sensor, rendering the question of where best to place a contact sensor unnecessary. At the same time, the compliance of the soft actuator remains unaffected. A small, embedded speaker emits a frequency sweep which travels through the actuator before it is recorded with an embedded microphone. The specific contact state of the actuator affects how the sound is modulated while traversing the structure. We learn to recognize these changes in the sound and map them to the corresponding contact locations. We demonstrate the method on the PneuFlex actuator. The active acoustic sensor achieves a classification rate of 93% and mean regression error of 3.7mm. It is robust against background noises and different objects. Finally, we test it on a Panda robot arm and show that it is unaffected by motor noises and other active sensors.

- PneuAct-II: Hybrid Manufactured Electromagnetically Stealth Pneumatic Stepper Actuator

    Author: Sojoodi Farimani, Foad | University of Twente
    Author: Mojarradi, Morteza | University of Twente
    Author: Hekman, Edsko E.G. | University of Twente
    Author: Misra, Sarthak | University of Twente
 
    keyword: Additive Manufacturing; Medical Robots and Systems; Hydraulic/Pneumatic Actuators

    Abstract : Additive manufacturing (AM) is one of the emerging production methodologies transforming the industrial landscape. However, application of the technology in fluidic power transmission and actuation is still limited. AM pneumatic stepper motors have been previously introduced to the field of image-guided surgical robotics, where their disposability and customizability are considered a significant advantage over conventional manufacturing. However, intrinsic dimensional limitations of AM parts and their poor surface quality affect mechanical performance. In this study, a novel design, PneuAct-II, is presented combining AM, subtractive machining, and off-the-shelf components to achieve higher mechanical performance and resolution. Moreover, a motor identification setup has been built to automatically measure different aspects of the PneuAct motors, including wear, friction, leakage, and stall behavior at various boundary conditions. The effects of input pressure, stepping frequency, signal-width, and external torque on the stall behavior of motors with different clearances are studied. A maximum torque of 0.39N.m at an input pressure of 6.5bar is achieved for a motor with a total volume of 90cm3, and a clearance of 156&#120583;m. A nominal resolution of 2.25� at full-pitch and 1.125� at half-pitch is accomplished. Both resolution and mechanical performance (667 N.m/bar.m3) outperform the state-of-the-art.

- A Bidirectional 3D-Printed Soft Pneumatic Actuator and Graphite-Based Flex Sensor for Versatile Grasping

    Author: Low, Jin Huat | National University of Singapore
    Author: Goh, Jing Yuan Aaron | National University of Singapore
    Author: Cheng, Nicholas | National University of Singapore
    Author: Khin, Phone May | National University of Singapore
    Author: Han, Qian Qian | National University of Singapore
    Author: Yeow, Chen-Hua | National University of Singapore
 
    keyword: Soft Robot Applications; Grippers and Other End-Effectors; Soft Sensors and Actuators

    Abstract : THIS paper presents a bidirectional 3D-printed soft pneumatic actuator that is capable of inward and outward bending. A direct 3D-printing approach is adopted to fabricate the actuator, which reduces fabrication complexity and allows for easy customization of actuator dimensions for various applications. To illustrate the applicability of the bidirectional actuators, four of these actuators were incorporated into a gripper system. A suite of various functional grasping tasks, such as packaging, assembly, and alignment tasks, were successfully conducted. It was observed that the unique bidirectional bending characteristic of the actuator allows the gripper to grasp objects with sizes up to 245% larger than its default grasping width. To complement the gripper system, a graphite-based flex sensor that is able to sense bending in two directions is developed to control the bidirectional actuators. A preliminary test was conducted successfully where the user controlled the gripper system to grasp, hold, and release an object using a glove with the sensors.

- A Proprioceptive Bellows (PB) Actuator with Position Feedback and Force Estimation

    Author: Zhou, Jianshu | The Univerisity of Hong Kong
    Author: Chen, Yonghua | The University of Hong Kong
    Author: Chen, Xiaojiao | The University of Hong Kong
    Author: Wang, Zheng | The University of Hong Kong
    Author: Li, Yunquan | The University of Hong Kong
    Author: Liu, Yunhui | Chinese University of Hong Kong
 
    keyword: Soft Robot Applications; Soft Sensors and Actuators; Perception for Grasping and Manipulation

    Abstract : Soft robot is known for great safety in human-centered environments due to its inherent compliance. However, the compliance resulting from the soft continuum structure and viscoelastic material also induces challenges for sensing and control of soft robots. In this paper, we propose a proprioceptive soft actuator design approach based on 3D printed conductive material and 3D printed deformable structure, such as bellows. The conductive bellow exhibits effective resistance change and structural deformation, thus provides a promising solution for the challenge of deformable soft robots that need integrated actuation and sensing. The proposed proprioceptive bellow actuator (PB actuator) achieves effective position feedback and real-time output force estimation. Using a dedicated control logic of the pressure controller, the PB actuator can not only provide anticipated motion but also estimate the interactive force based on real-time position sensing and input pressure. The design, fabrication, modeling, control, and experimental validation of our proposed PB actuator are discussed in detail in this paper. The parameters of PB actuator are highly customizable depending on the intended applications. Based on the proposed PB actuator, two specialized grippers, T and Y gripper, are designed and prototyped to demonstrate the grasping force estimation capability. The proposed proprioceptive soft robotic approach provides a promising solution to design behavior steerable soft robots.

-  Automatic Design of Soft Dielectric Elastomer Actuators with Optimal Spatial Electric Fields (I)

    Author: Chen, Feifei | Shanghai Jiao Tong University
    Author: Liu, Kun | shanghai jiaotong university
    Author: Wang, Yiqiang | Technical University of Denmark
    Author: Zou, Jiang | Shanghai Jiao Tong University
    Author: Gu, Guoying | Shanghai Jiao Tong University
    Author: Zhu, Xiangyang | Shanghai Jiao Tong University

- Stochastic Control for Orientation and Transportation of Microscopic Objects Using Multiple Optically Driven Robotic Fingertips (I)

    Author: Ta, Quang Minh | Nanyang Technological University
    Author: Cheah, C. C. | Nanyang Technological University
 
    keyword: Robust/Adaptive Control of Robotic Systems; Dexterous Manipulation; Automation at Micro-Nano Scales

    Abstract : The effect of Brownian motion on maneuvering of micro-objects in a fluid medium is one of the fundamental differences between micro-manipulation and robotic manipulators in the physical world. Besides, due to the limitation of feasible sensors and actuators in micro-manipulation, current control techniques for manipulation of micro-objects or cells are mostly dependent on the physical properties of target micro-objects or cells. In this paper, we propose the first stochastic control technique to achieve simultaneous orientation and transportation of micro-objects with Brownian perturbations. Several micro-particles which are optically trapped and driven by laser beams are utilized as fingertips to first grasp a target micro-object. Cooperative control of robot-assisted stage and the fingertips is then performed to achieve the control objective, in which the target micro-object is transported toward a desired position by using the robot-assisted stage, and at the same time, it is oriented toward a desired angular position by using the fingertips. This paper provides a stochastic control framework for simultaneous orientation and transportation of micro- objects with arbitrary types in the micro-world, and thus bringing micro-manipulation using optical tweezers closer to robotic manipulation in the physical world.

- Soft Fingertips with Adaptive Sensing and Active Deformation for Robust Grasping of Delicate Objects

    Author: He, Liang | Imperial College London
    Author: Lu, Qiujie | Imperial College London
    Author: Abad Guaman, Sara Adela | Imperial College London
    Author: Rojas, Nicolas | Imperial College London
    Author: Nanayakkara, Thrishantha | Imperial College London
 
    keyword: Soft Sensors and Actuators; Grasping; Grippers and Other End-Effectors

    Abstract : Soft fingertips have shown significant adaptability for grasping a wide range of object shapes thanks to elasticity. This ability can be enhanced to grasp soft, delicate objects by adding touch sensing. However, in these cases, the complete restraint and robustness of the grasps have proved to be challenging, as the exertion of additional forces on the fragile object can result in damage. This paper presents a novel soft fingertip design for delicate objects based on the concept of embedded air cavities, which allow the dual ability of tactile sensing and active shape-changing. The pressurized air cavities act as soft tactile sensors to control gripper position from internal pressure variation; and active fingertip deformation is achieved by applying positive pressure to these cavities, which then enable a delicate object to be kept securely in position, despite externally applied forces, by form closure. We demonstrate this improved grasping capability by comparing the displacement of grasped delicate objects exposed to high-speed motions. Results show that passive soft fingertips fail to restrain fragile objects at accelerations as low as 0.1 m/s^2, in contrast, with the proposed fingertips delicate objects are completely secure even at accelerations of more than 5 m/s^2.

- Sensorization of a Continuum Body Gripper for High Force and Delicate Object Grasping

    Author: Hughes, Josie | MIT
    Author: Li, Shuguang | MIT/Harvard University
    Author: Rus, Daniela | MIT
 
    keyword: Soft Sensors and Actuators; Grasping; Perception for Grasping and Manipulation

    Abstract : The goal of achieving `universal grasping' where many objects can be handled with minimal control input is the focus of much research due to potential high impact applications ranging from grocery packing to recycling. However, many of the grippers developed suffer from limited sensing capabilities which can prevent handing of both heavy bulky items and also lightweight delicate objects which require fine control when grasping. Sensorizing such grippers is often challenging due to the highly deformable surfaces. We propose a novel sensing approach which uses highly flexible latex bladders. By measuring changes in the air pressure of the bladders, normal force and longitudinal strain can be measured. These sensors have been integrated into a 'Magic Ball' origami gripper to provide both tactile and proprioceptive sensing. The sensors show reasonable sensitivity and repeatability, are durable and low-cost, and can be easily integrated into the gripper without affecting performance. When the sensors are used for classification, they enabled identification of 10 objects with over 90% accuracy, and also allow failure to be detected through slippage detection. A control algorithm has been developed which uses the sensor feedback to extend the capabilities of the gripper to include both delicate and strong grasping. It is shown that this closed loop controller enables delicate grasping of potato chips; 80% of those tested were grasped without damage.

- Eye-In-Hand Visual Servoing Enhanced with Sparse Strain Measurement for Soft Continuum Robots

    Author: Wang, Xiaomei | The University of Hong Kong
    Author: Fang, Ge | The University of Hong Kong
    Author: Wang, Kui | The University of Hong Kong
    Author: Xie, Xiaochen | The University of Hong Kong
    Author: Lee, Kit-Hang | The University of Hong Kong
    Author: Ho, Justin Di-Lang | The University of Hong Kong
    Author: Tang, Wai Lun | The University of Hong Kong
    Author: Lam, James | University of Hong Kong
    Author: Kwok, Ka-Wai | The University of Hong Kong
 
    keyword: Soft Sensors and Actuators; Modeling, Control, and Learning for Soft Robots; Visual Servoing

    Abstract : In the feature/object tracking of eye-in-hand visual servoing, 2D motion estimation relying only on image plane feedback is easily affected by vision occlusion, blurring, or poor lighting. For the commonly-used template matching method, tracking performance greatly depends on the image quality. Fiber Bragg gratings (FBGs), a type of high-frequency flexible strain sensors, can be used as an assistant device for soft robot control. We propose a method to enhance motion estimation in soft robotic visual servoing by fusing the results from template matching and FBG wavelength shift to achieve more accurate tracking in applications such as minimally invasive surgery. Path following performance is validated in a simulated laparoscopic scene and LEGO�-constructed scene, demonstrating significant improvement to feature tracking and robot motion, even under external forces.

- A Soft Gripper with Retractable Nails for Advanced Grasping and Manipulation

    Author: Jain, Snehal | SUTD
    Author: Stalin, Thileepan | Singapore University of Technology and Design
    Author: Subramaniam, Vignesh | University of Florida
    Author: Agarwal, Jai | Birla Institute of Technology and Science, Pilani
    Author: Valdivia y Alvarado, Pablo | Singapore University of Technology and Design, MIT
 
    keyword: Grasping; Grippers and Other End-Effectors; Soft Robot Materials and Design

    Abstract : This study describes the enhancement of a vacuum actuated soft gripper's grasping capabilities using retractable finger nails and an active re-configurable palm. The finger nail mechanism is pneumatically actuated and enables the gripper to perform complex grasping and manipulation tasks with high repeatability. The retracted nails can exert normal grasping forces of up to 1.8N and enable grasping of objects up to 200 microns thick from flat surfaces, while allowing the gripper to execute delicate pinch grasps. A wide array of robotic grasping tasks that were not possible without nails are also described.

- A Sensorized Hybrid Gripper to Evaluate a Grasping Quality Based on a Largest Minimum Wrench

    Author: Park, Wookeun | UNIST
    Author: Seo, Seongmin | UNIST
    Author: Oh, Jinhyeok | UNIST
    Author: Bae, Joonbum | UNIST
 
    keyword: Soft Sensors and Actuators; Grasping; Soft Robot Applications

    Abstract : Soft pneumatic grippers, which are based on soft pneumatic actuators have been widely studied owing to their simple morphological structure, inherent compliance, and pliable grasp. Additionally, the integration of the soft gripper with various sensors to improve its functionality has also been extensively studied. Although the soft gripper is known to exhibit a robust grasping performance without accurate control, the grasping quality of the soft gripper has rarely been studied due to the lack of adequate embedded sensors and quality metrics of the soft gripper. Therefore, a hybrid gripper, which is a soft gripper with rigid components, was sensorized by embedding a soft force sensor and a bending sensor to evaluate the grasping quality. Furthermore, a new grasping quality metric for a soft gripper was proposed, which calculates the largest minimum wrench of a convex hull in the wrench space. The proposed grasping quality metric was experimentally verified, and a real-time program was developed to evaluate the grasping quality.

- A Soft Pressure Sensor Skin for Hand and Wrist Orthoses

    Author: Tan, Xinyang | Imperial College London
    Author: He, Liang | Imperial College London
    Author: Cao, Jiangang | Xuzhou Central Hospital
    Author: Chen, Wei | Xuzhou Central Hospital
    Author: Nanayakkara, Thrishantha | Imperial College London
 
    keyword: Soft Sensors and Actuators; Force and Tactile Sensing; Human Factors and Human-in-the-Loop

    Abstract : Side effects caused by excessive contact pressure such as discomfort and pressure sores are commonly complained by patients wearing orthoses. These problems leading to low patient compliance decrease the effectiveness of the device. To mitigate side effects, this study describes the design and fabrication of a soft sensor skin with strategically placed 12 sensor units for static contact pressure measurement beneath a hand and wrist orthosis. A Finite Element Model was built to simulate the pressure on the hand of a subject and sensor specifications were obtained from the result to guide the design. By testing the fabricated soft sensor skin on the subject, contact pressure between 0.012 MPa and 0.046 MPa was detected, revealing the maximum pressure at the thumb metacarpophalangeal joint which was the same location of the highest pressure of simulation. In this paper, a new fabrication method combining etching and multi-material additive manufacture was introduced to produce multiple sensor units as a whole. Furthermore, a novel fish-scale structure as the connection among sensors was introduced to stabilize sensor units and reinforce the soft skin. Experimental analysis reported that the sensor signal is repeatable, and the fish-scale structure facilitates baseline resuming of sensor signal during relaxation.

- Characterisation of Self-Locking High-Contraction Electro-Ribbon Actuators

    Author: Taghavi, Majid | University of Bristol
    Author: Helps, Tim | University of Bristol
    Author: Rossiter, Jonathan | University of Bristol
 
    keyword: Soft Sensors and Actuators; Soft Robot Applications; Compliant Joint/Mechanism

    Abstract : Actuators are essential devices that exert force and do work. The contraction of an actuator (how much it can shorten) is an important property that strongly influences its applications, especially in engineering and robotics. While high contractions have been achieved by thermally- or fluidically-driven technologies, electrically-driven actuators typically cannot contract by more than 50%. Recently developed electro-ribbon actuators are simple, low cost, scalable electroactive devices powered by dielectrophoretic liquid zipping (DLZ) that exhibit high efficiency (~70%), high power equivalent to mammalian muscle (~100 W/kg), contractions exceeding 99%. We characterise the electro-ribbon actuator and explore contraction variation with voltage and load. We describe the unique self-locking behaviour of the electro-ribbon actuator which could allow for low-power-consumption solenoids and valves. Finally, we show the interdependence of constituent material properties and the important role that material choice plays in maximising performance.

- Helically Wrapped Supercoiled Polymer (HW-SCP) Artificial Muscles: Design, Characterization, and Modeling

    Author: Tsabedze, Thulani | University of Nevada, Reno
    Author: Mullen, Christopher | University of Nevada Reno
    Author: Coulter, Ryan | University of Nevada Reno
    Author: Wade, Scott | Boston University
    Author: Zhang, Jun | University of Nevada Reno
 
    keyword: Soft Sensors and Actuators; Biomimetics; Compliant Joint/Mechanism

    Abstract : Supercoiled polymer (SCP) artificial muscles exhibit many desirable properties such as large contractions and high power density. However, their full potential as robotic muscles is challenged by insufficient strain or force generation -- non-mandrel-coiled SCP actuators produce up to 10-20% strain; mandrel-coiled SCP actuators often lift up to 10-30g of weight. It is strongly desired but difficult to obtain SCP actuators that produce large strain and large force. In this paper, the design, characterization, and modeling of helically wrapped SCP (HW-SCP) actuators are presented, which can produce up to 40-60% strain and lift more than 90g of weight. By adjusting their configuration parameters, their strain and force performance can be changed. Experiments are conducted to characterize the force production, strain, and speed of HW-SCP actuators. A Preisach hysteresis model and a polynomial model are adopted to accurately capture the actuator behaviors. This work contributes to the field of high-performance artificial muscles.

- A Variable Stiffness Soft Continuum Robot Based on Pre-Charged Air, Particle Jamming, and Origami

    Author: Li, Yujia | Southwest Petroleum University
    Author: Ren, Tao | Xihua University
    Author: Chen, Yonghua | The University of Hong Kong
    Author: Chen, Michael Z. Q. | Nanjing University of Science and Technology
 
    keyword: Soft Sensors and Actuators; Soft Robot Applications; Grippers and Other End-Effectors

    Abstract : Soft continuum robots have many applications such as medical surgeries, service industries, rescue tasks, and underwater exploration. Flexibility and good accessibility of such robots are the key reasons for their popularity. However, the complexity of their structural design and control systems limit their broader applications. In this paper, a novel variable stiffness soft continuum robot based on pre-charged air, particle jamming, and origami is proposed. The robot is a bellow-like origami structure with internal chambers. A spine-like chamber is filled with particles, and three identical chambers surrounding the spine chamber are filled with pressurized air. When the origami structure is compressed, the particles are jammed by the compression force and the increased pressure of the three air chambers, thus increasing the overall stiffness of the robot. The robot expansion-contraction and bending are controlled by three tendons. An analytical model of the proposed stiffness variation mechanism has been developed. The effects of various parameters on the lateral and axial stiffness of the soft continuum robot have been investigated by experimental studies. A prototype robot has been fabricated to demonstrate grasping operations.

- A Pneumatic/Cable-Driven Hybrid Linear Actuator with Combined Structure of Origami Chambers and Deployable Mechanism

    Author: Zhang, Zhuang | Shanghai Jiao Tong University
    Author: Chen, Genliang | Shanghai Jiao Tong University
    Author: Wu, Haiyu | Shanghai Jiao Tong University
    Author: Kong, Lingyu | Zhejiang Lab
    Author: Wang, Hao | Shanghai Jiao Tong University
 
    keyword: Soft Sensors and Actuators; Mechanism Design; Soft Robot Materials and Design

    Abstract : Pneumatic actuators have been widely used in robotics due to their inherent compliance and relatively high strength. In this letter, the     Authors report on the design, analysis and experimental validation of a novel pneumatic/cable-driven hybrid linear actuator whose structure is a combination of origami chambers and passive deployable mechanism. Under the joint actuation of the cable and compressed air, the proposed actuator can generate bidirectional motion; meanwhile, both thrust and tensile force can be produced. The combined structure of the rigid deployable mechanism and the axially soft origami chambers possesses high radial stiffness and an extension ratio up to 200% without radial expansion. The position can be controlled at whole motion range through a simple strategy and the actuation pressure can be as low as 2 kPa at no load. The kinematic as well as the quasi-static model is developed to accurately predict the behavior of the actuator and design the control strategy. A prototype is built based on a new fabrication method, on which the validation experiments are conducted. The experimental results prove the effectiveness of the model and show that the prototype possesses acceptable positioning accuracy, even when an external load is exerted on its moving plate.

- Simple, Low-Hysteresis, Foldable, Fabric Pneumatic Artificial Muscle

    Author: Naclerio, Nicholas | University of California, Santa Barbara
    Author: Hawkes, Elliot Wright | University of California, Santa Barbara
 
    keyword: Soft Sensors and Actuators; Hydraulic/Pneumatic Actuators; Soft Robot Materials and Design

    Abstract : Soft robots offer advantages over rigid robots in adaptability, robustness to uncertainty, and human safety. However, realizing soft actuators for these robots is still a challenge. We present a simple, highly conformable pneumatic artificial muscle made of a thin, single layer of woven, bias-cut fabric. The airtight fabric is adhered together with a flexible adhesive, negating the need for a bladder or sewing. Thus, it is foldable when depressurized and behaves like a McKibben muscle when pressurized, but without the friction of a bladder or braided sheath. Experiments show that the muscle exhibits repeatable, near-linear behavior with less than 1% hysteresis, over an order of magnitude less than that of McKibben muscles. Dynamic testing shows that the muscle responds quickly, even at lengths over 60 cm, contracting in 0.03 s, an order of magnitude quicker than series pouch motors. A fatigue test shows that its life exceeds 100,000 cycles. We also demonstrate that the muscles well suited for steering tip-extending robots, and actuating folding, deployable structures. Our muscle offers improvements over various existing pneumatic artificial muscles, providing a simple new option for soft robotic actuation that has potential to advance the field.

- Flat Inflatable Artificial Muscles with Large Stroke and Adjustable Force-Length Relations (I)

    Author: Kwon, Junghan | Seoul National University
    Author: Yoon, Sohee John | Seoul National University
    Author: Park, Yong-Lae | Seoul National University
 
    keyword: Soft Sensors and Actuators; Hydraulic/Pneumatic Actuators; Soft Robot Materials and Design

    Abstract : The performance of inflatable artificial muscles depends greatly on their designs and the output shapes resulting from the geometric constraints. Although there have been attempts to apply physical constraints on the air chamber to achieve larger stroke lengths and increased force-length ratios, it has been difficult to achieve the above two goals while maintaining a compact form factor. In this article, we propose flat inflatable artificial muscles that have large contraction ratios (up to 0.5) and show increased forces in wider ranges of contractions by adding an internal geometric constraint. Addition of an external constraint, such as rigid plates, further increased the maximum contraction ratio (up to 0.553) through a synergistic effect. We show that various force-length relations can be achieved by adjusting the height of the plates. Theoretical models based on the geometry and the principle of virtual work are experimentally validated using actuator prototypes made of heat-sealable plastic sheets. Also, compact capacitive sensors are integrated in design for proprioceptive feedback of the proposed actuators, and their feasibility and effectiveness are experimentally evaluated through closed-loop control.

- Joint Rotation Angle Sensing of Flexible Endoscopic Surgical Robots

    Author: Lai, Wenjie | Nanyang Technological University
    Author: Cao, Lin | Nanyang Technological University
    Author: Phan, Phuoc Thien | Nanyang Technological University
    Author: Wu, I-Wen | FBG Sensing Consulting Service Inc
    Author: Tjin, Swee Chuan | Nanyang Technological University
    Author: Phee, Louis | Nanyang Technological University
 
    keyword: Soft Sensors and Actuators; Medical Robots and Systems; Tendon/Wire Mechanism

    Abstract : Accurate motion control of surgical robots is critical for the efficiency and safety of both teleoperated robotic surgery and ultimate autonomous robotic surgery. However, fine motion control for a flexible endoscopic surgical robot is highly challenging because of the motion hysteresis of tendon-sheath mechanisms (TSMs) in the long, tortuous, and dynamically shape-changing robot body. Aiming to achieve precise closed-loop motion control, we propose a small and flexible sensor to directly sense the large and sharp rotations of the articulated joints of a flexible endoscopic surgical robot. The sensor, a Fiber Bragg Grating (FBG) eccentrically embedded in a thin and flexible epoxy substrate, can significantly bend with a large bending angle range of [-62.9°, 75.5°] and small bending radius of 6.9 mm. Mounted in-between the two pivot-connected links of a joint, the sensor will bend once the joint is actuated, resulting in the wavelength shift of the FBG. In this study, the relationship between the wavelength shift and the rotation angle of the joint was theoretically modeled and then experimentally verified before and after the installation of the sensor in a robotic endoscopic grasper. The sensor can track the rotation of the robotic joint with an RMSE of 3.34°. This small and flexible sensor has good repeatability, high sensitivity (~147.5 pm/degree), and low hysteresis (7.72%). It is suitable for surgical robots with large joint rotation angles and small bending radius.

- Soft, Round, High Resolution Tactile Fingertip Sensors for Dexterous Robotic Manipulation

    Author: Romero, Branden | Massachusetts Institute of Technology
    Author: Veiga, Filipe Fernandes | MIT
    Author: Adelson, Edward | MIT
 
    keyword: Soft Sensors and Actuators; Dexterous Manipulation; Sensor-based Control

    Abstract : High resolution tactile sensors are often bulky and have shape profiles that make them awkward for use in manipulation. This becomes important when using such sensors as fingertips for dexterous multi-fingered hands, where boxy or planar fingertips limit the available set of smooth manipulation strategies. High resolution optical based sensors such as GelSight have until now been constrained to relatively flat geometries due to constraints on illumination geometry. Here, we show how to construct a rounded fingertip that utilizes a form of light piping for directional illumination. Our sensors can replace the standard rounded fingertips of the Allegro hand. They can capture high resolution maps of the contact surfaces, and can be used to support various dexterous manipulation tasks.

- Creating a Soft Tactile Skin Employing Fluorescence Based Optical Sensing

    Author: De Chiara, Federica | King's College London
    Author: Wang, Shuxin | Tianjin University
    Author: Liu, Hongbin | King's College London
 
    keyword: Soft Sensors and Actuators; Haptics and Haptic Interfaces; Surgical Robotics: Steerable Catheters/Needles

    Abstract : Currently, optical tactile sensors propose solutions to measure contact forces at the tip of flexible medical instruments. However, the sensing capability of normal pressures applied to the surface along the tool body is still an open challenge. To deal with this challenge, this paper proposes a sensor design employing an angled tip optical fiber to measure the intensity modulation of a fluorescence signal proportional to the applied force. The fiber is used as both emitter of the excitation light and receiver of the fluorescence signal. This configuration allows to (i) halve the number of optical fibers and (ii) improve the signal to noise ratio thanks to the wavelength shift between excitation and fluorescence emission. The proposed design makes use of soft and flexible materials only, avoiding the size constraints given by rigid optical components and facilitating further miniaturization. The employed materials are bio-compatible and guarantee chemical inertness and non-toxicity for medical uses. In this work, the sensing principle is validated using a single optical fiber. Then, a soft stretchable skin pad, containing four tactile sensing elements, is presented to demonstrate the feasibility of this new force sensor design.

- FootTile: A Rugged Foot Sensor for Force and Center of Pressure Sensing in Soft Terrain

    Author: Ruppert, Felix | Max Planck Institute for Intelligent Systems
    Author: Badri-Spröwitz, Alexander | Max Planck Institute for Intelligent Systems
 
    keyword: Soft Sensors and Actuators; Legged Robots; Force and Tactile Sensing

    Abstract : In this paper, we present FootTile, a foot sensor for reaction force and center of pressure sensing in challenging terrain. We compare our sensor design to standard biomechanical devices, force plates and pressure plates. We show that FootTile can accurately estimate force and pressure distribution during legged locomotion. FootTile weighs 0.9 g, has a sampling rate of 330 Hz, a footprint of 10x10 mm and can easily be adapted in sensor range to the required load case. In three experiments, we validate: first, the performance of the individual sensor, second an array of FootTiles for center of pressure sensing and third the ground reaction force estimation during locomotion in granular substrate. We then go on to show the accurate sensing capabilities of the waterproof sensor in liquid mud, as a showcase for real world rough terrain use.

- A Vision-Based Soft Somatosensory Approach for Distributed Pressure and Temperature Sensing

    Author: Yu, Chen | King's College London
    Author: Lindenroth, Lukas | University College London
    Author: Hu, Jian | King's College London
    Author: Back, Junghwan | King's College London
    Author: Abrahams, George | King's College London
    Author: Liu, Hongbin | King's College London
 
    keyword: Soft Sensors and Actuators; Soft Robot Applications; Soft Robot Materials and Design

    Abstract : Emulating the somatosensory system in instruments such as robotic hands and surgical grippers has the potential to revolutionize these domains. Using a combination of different sensing modalities is problematic due to the limited space and incompatibility of these sensing principles. Therefore, in contrast to the natural world, it is currently difficult to concurrently measure the force, geometry, and temperature of contact in conventional tactile sensing. To this end, here we present a soft multifunctional tactile sensing principle. The temperature is estimated using a thermos chromic liquid crystal ink layer which exhibits colour variation under temperature change. The shape and force of contact is estimated through the 3-D reconstruction of a deformed soft silicone surface. Our experiments have demonstrated high accuracy in all three modalities, which can be measured at the same time. The resolution of the distributed force and temperature sensing was found to be 0.7N and 0.4&#8451; respectively.

- A Stretchable Capacitive Sensory Skin for Exploring Cluttered Environments

    Author: Gruebele, Alexander | Stanford University
    Author: Roberge, Jean-Philippe | École De Technologie Supérieure
    Author: Zerbe, Andrew | Stanford University
    Author: Ruotolo, Wilson | Stanford University
    Author: Huh, Tae Myung | Stanford University
    Author: Cutkosky, Mark | Stanford University
 
    keyword: Soft Sensors and Actuators; Sensor Networks; Grasping

    Abstract : We present a design and fabrication method using low-cost materials for a new tactile sensor that is highly stretchable (up to 60%) and for which the signal is substantially unaffected by stretching, immersion in water, or electromag- netic noise. The sensor can be wrapped around the front, side and back surfaces of fingers and allows them to flex without affecting the signal. The sensor consists of multiple layers of UV laser-patterned metallic capacitive elements and interconnects, encapsulated in a silicone membrane. It survives large impacts and over a thousand stretching cycles without a change in performance. We use low-cost capacitance-to-digital converters for filtering and communication. To meet different requirements for the front and back surfaces of fingers, the sensitivity of taxels can be tuned by varying the dielectric pattern and in CDC firmware. The skin detects contacts as low as 60 Pa and is intended for manipulation in cluttered environments where the back of the hand may accidentally brush objects.

## Wearable Robots

- SwarmRail: A Novel Overhead Robot System for Indoor Transport and Mobile Manipulation

    Author: Görner, Martin | German Aerospace Center (DLR)
    Author: Benedikt, Fabian | German Aerospace Center (DLR)
    Author: Grimmel, Ferdinand | German Aerospace Center (DLR)
    Author: Hulin, Thomas | German Aerospace Center (DLR)
 
    keyword: Wheeled Robots; Mobile Manipulation; Logistics

    Abstract : SwarmRail represents a novel solution to overhead manipulation from a mobile unit that drives in an aboveground rail-structure. The concept is based on the combination of omnidirectional mobile platform and L-shaped rail profiles that form a through-going central gap. This gap makes possible mounting a robotic manipulator arm overhead at the underside of the mobile platform. Compared to existing solutions, SwarmRail enables continuous overhead manipulation while traversing rail crossings. It also can be operated in a robot swarm, as it allows for concurrent operation of a group of mobile SwarmRail units inside a single rail network. Experiments on a first functional demonstrator confirm the functional capability of the concept. Potential fields of applications reach from industry over logistics to vertical farming.

- Fast Local Planning and Mapping in Unknown Off-Road Terrain

    Author: Overbye, Timothy | Texas A&amp;M University
    Author: Saripalli, Srikanth | Texas A&amp;M
 
    keyword: Wheeled Robots; Field Robots; Motion and Path Planning

    Abstract : In this paper, we present a fast, on-line mapping and planning solution for operation in unknown, off-road, environments. We combine obstacle detection along with a terrain gradient map to make simple and adaptable cost map. This map can be created and updated at 10~Hz. An A* planner finds optimal paths over the map. Finally, we take multiple samples over the control input space and do a kinematic forward simulation to generated feasible trajectories. Then the most optimal trajectory, as determined by the cost map and proximity to A* path, is chosen and sent to the controller. Our method allows real time operation at rates of 30~Hz. We demonstrate the efficiency of our method in various off-road terrain at high speed.

- Multifunctional 3-DOF Wearable Supernumerary Robotic Arm Based on Magnetorheological Clutches

    Author: Veronneau, Catherine | Universite De Sherbrooke
    Author: Denis, Jeff | Université De Sherbrooke
    Author: Lebel, Louis-Philippe | Université De Sherbrooke
    Author: Denninger, Marc | Université De Sherbrooke
    Author: Blanchard, Vincent | Université De Sherbrooke
    Author: Girard, Alexandre | Université De Sehrbrooke
    Author: Plante, Jean-Sebastien | Université De Sherbrooke
 
    keyword: Wearable Robots; Product Design, Development and Prototyping; Physical Human-Robot Interaction

    Abstract : Supernumerary robotic limbs (SRL) are wearable extra limbs intended to help humans perform physical tasks beyond conventional capabilities in domestic or industrial applications. However, unique design challenges are associated with SRLs as they are mounted on the human body. SRLs must 1) be lightweight to avoid burdening the user, 2) be fast enough to compensate for human motions, 3) be strong enough to accomplish various tasks, 4) have high force-bandwidth and good backdrivability to control interaction forces. This paper studies the potential of a 3-DOF supernumerary robotic arm powered by magnetorheological (MR) clutches and hydrostatic transmission lines. The tethered configuration allows the power-unit to be located on the ground, which minimizes the mass worn (4.2 kg) by the user. MR clutches minimize the actuation inertia in order to provide fast dynamics and backdrivability. An experimental open-loop force-bandwidth of 18 Hz is founded at each joint and the maximal speed reached by the end-effector is 3.4 m/s, which is sufficient for compensating human motions. Also, the two first joints provide 35 Nm and the third joint, 29 Nm, which is strong enough to hold manual tools. Finally,the SRL is put in real practical situations, as fruit picking, painting, tools holding and badminton playing. The capability of the proposed SRL to perform successfully various tasks with high speed and smoothness suggests a strong potential of SRLs to become future commonly used devices.

- Leveraging the Human Operator in the Design and Control of Supernumerary Robotic Limbs

    Author: Guggenheim, Jacob | MIT
    Author: Hoffman, Rachel | Massachusetts Institute of Technology
    Author: Song, Hanjun | Massachusetts Institute of Technology
    Author: Asada, Harry | MIT
 
    keyword: Wearable Robots; Physical Human-Robot Interaction; Human-Centered Robotics

    Abstract : A human has over 200 muscles in the body, creating a high degree of flexibility and redundancy in movement. This paper exploits this high degree of redundancy for the actuation and control of Supernumerary Robotic Limbs (SuperLimbs), which are attached to a human body. SuperLimbs containing many active joints tend to be too heavy to wear comfortably. Since SuperLimbs are attached to a human body at their base, Superlimbs can be positioned directly by moving the base with movements of the human body. No active joints are needed for the SuperLimbs in certain directions if the human body can generate the same movements as the SuperLimbs, thus allowing for the design of reduced-actuator Superlimbs. Here, we present a method for quantifying the usable degrees of freedom (DOFs) of a human body for a specific task so that the number of Superlimb actuators can be reduced. The high degree of redundant human DOFs can also be utilized for communication and control. Human's fingers are often redundant for performing a task, e.g. holding a box. Although both hands are busy, some combination of the finger forces is still available for generating signal patterns. An algorithm is developed for generating coded finger force patterns without interfering with the performance of the primary task. Both methods are implemented on a simple SuperLimb and a human subject demonstrates the usefulness of the methods.

- Revisiting Scaling Laws for Robotic Mobility in Granular Media

    Author: Thoesen, Andrew | Arizona State University
    Author: McBryan, Teresa | Arizona State University
    Author: Green, Marko | Arizona State University
    Author: Martia, Justin | Arizona State University
    Author: Mick, Darwin | Arizona State University
    Author: Marvi, Hamidreza | Arizona State University
 
    keyword: Wheeled Robots; Field Robots; Space Robotics and Automation

    Abstract : The development, building, and testing of robotic vehicles for applications in deformable media can be costly. Typical approaches rely on full-sized builds empirically evaluating performance metrics such as drawbar pull and slip. Recently developed granular scaling laws offer a new opportunity for terramechanics as a field. Using non-dimensional analysis on the wheel characteristics and treating the terrain as a deformable continuum, the performance of a larger, more massive wheel may be predicted from a smaller one. This allows for new wheel design approaches. However, robot-soil interaction and specific characteristics of the soil or robot dynamics may create discrepancies in prediction. In particular, we find that for a lightweight rover (2-5 kg), the scaling laws significantly overpredicted mechanical power requirements. To further explore the limitations of the current granular scaling laws, a pair of differently sized grousered wheels were tested at three masses and a pair of differently sized sandpaper wheels were tested at two masses across five speeds. Analysis indicates similar error for both designs, a mass dependency for all five pairs that explains the laws' overprediction, and a speed dependency for both of the heaviest sets. The findings create insights for using the laws with lightweight robots in granular media and generalizing granular scaling laws.

- Learning a Control Policy for Fall Prevention on an Assistive Walking Device

    Author: C V Kumar, Visak | Georgia Institute of Technology
    Author: Ha, Sehoon | Google Brain
    Author: Sawicki, Gregory | Georgia Institute of Technology
    Author: Liu, Karen | Georgia Tech
 
    keyword: Wearable Robots; Deep Learning in Robotics and Automation; Physically Assistive Devices

    Abstract : Fall prevention is one of the most important components in senior care. We present a technique to augment an assistive walking device with the ability to prevent falls. Given an existing walking device, our method develops a fall predictor and a recovery policy by utilizing the onboard sensors and actuators. The key component of our method is a robust human walking policy that models realistic human gait under a moderate level of perturbations. We use this human walking policy to provide training data for the fall predictor, as well as to teach the recovery policy how to best modify the person's gait when a fall is imminent. Our evaluation shows that the human walking policy generates walking sequences similar to those reported in biomechanics literature. Our experiments in simulation show that the augmented assistive device can indeed help recover balance from a variety of external perturbations. We also provide a quantitative method to evaluate the design choices for an assistive device.

- Assistive Force of a Belt-Type Hip Assist Suit for Lifting the Swing Leg During Walking

    Author: Guo, Shijie | Hebei University of Technology
    Author: Xiang, Qian | Hebei University of Technology
    Author: Hashimoto, Kazunobu | Ningbo Intelligent Manufacturing Industry Research Institute
    Author: Jin, Shanhai | Yanbian University
 
    keyword: Wearable Robots; Rehabilitation Robotics; Physically Assistive Devices

    Abstract : This paper proposes a relatively simple function of assistive force for a belt-type hip assist suit developed by the     Authors' group. The function, which is inspired by the muscle force of the rectus femoris, contains only two parameters, the magnitude and a phase shift factor. Thus, it can reduce the amount of calculation in generating the desired assistive force during walking. Tests were performed on three healthy subjects to confirm its effect and to investigate its influence on the motions of hip, knee and ankle joints. It was demonstrated that the effect of the assist depended greatly on the phase shift factor, i.e., the location of the peak of the assistive force in a swing period. A large effect was observed when the peak of the assistive force came at mid-swing phase. The results of the tests showed that the proposed force function could help to increase walk ratio (the ratio of step length to the number of steps per minute) by an average value of 11.2% at a force magnitude of 35 N, which could produce an assistive torque of the same order as the magnitude of the muscle force of the rectus femoris around the hip joint.

- Soft Pneumatic System for Interface Pressure Regulation and Automated Hands-Free Donning in Robotic Prostheses

    Author: Ambrose, Alexander | Georgia Institute of Technology
    Author: Hammond III, Frank L. | Georgia Institute of Technology
 
    keyword: Wearable Robots; Prosthetics and Exoskeletons; Soft Robot Applications

    Abstract : This paper discusses the design and preliminary evaluation of a soft pneumatic socket (SPS) with real-time pressure regulation and an automated underactuated donning mechanism (UDM). The ability to modulate the pressure at the human-socket interface of a prosthesis or wearable device to accommodate user's activities has the potential to make the user more comfortable. Furthermore, a hands-free, underactuated donning mechanism designed to reliably and safely don the socket onto the user may increase the convenience of prostheses and wearable devices. The pneumatic socket and donning mechanism are evaluated on synthetic forearm model designed to closely match the mechanical properties of the human forearm. The pneumatic socket was tested to determine the maximum loads it can withstand before slipping and the displacement of the socket after loading. The donning mechanism was able to successfully don the socket on to the replica forearm with a 100% success rate for the 30 trials that were tested. Both devices were also tested to determine the pressures they impart on the user. The highest pressures the socket can impart on the user is 4psi and the maximum pressure the donning mechanism imparts on the user is 0.83psi. These pressures were found to be lower than the reported pressures that cause pain and tissue damage.

- Automated Detection of Soleus Concentric Contraction in Variable Gait Conditions for Improved Exosuit Control

    Author: Nuckols, Richard | Harvard University
    Author: Swaminathan, Krithika | Harvard University
    Author: Lee, Sangjun | Harvard University
    Author: Awad, Louis | Harvard University
    Author: Walsh, Conor James | Harvard University
    Author: Howe, Robert D. | Harvard University
 
    keyword: Wearable Robots; Computer Vision for Other Robotic Applications; Physical Human-Robot Interaction

    Abstract : Exosuits can reduce metabolic demand and improve gait. Controllers explicitly derived from biological mechanisms that reflect the user's joint or muscle dynamics should in theory allow for individualized assistance and enable adaptation to changing gait. With the goal of developing an exosuit control strategy based on muscle power, we present an approach for estimating, at real time rates, when the soleus muscle begins to generate positive power. A low-profile ultrasound system recorded B-mode images of the soleus in walking individuals. An automated routine using optical flow segmented the data to a normalized gait cycle and estimated the onset of concentric contraction at real-time rates (~130Hz). Segmentation error was within 1% of the gait cycle compared to using ground reaction forces. Estimation of onset of concentric contraction had a high correlation (R2=0.92) and an RMSE of 2.6% gait cycle relative to manual estimation. We demonstrated the ability to estimate the onset of concentric contraction during fixed speed walking in healthy individuals that ranged from 39.3% to 45.8% of the gait cycle and feasibility in two persons post-stroke walking at comfortable walking speed. We also showed the ability to measure a shift in onset timing to 7% earlier when the biological system adapts from level to incline walking. Finally, we provided an initial evaluation for how the onset of concentric contraction might be used to inform exosuit control in level and incline walking.

- Soft Sensing Shirt for Shoulder Kinematics Estimation

    Author: Jin, Yichu | Harvard University
    Author: Glover, Christina | Harvard University
    Author: Cho, Haedo | Harvard University
    Author: Araromi, Oluwaseun Adelowo | Harvard University
    Author: Graule, Moritz A. | Harvard University
    Author: Li, Na | Harvard University
    Author: Wood, Robert | Harvard University
    Author: Walsh, Conor James | Harvard University
 
    keyword: Wearable Robots; Soft Sensors and Actuators

    Abstract : Soft strain sensors have been explored as an unobtrusive approach for wearable motion tracking. However, accurate tracking of multi-DOF noncyclic joint movements remains a challenge. This paper presents a soft sensing shirt for tracking shoulder kinematics of both cyclic and random arm movements in 3 DOFs: adduction/abduction, horizontal flexion/extension, and internal/external rotation. The sensing shirt consists of 8 textile-based capacitive strain sensors sewn around the shoulder joint that communicate to a customized readout electronics board through sewn micro coaxial cables. An optimized sensor design includes passive shielding and demonstrates high linearity and low hysteresis, making it suitable for wearable motion tracking. In a study with a single human subject, we evaluated the tracking capability of the integrated shirt in comparison with a ground truth optical motion capture system. An ensemble-based regression algorithm was implemented in post-processing to estimate joint angles and angular velocities from the strain sensor data. Results demonstrated root mean square errors less than 4.5 deg for joint angle estimation and normalized root mean square errors less than 4% for joint velocity estimation. Furthermore, we applied a recursive feature elimination-based sensor selection analysis to down select the number of sensors for future shirt designs. This sensor selection analysis found that 5 sensors out of 8 were sufficient to generate comparable accuracies.

- Characterizing Torso Stiffness in Female Adolescents with and without Scoliosis

    Author: Murray, Rosemarie | Columbia University
    Author: Ophaswongse, Chawin | Columbia University
    Author: Park, Joon-Hyuk | University of Central Florida
    Author: Agrawal, Sunil | Columbia University
 
    keyword: Wearable Robots; Rehabilitation Robotics; Physical Human-Robot Interaction

    Abstract : Adolescent Idiopathic Scoliosis (AIS) is a spinal curvature that affects 3% of the population and disproportionately affects females. It is treated with bracing and many researchers are developing models of the torso to optimize the effectiveness of brace designs. Unfortunately, the data available to create these models is limited by the experimental methods employed. One method, in vitro spine cadaver stiffness measurements, is generally based on specimens from the elderly, which are not representative of the adolescent population. The other method, radiographic studies, can only provide a limited amount of information because of the radiation exposure that multiple images require. In this work, we present a Robotic Spine Exoskeleton (RoSE) tailored to the population in greatest need of AIS interventions--female adolescents. We use it to create a three-dimensional stiffness characterization of the torso in vivo for eight female adolescents with scoliosis and eight without this condition. The key findings include an interaction effect of DOF and torso segment on translational collinear stiffnesses, and an interaction effect of DOF and group on rotational collinear stiffnesses. We also found that the 3D coupling stiffness pattern is in line with that of the human spine, regardless of spinal deformity. Also, the magnitude of the torso stiffness for the tested population is less than that of the adult male population previously characterized.

## Cognitive Human-Robot Interaction
- Scaled Autonomy: Enabling Human Operators to Control Robot Fleets

    Author: Swamy, Gokul | UC Berkeley
    Author: Reddy, Siddharth | UC Berkeley
    Author: Levine, Sergey | UC Berkeley
    Author: Dragan, Anca | University of California Berkeley
 
    keyword: Cognitive Human-Robot Interaction; Telerobotics and Teleoperation; Learning from Demonstration

    Abstract : Autonomous robots often encounter challenging situations where their control policies fail and an expert human operator must briefly intervene, e.g., through teleoperation. In settings where multiple robots act in separate environments, a single human operator can manage a fleet of robots by identifying and teleoperating one robot at any given time. The key challenge is that users have limited attention: as the number of robots increases, users lose the ability to decide which robot requires teleoperation the most. Our goal is to automate this decision, thereby enabling users to supervise more robots than their attention would normally allow for. Our insight is that we can model the user's choice of which robot to control as an approximately optimal decision that maximizes the user's utility function. We learn a model of the user's preferences from observations of the user's choices in easy settings with a few robots, and use it in challenging settings with more robots to automatically identify which robot the user would most likely choose to control, if they were able to evaluate the states of all robots at all times. We run simulation experiments and a user study with twelve participants that show our method can be used to assist users in performing a simulated navigation task. We also run a hardware demonstration that illustrates how our method can be applied to a real-world mobile robot navigation task.

- An Actor-Critic Approach for Legible Robot Motion Planner

    Author: Zhao, Xuan | City University of Hong Kong
    Author: Fan, Tingxiang | The University of Hong Kong
    Author: Wang, Dawei | The University of Hong Kong
    Author: Hu, Zhe | City University of Hong Kong
    Author: Han, Tao | City University of Hong Kong
    Author: Pan, Jia | University of Hong Kong
 
    keyword: Cognitive Human-Robot Interaction; AI-Based Methods

    Abstract : In human-robot collaboration, it is crucial for the robot to make its intentions clear and predictable to the human partners. Inspired by the mutual learning and adaptation of human partners, we suggest an actor-critic approach for a legible robot motion planner. This approach includes two neural networks and a legibility evaluator: 1) A policy network based on deep reinforcement learning (DRL); 2) A Recurrent Neural Networks (RNNs) based sequence to sequence (Seq2Seq) model as a motion predictor; 3) A legibility evaluator that maps motion to legible reward. Through a series of human-subject experiments, we demonstrate that with a simple handicraft function and no real-human data, our method lead to improved collaborative performance against a baseline method and a non-prediction method.

- May I Draw Your Attention? Initial Lessons from the Large-Scale Generative Mark Maker

    Author: Phillips, Aidan | University of Pittsburgh
    Author: Vinoo, Ashwin | Oregon State University
    Author: Fitter, Naomi T. | University of Southern California
 
    keyword: Entertainment Robotics; Human-Centered Robotics; Cognitive Human-Robot Interaction

    Abstract : Everyday robots are emerging in contexts from household chores to entertainment, and an accompanying need arises to understand perceptions of these systems. We propose a sleek 2D hanging pen plotter as a useful tool for both furthering art and studying human responses to ambient everyday robots. Aspects of this system and the pieces it produced were grounded in ideas from conceptual and generative art. We installed our robotic system in three different spaces in the wild, recorded video footage of the installations, consulted with expert artists, and interviewed a subset of exhibit visitors. Key findings included visitor assumptions of robot responsiveness and differences in user behaviors between performing arts and engineering environments. The exploratory products of this work can benefit artists who employ generative concepts in their work, as well as roboticists who seek further understanding of human-robot interaction in the wild.

- Intuitive 3D Control of a Quadrotor in User Proximity with Pointing Gestures

    Author: Gromov, Boris | IDSIA
    Author: Guzzi, Jerome | IDSIA, USI-SUPSI
    Author: Gambardella, Luca | USI-SUPSI
    Author: Giusti, Alessandro | IDSIA Lugano, SUPSI
 
    keyword: Cognitive Human-Robot Interaction; Gesture, Posture and Facial Expressions; Human-Centered Robotics

    Abstract : We present an approach for controlling the position of a quadrotor in 3D space using pointing gestures; the task is difficult because it is in general ambiguous to infer where, along the pointing ray, the robot should go. We propose and validate a pragmatic solution based on a push button acting as a simple additional input device which switches between different virtual workspace surfaces. Results of a study involving ten subjects show that the approach performs well on a challenging 3D piloting task, where it compares favorably with joystick control.

- Joint Inference of States, Robot Knowledge, and Human (False-)Beliefs

    Author: Yuan, Tao | University of California, Los Angeles
    Author: Liu, Hangxin | University of California, Los Angeles
    Author: Fan, Lifeng | University of California, Los Angeles
    Author: Zheng, Zilong | UCLA
    Author: Gao, Tao | Massachusetts Institute of Technology
    Author: Zhu, Yixin | University of California, Los Angeles
    Author: Zhu, Song-Chun | UCLA
 
    keyword: Cognitive Human-Robot Interaction; Semantic Scene Understanding; Visual Learning

    Abstract : Aiming to understand how human (false-)belief---a core socio-cognitive ability---would affect human interactions with robots, this paper proposes to adopt a graphical model to unify the representation of object states, robot knowledge, and human (false-)beliefs. Specifically, a pg is learned from a single-view spatiotemporal parsing by aggregating various object states along the time; such a learned representation is accumulated as the robot's knowledge. An inference algorithm is derived to fuse individual pg from all robots across multi-views into a joint pg, which affords more effective reasoning and inference capability to overcome the errors originated from a single view. In the experiments, through the joint inference over pgs, the system correctly recognizes human (false-)belief in various settings and achieves better cross-view accuracy on a challenging small object tracking dataset.

- Visual-Audio Cognitive Architecture for Autonomous Learning of Face Localisation by a Humanoid Robot

    Author: Gonzalez-Billandon, Jonas | Istituto Italiano Di Tecnologia, University of Genova
    Author: Sciutti, Alessandra | Italian Institute of Technology
    Author: Tata, Matthew | University of Lethbridge
    Author: Sandini, Giulio | Italian Institute of Technology
    Author: Rea, Francesco | Istituto Italiano Di Tecnologia
 
    keyword: Cognitive Human-Robot Interaction; Social Human-Robot Interaction; Learning and Adaptive Systems

    Abstract : Newborn infants are naturally attracted to human faces, a crucial source of information for social interaction. In robotics, acquisition of such information is crucial and social robots should also learn to exhibit such social skill. Deep learning algorithms have been used to resemble hierarchical processes of learning and generalization inspired by biological models. However, a major drawback of these methods is that they are not autonomous. They require a large amount of data and human supervision is extensively involved in the process. The challenge is to propose autonomous behaviours that can guide a robot to learn relevant social skills. In this work, we address this problem in the field of facial localisation by proposing a learning system based on a biologically-inspired cognitive framework. The proposed cognitive architecture builds on existing work and uses visual-audio orienting attention and a proactive stereo vision mechanism to autonomously direct a robot's attentive focus towards human faces. The gathered information is used to incrementally generate a dataset that can be used to train a state-of-the-art deep network. The learning system replicates the typical learning process of infants and enhances the learning generalization process by leveraging on the interaction experience with people. The integration of HRI with machine learning, inspired by early development in humans, constitutes an innovative approach for improving autonomous learning in robots.

- Motion Reasoning for Goal-Based Imitation Learning

    Author: Huang, De-An | Stanford University
    Author: Chao, Yu-Wei | Univeristy of Michigan
    Author: Paxton, Chris | NVIDIA Research
    Author: Deng, Xinke | University of Illinois at Urbana-Champaign
    Author: Fei-Fei, Li | Stanford University
    Author: Niebles, Juan Carlos | Stanford University
    Author: Garg, Animesh | University of Toronto
    Author: Fox, Dieter | University of Washington
 
    keyword: Cognitive Human-Robot Interaction; Perception for Grasping and Manipulation; Task Planning

    Abstract : We address goal-based imitation learning, where the aim is to output the symbolic goal from a third-person video demonstration. This enables the robot to plan for execution and reproduce the same goal in a completely different environment. The key challenge is that the goal of a video demonstration is often ambiguous at the level of semantic actions. The human demonstrators might unintentionally achieve certain subgoals in the demonstrations with their actions. Our main contribution is to propose a motion reasoning framework that combines task and motion planning to disambiguate the true intention of the demonstrator in the video demonstration. This allows us to recognize the goals that cannot be disambiguated by previous action-based approaches. We evaluate our approach on a new dataset of 96 video demonstrations in a mockup kitchen environment. We show that our motion reasoning plays an important role in recognizing the actual goal of the demonstrator and improves the success rate by over 20%. We further show that by using the automatically inferred goal from the video demonstration, our robot is able to reproduce the same task in a real kitchen environment.

- Flexible Online Adaptation of Learning Strategy Using EEG-Based Reinforcement Signals in Real-World Robotic Applications

    Author: Kim, Su Kyoung | German Research Center for Artificial Intelligence (DFKI)
    Author: Kirchner, Elsa Andrea | University of Bremen
    Author: Kirchner, Frank | University of Bremen
 
    keyword: Cognitive Human-Robot Interaction; Brain-Machine Interface; Learning and Adaptive Systems

    Abstract : Flexible adaptation of learning strategy depending on online changes of the user's current intents have a high relevance in human-robot collaboration. In our previous study, we proposed an intrinsic interactive reinforcement learning approach for human-robot interaction, in which a robot learns his/her action strategy based on intrinsic human feedback that is generated in the human's brain as neural signature of the human's implicit evaluation of the robot's actions. Our approach has an inherent property that allows robots to adapt their behavior depending on online changes of the human's current intents. Such flexible adaptation is possible, since robot learning is updated in real time by human's online feedback. In this paper, the adaptivity of robot learning is tested on eight subjects who change their current control strategy by adding a new gesture to the previous used gestures. This paper evaluates the learning progress by analyzing learning phases (before and after adding a new gesture for control). The results show that the robot can adapt the previously learned policy depending on online changes of the user's intents. Especially, learning progress is interrelated with the classification performance of electroencephalograms (EEGs), which are used to measure the human's implicit evaluation of the robot's actions.

- Object-Oriented Semantic Graph Based Natural Question Generation

    Author: Moon, Jiyoun | Seoul National University
    Author: Lee, Beom-Hee | Seoul National University
 
    keyword: Cognitive Human-Robot Interaction; Cooperating Robots; SLAM

    Abstract : Generating a natural question can enable autonomous robots to propose problems according to their surroundings. However, recent studies on question generation rarely consider semantic graph mapping, which is widely used to understand environments. In this paper, we introduce a method to generate natural questions using object-oriented semantic graphs. First, a graph convolutional network extracts features from the graph. Then, a recurrent neural network generates the natural question from the extracted features. Using graphs, we can generate natural questions for both single and sequential scenes. The proposed method outperforms conventional methods on a publicly available dataset for single scenes and can generate questions for sequential scenes.

- Towards Safe Human-Robot Collaboration Using Deep Reinforcement Learning

    Author: El-Shamouty, Mohamed | Fraunhofer IPA
    Author: Wu, Xinyang | Fraunhofer IPA
    Author: Yang, Shanqi | Fraunhofer IPA
    Author: Albus, Marcel | Fraunhofer IPA
    Author: Huber, Marco F. | University of Stuttgart
 
    keyword: Cognitive Human-Robot Interaction; Robot Safety; Motion and Path Planning

    Abstract : Safety in Human-Robot Collaboration (HRC) is a bottleneck to HRC-productivity in industry. With robots being the main source of hazards, safety engineers use over-emphasized safety measures, and carry out lengthy and expensive risk assessment processes on each HRC-layout reconfiguration. Recent advances in deep Reinforcement Learning (RL) offer solutions to add intelligence and comprehensibility of the environment to robots. In this paper, we propose a framework that uses deep RL as an enabling technology to enhance intelligence and safety of the robots in HRC scenarios and, thus, reduce hazards incurred by the robots. The framework offers a systematic methodology to encode the task and safety requirements and context of applicability into RL settings. The framework also considers core components, such as behavior explainer and verifier, which aim for transferring learned behaviors from research labs to industry. In the evaluations, the proposed framework shows the capability of deep RL agents learning collision-free point-to-point motion on different robots inside simulation, as shown in the supplementary video.

- Deep Compositional Robotic Planners That Follow Natural Language Commands

    Author: Kuo, Yen-Ling | MIT
    Author: Katz, Boris | MIT
    Author: Barbu, Andrei | MIT
 
    keyword: Cognitive Human-Robot Interaction; Learning from Demonstration

    Abstract : We demonstrate how a sampling-based robotic planner can be augmented to learn to understand a sequence of natural language commands in a continuous configuration space to move and manipulate objects. Our approach combines a deep network structured according to the parse of a complex command that includes objects, verbs, spatial relations, and attributes, with a sampling-based planner, RRT. A recurrent hierarchical deep network controls how the planner explores the environment, determines when a planned path is likely to achieve a goal, and estimates the confidence of each move to trade off exploitation and exploration between the network and the planner. Planners are designed to have near-optimal behavior when information about the task is missing, while networks learn to exploit observations which are available from the environment, making the two naturally complementary. Combining the two enables generalization to new maps, new kinds of obstacles,and more complex sentences that do not occur in the training set. Little data is required to train the model despite it jointly acquiring a CNN that extracts features from the environment as it learns the meanings of words. The model provides a level of interpretability through the use of attention maps allowing users to see its reasoning steps despite being an end-to-end model. This end-to-end model allows robots to learn to follow natural language commands in challenging continuous environments.

- Learning User Preferences from Corrections on State Lattices

    Author: Wilde, Nils | University of Waterloo
    Author: Kulic, Dana | Monash University
    Author: Smith, Stephen L. | University of Waterloo
 
    keyword: Cognitive Human-Robot Interaction; Motion and Path Planning

    Abstract :  Enabling a broader range of users to efficiently deploy autonomous mobile robots requires intuitive frameworks for specifying a robot's task and behaviour. We present a novel approach using learning from corrections (LfC), where a user is iteratively presented with a solution to a motion planning problem. Users might have preferences about parts of a robot's environment that are suitable for robot traffic or that should be avoided as well as preferences on the control actions a robot can take. The robot is initially unaware of these preferences; thus, we ask the user to provide a correction to the presented path. We assume that the user evaluates paths based on environment and motion features. From a sequence of corrections we learn weights for these features, which are then considered by the motion planner, resulting in future paths that better fit the user's preferences. We prove completeness of our algorithm and demonstrate its performance in simulations. Thereby, we show that the learned preferences yield good results not only for a set of training tasks but also for test tasks, as well as for different types of user behaviour.

## Robotics in Agriculture and Forestry
- Visual Servoing-Based Navigation for Monitoring Row-Crop Fields

    Author: Ahmadi, Alireza | University of Bonn
    Author: Nardi, Lorenzo | University of Bonn
    Author: Chebrolu, Nived | University of Bonn
    Author: Stachniss, Cyrill | University of Bonn
 
    keyword: Robotics in Agriculture and Forestry; Visual-Based Navigation; Visual Servoing

    Abstract : Autonomous navigation is a pre-requisite for field robots to carry out precision agriculture tasks. Typically, a robot has to navigate through a whole crop field several times during a season for monitoring the plants, for applying agro-chemicals, or for performing targeted intervention actions. In this paper, we propose a framework tailored for navigation in row-crop fields by exploiting the regular crop-row structure present in the fields. Our approach uses only the images from on-board cameras without the need for performing explicit localization or maintaining a map of the field and thus can operate without expensive RTK-GPS solutions often used in agriculture automation systems. Our navigation approach allows the robot to follow the crop-rows accurately and handles the switch to the next row seamlessly within the same framework. We implemented our approach using C++ and ROS and thoroughly tested it in several simulated environments with different shapes and sizes of field. We also demonstrated the system running at frame-rate on an actual robot operating on a test row-crop field. The code and data have been published.

- Optimal Routing Schedules for Robots Operating in Aisle-Structures

    Author: Betti Sorbelli, Francesco | University of Perugia
    Author: Carpin, Stefano | University of California, Merced
    Author: Cor�, Federico | Gran Sasso Science Institute
    Author: Navarra, Alfredo | University of Perugia
    Author: Pinotti, Cristina M. | University of Perugia
 
    keyword: Robotics in Agriculture and Forestry; Inventory Management; Planning, Scheduling and Coordination

    Abstract : In this paper, we consider the Constant-cost Orienteering Problem (COP) where a robot, constrained by a limited travel budget, aims at selecting a path with the largest reward in an aisle-graph. The aisle-graph consists of a set of loosely connected rows where the robot can change lane only at either end, but not in the middle. Even when considering this special type of graphs, the orienteering problem is known to be NP-hard. We optimally solve in polynomial time two special cases, COP-FR where the robot can only traverse full rows, and COP-SC where the robot can access the rows only from one side. To solve the general COP, we then apply our special case algorithms as well as a new heuristic that suitably combines them. Despite its light computational complexity and being confined into a very limited class of paths, the optimal solutions for COP-FR turn out to be competitive even for COP in both real and synthetic scenarios. Furthermore, our new heuristic for the general case outperforms state-of-art algorithms, especially for input with highly unbalanced rewards.

- Time Optimal Motion Planning with ZMP Stability Constraint for Timber Manipulation

    Author: Song, Jiazhi | McGill University
    Author: Sharf, Inna | McGill University
 
    keyword: Robotics in Agriculture and Forestry; Motion and Path Planning; Optimization and Optimal Control

    Abstract : This paper presents a dynamic stability-constrained optimal motion planning algorithm developed for a timber harvesting machine working on rough terrain. First, the kinematics model of the machine, and the Zero Moment Point (ZMP) stability measure is presented. Then, an approach to simplify the model to gain insight and achieve a fast solution of the optimization problem is introduced. The performance and computation time of the motion plan obtained with the simplified model is compared against that obtained with the full kinematics model of the machine with the help of MATLAB simulations. The results demonstrate feasibility of fast motion planning while satisfying the dynamic stability constraint.

- Plucking Motions for Tea Harvesting Robots Using Probabilistic Movement Primitives

    Author: Motokura, Kurena | Keio University
    Author: Takahashi, Masaki | Keio University
    Author: Ewerton, Marco | Idiap Research Institute
    Author: Peters, Jan | Technische Universitét Darmstadt
 
    keyword: Robotics in Agriculture and Forestry; Learning from Demonstration; Manipulation Planning

    Abstract : This study proposes a harvesting robot capable of plucking tea leaves. In order to harvest high-quality tea, the robot is required to pluck the petiole of the leaf without cutting it using blades. To pluck the leaves, it is necessary to reproduce a complicated human hand motion of pulling while rotating. Furthermore, the rotation and pulling of the hand, and the time taken, vary greatly depending on conditions that include the maturity of the leaves, thickness of the petioles, and thickness and length of the branches. Therefore, it is necessary to determine the amount of translational and rotational movements, and the length of time of the motion, according to each situation. In this study, the complicated motion is reproduced by learning from demonstration. The condition is judged in terms of the stiffness of the branches, which is defined as the force received from the branches per unit length when the gripped leaf is slightly pulled up. Combining the learned motions probabilistically at a ratio determined by the branch stiffness, the appropriate motion is generated, even for situations where no motion is taught. We compared the motions generated by the proposed method with the motions taught by humans, and verified the effectiveness of the proposed method. It was confirmed by experiment that the proposed method can harvest high-quality tea.

- SLOAM: Semantic Lidar Odometry and Mapping for Forest Inventory

    Author: Chen, Steven W | University of Pennsylvania
    Author: Vicentim Nardari, Guilherme | University of S�o Paulo
    Author: Lee, Elijah S. | University of Pennsylvania
    Author: Qu, Chao | University of Pennsylvania
    Author: Liu, Xu | University of Pennsylvania
    Author: Romero, Roseli Ap. Francelin | Universidade De Sao Paulo
    Author: Kumar, Vijay | University of Pennsylvania, School of Engineering and Applied Sc
 
    keyword: Robotics in Agriculture and Forestry; Deep Learning in Robotics and Automation; Aerial Systems: Applications

    Abstract : This paper describes an end-to-end pipeline for tree diameter estimation based on semantic segmentation and lidar odometry and mapping. Accurate mapping of this type of environment is challenging since the ground and the trees are surrounded by leaves, thorns and vines, and the sensor typically experiences extreme motion. We propose a semantic feature based pose optimization that simultaneously refines the tree models while estimating the robot pose. The pipeline utilizes a custom virtual reality tool for labeling 3D scans that is used to train a semantic segmentation network. The masked point cloud is used to compute a trellis graph that identifies individual instances and extracts relevant features that are used by the SLAM module. We show that traditional lidar and image based methods fail in the forest environment on both Unmanned Aerial Vehicle (UAV) and hand-carry systems, while our method is more robust, scalable, and automatically generates tree diameter estimations.

- Push and Drag: An Active Obstacle Separation Method for Fruit Harvesting Robots

    Author: Xiong, Ya | Norwegian University of Life Sciences
    Author: Ge, Yuanyue | Norwegian University of Life Sciences
    Author: From, P�l Johan | Norwegian University of Life Sciences
 
    keyword: Robotics in Agriculture and Forestry; Manipulation Planning; Field Robots

    Abstract : Selectively picking a target fruit surrounded by obstacles is one of the major challenges for fruit harvesting robots. Different from traditional obstacle avoidance methods, this paper presents an active obstacle separation strategy that combines push and drag motions. The separation motion and trajectory are generated based on the 3D visual perception of the obstacle information around the target. A linear push is used to clear the obstacles from the area below the target, while a zig-zag push that contains several linear motions is proposed to push aside more dense obstacles. The zig-zag push can generate multi-directional pushes and the side-to-side motion can break the static contact force between the target and obstacles, thus helping the gripper to receive a target in more complex situations. Moreover, we propose a novel drag operation to address the issue of mis-capturing obstacles located above the target, in which the gripper drags the target to a place with fewer obstacles and then pushes back to move the obstacles aside for further detachment. Furthermore, an image processing pipeline consisting of color thresholding, object detection using deep learning and point cloud operation, is developed to implement the proposed method on a harvesting robot. Field tests show that the proposed method can improve the picking performance substantially. This method helps to enable complex clusters of fruits to be harvested with a higher success rate than conventional methods.

## Calibration and Identification

- Unified Intrinsic and Extrinsic Camera and LiDAR Calibration under Uncertainties

    Author: K�mmerle, Julius | FZI Forschungszentrum Informatik
    Author: K�hner, Tilman | FZI Forschungszentrum Informatik
 
    keyword: Calibration and Identification; Sensor Fusion

    Abstract : Many approaches for camera and LiDAR calibration are presented in literature but none of them estimates all intrinsic and extrinsic parameters simultaneously and therefore optimally in a probabilistic sense. In this work, we present a method to simultaneously estimate intrinsic and extrinsic parameters of cameras and LiDARs in a unified problem.We derive a probabilistic formulation that enables flawless integration of different measurement types without hand-tuned weights.An arbitrary number of cameras and LiDARs can be calibrated simultaneously.Measurements are not required to be synchronized.The method is designed to work with any camera model. In evaluation, we show that additional LiDAR measurements significantly improve intrinsic camera calibration.Further, we show on real data that our method achieves state-of-the-art calibration precision with high reliability.

- AC/DCC : Accurate Calibration of Dynamic Camera Clusters for Visual SLAM

    Author: Rebello, Jason | University of Toronto
    Author: Fung, Angus | University of Toronto
    Author: Waslander, Steven Lake | University of Toronto
 
    keyword: Calibration and Identification; SLAM; Visual-Based Navigation

    Abstract : In order to relate information across cameras in a Dynamic Camera Cluster (DCC), an accurate time-varying set of extrinsic calibration transformations need to be determined. Previous calibration approaches rely solely on collecting measurements from a known fiducial target which limits calibration accuracy as insufficient excitation of the gimbal is achieved. In this paper, we improve DCC calibration accuracy by collecting measurements over the entire configuration space of the gimbal and achieve a 10X improvement in pixel re-projection error. We perform a joint optimization over the calibration parameters between any number of cameras and unknown joint angles using a pose-loop error optimization approach, thereby avoiding the need for overlapping fields-of-view. We test our method in simulation and provide a calibration sensitivity analysis for different levels of camera intrinsic and joint angle noise. In addition, we provide a novel analysis of the degenerate parameters in the calibration when joint angle values are unknown, which avoids situations in which the calibration cannot be uniquely recovered. The calibration code will be made available at https://github.com/TRAILab/AC-DCC

- Analytic Plane Covariances Construction for Precise Planarity-Based Extrinsic Calibration of Camera and LiDAR

    Author: Koo, Gunhee | Korea University
    Author: Kang, Jaehyeon | Korea University
    Author: Jang, Bumchul | Korea University
    Author: Doh, Nakju | Korea University
 
    keyword: Calibration and Identification; Sensor Fusion; RGB-D Perception

    Abstract : Planarity of checkerboards is a widely used feature for extrinsic calibration of camera and LiDAR. In this study, we propose two analytically derived covariances of (i) plane parameters and (ii) plane measurement, for precise extrinsic calibration of camera and LiDAR. These covariances allow the graded approach in planar feature correspondences by exploiting the uncertainty of a set of given features in calibration. To construct plane parameter covariance, we employ the error model of 3D corner points and the analytically formulated plane parameter errors. Next, plane measurement covariance is directly derived from planar regions of point clouds using the out-of-plane errors. In simulation validation, our method is compared to an existing uncertainty-excluding method using the different number of target poses and the different levels of noise. In field experiment, we validated the applicability of the proposed analytic plane covariances for precise calibration using the basic planarity-based method and the latest planarity-and-linearity-based method.

-  A Stable Adaptive Observer for Hard-Iron and Soft-Iron Bias Calibration and Compensation for Two-Axis Magnetometers: Theory and Experimental Evaluation

    Author: Spielvogel, Andrew Robert | Johns Hopkins University
    Author: Whitcomb, Louis | The Johns Hopkins University

- Extrinsic Calibration of an Eye-In-Hand 2D LiDAR Sensor in Unstructured Environments Using ICP

    Author: Peters, Arne | Technical University of Munich
    Author: Knoll, Alois | Tech. Univ. Muenchen TUM
    Author: Schmidt, Adam | TNO - the Netherlands Organisation for Applied Scientific Resear
 
    keyword: Calibration and Identification; Range Sensing; Computer Vision for Other Robotic Applications

    Abstract : We propose a calibration method for the six degrees of freedom (DOF) extrinsic pose of a 2D laser rangefinder mounted to a robot arm. Our goal is to design a system that allows on-site re-calibration without requiring any kind of special environment or calibration objects. By moving the sensor we generate 3D scans of the surrounding area on which we run a iterative closest point (ICP) variant to estimate the missing part of the kinematic chain. With this setup we can simply scale the density and format of our 3D scan by adjusting the robot speed and trajectory, allowing us to exploit the power of a high resolution 3D scanner for a variety of tasks such as mapping, object recognition and grasp planning. Our evaluation, performed on synthetic datasets as well as from real-data shows that the presented approach provides good results both in terms of convergence on crude initial parameters as well as in the precision of the final estimate.

- Geometric Robot Dynamic Identification: A Convex Programming Approach (I)

    Author: Lee, Taeyoon | Seoul National University
    Author: Wensing, Patrick M. | University of Notre Dame
    Author: Park, Frank | Seoul National University
 
    keyword: Calibration and Identification; Dynamics

    Abstract : Recent work has shed light on the often unreliable performance of constrained least-squares estimation methods for robot mass-inertial parameter identification, particularly for high degree-of-freedom systems subject to noisy and incomplete measurements. Instead, differential geometric identification methods have proven to be significantly more accurate and robust. These methods account for the fact that the mass-inertial parameters reside in a curved Riemannian space, and allow perturbations in the mass-inertial properties to be measured in a coordinate-invariant manner. Yet, a continued drawback of existing geometric methods is that the corresponding optimization problems are inherently nonconvex, have numerous local minima, and are computationally highly intensive to solve. In this paper, we propose a convex formulation under the same coordinate-invariant Riemannian geometric framework that directly addresses these and other deficiencies of the geometric approach. Our convex formulation leads to a globally optimal solution, reduced computations, faster and more reliable convergence, and easy inclusion of additional convex constraints. The main idea behind our approach is an entropic divergence measure that allows for the convex regularization of the inertial parameter identification problem. Extensive experiments with the 3-DoF MIT Cheetah leg, the 7-DoF AMBIDEX tendon-driven arm, and a 16-link articulated human model show markedly improved robustness and generalizability.

- A Novel Calibration Method between a Camera and a 3D LiDAR with Infrared Images

    Author: Chen, Shoubin | Wuhan University
    Author: Liu, Jingbin | Wuhan University
    Author: Liang, Xinlian | Finnish Geospatial Research Institute
    Author: Zhang, Shuming | Wuhan University
    Author: Ruizhi, Chen | Wuhan University
    Author: Hyypp�, Juha | Finnish Geospatial Research Institute
 
    keyword: Calibration and Identification; Sensor Fusion; Range Sensing

    Abstract : Fusions of LiDARs (light detection and ranging) and cameras have been effectively and widely employed in the communities of autonomous vehicles, virtual reality and mobile mapping systems (MMS) for different purposes, such as localization, high definition map or simultaneous location and mapping. However, the extrinsic calibration between a camera and a 3D LiDAR is a fundamental prerequisite to guarantee its performance. Some previous methods are inaccurate, have calibration error that is several times the beam divergence, and often require special calibration objects, thereby limiting their ubiquitous use for calibration. To overcome these shortcomings, we propose a novel and high-accuracy method for the extrinsic calibration between a camera and a 3D LiDAR. Our approach relies on the infrared images from a camera with an infrared filter, and the 2D-3D corresponding points in a scene with the corners of a wall can be extracted to calculate the six extrinsic parameters. Experiments using the Velodyne VLP-16 sensor show that the method can achieve an extrinsic accuracy at the level of the beam divergence, which is fully analyzed and validated from two different aspects. Therefore, the calibration method in this paper is highly accurate, effective and does not require special complicated calibration objects; thus, it meets the requirements of practical applications.

- Online Camera-LiDAR Calibration with Sensor Semantic Information

    Author: Zhu, Yufeng | Pony.ai
    Author: Li, Chenghui | Carnegie Mellon University
    Author: Zhang, Yubo | Pony.ai
 
    keyword: Calibration and Identification; Object Detection, Segmentation and Categorization

    Abstract : As a crucial step of sensor data fusion, sensor calibration plays a vital role in many cutting-edge machine vision applications, such as autonomous vehicles and AR/VR. Existing techniques either require quite amount of manual work and complex settings, or are unrobust and prone to produce suboptimal results. In this paper, we investigate the extrinsic calibration of an RGB camera and a light detection and ranging (LiDAR) sensor, which are two of the most widely used sensors in autonomous vehicles for perceiving the outdoor environment. Specifically, we introduce an online calibration technique that automatically computes the optimal rigid motion transformation between the aforementioned two sensors and maximizes their mutual information of perceived data, without the need of tuning environment settings. By formulating the calibration as an optimization problem with a novel calibration quality metric based on semantic features, we successfully and robustly align pairs of temporally synchronized camera and LiDAR frames in real time. Demonstrated on several autonomous driving tasks, our method outperforms state-of-the-art edge feature based auto-calibration approaches in terms of robustness and accuracy.

- Precise 3D Calibration of Wafer Handling Robot by Visual Detection and Tracking of Elliptic-Shape Wafers

    Author: Wang, Zining | University of California, Berkeley
    Author: Tomizuka, Masayoshi | University of California
 
    keyword: Calibration and Identification; Visual Tracking; Computer Vision for Automation

    Abstract : This work provides a framework for the 3D calibration of wafers and a wafer handling robot by monocular. The proposed method precisely reconstructs the 3D pose of wafers from a set of images captured by the camera mounted on the robot. Besides, it calibrates the robot kinematics simultaneously. A robust ellipse detection and tracking algorithm based on the edge arcs is developed to recognize wafers among images. Then a joint optimization is constructed from pose graph to simultaneously solve the 3D poses of wafers and other calibration parameters of the robot-camera system. The proposed tracking method is able to associate multiple incomplete elliptic segments using a GMM-based registration model. And it is point-based where no feature descriptor is required. The proposed 3D pose optimization incorporates shape constraint and is more accurate than the point-wise reconstruction of classic bundle adjustment methods.

- Globally Optimal Relative Pose Estimation for Camera on a Selfie Stick

    Author: Joo, Kyungdon | Korea Advanced Institute of Science and Technology (KAIST)
    Author: Li, Hongdong | Australian National University and NICTA
    Author: Oh, Tae-Hyun | MIT
    Author: Bok, Yunsu | Electronics and Telecommunication Research Institute (ETRI)
    Author: Kweon, In So | KAIST
 
    keyword: Calibration and Identification; Computer Vision for Other Robotic Applications; SLAM

    Abstract : Taking selfies has become a photographic trend nowadays. We envision the emergence of the �video selfie� capturing a short continuous video clip (or burst photography) of the user, themselves. A selfie stick is usually used, whereby a camera is mounted on a stick for taking selfie photos. In this scenario, we observe that the camera typically goes through a special trajectory along a sphere surface. Motivated by this observation, in this work, we propose an efficient and globally optimal relative camera pose estimation between a pair of two images captured by a camera mounted on a selfie stick. We exploit the special geometric structure of the camera motion constrained by a selfie stick and define its motion as spherical joint motion. By the new parametrization and calibration scheme, we show that the pose estimation problem can be reduced to a 3-DoF (degrees of freedom) search problem, instead of a generic 6-DoF problem. This allows us to derive a fast branch-and-bound global optimization, which guarantees a global optimum. Thereby, we achieve efficient and robust estimation even in the presence of outliers. By experiments on both synthetic and real-world data, we validate the performance as well as the guaranteed optimality of the proposed method.

- Online Calibration of Exterior Orientations of a Vehicle-Mounted Surround-View Camera System

    Author: Ouyang, Zhanpeng | Shanghaitech University
    Author: Hu, Lan | ShanghaiTech University
    Author: Lu, Yukan | Motovis
    Author: Wang, Zhirui | Motovis
    Author: Peng, Xin | ShanghaiTech University
    Author: Kneip, Laurent | ShanghaiTech
 
    keyword: Calibration and Identification; Omnidirectional Vision; Localization

    Abstract : The increasing availability of surround-view camera systems in passenger vehicles motivates their use as an exterior perception modality for intelligent vehicle behaviour. An important problem within this context is the extrinsic calibration between the cameras, which is challenging due to the often reduced overlap between the fields of view of neighbouring views. Our work is motivated by two insights. First, we argue that the accuracy of vision-based vehicle motion estimation depends crucially on the quality of exterior orientation calibration, while design parameters for camera positions typically provide sufficient accuracy. Second, we demonstrate how planar vehicle motion related direction vectors can be used to accurately identify individual camera-to-vehicle rotations, which are more useful than the commonly and tediously derived camera-to-camera transformations. We present a complete and highly practicable online optimisation strategy to obtain the exterior orientation parameters and conclude with successful tests on simulated, indoor, and large-scale outdoor experiments.

- Learning Camera Miscalibration Detection

    Author: Cramariuc, Andrei | ETHZ
    Author: Petrov, Aleksandar | ETH Zurich
    Author: Suri, Rohit | ETH Zurich
    Author: Mittal, Mayank | ETH
    Author: Siegwart, Roland | ETH Zurich
    Author: Cadena Lerma, Cesar | ETH Zurich
 
    keyword: Calibration and Identification; Deep Learning in Robotics and Automation; Computer Vision for Other Robotic Applications

    Abstract : Self-diagnosis and self-repair are some of the key challenges in deploying robotic platforms for long-term real-world applications. One of the issues that can occur to a robot is miscalibration of its sensors due to aging, environmental transients, or external disturbances. Precise calibration lies at the core of a variety of applications, due to the need to accurately perceive the world. However, while a lot of work has focused on calibrating the sensors, not much has been done towards identifying when a sensor needs to be recalibrated. This paper focuses on a data-driven approach to learn the detection of miscalibration in vision sensors, specifically RGB cameras. Our contributions include a proposed miscalibration metric for RGB cameras and a novel semi-synthetic dataset generation pipeline based on this metric. Additionally, by training a deep convolutional neural network, we demonstrate the effectiveness of our pipeline to identify whether a recalibration of the camera's intrinsic parameters is required or not. The code is available at http://github.com/ethz-asl/camera_miscalib_detection.

## Industrial Robots

- An End-Effector Wrist Module for the Kinematically Redundant Manipulation of Arm-Type Robots

    Author: Chang, Yu-Hsiang | National Cheng Kung University
    Author: Liu, Yen-Chun | National Cheng Kung University
    Author: Lan, Chao-Chieh | National Cheng Kung University
 
    keyword: Kinematics; Dexterous Manipulation; Mechanism Design

    Abstract : Industrial arm-type robots have multiple degrees-of-freedom (DoFs) and high dexterity but the use of the roll-pitch-roll wrist configuration yields singularities inside the reachable workspace. Excessive joint velocities will occur when encountering these singularities. Arm-type robots currently don�t have enough dexterity to move the end-effector path away from the wrist singularities. Robots with redundant DoFs can be used to provide additional dexterity required to avoid the singularities and reduce the excessive joint velocity. An end-effector wrist module is proposed in this paper to provide two redundant DoFs when interfaced with an existing 6-DoF robot. The new 8-DoF robot has a compact roll-pitch-yaw wrist that has no singularities inside the reachable workspace. The highly redundant robot can also be used to avoid collisions in various directions. Path tracking simulation examples are provided to show the advantages of the proposed design when compared with existing redundant or nonredundant robots. We expect that this module can serve as a cost-effective solution in applications where singularity-free motion or collision-free motion is required.

- Robust Path Following of the Tractor-Trailers System in GPS-Denied Environments

    Author: Zhou, Shunbo | The Chinese University of Hong Kong
    Author: Zhao, Hongchao | The Chinese University of Hong Kong
    Author: Chen, Wen | The Chinese University of Hong Kong
    Author: Miao, Zhiqiang | Hunan University
    Author: Liu, Zhe | The Chinese University of Hong Kong
    Author: Wang, Hesheng | Shanghai Jiao Tong University
    Author: Liu, Yunhui | Chinese University of Hong Kong
 
    keyword: Industrial Robots; Visual Servoing

    Abstract : This paper reports a general path following framework for the tractor-trailers system in Global Positioning System (GPS)-denied environments. Compared to existing methods, this approach prioritizes a robust, cost-optimized, and easy-to-implement solution. First, to achieve accurate path following, a force sensor is subtly introduced to capture the impact of an arbitrary number of trailers and varying payloads on the tractor dynamics. A robust controller is then designed on the basis of a newly derived tractor dynamic model and the lateral force compensation. Second, a novel visual-inertial estimator, which explicitly considers the nonlinear velocity dynamics, is developed to allow real-time translational velocity and position estimation for dynamic feedback control. It is rigorously proved by the Lyapunov theory that the stability of the proposed estimation and control system is guaranteed. Full-scale experiments are conducted to demonstrate the feasibility of the approach.

- Online Trajectory Planning for an Industrial Tractor Towing Multiple Full Trailers

    Author: Zhao, Hongchao | The Chinese University of Hong Kong
    Author: Chen, Wen | The Chinese University of Hong Kong
    Author: Zhou, Shunbo | The Chinese University of Hong Kong
    Author: Liu, Zhe | The Chinese University of Hong Kong
    Author: Zheng, Fan | The Chinese University of Hong Kong
    Author: Liu, Yunhui | Chinese University of Hong Kong
 
    keyword: Industrial Robots; Motion and Path Planning

    Abstract : This paper presents a novel solution for online trajectory planning of a full-size tractor-trailers vehicle composed of a car-like tractor and arbitrary number of passive full trailers. The motion planning problem for such systems was rarely addressed due to the complex nonlinear dynamics. A simulation-based prediction method is proposed to easily handle the complicated nonlinear dynamics and efficiently generate the obstacle-free and dynamically feasible trajectories. The vehicle dynamics model and a two-layer controller are used in the prediction. Implementation results on the real-world full-size industrial tractor-trailers vehicle are presented to validate the performance of the proposed methods.

- Towards Efficient Human Robot Collaboration with Robust Plan Recognition and Trajectory Prediction

    Author: Cheng, Yujiao | University of California, Berkeley
    Author: Sun, Liting | University of California, Berkeley
    Author: Liu, Changliu | Carnegie Mellon University
    Author: Tomizuka, Masayoshi | University of California
 
    keyword: Industrial Robots; Recognition; Cognitive Human-Robot Interaction

    Abstract : Human-robot collaboration (HRC) is becoming increasingly important as the paradigm of manufacturing is shifting from mass production to mass customization. The introduction of HRC can significantly improve the flexibility and intelligence of automation. To efficiently finish tasks in HRC systems, the robots need to not only predict the future movements of human, but also more high-level plans, i.e., the sequence of actions to finish the tasks. However, due to the stochastic and time-varying nature of human collaborators, it is quite challenging for the robot to efficiently and accurately identify such task plans and respond in a safe manner. To address this challenge, we propose an integrated human-robot collaboration framework. Both plan recognition and trajectory prediction modules are included for the generation of safe and efficient robotic motions. Such a framework enables the robots to perceive, predict and adapt their actions to the human's work plan and intelligently avoid collisions with the human. Moreover, by explicitly leveraging the hierarchical relationship between plans and trajectories, more robust plan recognition performance can be achieved. Physical experiments were conducted on an industrial robot to verify the proposed framework. The results show that the proposed framework could accurately recognize the human workers' plans and thus significantly improve the time efficiency of the HRC team even in the presence of motion classification noises.

- Collaborative Human-Robot Framework for Delicate Sanding of Complex Shape Surface

    Author: Maric, Bruno | Univeristy of Zagreb, Faculty of Electrical Engineering and Comp
    Author: Mutka, Alan | Faculty of EE&amp;C
    Author: Orsag, Matko | University of Zagreb, Faculty of Electrical Engineering and Comp
 
    keyword: Industrial Robots; Contact Modeling; Force Control

    Abstract : This letter presents a collaborative human-robot framework for delicate sanding of complex shape surfaces. Delicate sanding is performed using a standard industrial manipulator, equipped with the force/torque sensor and specially designed compliant control algorithm. Together with the compliant control, we discuss trajectory planning and safety problem of such an approach. The experience of the human workers is exploited trough the intuitive framework and applied to plan the trajectories for the robot. The flexibility and the reliability of the proposed framework is tested in real working conditions in the factory.

- External Force Estimation for Industrial Robots with Flexible Joints

    Author: Lin, Yang | Huazhong University of Science and Technology
    Author: Zhao, Huan | Huazhong University of Science and Technology
    Author: Ding, Han | Huazhong University of Science and Technology
 
    keyword: Industrial Robots; Dynamics

    Abstract : With no force sensors, estimating forces for robotic manipulation has gained a lot of attention. However, for industrial robots with harmonic drives (flexible joints), deviations between joint and motor positions inevitably deteriorate the force estimation performance due to the lack of encoders on the joint side. To this end, this paper presents a method to estimate not only joint states but also external forces. The method includes an extended disturbance state observer (DSO) and a proposed task-oriented disturbance modeling (TDM). First, a robust DSO is extended to robots with flexible joints aiming to estimate joint states and disturbances. Then, due to the observed disturbances including (possibly) external forces and also uncertainties such as measurement noises and model errors of the robot dynamics, a learning part is proposed to model the task-oriented disturbances during no-contact motion and to improve the effect of uncertainties on the force estimation performance. Finally, when the robot comes in contact with the environment, external forces are estimated as the differences between the modeled (no-contact) disturbances and the real-time observed disturbances. Experimental results obtained on a six-degrees-of-freedom (6-DOF) industrial robot with flexible joints, show the feasibility and effectiveness of the proposed method.

- Robotic General Parts Feeder: Bin-Picking, Regrasping, and Kitting

    Author: Domae, Yukiyasu | The National Institute of Advanced Industrial Science and Techno
    Author: Noda, Akio | Osaka Institute of Technology
    Author: Nagatani, Tatsuya | Mitsubishi Electric Corp
    Author: Wan, Weiwei | Osaka University
 
    keyword: Industrial Robots; Manipulation Planning; Multi-Robot Systems

    Abstract : Parts feeding of multiple objects is an unsolved problem which should be tackled by robotics. We propose a systematic approach to make general parts feeders for various shape's rigid parts. We divided the problem into three subcomponents: bin-picking, regrasping, and kitting. The subcomponents are designed to solve the large systematic problem by using a coarse-to-fine approach. Multiple robot arms are connected as a pipe line system to solve each subcomponent. In addition, we proposed a semi-automatic method for teaching of regrasping by multiple robots. Thus the robot systems can supply multiple types of parts. In our experiment by using eleven types of industrial parts which has various shapes, the Mean Picks Per Hour (MPPH) of the system becomes about 350. The score is faster than the state-of-the-art robotic bin- picking system. In addition, lead time by the proposed method for changing parts is less than by a combination of traditional parts feeders or a manual labor.

- Planning, Learning and Reasoning Framework for Robot Truck Unloading

    Author: Islam, Fahad | National University of Sciences and Technology
    Author: Vemula, Anirudh | Carnegie Mellon University
    Author: Kim, Sung-Kyun | NASA Jet Propulsion Laboratory, Caltech
    Author: Dornbush, Andrew | Carnegie Mellon University
    Author: Salzman, Oren | Technion
    Author: Likhachev, Maxim | Carnegie Mellon University
 
    keyword: Factory Automation; Industrial Robots; Task Planning

    Abstract : We consider the task of autonomously unloading boxes from trucks using an industrial manipulator robot. There are multiple challenges that arise: (1) real-time motion planning for a complex robotic system carrying two articulated mechanisms, an arm and a scooper, (2) decision-making in terms of what action to execute next given imperfect information about boxes such as their masses, (3) accounting for the sequential nature of the problem where current actions affect future state of the boxes, and (4) real-time execution that interleaves high-level decision-making with lower level motion planning. In this work, we propose a planning, learning, and reasoning framework to tackle these challenges, and describe its components including motion planning, belief space planning for offline learning, online decision-making based on offline learning, and an execution module to combine decision-making with motion planning. We analyze the performance of the framework on real-world scenarios. In particular, motion planning and execution modules are evaluated in simulation and on a real robot, while offline learning and online decision-making are evaluated in simulated real-world scenarios.

- Evaluation of Perception Latencies in a Human-Robot Collaborative Environment

    Author: Aalerud, Atle | University of Agder
    Author: Hovland, Geir | University of Agder
 
    keyword: Industrial Robots; Computer Vision for Other Robotic Applications; RGB-D Perception

    Abstract : The latency in vision-based sensor systems used in human-robot collaborative environments is an important safety parameter which in most cases has been neglected by researchers. The main reason for this neglect is the lack of an accurate ground-truth sensor system with a minimal delay to benchmark the vision-sensors against. In this paper the latencies of 3D vision-based sensors are experimentally evaluated and analyzed using an accurate laser-tracker system which communicates on a dedicated EtherCAT channel with minimal delay. The experimental results in the paper demonstrate that the latency in the vision-based sensor system is many orders higher than the latency in the control and actuation system.

- Assembly of Randomly Placed Parts Realized by Using Only One Robot Arm with a General Parallel-Jaw Gripper

    Author: Zhao, Jie | Harbin Institute of Technology, Shenzhen
    Author: Wang, Xiaoman | Harbin Institute of Technology, Shenzhen
    Author: Wang, Shengfan | Harbin Institute of Technology
    Author: Jiang, Xin | Harbin Institute of Technology, Shenzhen
    Author: Liu, Yunhui | Chinese University of Hong Kong
 
    keyword: Factory Automation; Dexterous Manipulation; Grippers and Other End-Effectors

    Abstract : In industry assembly lines, parts feeding machines are widely employed as the prologue of the whole procedure. They play the role of sorting the parts randomly placed in bins to the state with specified pose.	With the help of the parts feeding machines, the subsequent assembly processes by robot arm can always start from the same condition. Thus it is expected that function of parting feeding machine and the robotic assembly can be integrated with one robot arm. This scheme can provide great flexibility and can also contribute to reduce the cost. The difficulties involved in this scheme lie in the fact that in the part feeding phase, the pose of the part after grasping may be not proper for the subsequent assembly. Sometimes it can not even guarantee a stable grasp. In this paper, we proposed a method to integrate parts feeding and assembly within one robot arm.	This proposal utilizes a specially designed gripper tip mounted on the jaws of a two-fingered gripper. With the modified gripper, in-hand manipulation of the grasped object is realized, which can ensure the control of the orientation and offset position of the grasped object. The proposal in this paper is verified by a simulated assembly in which a robot arm completed the assembly process including parts picking from bin and a subsequent peg-in-hole assembly.

- Drive-Based Vibration Damping Control for Robot Machining

    Author: Mesmer, Patrick | University of Stuttgart
    Author: Neubauer, Michael | University of Stuttgart
    Author: Lechler, Armin | University Stuttgart
    Author: Verl, Alexander | University of Stuttgart
 
    keyword: Industrial Robots; Motion Control

    Abstract : The objective of this letter is to propose a drive-based control method for damping joint vibrations in order to improve the machining quality and the productivity of robot machining. The machining quality is significantly determined by the transfer behavior of the gearboxes installed in the robot joints. This letter presents a novel approach for drive-based damping of these vibrations and thus for increasing the dynamic path accuracy on the basis of secondary encoders. The approach represents an enhancement of the independent joint control, which is widely used in industry. The simulation as well as the experimental results on a KUKA KR210-2 demonstrate the effectiveness of the presented control method for damping gearbox vibrations and increasing the dynamic path accuracy of industrial robot manipulators.

- Toward Fast and Optimal Robotic Pick-And-Place on a Moving Conveyor

    Author: Han, Shuai D. | Rutgers University
    Author: Feng, Si Wei | Rutgers University
    Author: Yu, Jingjin | Rutgers University
 
    keyword: Factory Automation; Planning, Scheduling and Coordination; Industrial Robots

    Abstract : Robotic pick-and-place (PNP) operations on moving conveyors find a wide range of industrial applications. In practice, simple greedy heuristics (e.g., prioritization based on the time to process a single object) are applied that achieve reasonable efficiency. We show analytically that, under a simplified telescoping robot model, these greedy approaches do not ensure time optimality of PNP operations. To address the shortcomings of classical solutions, we develop algorithms that compute optimal object picking sequences for a predetermined finite horizon. Employing dynamic programming techniques and additional heuristics, our methods scale to up to tens to hundreds of objects. In particular, the fast algorithms we develop come with running time guarantees, making them suitable for real-time PNP applications demanding high throughput. Extensive evaluation of our algorithmic solution over dominant industrial PNP robots used in real-world applications, i.e., Delta robots and Selective Compliance Assembly Robot Arm (SCARA) robots, shows that a typical efficiency gain of around 10%-40% over greedy approaches can be realized.

## Biomimetics

- A Bio-Inspired Transportation Network for Scalable Swarm Foraging

    Author: Lu, Qi | University of New Mexico
    Author: Fricke, George Matthew | The University of New Mexico
    Author: Tsuno, Takaya | Mie University
    Author: Moses, Melanie | University of New Mexico
 
    keyword: Collision Avoidance; Swarms; Biologically-Inspired Robots

    Abstract : Scalability is a significant challenge for robot swarms. Generally, larger groups of cooperating robots produce more inter-robot collisions, and in swarm robot foraging, larger search arenas result in larger travel costs. This paper demonstrates a scale-invariant swarm foraging algorithm that ensures that each robot finds and delivers resources to a central collection zone at the same rate regardless of the size of the swarm or the search area. Dispersed mobile depots aggregate locally foraged resources and transport them to a central place via a hierarchical branching transportation network. This approach is inspired by ubiquitous fractal branching networks such as tree branches and mammal cardiovascular networks that deliver resources to cells and determine the scale and pace of life. We demonstrate that biological scaling laws predict how quickly robots forage in simulations of up to thousands of robots searching over thousands of square meters. We then use biological scaling claims to determine the capacity of depot robots in order to overcome scaling constraints and produce scale-invariant robot swarms. We verify the claims for large swarms in simulation and implement a simple depot design in simulation and hardware.

- Stance Control Inspired by Cerebellum Stabilizes Reflex-Based Locomotion on HyQ Robot

    Author: Urbain, Gabriel | Ghent University
    Author: Barasuol, Victor | Istituto Italiano Di Tecnologia
    Author: Semini, Claudio | Istituto Italiano Di Tecnologia
    Author: Dambre, Joni | Ghent University
    Author: Wyffels, Francis | Ghent University
 
    keyword: Neurorobotics; Legged Robots; Neural and Fuzzy Control

    Abstract : Advances in legged robotics are strongly rooted in animal observations. A clear illustration of this claim is the generalization of Central Pattern Generators (CPG), first identified in the cat spinal cord, to generate cyclic motion in robotic locomotion. Despite a global endorsement of this model, physiological and functional experiments in mammals have also indicated the presence of descending signals from the cerebellum, and reflex feedback from the lower limb sensory cells, that closely interact with CPGs. To this day, these interactions are not fully understood. In some studies, it was demonstrated that pure reflex-based locomotion in the absence of oscillatory signals could be achieved in realistic musculoskeletal simulation models or small compliant quadruped robots. At the same time, biological evidence has attested the functional role of the cerebellum for predictive control of balance and stance within mammals. In this paper, we promote both approaches and successfully apply reflex-based dynamic locomotion, coupled with a balance and gravity compensation mechanism, on the state-of-art HyQ robot. We discuss the importance of this stability module to ensure a correct foot lift-off and maintain a reliable gait. The robotic platform is further used to test two different architectural hypotheses inspired by the cerebellum. An analysis of experimental results demonstrates that the most biologically plausible alternative also leads to better results for robust locomotion.

- Error Estimation and Correction in a Spiking Neural Network for Map Formation in Neuromorphic Hardware

    Author: Kreiser, Raphaela | Institute of Neuroinformatics, Univeristy Zurich and ETH Zurich
    Author: Waibel, Gabriel Guenter | ETH Zurich
    Author: Armengol, Nuria | ETH Zurich
    Author: Renner, Alpha | Institute of Neuroinformatics, University of Zurich and ETH Zuri
    Author: Sandamirskaya, Yulia | University and ETH Zurich
 
    keyword: Neurorobotics; Biologically-Inspired Robots; Biomimetics

    Abstract : Neuromorphic hardware offers computing platforms for the efficient implementation of spiking neural networks (SNNs) that can be used for robot control. Here, we present such an SNN on a neuromorphic chip that solves a number of tasks related to simultaneous localization and mapping (SLAM): forming a map of an unknown environment and, at the same time, estimating the robot's pose. In particular, we present an SNN mechanism to detect and estimate errors when the robot revisits a known landmark and updates both the map and the path integration speed to reduce the error. The whole system is fully realized in a neuromorphic device, showing the feasibility of a purely SNN-based SLAM, which could be efficiently implemented in a small form-factor neuromorphic chip.

- A Hybrid Compact Neural Architecture for Visual Place Recognition

    Author: Chanc�n Le�n, Marvin Aldo | Queensland University of Technology
    Author: Hernandez-Nunez, Luis | Harvard University
    Author: Narendra, Ajay | Macquarie University
    Author: Barron, Andrew | Macquarie University
    Author: Milford, Michael J | Queensland University of Technology
 
    keyword: Biomimetics; Localization; Visual-Based Navigation

    Abstract : State-of-the-art algorithms for visual place recognition, and related visual navigation systems, can be broadly split into two categories: computer-science-oriented models including deep learning or image retrieval-based techniques with minimal biological plausibility, and neuroscience-oriented dynamical networks that model temporal properties underlying spatial navigation in the brain. In this letter, we propose a new compact and high-performing place recognition model that bridges this divide for the first time. Our approach comprises two key neural models of these categories: (1) FlyNet, a compact, sparse two-layer neural network inspired by brain architectures of fruit flies, Drosophila melanogaster, and (2) a one-dimensional continuous attractor neural network (CANN). The resulting FlyNet+CANN network incorporates the compact pattern recognition capabilities of our FlyNet model with the powerful temporal filtering capabilities of an equally compact CANN, replicating entirely in a hybrid neural implementation the functionality that yields high performance in algorithmic localization approaches like SeqSLAM. We evaluate our model, and compare it to three state-of-the-art methods, on two benchmark real-world datasets with small viewpoint variations and extreme environmental changes - achieving 87% AUC results under day to night transitions compared to 60% for Multi-Process Fusion, 46% for LoST-X and 1% for SeqSLAM, while being 6.5, 310, and 1.5 times faster, respectively.

- Musculoskeletal AutoEncoder: A Unified Online Acquisition Method of Intersensory Networks for State Estimation, Control, and Simulation of Musculoskeletal Humanoids

    Author: Kawaharazuka, Kento | The University of Tokyo
    Author: Tsuzuki, Kei | University of Tokyo
    Author: Onitsuka, Moritaka | The University of Tokyo
    Author: Asano, Yuki | The University of Tokyo
    Author: Okada, Kei | The University of Tokyo
    Author: Kawasaki, Koji | The University of Tokyo
    Author: Inaba, Masayuki | The University of Tokyo
 
    keyword: Biomimetics; Humanoid Robots; Tendon/Wire Mechanism

    Abstract : While the musculoskeletal humanoid has various biomimetic benefits, the modeling of its complex structure is difficult, and many learning-based systems have been developed so far. There are various methods, such as control methods using acquired relationships between joints and muscles represented by a data table or neural network, and state estimation methods using Extended Kalman Filter or table search. In this study, we construct a Musculoskeletal AutoEncoder representing the relationship among joint angles, muscle tensions, and muscle lengths, and propose a unified method of state estimation, control, and simulation of musculoskeletal humanoids using it. By updating the Musculoskeletal AutoEncoder online using the actual robot sensor information, we can continuously conduct more accurate state estimation, control, and simulation than before the online learning. We conducted several experiments using the musculoskeletal humanoid Musashi, and verified the effectiveness of this study.

- Snake-Inspired Kirigami Skin for Lateral Undulation of a Soft Snake Robot

    Author: Branyan, Callie | Oregon State University
    Author: Hatton, Ross | Oregon State University
    Author: Menguc, Yigit | Facebook Reality Labs
 
    keyword: Soft Robot Materials and Design; Biologically-Inspired Robots; Flexible Robots

    Abstract : Frictional anisotropy, as produced by the directionality of scales in snake skin, is necessary to propel snakes across flat, hard surfaces. This work illustrates the design, fabrication, and testing of a snake-inspired skin based on kirigami techniques that, when attached to a soft snake robot, improves the robot's locomotion capabilities when implementing a lateral undulation gait. Examination of snake scales in nature informed the shape and texture of the synthetic scales, which are activated through the buckling of kirigami lattices. Biological snakes have microornamentation on their scales, which is replicated by scoring ridges into the plastic skin. This microornamentation contributes to the lateral resistance necessary for lateral undulation. The skin's frictional properties were experimentally determined, as were their contributions to the locomotion of the robot across a flat, hard, textured surface. Contributions to locomotion from scale profile geometry, scale microornamentation, and scale angle of attack were identified. The range of longitudinal COF ratios was 1.0 to 3.0 and the range of lateral COF ratios was 0.9 to 3.3. The highest performing skin was the triangular scale profile with microornamentation, producing a velocity of 6 mm/s (0.03 BL/s) which is an increase of 335% over the robot with no skin when activated to maximum achievable curvature.

- Bio-Inspired Distance Estimation Using the Self-Induced Acoustic Signature of a Motor-Propeller System

    Author: Calkins, Luke | Duke University
    Author: Lingevitch, Joseph | U.S. Naval Research Laboratory
    Author: McGuire, Loy | U.S. Naval Research Laboratory
    Author: Geder, Jason | U.S. Naval Research Laboratory
    Author: Kelly, Matthew | U.S. Naval Research Laboratory
    Author: Zavlanos, Michael M. | Duke University
    Author: Sofge, Donald | Naval Research Laboratory
    Author: Lofaro, Daniel | George Mason University
 
    keyword: Biomimetics; Range Sensing; Robot Audition

    Abstract : In this paper we propose an algorithm to actively control the distance of a motor-propeller system (MPS) to a large obstacle using data from a single microphone. The method is based upon a broadband constructive/destructive interference pattern across the audible frequency band that is present when the MPS is near an obstacle. By taking the difference between the power spectrum in the obstacle-free case and the spectrum when recording near an obstacle, a broadband oscillation with respect to frequency is revealed. The frequency of this oscillation is linearly-related to the distance from the microphone to the wall. We present both static and dynamic experiments showcasing the ability of the proposed method to estimate the distance to a wall as well as actively control it.

- A Bio-Inspired 3-DOF Light-Weight Manipulator with Tensegrity X-Joints

    Author: Fasquelle, Benjamin | Ecole Centrale De Nantes, LS2N
    Author: Furet, Matthieu | Laboratoire Des Sciences Du Num�rique De Nantes (LS2N)
    Author: Khanna, Parag | Laboratoire Des Sciences Du Num�rique De Nantes, École Centrale
    Author: Chablat, Damien | Laboratoire Des Sciences Du Num�rique De Nantes
    Author: Chevallereau, Christine | CNRS
    Author: Wenger, Philippe | Ecole Centrale De Nantes
 
    keyword: Biomimetics; Motion Control of Manipulators; Tendon/Wire Mechanism

    Abstract : This paper proposes a new kind of light-weight manipulators suitable for safe interactions. The proposed manipulators use anti-parallelogram joints in series, referred to as X-joints. Each X-joint is remotely actuated with cables and springs in parallel, thus realizing a tensegrity one-degree-of-freedom mechanism. As compared to manipulators built with simple revolute joints in series, manipulators with tensegrity X-joint offer a number of advantages, such as an intrinsic stability, variable stiffness and lower inertia. This new design was inspired by the musculosleketon architecture of the bird neck that is known to have remarkable features such as a high dexterity. The paper analyzes in detail the kinetostatics of a X-joint and proposes a 3-degree-of-freedom manipulator made of three such joints in series. Both simulation results and experiment results conducted on a test-bed prototype are presented and discussed.

- The Lobster-Inspired Antagonistic Actuation Mechanism towards a Bending Module

    Author: Chen, Yaohui | Monash University
    Author: Chung, Hoam | Monash University
    Author: Chen, Bernard | Monash University
    Author: , Baoyinjiya | Monash University
    Author: Sun, Yonghang | Monash Univerity
 
    keyword: Biomimetics; Soft Sensors and Actuators

    Abstract : This paper describes a new type of bending module inspired, in part, by the musculoskeletal structure of the lobster leg joint. The bending module proposed combines enhanced torque output, reconfigurability in assembling, safe compliant actuation, and accurate control on its mechanical performance. In this module, antagonistic soft chambers are enveloped by exoskeleton shells, and the bending angle and the stiffness can be independently adjusted by controlling the input pressure in the two chambers. Theoretical models are developed to characterize the relationships between the input pressure, bending angle, and stiffness, and a controller for angle control and stiffness tuning is constructed with experimental validation. The fabricated module can reach the maximum torque output of 109.7 Ncdotmm under 40 kPa and the stiffness range from 40 to 220 Ncdotmm / rad, demonstrating its capacity to fulfill both safe interactions and forceful tasks.

- Emulating Duration and Curvature of Coral Snake Anti-Predator Thrashing Behaviors Using a Soft-Robotic Platform

    Author: Danforth, Shannon | University of Michigan
    Author: Kohler, Margaret | University of Michigan
    Author: Bruder, Daniel | University of Michigan
    Author: Davis Rabosky, Alison | University of Michigan
    Author: Kota, Sridhar | University of Michigan
    Author: Vasudevan, Ram | University of Michigan
    Author: Moore, Talia | University of Michigan
 
    keyword: Biomimetics; Soft Robot Applications; Soft Robot Materials and Design

    Abstract : This paper presents a soft-robotic platform for exploring the ecological relevance of non-locomotory movements via animal-robot interactions. Coral snakes (genus <i>Micrurus</i>) and their mimics use vigorous, non-locomotory, and arrhythmic thrashing to deter predation. There is variation across snake species in the duration and curvature of anti-predator thrashes, and it is unclear how these aspects of motion interact to contribute to snake survival. This paper applies soft robots composed of fiber-reinforced elastomeric enclosures (FREEs) to emulate the anti-predator behaviors of three genera of snake. Curvature and duration of motion are estimated for both live snakes and robots, providing a quantitative assessment of the robots' ability to emulate snake poses. The curvature values of the fabricated soft-robotic head, midsection, and tail segments are found to overlap with those exhibited by live snakes. Soft robot motion durations were less than or equal to those of snakes for all three genera. Additionally, combinations of segments were selected to emulate three specific snake genera with distinct anti-predatory behavior, producing curvature values that aligned well with live snake observations.

- Directional Mechanical Impedance of the Human Ankle During Standing with Active Muscles

    Author: Aramizo Ribeiro, Guilherme | Purdue University
    Author: Knop, Lauren | Michigan Technological University
    Author: Rastgaar, Mo | Purdue University
 
    keyword: Biomimetics; Kinematics; Neurorobotics

    Abstract : The directional mechanical impedance of the human ankle was identified from subjects in a standing posture with varying levels of muscle activity. The impedance modeled the different torque responses to angle perturbations about different axes of rotation. This work proposed a novel impedance model that incorporated the coupling between multiple degrees of freedom of the ankle and was validated theoretically and experimentally. The reconstructed torque had an average variance accounted above 94% across twelve subjects. In addition, the impedance varied between and within trials and this variation was explained by changes in the ankle states, i.e., the ankle angle, torque, and muscle activities. These results have implications in the design of new prostheses controllers and the understanding of the human ankle function.

- Insect�Computer Hybrid Robot Achieves a Walking Gait Rarely Seen in Nature by Replacing the Anisotropic Natural Leg Spines with Isotropic Artificial Leg Spines (I)
 
    Author: Cao, Feng | Nanyang Technological University
    Author: Sato, Hirotaka | Nanyang Technological University
 
    keyword: Biomimetics; Biologically-Inspired Robots; Legged Robots

    Abstract : This paper demonstrates that our developed beetle-computer hybrid legged robot achieves backward walk which is impossible by intact beetles themselves in nature. Judging from the curvature of the natural leg spine, we hypothesized that the natural spine has anisotropic function: the natural spine would provide foot traction only in forward walk but not in backward. The hypothesis was verified as beetles hardly walk backward due to often slips. We then designed an artificial leg spine which isotropically functions in walk: the foot traction was increased and slip-less walk was achieved in both backward and forward walk with the artificial spines being implanted into the beetle legs. For these investigations, a wireless communication device, or "backpack", was mounted and wired to a live beetle for electrically stimulating leg muscles to remotely modulate leg motions and to perform the forward and backward walking on demand. Overall, the beetle hybrid robot revealed the anisotropic function of the natural leg spine and also achieved the backward walk which the intact beetle cannot intrinsically perform.

## Robust/Adaptive Control of Robotic Systems

- Adaptive Visual Shock Absorber with Visual-Based Maxwell Model Using Magnetic Gear

    Author: Tanaka, Satoshi | The University of Tokyo
    Author: Koyama, Keisuke | University of Tokyo
    Author: Senoo, Taku | University of Tokyo
    Author: Ishikawa, Masatoshi | University of Tokyo
 
    keyword: Robust/Adaptive Control of Robotic Systems; Force Control; Mechanism Design

    Abstract : In this study, a visual shock absorber capable of adapting to free-fall objects with various weights and speeds is designed and realized. The key element is a magnetic gear to passively absorb shock in the moment of contact, which is difficult for traditional feedback control to deal with. The magnetic gear allows the seamless transfer of control from the non-contact state to the contact state. 1000 Hz high-speed visual object tracking is used for preparation with position and velocity control in the object non-contact state. In the moment of object contact, the high backdrivability of the magnetic gear response by hardware provides high responsiveness to external force. After the impact, the plastic deformation control of a parallel-expressed Maxwell model handles the contact state.

- Slip-Based Nonlinear Recursive Backstepping Path Following Controller for Autonomous Ground Vehicles

    Author: Xin, Ming | Inceptio Technology
    Author: Zhang, Kai | Inceptio Technology, Inc
    Author: Lackner, David | Inceptio Technology
    Author: Minor, Mark | University of Utah
 
    keyword: Robust/Adaptive Control of Robotic Systems; Dynamics; Wheeled Robots

    Abstract :  Path following accuracy and error convergence with graceful motion in vehicle steering control is challenging due to the competing nature of these requirements, especially across a range of operating speeds. This work is founded upon slip-based kinematic and dynamic models, which allow derivation of controllers considering error due to sideslip and the mapping between steering commands and graceful lateral motion. A novel recursive backstepping steering controller is proposed that better couples yaw-rate based path following commands to steering angle and rate. Observer based sideslip estimates are combined with heading error in the kinematic controller to provide feedforward slip compensation. Path following error is compensated by a Variable Structure Controller (VSC) to balance graceful motion, path following error, and robustness. Yaw rate commands are used by a backstepping dynamic controller to generate robust steering commands. A High Gain Observer (HGO) estimates sideslip and yaw rate for output feedback control. Stability analysis is provided and peaking is addressed. Field experimental results evaluate the work and provide comparisons to MPC.

- Fast and Safe Path-Following Control Using a State-Dependent Directional Metric

    Author: Li, Zhichao | University of California San Diego
    Author: Arslan, Omur | Eindhoven University of Technology
    Author: Atanasov, Nikolay | University of California, San Diego
 
    keyword: Robust/Adaptive Control of Robotic Systems; Reactive and Sensor-Based Planning; Robot Safety

    Abstract : This paper considers the problem of fast and safe autonomous navigation in partially known environments. Our main contribution is a control policy design based on ellipsoidal trajectory bounds obtained from a quadratic state-dependent distance metric. The ellipsoidal bounds are used to embed directional preference in the control design, leading to system behavior that is adapted to local environment geometry, carefully considering medial obstacles while paying less attention to lateral ones. We use a virtual reference governor system to adaptively follow a desired navigation path, slowing down when system safety may be violated and speeding up otherwise. The resulting controller is able to navigate complex environments faster than common Euclidean-norm and Lyapunov-function-based designs, while retaining stability and collision avoidance guarantees.

- Backlash-Compensated Active Disturbance Rejection Control of Nonlinear Multi-Input Series Elastic Actuators

    Author: DeBoon, Brayden | University of Ontario Institute of Technology
    Author: Nokleby, Scott | University of Ontario Institute of Technology
    Author: Rossa, Carlos | Ontario Tech University
 
    keyword: Robust/Adaptive Control of Robotic Systems; Physical Human-Robot Interaction; Robot Safety

    Abstract : Series elastic actuators with passive compliance have been gaining increasing popularity in force-controlled robotic manipulators. One of the reasons is the actuator's ability to infer the applied torque by measuring the deflection of the elastic element as opposed to directly with dedicated torque sensors. Proper deflection control is pinnacle to achieve a desired output torque and, therefore, small deviances in positional measurements or a nonlinear deformation can have adverse effects on performance. In applications with larger torque requirements, the actuators typically use gear reductions which inherently result in mechanical backlash. This combined with the nonlinear behaviour of the elastic element and unmodelled dynamics, can severely compromise force fidelity.<p>This paper proposes a backlash compensating active disturbance rejection controller (ADRC) for multi-input series elastic actuators. In addition to proper deflection control, a multi-input active disturbance rejection controller is derived and implemented experimentally to mitigate any unmodelled nonlinearities or perturbations to the plant model. The controller is experimentally validated on a hybrid motor-brake-clutch series elastic actuator and the controller performance is compared against traditional error-based controllers. It is shown that the backlash compensated ADRC outperforms classical PID and ADRC methods and is a viable solution to positional measurement error in elastic actuators.

- On Generalized Homogenization of Linear Quadrotor Controller

    Author: Wang, Siyuan | Inria
    Author: Polyakov, Andrey | INRIA Lille
    Author: Zheng, Gang | INRIA
 
    keyword: Robust/Adaptive Control of Robotic Systems; Aerial Systems: Mechanics and Control; Motion Control

    Abstract : A novel scheme for an "upgrade" of a linear control algorithm to a non-linear one is developed based on the concepts of a generalized homogeneity and an implicit homogeneous feedback design. Some tuning rules for a guaranteed improvement of a regulation quality are proposed. Theoretical results are confirmed by real experiments with the quadrotor QDrone of Quanser(TM).

- Coordinated Optical Tweezing and Manipulation of Multiple Microscopic Objects with Stochastic Perturbations

    Author: Ta, Quang Minh | Nanyang Technological University
    Author: Cheah, C. C. | Nanyang Technological University
 
    keyword: Robust/Adaptive Control of Robotic Systems; Motion Control; Automation at Micro-Nano Scales

    Abstract : The Brownian motion of micro-objects in fluid mediums is a fundamental distinction between optical manipulation and robotic manipulation in the macro-world. Besides, current control techniques for optical manipulation generally assume that the manipulated micro-objects are initially trapped prior to the manipulation processes. This paper proposes a robotic control technique for fully automated optical trapping and manipulation of multiple micro-objects with stochastic perturbations. Cooperative control of robotic stage and optical traps is performed to achieve the control objective, in which multiple micro-objects are trapped in sequence by using the robotic stage, and the trapped micro-objects are then manipulated toward a desired region by using laser-steering system. The transition from the trapping operation to manipulation of the trapped micro-objects is fully automated. In this paper, a closed-loop control approach of the optical traps is formulated, and thus ensuring the completeness of the manipulation tasks. The stability of the control system is investigated from a stochastic perspective, and the performance of the proposed control technique is illustrated with experimental results.

- Contact Surface Estimation Via Hapic Perception

    Author: Lin, Hsiu-Chin | McGIll University
    Author: Mistry, Michael | University of Edinburgh
 
    keyword: Robust/Adaptive Control of Robotic Systems; Legged Robots; Field Robots

    Abstract : Legged systems need to optimize contact force in order to maintain contacts. For this, the controller needs to have the knowledge of the surface geometry and how slippery the terrain is. We can use a vision system to realize the terrain, but the accuracy of the vision system degrades in harsh weather, and it cannot visualize the terrain if it is covered with water or grass. Also, the degree of friction cannot be directly visualized. In this paper, we propose an online method to estimate the surface information via haptic exploration. We also introduce a probabilistic criterion to measure the quality of the estimation. The method is validated on both simulation and a real robot platform.

- Local Policy Optimization for Trajectory-Centric Reinforcement Learning

    Author: Kolaric, Patrik | University of Texas at Arlington Research Institute, TX, USA
    Author: Jha, Devesh | Mitsubishi Electric Research Laboratories
    Author: Raghunathan, Arvind | Mitsubishi Electric Research Laboratories
    Author: Lewis, Frank | The University of Texas at Arlington
    Author: Benosman, Mouhacine | Mitsubishi Electric Research Laboratories
    Author: Romeres, Diego | Mitsubishi Electric Research Laboratories
    Author: Nikovski, Daniel | MERL
 
    keyword: Robust/Adaptive Control of Robotic Systems; Optimization and Optimal Control; Learning and Adaptive Systems

    Abstract : The goal of this paper is to present a method for simultaneous trajectory and local stabilizing policy optimization to generate local policies for trajectory-centric model-based reinforcement learning (MBRL). This is motivated by the fact that global policy optimization for non-linear systems could be a very challenging problem both algorithmically and numerically. However, a lot of robotic manipulation tasks are trajectory-centric, and thus do not require a global model or policy. Due to inaccuracies in the learned model estimates, an open-loop trajectory optimization process mostly results in very poor performance when used on the real system. Motivated by these problems, we try to formulate the problem of trajectory optimization and local policy synthesis as a single optimization problem. It is then solved simultaneously as an instance of nonlinear programming. We provide some results for analysis as well as achieved performance of the proposed technique under some simplifying assumptions.

- Automatic Snake Gait Generation Using Model Predictive Control

    Author: Hannigan, Emily | Columbia University
    Author: Song, Bing | Columbia University
    Author: Khandate, Gagan | Columbia University
    Author: Haas-Heger, Maximilian | Columbia University
    Author: Yin, Ji | Columbia University
    Author: Ciocarlie, Matei | Columbia University
 
    keyword: Robust/Adaptive Control of Robotic Systems; Dynamics

    Abstract : Snake robots have the potential to perform jobs like rescue operations in challenging terrains. There is less work focused on snake gait generation across multiple environmental conditions, i.e., the Coulomb fricion, the viscous friction, and fluid dynamics. We propose a MPC-based gait generation approach that can automatically produce effective gaits over different environments with the same implementation, i.e., without human intuition or retuning parameters. The automatic generated gaits can be both faster and more energy efficient than Pareto-optimal serpenoid gaits. This MPC-based approach can also automatically generate complex gaits like obstacle avoidance. Study on practical applicabilty shows the potential of the online implementation of our approach. To satisfy the dynamic smoothness requirement of MPC, We also propose a more accurate anisotropic Coulomb friction model derived by maximum dissipation principle. This is the first time this anisotropic Coulomb fricton model introduced to snake robots.

- Safe and Fast Tracking on a Robot Manipulator: Robust MPC and Neural Network Control

    Author: Nubert, Julian | ETH Zurich
    Author: Koehler, Johannes | University of Stuttgart
    Author: Berenz, Vincent | Max Planck Institute for Intelligent Systems
    Author: Allgower, Frank | University of Stuttgart
    Author: Trimpe, Sebastian | Max Planck Institute for Intelligent Systems
 
    keyword: Robust/Adaptive Control of Robotic Systems; Motion Control; Deep Learning in Robotics and Automation

    Abstract : Fast feedback control and safety guarantees are essential in modern robotics. We present an approach that achieves both by combining novel robust model predictive control (MPC) with function approximation via (deep) neural networks (NNs). The result is a new approach for complex tasks with nonlinear, uncertain, and constrained dynamics as are common in robotics. Specifically, we leverage recent results in MPC research to propose a new robust setpoint tracking MPC algorithm, which achieves reliable and safe tracking of a dynamic setpoint while guaranteeing stability and constraint satisfaction. The presented robust MPC scheme constitutes a one-layer approach that unifies the often separated planning and control layers, by directly computing the control command based on a reference and possibly obstacle positions. As a separate contribution, we show how the computation time of the MPC can be drastically reduced by approximating the MPC law with a NN controller. The NN is trained and validated from offline samples of the MPC, yielding statistical guarantees, and used in lieu thereof at run time. Our experiments on a state-of-the-art robot manipulator are the first to show that both the proposed robust and approximate MPC schemes scale to real-world robotic systems.

- 3D Path-Following Using MRAC on a Millimeter-Scale Spiral-Type Magnetic Robot

    Author: Zhao, Haoran | University of Houston
    Author: Julien, Leclerc | University of Houston
    Author: Feucht, Maria | Baylor University
    Author: Bailey, Olivia | University of Maryland Baltimore County
    Author: Becker, Aaron | University of Houston
 
    keyword: Robust/Adaptive Control of Robotic Systems; Motion Control; Biologically-Inspired Robots

    Abstract : This paper focuses on the 3D path-following of a spiral-type helical magnetic swimmer in a water-filled workspace. The swimmer has a diameter of 2.5 mm, a length of 6 mm, and is controlled by an external time-varying magnetic field. A method to compensate undesired magnetic gradient forces is proposed and tested. Five swimmer designs with different thread pitch values were experimentally analyzed. All were controlled by the same model reference adaptive controller (MRAC). Compared to a conventional hand-tuned PI controller, their 3D path-following performance is significantly improved by using MRAC. At an average speed of 50 mm/s, the path-following mean error of the MRAC is 3.8+/-1.8 mm, less than one body length of the swimmer. The versatility

- Adaptive Model-Based Myoelectric Control for a Soft Wearable Arm Exosuit (I)

    Author: Lotti, Nicola | University of Heidelberg
    Author: Xiloyannis, Michele | Eidgen�ssische Technische Hochschule (ETH) Zurich
    Author: Durandau, Guillaume | University of Twente
    Author: Galofaro, Elisa | University of Genoa
    Author: Sanguineti, Vittorio | University of Genoa
    Author: Masia, Lorenzo | Heidelberg University
    Author: Sartori, Massimo | University of Twente
 
    keyword: Robust/Adaptive Control of Robotic Systems; Soft Robot Applications; Wearable Robots

    Abstract : Despite advances in mechatronic design, the widespread adoption of wearable robots for supporting human mobility has been hampered by (i) ergonomic limitations in rigid exoskeletal structures, and by (ii) the lack of human machine interfaces capable of sensing musculoskeletal states and translating them into robot control commands. We have developed a new framework that combines, for the first time, a model-based HMI with a soft wearable arm exosuit, that has the potential of addressing key limitations in current HMI and wearable robots. Results showed that the model controlled exosuit operated synchronously with biological muscle contraction. Remarkably, the exosuit dynamically modulated mechanical assistance across all investigated loads, thereby displaying adaptive behavior. As a result, both the exosuit's intrinsic dynamics and the external mechanical loads appeared to be transparent to the individuals' musculoskeletal systems. This was reflected by the fact that, with exosuit assistance, both muscle electromyograms and resulting forces, always varied within comparable ranges across all investigated rotational velocities and loads, i.e. the external load effect on muscle function was minimized. The ability of seamlessly combining musculoskeletal force estimators with wearable soft mechatronics opens new avenues for assisting human movement both in healthy and impaired individuals.

## Space Robotics and Automation
- Planetary Rover Exploration Combining Remote and in Situ Measurements for Active Spectroscopic Mapping

    Author: Candela, Alberto | Carnegie Mellon University
    Author: Kodgule, Suhit | Carnegie Mellon University
    Author: Edelson, Kevin | Carnegie Mellon University
    Author: Vijayarangan, Srinivasan | Carnegie Mellon University
    Author: Thompson, David | Jet Propulsion Laboratory / California Institute of Technology
    Author: Noe Dobrea, Eldar | Planetary Science Institute
    Author: Wettergreen, David | Carnegie Mellon University
 
    keyword: Space Robotics and Automation; Field Robots; Learning and Adaptive Systems

    Abstract : Maintaining high levels of productivity for planetary rover missions is very difficult due to limited communication and heavy reliance on ground control. There is a need for autonomy that enables more adaptive and efficient actions based on real-time information. This paper presents an autonomous mapping and exploration approach for planetary rovers. We first describe a machine learning model that actively combines remote and rover measurements for mapping. We focus on spectroscopic data because they are commonly used to investigate surface composition. We then incorporate notions from information theory and non-myopic path planning to improve exploration productivity. Finally, we demonstrate the feasibility and successful performance of our approach via spectroscopic investigations of Cuprite, Nevada; a well-studied region of mineralogical and geological interest. We first perform a detailed analysis in simulations, and then validate those results with an actual rover in the field in Nevada.

- Magnetic Docking Mechanism for Free-Flying Space Robots with Spherical Surfaces

    Author: Watanabe, Keisuke | Japan Aerospace Exploration Agency
 
    keyword: Space Robotics and Automation; Mechanism Design; Compliant Joint/Mechanism

    Abstract : Autonomous operation of robots in the International Space Station (ISS) is required to maximize the use of limited resources and enable astronauts to concentrate more on the valuable tasks. To achieve this goal, we are developing a station where the robot approaches, docks, charges, and then undocks. In this paper, the     Authors proposed a magnetic docking mechanism for free-flying robots having spherical surfaces, which makes it possible for the robot to dock securely without requiring highly precise guidance, navigation and control capability. By making use of a slider guide and repelling magnet pairs, the mechanism can achieve tolerance for larger robot position error as compared to the conventional fixed guide mechanism. The experimental results showed that the proposed mechanism can effectively enlarge the acceptable error range of poses, and also reduce acceleration at the moment of impact. We also introduced the model to predict whether docking will be succeeded or not from the contact condition of the robot and the guide, using a machine learning technique, Gaussian Process Regression (GPR). The prediction results shows that the learnt model can express the contact condition of successful docking.

- Barefoot Rover: A Sensor-Embedded Rover Wheel Demonstrating In-Situ Engineering and Science Extractions Using Machine Learning

    Author: Marchetti, Yuliya | Jet Propulsion Laboratory
    Author: Lightholder, Jack | Jet Propulsion Laboratory
    Author: Junkins, Eric | Jet Propulsion Laboratory
    Author: Cross, Matthew | Western University
    Author: Mandrake, Lukas | Jet Propulsion Laboratory
    Author: Fraeman, Abigail | Jet Propulsion Laboratory
 
    keyword: Space Robotics and Automation; Force and Tactile Sensing; Learning and Adaptive Systems

    Abstract : In this work, we demonstrate an instrumented wheel concept which utilizes a 2D pressure grid, an electrochemical impedance spectroscopy (EIS) sensor and machine learning to extract meaningful metrics from the interaction between the wheel and surface terrain. These include continuous slip/skid estimation, balance, and sharpness for engineering applications. Estimates of surface hydration, texture, terrain patterns, and regolith physical properties such as cohesion and angle of internal friction are additionally calculated for science applications. Traditional systems rely on post-processing of visual images and vehicle telemetry to estimate these metrics. Through in-situ sensing, these metrics can be calculated in near real time and made available to onboard science and engineering autonomy applications. This work aims to provide a deployable system for future planetary exploration missions to increase science and engineering capabilities through increased knowledge of the terrain.

- Deep Learning for Spacecraft Pose Estimation from Photorealistic Rendering

    Author: Proen�a, Pedro F. | University of Surrey
    Author: Gao, Yang | University of Surrey
 
    keyword: Space Robotics and Automation; Simulation and Animation; Computer Vision for Automation

    Abstract : On-orbit proximity operations in space rendezvous, docking and debris removal require precise and robust 6D pose estimation under a wide range of lighting conditions and against highly textured background, i.e., the Earth. This paper investigates leveraging deep learning and photorealistic rendering for monocular pose estimation of known uncooperative spacecraft. We first present a simulator built on Unreal Engine 4, named URSO, to generate labeled images of spacecraft orbiting the Earth, which can be used to train and evaluate neural networks. Secondly, we propose a deep learning framework for pose estimation based on orientation soft classification, which allows modelling orientation ambiguity as a mixture model. This framework was evaluated both on URSO datasets and the European Space Agency pose estimation challenge. In this competition, our best model achieved 3rd place on the synthetic test set and 2nd place on the real test set. Moreover, our results show the impact of several architectural and training aspects, and we demonstrate qualitatively how models learned on URSO datasets can perform on real images from space.

- Concurrent Parameter Identification and Control for Free-Floating Robotic Systems During On-Orbit Servicing

    Author: Christidi-Loumpasefski, Olga-Orsalia | National Technical University of Athens
    Author: Rekleitis, Georgios | National Technical University of Athens
    Author: Papadopoulos, Evangelos | National Technical University of Athens
 
    keyword: Space Robotics and Automation; Calibration and Identification; Motion Control of Manipulators

    Abstract : To control a free-floating robotic system with uncertain parameters in OOS tasks with high accuracy, a fast parameter identification method, previously developed by the     Authors, is enhanced further and used concurrently with a controller. The method provides accurate parameter estimates, without any prior knowledge of any system dynamic properties. This control scheme compensates for the accumulated angular momentum on the reaction wheels (RWs), which acts as a disturbance to the robotic servicer base. While any controller using parameter information can be used, a transposed Jacobian controller, modified to include RW angular momentum disturbance rejection, is employed here. Three-dimensional simulations demonstrate the method's validity.

- A Dual Quaternion-Based Discrete Variational Approach for Accurate and Online Inertial Parameter Estimation in Free-Flying Robots

    Author: Ekal, Monica | Instituto Superior Tecnico
    Author: Ventura, Rodrigo | Instituto Superior Técnico
 
    keyword: Space Robotics and Automation; Calibration and Identification

    Abstract : The performance of model-based motion control for free-flying robots relies on accurate estimation of their parameters. In this work, a method of rigid body inertial parameter estimation which relies on a variational approach is presented. Instead of discretizing the continuous equations of motion, discrete dual quaternion equations based on variational mechanics are used to formulate a linear parameter estimation problem. This method depends only on the pose of the rigid body obtained from standard localization algorithms. Recursive semi-definite programming is used to estimate the inertial parameters (mass, rotational inertia and center of mass offset) online. Linear Matrix Inequality constraints based on the pseudo-inertia matrix ensure that the estimates obtained are fully physically consistent. Simulation results demonstrate that this method is robust to disturbances and the produced estimates are at least one order of magnitude more accurate when compared to discretization using finite differences.

## Perception for Grasping and Manipulation

- Transferable Task Execution from Pixels through Deep Planning Domain Learning

    Author: Kase, Kei | Waseda University
    Author: Paxton, Chris | NVIDIA Research
    Author: Mazhar, Hammad | NVIDIA
    Author: Ogata, Tetsuya | Waseda University
    Author: Fox, Dieter | University of Washington
 
    keyword: Deep Learning in Robotics and Automation; Reactive and Sensor-Based Planning; Task Planning

    Abstract : While robots can learn models to solve many manipulation tasks from raw visual input, they cannot usually use these models to solve new problems. On the other hand, symbolic planning methods such as STRIPS have long been able to solve new problems given only a domain definition and a symbolic goal, but these approaches often struggle on the real world robotic tasks due to the challenges of grounding these symbols from sensor data in a partially-observable world. We propose Deep Planning Domain Learning (DPDL), an approach that combines the strengths of both methods to learn a hierarchical model. DPDL learns a high-level model which predicts values for a large set of logical predicates consisting of the current symbolic world state, and separately learns a low-level policy which translates symbolic operators into executable actions on the robot. This allows us to perform complex, multi-step tasks even when the robot has not been explicitly trained on them. We show our method on manipulation tasks in a photorealistic kitchen scenario.

- Depth by Poking: Learning to Estimate Depth from Self-Supervised Grasping

    Author: Goodrich, Ben | Osaro, Inc
    Author: Kuefler, Alex | Osaro, Inc
    Author: Richards, William | Osaro, Inc
 
    keyword: Deep Learning in Robotics and Automation; RGB-D Perception; Perception for Grasping and Manipulation

    Abstract : Accurate depth estimation remains an open problem for robotic manipulation; even state of the art techniques including structured light and LiDAR sensors fail on reflective or transparent surfaces. We address this problem by training a neural network model to estimate depth from RGB-D images, using labels from physical interactions between a robot and its environment. Our network predicts, for each pixel in an input image, the z position that a robot's end effector would reach if it attempted to grasp or poke at the corresponding position. Given an autonomous grasping policy, our approach is self-supervised as end effector position labels can be recovered through forward kinematics, without human annotation. Although gathering such physical interaction data is expensive, it is necessary for training and routine operation of state of the art manipulation systems. Therefore, this depth estimator comes �for free� while collecting data for other tasks (e.g., grasping, pushing, placing). We show our approach achieves significantly lower root mean squared error than traditional structured light sensors and unsupervised deep learning methods on difficult, industry-scale jumbled bin datasets.

- Online Learning of Object Representations by Appearance Space Feature Alignment

    Author: Pirk, Soren | Robotics at Google
    Author: Khansari, Mohi | Google X
    Author: Bai, Yunfei | Google X
    Author: Lynch, Corey | Google Brain
    Author: Sermanet, Pierre | Google
 
    keyword: Deep Learning in Robotics and Automation; Object Detection, Segmentation and Categorization

    Abstract : We propose a self-supervised approach for learning representations of objects from monocular videos and demonstrate it is particularly useful for robotics. The main contributions of this paper are: 1) a self-supervised model called Object-Contrastive Network (OCN) that can discover and disentangle object attributes from video without using any labels; 2) we leverage self-supervision for online adaptation: the longer our online model looks at objects in a video, the lower the object identification error, while the offline baseline remains with a large fixed error; 3) we show the usefulness of our approach for a robotic pointing task; a robot can point to objects similar to the one presented in front of it. Videos illustrating online object adaptation and robotic pointing are provided as supplementary material.

- Visual Prediction of Priors for Articulated Object Interaction

    Author: Moses, Caris | Massachusetts Institute of Technology
    Author: Noseworthy, Michael | Massachusetts Institute of Technology
    Author: Kaelbling, Leslie | MIT
    Author: Lozano-Perez, Tomas | MIT
    Author: Roy, Nicholas | Massachusetts Institute of Technology
 
    keyword: Learning and Adaptive Systems; Deep Learning in Robotics and Automation; AI-Based Methods

    Abstract : Exploration in novel settings can be challenging without prior experience in similar domains. However, humans are able to build on prior experience quickly and efficiently. Children exhibit this behavior when playing with toys. For example, given a toy with a yellow and blue door, a child will explore with no clear objective, but once they have discovered how to open the yellow door, they will most likely be able to open the blue door much faster. Adults also exhibit this behaviour when entering new spaces such as kitchens. We develop a method, Contextual Prior Prediction, which provides a means of transferring knowledge between interactions in similar domains through vision. We develop agents that exhibit exploratory behavior with increasing efficiency, by learning visual features that are shared across environments, and how they correlate to actions. Our problem is formulated as a Contextual Multi-Armed Bandit where the contexts are images, and the robot has access to a parameterized action space. Given a novel object, the objective is to maximize reward with few interactions. A domain which strongly exhibits correlations between visual features and motion is kinemetically constrained mechanisms. We evaluate our method on simulated prismatic and revolute joints.

- MT-DSSD: Deconvolutional Single Shot Detector Using Multi Task Learning for Object Detection, Segmentation, and Grasping Detection

    Author: Araki, Ryosuke | Chubu University
    Author: Onishi, Takeshi | Chubu University
    Author: Hirakawa, Tsubasa | Chubu University
    Author: Yamashita, Takayoshi | Chubu University
    Author: Fujiyoshi, Hironobu | Chubu University
 
    keyword: Deep Learning in Robotics and Automation; Perception for Grasping and Manipulation; Computer Vision for Automation

    Abstract : This paper presents the multi-task Deconvolutional Single Shot Detector (MT-DSSD), which runs three tasks---object detection, semantic object segmentation, and grasping detection for a suction cup---in a single network based on the DSSD. Simultaneous execution of object detection and segmentation by multi-task learning improves the accuracy of these two tasks. Additionally, the model detects grasping points and performs the three recognition tasks necessary for robot manipulation. The proposed model can perform fast inference, which reduces the time required for grasping operation. Evaluations using the Amazon Robotics Challenge (ARC) dataset showed that our model has better object detection and segmentation performance than comparable methods, and robotic experiments for grasping show that our model can detect the appropriate grasping point.

- Using Synthetic Data and Deep Networks to Recognize Primitive Shapes for Object Grasping

    Author: Tang, Chao | Georgia Institute of Technology
    Author: Lin, Yunzhi | Georgia Institute of Technology
    Author: Chu, Fu-Jen | University of Michigan
    Author: Vela, Patricio | Georgia Institute of Technology
 
    keyword: Perception for Grasping and Manipulation; Grasping; Deep Learning in Robotics and Automation

    Abstract : A segmentation-based architecture is proposed to decompose objects into multiple primitive shapes from monocular depth input for robotic manipulation. The backbone deep network is trained on synthetic data with 6 classes of primitive shapes generated by a simulation engine. Each primitive shape is designed with parametrized grasp families, permitting the pipeline to identify multiple grasp candidates per shape primitive region. The grasps are priority ordered via proposed ranking algorithm, with the first feasible one chosen for execution. On task-free grasping of individual objects, the method achieves a 94% success rate. On task-oriented grasping, it achieves a 76% success rate.

- Real-Time, Highly Accurate Robotic Grasp Detection Using Fully Convolutional Neural Network with Rotation Ensemble Module

    Author: Park, Dongwon | UNIST
    Author: Seo, YongHyeok | Unist
    Author: Chun, Se Young | Ulsan National Institute of Science and Technology
 
    keyword: Perception for Grasping and Manipulation; Grasping; RGB-D Perception

    Abstract : Rotation invariance has been an important topic in computer vision tasks. Ideally, robot grasp detection should be rotation-invariant. However, rotation-invariance in robotic grasp detection has been only recently studied by using rotation anchor box that are often time-consuming and unreliable for multiple objects. In this paper, we propose a rotation ensemble module (REM) for robotic grasp detection using convolutions that rotates network weights. Our proposed REM was able to outperform current state-of-the-art methods by achieving up to 99.2% (image-wise), 98.6% (object-wise) accuracies on the Cornell dataset with real-time computation (50 frames per second). Our proposed method was also able to yield reliable grasps for multiple objects and up to 93.8% success rate for the real-time robotic grasping task with a 4-axis robot arm for small novel objects that was significantly higher than the baseline methods by 11-56%.

- Form2Fit: Learning Shape Priors for Generalizable Assembly from Disassembly

    Author: Zakka, Kevin | Stanford, Google
    Author: Zeng, Andy | Google
    Author: Lee, Johnny | Google
    Author: Song, Shuran | Columbia University
 
    keyword: Perception for Grasping and Manipulation; Deep Learning in Robotics and Automation; RGB-D Perception

    Abstract : Is it possible to learn policies for robotic assembly that can generalize to new objects? We explore this idea in the context of the kit assembly task. Since classic methods rely heavily on object pose estimation, they often struggle to generalize to new objects without 3D CAD models or task- specific training data. In this work, we propose to formulate the kit assembly task as a shape matching problem, where the goal is to learn a shape descriptor that establishes geometric correspondences between object surfaces and their target place- ment locations from visual input. This formulation enables the model to acquire a broader understanding of how shapes and surfaces fit together for assembly - allowing it to generalize to new objects and kits. To obtain training data for our model, we present a self-supervised data-collection pipeline that obtains ground truth object-to-placement correspondences by disassembling complete kits. Our resulting real-world system, Form2Fit, learns effective pick and place strategies for assem- bling objects into a variety of kits - achieving 90% average success rates under different initial conditions (e.g. varying object and kit poses), 94% success under new configurations of multiple kits, and over 86% success with completely new objects and kits. Code, videos, and supplemental material are available at https://form2fit.github.io

- Learning Rope Manipulation Policies Using Dense Object Descriptors Trained on Synthetic Depth Data

    Author: Sundaresan, Priya | University of California, Berkeley
    Author: Grannen, Jennifer | UC Berkeley
    Author: Thananjeyan, Brijen | UC Berkeley
    Author: Balakrishna, Ashwin | University of California, Berkeley
    Author: Laskey, Michael | University of California, Berkeley
    Author: Stone, Kevin | Toyota Research Institute
    Author: Gonzalez, Joseph E. | UC Berkeley
    Author: Goldberg, Ken | UC Berkeley
 
    keyword: Perception for Grasping and Manipulation; Deep Learning in Robotics and Automation; Manipulation Planning

    Abstract : Robotic manipulation of deformable 1D objects such as ropes, cables, and hoses is challenging due to the lack of high-fidelity analytic models and large configuration spaces. Furthermore, learning end-to-end manipulation policies directly from images and physical interaction requires significant time on a robot and can fail to generalize across tasks. We address these challenges using interpretable deep visual representations for rope, extending recent work on dense object descriptors for robot manipulation. This facilitates the design of interpretable and transferable geometric policies built on top of the learned representations, decoupling visual reasoning and control. We present an approach that learns point-pair correspondences between initial and goal rope configurations, which implicitly encodes geometric structure, entirely in simulation from synthetic depth images. We demonstrate that the learned representation - dense depth object descriptors (DDODs) - can be used to manipulate a real rope into a variety of different arrangements either by learning from demonstrations or using interpretable geometric policies. In 50 trials of a knot-tying task with the ABB YuMi Robot, the system achieves a 66% knot-tying success rate from previously unseen configurations. See https://tinyurl.com/rope-learning for supplementary material and videos.

- Efficient Two Step Optimization for Large Embedded Deformation Graph Based SLAM

    Author: Song, Jingwei | University of Technology, Sydney
    Author: Bai, Fang | University of Technology, Sydney
    Author: Zhao, Liang | University of Technology Sydney
    Author: Huang, Shoudong | University of Technology, Sydney
    Author: Xiong, Rong | Zhejiang University
 
    keyword: Perception for Grasping and Manipulation; Computer Vision for Other Robotic Applications; SLAM

    Abstract : Embedded deformation graph is a widely used technique in deformable geometry and graphical problems. Recently the technique has been transmitted to stereo (or RGBD) sensor based SLAM applications, it remains challenging to compromise the computational cost as the model grows. In practice, the processing time grows rapidly in accordance with the expansion of maps. In this paper, we propose an approach to decouple nodes of deformation graph in large scale dense deformable SLAM and keep the estimation time to be constant. We observe that only partial deformable nodes in the graph are connected to visible points. Based on this fact, the sparsity of the original Hessian matrix is utilized to split parameter estimation into two independent steps. With this new technique, we achieve faster parameter estimation with amortized computation complexity reduced from O(n^2) to closing O(1). As a result, the computation cost barely increases as the map keeps growing. Based on our strategy, computational bottleneck in large scale embedded deformation graph based applications will be greatly mitigated. The effectiveness is validated by experiments, featuring large scale deformation scenarios.

- Camera-To-Robot Pose Estimation from a Single Image

    Author: Lee, Timothy Edward | Carnegie Mellon University
    Author: Tremblay, Jonathan | Nvidia
    Author: To, Thang | Nvidia Corp
    Author: Cheng, Jia | Nvidia Corp
    Author: Mosier, Terry | NVIDIA
    Author: Kroemer, Oliver | Carnegie Mellon University
    Author: Fox, Dieter | University of Washington
    Author: Birchfield, Stan | NVIDIA
 
    keyword: Perception for Grasping and Manipulation; Object Detection, Segmentation and Categorization; Computer Vision for Other Robotic Applications

    Abstract : We present an approach for estimating the pose of an external camera with respect to a robot using a single RGB image of the robot. The image is processed by a deep neural network to detect 2D projections of keypoints (such as joints) associated with the robot. The network is trained entirely on simulated data using domain randomization to bridge the reality gap. Perspective-n-point (PnP) is then used to recover the camera extrinsics, assuming that the camera intrinsics and joint configuration of the robot manipulator are known. Unlike classic hand-eye calibration systems, our method does not require an off-line calibration step. Rather, it is capable of computing the camera extrinsics from a single frame, thus opening the possibility of on-line calibration. We show experimental results for three different camera sensors, demonstrating that our approach is able to achieve accuracy with a single frame that is comparable to that of classic off-line hand-eye calibration using multiple frames. With additional frames from a static pose, accuracy improves even further. Code, datasets, and pretrained models for three widely-used robot manipulators are made available.

- DIGIT: A Novel Design for a Low-Cost Compact High-Resolution Tactile Sensor with Application to In-Hand Manipulation

    Author: Lambeta, Mike Maroje | Facebook
    Author: Chou, Po-Wei | Facebook
    Author: Tian, Stephen | UC Berkeley
    Author: Yang, Brian | University of California, Berkeley
    Author: Maloon, Benjamin | Facebook
    Author: Most, Victoria Rose | Facebook
    Author: Stroud, Dave | Facebook
    Author: Santos, Raymond | Facebook
    Author: Byagowi, Ahmad | Facebook
    Author: Kammerer, Gregg | Facebook
    Author: Jayaraman, Dinesh | Facebook AI Research and University of Pennsylvania
    Author: Calandra, Roberto | Facebook
 
    keyword: Perception for Grasping and Manipulation; Deep Learning in Robotics and Automation; Force and Tactile Sensing

    Abstract : Despite decades of research, general purpose in-hand manipulation remains one of the unsolved challenges of robotics. One of the contributing factors that limit current robotic manipulation systems is the difficulty of precisely sensing contact forces -- sensing and reasoning about contact forces are crucial to accurately control interactions with the environment. As a step towards enabling better robotic manipulation, we introduce DIGIT, an inexpensive, compact, and high-resolution tactile sensor geared towards in-hand manipulation. DIGIT improves upon past vision-based tactile sensors by miniaturizing the form factor to be mountable on multi-fingered hands, and by providing several design improvements that result in an easier, more repeatable manufacturing process, and enhanced reliability. We demonstrate the capabilities of the DIGIT sensor by training deep neural network model-based controllers to manipulate glass marbles in-hand with a multi-finger robotic hand. To provide the robotic community access to reliable and low-cost tactile sensors, we open-source the DIGIT design at www.digit.ml.

- LyRN (Lyapunov Reaching Network): A Real-Time Closed Loop Approach from Monocular Vision

    Author: Zhuang, Zheyu | Australian National University
    Author: Yu, Xin | Australian National University
    Author: Mahony, Robert | Australian National University
 
    keyword: Perception for Grasping and Manipulation; Visual Servoing; Visual Learning

    Abstract : We propose a closed-loop, multi-instance control algorithm for visually guided reaching based on novel learning principles. A control Lyapunov function methodology is used to design a reaching action for a complex multi-instance task in the case where full state information (poses of all potential reaching points) is available. The proposed algorithm uses monocular vision and manipulator joint angles as the input to a deep convolution neural network to predict the value of the control Lyapunov function (cLf) and corresponding velocity control. The resulting network output is used in real-time as visual control for the grasping task with the multi-instance capability emerging naturally from the design of the control Lyapunov function.<p>We demonstrate the proposed algorithm grasping mugs (textureless and symmetric objects) on a table-top from an over-the-shoulder monocular RGB camera. The manipulator dynamically converges to the best-suited target among multiple identical instances from any random initial pose within the workspace. The system trained with simulated data only is able to achieve 90.3% grasp success rate in the real-world experiments with up to 85Hz closed-loop control on one GTX 1080Ti GPU and significantly outperforms a Pose-Based-Visual-Servo (PBVS) grasping system adapted from a state-of-the-art single shot RGB 6D pose estimation algorithm. A key contribution of the paper is the inclusion of a first-order differential constraint associate

- Object Finding in Cluttered Scenes Using Interactive Perception

    Author: Novkovic, Tonci | Autonomous Systems Lab, ETH Zurich
    Author: Pautrat, Remi | Inria Nancy Grand-Est
    Author: Furrer, Fadri | ETH Zurich
    Author: Breyer, Michel | Autonomous Systems Lab, ETH Zurich
    Author: Siegwart, Roland | ETH Zurich
    Author: Nieto, Juan | ETH Zurich
 
    keyword: Perception for Grasping and Manipulation; AI-Based Methods

    Abstract : Object finding in clutter is a skill that requires perception of the environment and in many cases physical interaction. In robotics, interactive perception defines a set of algorithms that leverage actions to improve the perception of the environment, and vice versa use perception to guide the next action. Scene interactions are difficult to model, therefore, most of the current systems use predefined heuristics. This limits their ability to efficiently search for the target object in a complex environment. In order to remove heuristics and the need for explicit models of the interactions, in this work we propose a reinforcement learning based active and interactive perception system for scene exploration and object search. We evaluate our work both in simulated and in real-world experiments using a robotic manipulator equipped with an RGB and a depth camera, and compare our system to two baselines. The results indicate that our approach, trained in simulation only, transfers smoothly to reality and can solve the object finding task efficiently and with more than 88% success rate.

- Multi-Modal Perception and Transfer Learning for Grasping Transparent and Specular Objects

    Author: Weng, Thomas | Carnegie Mellon University
    Author: Pallankize, Amith | BITS Pilani
    Author: Tang, Yimin | ShanghaiTech University
    Author: Kroemer, Oliver | Carnegie Mellon University
    Author: Held, David | Carnegie Mellon University
 
    keyword: Perception for Grasping and Manipulation; Grasping; RGB-D Perception

    Abstract : State-of-the-art object grasping methods rely on depth sensing to plan robust grasps, but commercially available depth sensors fail to detect transparent and specular objects. To improve grasping performance on such objects, we introduce a method for learning a multi-modal perception model by bootstrapping from an existing uni-modal model. This transfer learning approach requires only a pre-existing uni modal grasping model and paired multi-modal image data for training, foregoing the need for ground-truth grasp success labels nor real grasp attempts. Our experiments demonstrate that our approach is able to reliably grasp transparent and reflective objects. Video and supplementary material are available at: https://sites.google.com/view/transparent-specular-grasping.

- CCAN: Constraint Co-Attention Network for Instance Grasping

    Author: Cai, Junhao | Sun Yat-Sen University
    Author: Tao, Xuefeng | Sun Yat-Sen University
    Author: Cheng, Hui | Sun Yat-Sen University
    Author: Zhang, Zhanpeng | SenseTime Group Limited
 
    keyword: Perception for Grasping and Manipulation; Deep Learning in Robotics and Automation; Visual Learning

    Abstract : Instance grasping is a challenging robotic grasping task when a robot aims to grasp a specified target object in cluttered scenes. In this paper, we propose a novel end-to-end instance grasping method using only monocular workspace and query images, where the workspace image includes several objects and the query image only contains the target object. To effectively extract discriminative features and facilitate the training process, a learning-based method, referred to as Constraint Co-Attention Network (CCAN), is proposed which consists of a constraint co-attention module and a grasp affordance predictor. An effective co-attention module is presented to construct the features of a workspace image from the extracted features of the query image. By introducing soft constraints into the co-attention module, it highlights the target object's features while trivializes other objects' features in the workspace image. Using the features extracted from the co-attention module, the cascaded grasp affordance interpreter network only predicts the grasp configuration for the target object. The training of the CCAN is totally based on simulated self-supervision. Extensive qualitative and quantitative experiments show the effectiveness of our method both in simulated and real-world environments even for totally unseen objects.

- RLBench: The Robot Learning Benchmark &amp; Learning Environment

    Author: James, Stephen | Imperial College London
    Author: Ma, Zicong | Imperial College London
    Author: Rovick Arrojo, David | Imperial College London
    Author: Davison, Andrew J | Imperial College London
 
    keyword: Perception for Grasping and Manipulation; Performance Evaluation and Benchmarking; Deep Learning in Robotics and Automation

    Abstract : We present a challenging new benchmark and learning-environment for robot learning: RLBench. The benchmark features 100 completely unique, hand-designed tasks, ranging in difficulty from simple target reaching and door opening to longer multi-stage tasks, such as opening an oven and placing a tray in it. We provide an array of both proprioceptive observations and visual observations, which include rgb, depth, and segmentation masks from an over-the-shoulder stereo camera and an eye-in-hand monocular camera. Uniquely, each task comes with an infinite supply of demos through the use of motion planners operating on a series of waypoints given during task creation time; enabling an exciting flurry of demonstration-based learning possibilities. RLBench has been designed with scalability in mind; new tasks, along with their motion-planned demos, can be easily created and then verified by a series of tools, allowing users to submit their own tasks to the RLBench task repository. This large-scale benchmark aims to accelerate progress in a number of vision-guided manipulation research areas, including: reinforcement learning, imitation learning, multi-task learning, geometric computer vision, and in particular, few-shot learning. With the benchmark's breadth of tasks and demonstrations, we propose the first large-scale few-shot challenge in robotics. We hope that the scale and diversity of RLBench offers unparalleled research opportunities in the robot learning community and beyond.

- Learning Task-Oriented Grasping from Human Activity Datasets

    Author: Kokic, Mia | KTH
    Author: Kragic, Danica | KTH
    Author: Bohg, Jeannette | Stanford University
 
    keyword: Perception for Grasping and Manipulation; Deep Learning in Robotics and Automation

    Abstract : We propose to leverage a real-world, human activity RGB dataset to teach a robot Task-Oriented Grasping (TOG). We develop a model that takes as input an RGB image and outputs a hand pose and configuration as well as an object pose and a shape. We follow the insight that jointly estimating hand and object poses increases accuracy compared to estimating these quantities independently of each other. Given the trained model, we process an RGB dataset to automatically obtain the data to train a TOG model. This model takes as input an object point cloud and outputs a suitable region for task-specific grasping. Our ablation study shows that training an object pose predictor with the hand pose information (and vice versa) is better than training without this information. Furthermore, our results on a real-world dataset show the applicability and competitiveness of our method over state-of-the-art. Experiments with a robot demonstrate that our method can allow a robot to preform TOG on novel objects.

- Inferring the Material Properties of Granular Media for Robotic Tasks

    Author: Matl, Carolyn | University of California, Berkeley
    Author: Narang, Yashraj | NVIDIA
    Author: Bajcsy, Ruzena | Univ of California, Berkeley
    Author: Ramos, Fabio | University of Sydney, NVIDIA
    Author: Fox, Dieter | University of Washington
 
    keyword: Perception for Grasping and Manipulation; Modeling, Control, and Learning for Soft Robots; Simulation and Animation

    Abstract : Granular media (e.g., cereal grains, plastic resin pellets, and pills) are ubiquitous in robotics-integrated industries, such as agriculture, manufacturing, and pharmaceutical development. This prevalence mandates the accurate and efficient simulation of these materials. This work presents a software and hardware framework that automatically calibrates a fast physics simulator to accurately simulate granular materials by inferring material properties from real-world depth images of granular formations (i.e., piles and rings). Specifically, coefficients of sliding friction, rolling friction, and restitution of grains are estimated from summary statistics of grain formations using likelihood-free Bayesian inference. The calibrated simulator accurately predicts unseen granular formations in both simulation and experiment; furthermore, simulator predictions are shown to generalize to more complex tasks, including using a robot to pour grains into a bowl, as well as to create a desired pattern of piles and rings.

- KETO: Learning Keypoint Representations for Tool Manipulation

    Author: Qin, Zengyi | Stanford
    Author: Fang, Kuan | Stanford University
    Author: Zhu, Yuke | Stanford University
    Author: Fei-Fei, Li | Stanford University
    Author: Savarese, Silvio | Stanford University
 
    keyword: Perception for Grasping and Manipulation; RGB-D Perception

    Abstract : We aim to develop an algorithm for robots to manipulate novel objects as tools for completing different task goals. An efficient and informative representation would facilitate the effectiveness and generalization of such algorithms. For this purpose, we present KETO, a framework of learning keypoint representations of tool-based manipulation. For each task, a set of task-specific keypoints is jointly predicted from 3D point clouds of the tool object by a deep neural network. These keypoints offer a concise and informative description of the object to determine grasps and subsequent manipulation actions. The model is learned from self-supervised robot interactions in the task environment without the need for explicit human annotations. We evaluate our framework in three manipulation tasks with tool use. Our model consistently outperforms state-of-the-art methods in terms of task success rates. Qualitative results of keypoint prediction and tool generation are shown to visualize the learned representations.

- Learning to See before Learning to Act: Visual Pre-Training for Manipulation

    Author: Lin, Yen-Chen | Massachusetts Institute of Technology
    Author: Zeng, Andy | Google
    Author: Song, Shuran | Columbia University
    Author: Isola, Phillip | UC Berkeley
    Author: Lin, Tsung-Yi | Google
 
    keyword: Perception for Grasping and Manipulation; Deep Learning in Robotics and Automation; Visual Learning

    Abstract : Does having visual priors (e.g. the ability to detect objects) facilitate learning to perform vision-based manipula- tion (e.g. picking up objects)? We study this problem under the framework of transfer learning, where the model is first trained on a passive vision task (i.e., the data distribution does not depend on the agent's decisions), then adapted to perform an active manipulation task (i.e., the data distribution does depend on the agent's decisions). We find that pre-training on vision tasks significantly improves generalization and sample efficiency for learning to manipulate objects. However, realizing these gains requires careful selection of which parts of the model to transfer. Our key insight is that outputs of standard vision models highly correlate with affordance maps commonly used in manipulation. Therefore, we explore directly transferring model parameters from vision networks to affordance prediction networks, and show that this can result in successful zero- shot adaptation, where a robot can pick up certain objects with zero robotic experience. With just a small amount of robotic experience, we can further fine-tune the affordance model to achieve better results. With just 10 minutes of suction experience or 1 hour of grasping experience, our method achieves &#8764; 80% success rate at picking up novel objects.

-  Learning Continuous 3D Reconstructions for Geometrically Aware Grasping

    Author: Van der Merwe, Mark | University of Utah
    Author: Lu, Qingkai | University of Utah
    Author: Sundaralingam, Balakumar | University of Utah
    Author: Matak, Martin | University of Utah
    Author: Hermans, Tucker | University of Utah

- Contact-Based In-Hand Pose Estimation Using Particle Filtering

    Author: von Drigalski, Felix Wolf Hans Erich | OMRON SINIC X Corporation
    Author: Taniguchi, Shohei | The University of Tokyo
    Author: Lee, Robert | Australian Centre for Robotic Vision
    Author: Matsubara, Takamitsu | Nara Institute of Science and Technology
    Author: Hamaya, Masashi | OMRON SINIC X Corporation
    Author: Tanaka, Kazutoshi | OMRON SINIC X Corporation
    Author: Ijiri, Yoshihisa | OMRON Corp
 
    keyword: Perception for Grasping and Manipulation; Intelligent and Flexible Manufacturing; Factory Automation

    Abstract : In industrial assembly tasks, the position of an object grasped by the robot has to be known with high precision in order to insert or place it. In real applications, this problem is commonly solved by jigs that are specially produced for each part. However, they significantly limit flexibility and are prohibitive when the target parts change often, so a flexible method to localize parts with high accuracy after grasping is desired. To solve this problem, we propose a method that can estimate the position of an object in the robot's hand to sub-millimeter precision, and can improve its estimate incrementally, using only minimal calibration and a force sensor. Our method is applicable to any robotic gripper and any rigid object that the gripper can hold, and requires only a force sensor. We demonstrate that the method can determine the position of an object to a precision of under 1~mm without using any part-specific jigs or equipment.

- A Single Multi-Task Deep Neural Network with Post-Processing for Object Detection with Reasoning and Robotic Grasp Detection

    Author: Park, Dongwon | UNIST
    Author: Seo, YongHyeok | Unist
    Author: Shin, Dongju | UNIST
    Author: Choi, Jaesik | Ulsan National Institute of Science and Technology
    Author: Chun, Se Young | Ulsan National Institute of Science and Technology
 
    keyword: Perception for Grasping and Manipulation; Grasping; RGB-D Perception

    Abstract : Applications of deep neural network (DNN) based object and grasp detections could be expanded significantly when the network output is processed by a high-level reasoning over relationship of objects. Recently, robotic grasp detection and object detection with reasoning have been investigated using DNNs. There have been efforts to combine these multi-tasks using separate networks so that robots can deal with situations of grasping specific target objects in the cluttered, stacked, complex piles of novel objects from a single RGB-D camera. We propose a single multi-task DNN that yields accurate detections of objects, grasp position and relationship reasoning among objects. Our proposed methods yield state-of-the-art performance with the accuracy of 98.6% and 74.2% with the computation speed of 33 and 62 frame per second on VMRD and Cornell datasets, respectively. Our methods also yielded 95.3% grasp success rate for novel object grasping tasks with a 4-axis robot arm and 86.7% grasp success rate in cluttered novel objects with a humanoid robot.


- In-Hand Object Pose Tracking Via Contact Feedback and GPU-Accelerated Robotic Simulation

    Author: Liang, Jacky | Carnegie Mellon University
    Author: Handa, Ankur | IIIT Hyderabad
    Author: Van Wyk, Karl | NVIDIA
    Author: Makoviichuk, Viktor | NVIDIA
    Author: Kroemer, Oliver | Carnegie Mellon University
    Author: Fox, Dieter | University of Washington
 
    keyword: Perception for Grasping and Manipulation; Simulation and Animation; Force and Tactile Sensing

    Abstract : Tracking the pose of an object while it is being held and manipulated by a robot hand is difficult for vision-based methods due to significant occlusions. Prior works have explored using contact feedback and particle filters to localize in-hand objects. However, they have mostly focused on the static grasp setting and not when the object is in motion, as doing so requires explicit modeling of complex contact dynamics. In this work, we propose using GPU-accelerated parallel robot simulations and sample-based optimization algorithms to track the in-hand object pose with contact feedback during manipulation. We perform detailed ablation studies over 3 proposed optimizers in simulation, and we evaluate our method in the real world using a 4-fingered Allegro hand with SynTouch BioTac contact sensors, all mounted on a 7-DoF Kuka arm. Our algorithm runs in real-time (30Hz) on a single GPU, and it achieves an average point cloud distance error of 6mm in simulation and 13mm in the real world.

- Robust, Occlusion-Aware Pose Estimation for Objects Grasped by Adaptive Hands

    Author: Wen, Bowen | Rutgers University
    Author: Mitash, Chaitanya | Rutgers University
    Author: Soorian, Sruthi | Rutgers University
    Author: Kimmel, Andrew | Rutgers University
    Author: Sintov, Avishai | Tel-Aviv University
    Author: Bekris, Kostas E. | Rutgers, the State University of New Jersey
 
    keyword: Perception for Grasping and Manipulation; Computer Vision for Automation; RGB-D Perception

    Abstract : Many manipulation tasks, such as placement or within-hand manipulation, require the object's pose relative to a robot hand. The task is difficult when the hand significantly occludes the object. It is especially hard for adaptive hands, for which it is not easy to detect the finger's configuration. In addition, RGB-only approaches face issues with texture-less objects or when the hand and the object look similar. This paper presents a depth-based framework, which aims for robust pose estimation and short response times. The approach detects the adaptive hand's state via efficient parallel search given the highest overlap between the hand's model and the point cloud. The hand's point cloud is pruned and robust global registration is performed to generate object pose hypotheses, which are clustered. False hypotheses are pruned via physical reasoning. The remaining poses' quality is evaluated given agreement with observed data. Extensive evaluation on synthetic and real data demonstrates the accuracy and computational efficiency of the framework when applied on challenging, highly-occluded scenarios for different object types. An ablation study identifies how the framework's components help in performance. This work also provides a dataset for in-hand 6D object pose estimation. Code and dataset are available at: https://github.com/wenbowen123/icra20-hand-object-pose

- Robust 6D Object Pose Estimation by Learning RGB-D Features

    Author: Tian, Meng | National University of Singapore
    Author: Pan, Liang | National University of Singapore
    Author: Ang Jr, Marcelo H | National University of Singapore
    Author: Lee, Gim Hee | National University of Singapore
 
    keyword: Perception for Grasping and Manipulation; Object Detection, Segmentation and Categorization; RGB-D Perception

    Abstract : Accurate 6D object pose estimation is fundamental to robotic manipulation and grasping. Previous methods follow a local optimization approach which minimizes the distance between closest point pairs to handle the rotation ambiguity of symmetric objects. In this work, we propose a novel discrete-continuous formulation for rotation regression to resolve this local-optimum problem. We uniformly sample rotation anchors in SO(3), and predict a constrained deviation from each anchor to the target, as well as uncertainty scores for selecting the best prediction. Additionally, the object location is detected by aggregating point-wise vectors pointing to the 3D center. Experiments on two benchmarks: LINEMOD and YCB-Video, show that the proposed method outperforms state-of-the-art approaches. Our code is available at https://github.com/mentian/object-posenet.

- Split Deep Q-Learning for Robust Object Singulation

    Author: Sarantopoulos, Iason | Aristotle University of Thessaloniki
    Author: Kiatos, Marios | Aristotle University of Thessaloniki
    Author: Doulgeri, Zoe | Aristotle University of Thessaloniki
    Author: Malassiotis, Sotiris | Centre for Research and Technology Hellas
 
    keyword: Perception for Grasping and Manipulation; Learning and Adaptive Systems

    Abstract : Extracting a known target object from a pile of other objects in a cluttered environment is a challenging robotic manipulation task encountered in many robotic applications. In such conditions, the target object touches or is covered by adjacent obstacle objects, thus rendering traditional grasping techniques ineffective. In this paper, we propose a pushing policy aiming at singulating the target object from its surrounding clutter, by means of lateral pushing movements of both the neighboring objects and the target object until sufficient 'grasping room' has been achieved. To achieve the above goal we employ reinforcement learning and particularly Deep Q-learning (DQN) to learn optimal push policies by trial and error. A novel Split DQN is proposed to improve the learning rate and increase the modularity of the algorithm. Experiments show that although learning is performed in a simulated environment the transfer of learned policies to a real environment is effective thanks to robust feature selection. Finally, we demonstrate that the modularity of the algorithm allows the addition of extra primitives without retraining the model from scratch.

- 6-DOF Grasping for Target-Driven Object Manipulation in Clutter

    Author: Murali, Adithyavairavan | Carnegie Mellon University
    Author: Mousavian, Arsalan | NVIDIA
    Author: Eppner, Clemens | NVIDIA
    Author: Paxton, Chris | NVIDIA Research
    Author: Fox, Dieter | University of Washington
 
    keyword: Perception for Grasping and Manipulation; Grasping; RGB-D Perception

    Abstract : Grasping in cluttered environments is a fundamental but challenging robotic skill. It requires both reasoning about unseen object parts and potential collisions with the manipulator. Most existing data-driven approaches avoid this problem by limiting themselves to top-down planar grasps which is insufficient for many real-world scenarios and greatly limits possible grasps. We present a method that plans 6-DOF grasps for any desired object in a cluttered scene from partial point cloud observations. Our method achieves a grasp success of 80.3%, outperforming baseline approaches by 17.6% and clearing 9 cluttered table scenes that contain 51 objects in total on a real robotic platform. By using our learned collision checking module, we can even reason about effective grasp sequences to retrieve objects that are not immediately accessible.

- Single Shot 6D Object Pose Estimation

    Author: Kleeberger, Kilian | Fraunhofer IPA
    Author: Huber, Marco F. | University of Stuttgart
 
    keyword: Perception for Grasping and Manipulation; AI-Based Methods; Deep Learning in Robotics and Automation

    Abstract : In this paper, we introduce a novel single shot approach for 6D object pose estimation of rigid objects based on depth images. For this purpose, a fully convolutional neural network is employed, where the 3D input data is spatially discretized and pose estimation is considered as a regression task that is solved locally on the resulting volume elements. With 65 fps on a GPU, our Object Pose Network (OP-Net) is extremely fast, is optimized end-to-end, and estimates the 6D pose of multiple objects in the image simultaneously. Our approach does not require manually 6D pose-annotated real-world datasets and transfers to the real world, although being entirely trained on synthetic data. The proposed method is evaluated on public benchmark datasets, where we can demonstrate that state-of-the-art methods are significantly outperformed.

## Humanoid Robots

- HRP-4 Walks on Soft Feet

    Author: Catalano, Manuel Giuseppe | Istituto Italiano Di Tecnologia
    Author: Frizza, Irene | University of Pisa
    Author: Morandi, Cecilia | University of Pisa
    Author: Grioli, Giorgio | Istituto Italiano Di Tecnologia
    Author: Ayusawa, Ko | AIST
    Author: Ito, Takahiro | University of Tsukuba
    Author: Venture, Gentiane | Tokyo University of Agriculture and Technology
 
    keyword: Legged Robots; Humanoid and Bipedal Locomotion; Humanoid Robots

    Abstract : The majority of humanoid robots adopt flat feet, a choice that can limit their performance when maneuvering over uneven terrains. Recently, a soft robotic foot designed to adapt to the ground was proposed to overcome part of these limitations. This paper presents the results of testing two such feet on the humanoid robot HRP-4, and compares them to what obtained with the original flat feet of the robot. After describing the SoftFoot and how it has been adapted to the robot, the biped is tested while balancing, stepping and walking. Tests are carried out on flat ground and on obstacles of different heights. For comparison purposes, the original HRP-4 controller has been used for both types of feet with no changes (except for re-evaluation of the CoM position). Analysis of the ankle pitch angle, ankle pitch torque, knee pitch angle, knee pitch torque, waist roll angle and waist pitch angle, show a substantial improvement in obstacle negotiation performance of HRP-4, when using the SoftFoot, even without optimizing the controller to exploit the SoftFoot features.

- A Study on Sparse Hierarchical Inverse Kinematics Algorithms for Humanoid Robots

    Author: Mingo Hoffman, Enrico | Fondazione Istituto Italiano Di Tecnologia
    Author: Parigi Polverini, Matteo | Istituto Italiano Di Tecnologia (IIT)
    Author: Laurenzi, Arturo | Istituto Italiano Di Tecnologia
    Author: Tsagarakis, Nikos | Istituto Italiano Di Tecnologia
 
    keyword: Humanoid Robots; Optimization and Optimal Control; Kinematics

    Abstract : In humanoid robotic platforms, classical inverse kinematics algorithms based on L2-regularisation of joint velocities or accelerations, tends to engage the motion of all the available degrees of freedom, resulting in movements of the whole robot structure, which are inherently not sparse. The role of sparsity in motion control has recently gained interest in the robotics community for various reasons, e.g. human-like motions, human-robot interaction, actuation parsimony, yet an exhaustive mathematical analysis is still missing. In order to address this topic, we here propose and compare possible sparse optimization approaches applied to hierarchical inverse kinematics for humanoid robots. This is achieved through LASSO regression and MILP optimization to resolve the IK problem. A first order formulation of the sparse regression problem is further introduced to reduce chattering on the joint velocity profiles. This paper presents the theory behind the proposed approaches and performs a comparison analysis based on simulated and real experiments on different humanoid platforms.

- Inferring the Geometric Nullspace of Robot Skills from Human Demonstrations

    Author: Cai, Caixia | Institute for Infocomm Research, A*STAR
    Author: Liang, Ying Siu | Agency for Science, Technology and Research (A*STAR)
    Author: Somani, Nikhil | Agency for Science, Technology and Research (A*STAR)
    Author: Wu, Yan | A*STAR Institute for Infocomm Research
 
    keyword: Humanoid Robots; Behavior-Based Systems; Learning from Demonstration

    Abstract : In this paper we present a framework to learn skills from human demonstrations in the form of geometric nullspaces, which can be executed using a robot. We collect data of human demonstrations, fit geometric nullspaces to them, and also infer their corresponding geometric constraint models. These geometric constraints provide a powerful mathematical model as well as an intuitive representation of the skill in terms of the involved objects. To execute the skill using a robot, we combine this geometric skill description with the robot's kinematics and other environmental constraints, from which poses can be sampled for the robot's execution. The result of our framework is a system that takes the human demonstrations as input, learns the underlying skill model, and executes the learnt skill with different robots in different dynamic environments. We evaluate our approach on a simulated industrial robot, and execute the final task on the iCub humanoid robot.

- A Dynamical System Approach for Adaptive Grasping, Navigation and Co-Manipulation with Humanoid Robots

    Author: Figueroa, Nadia | Massachusetts Institute of Technology (MIT)
    Author: Faraji, Salman | EPFL
    Author: Koptev, Mikhail | École Polytechnique Fédérale De Lausanne
    Author: Billard, Aude | EPFL
 
    keyword: Motion and Path Planning; Humanoid Robots; Compliance and Impedance Control

    Abstract : In this paper, we present an integrated approach that provides compliant control of an iCub humanoid robot and adaptive reaching, grasping, navigating and co-manipulating capabilities. We use state-dependent dynamical systems (DS) to (i) coordinate and drive the robot's hands (in both position and orientation) to grasp an object using an intermediate virtual object, and (ii) drive the robot's base while walking/navigating. The use of DS as motion generators allows us to adapt smoothly as the object moves and to re-plan on-line motion of the arms and body to reach the object's new location. The desired motion generated by the DS are used in combination with a whole-body compliant control strategy that absorbs perturbations while walking and offers compliant behaviors for grasping and manipulation tasks. Further, the desired dynamics for the arm and body can be learned from demonstrations. By integrating these components, we achieve unprecedented adaptive behaviors for whole body manipulation. We showcase this in simulations and real-world experiments where iCub robots (i) walk-to-grasp objects, (ii) follow a human (or another iCub) through interaction and (iii) learn to navigate or co-manipulate an object from human guided demonstrations; whilst being robust to changing targets and perturbations.

- Humanoid Robots in Aircraft Manufacturing (I)
 
    Author: Kheddar, Abderrahmane | CNRS-AIST JRL (Joint Robotics Laboratory), UMI3218/CRT
    Author: Caron, Stephane | ANYbotics AG
    Author: Gergondet, Pierre | CNRS
    Author: Comport, Andrew Ian | CNRS-I3S/UNS
    Author: Tanguy, Arnaud | CNRS-UM LIRMM
    Author: Ott, Christian | German Aerospace Center (DLR)
    Author: Henze, Bernd | Agile Robots AG
    Author: Mesesan, George | German Aerospace Center (DLR)
    Author: Englsberger, Johannes | DLR (German Aerospace Center)
    Author: Roa, Maximo A. | DLR - German Aerospace Center
    Author: Wieber, Pierre-Brice | INRIA Rh�ne-Alpes
    Author: Chaumette, Francois | Inria Rennes-Bretagne Atlantique
    Author: Spindler, Fabien | INRIA
    Author: Oriolo, Giuseppe | Sapienza University of Rome
    Author: Lanari, Leonardo | Sapienza University of Rome
    Author: Escande, Adrien | AIST
    Author: Chappellet, Kevin | CNRS
    Author: Kanehiro, Fumio | National Inst. of AIST
    Author: Rabate, Patrice | Airbus Group
 
    keyword: Humanoid Robots; Industrial Robots; Additive Manufacturing

    Abstract : We report results from a collaborative project that investigated the deployment of humanoid robotic solutions in aircraft manufacturing for some assembly operations where access is not possible for wheeled or rail-ported robotic platforms. Recent developments in multi-contact planning and control, bipedal walking, embedded SLAM, whole-body multi-sensory task space optimization control, and contact detection and safety, suggest that humanoids could be a plausible solution for automation given the specific requirements in such large-scale manufacturing sites. The main challenge is to integrate these scientific and technological advances into two existing humanoid platforms: the position controlled HRP-4 and the torque controlled TORO. This integration effort was demonstrated in a bracket assembly operation inside a 1:1 scale A350 mock-up of the front part of the fuselage at the Airbus Saint-Nazaire site. We present and discuss the main results that have been achieved in this project and provide recommendations for future work.

- A Multi-Mode Teleoperation Framework for Humanoid Loco-Manipulation (I)

    Author: Penco, Luigi | INRIA
    Author: Scianca, Nicola | Sapienza University of Rome
    Author: Modugno, Valerio | Sapienza Université Di Roma
    Author: Lanari, Leonardo | Sapienza University of Rome
    Author: Oriolo, Giuseppe | Sapienza University of Rome
    Author: Ivaldi, Serena | INRIA
 
    keyword: Telerobotics and Teleoperation; Humanoid Robots; Human-Centered Robotics

    Abstract : Every year millions of people die due to work-related diseases or are severely injured as a result of accidents on the workplace. The introduction of humanoid	robots in the work environment can help us reduce the occurrence of such dramatic events. Thanks to their dexterity and agility, humanoids have a number of advantages over other kinds of mobile robots. They can move more easily in cluttered and human-centered environments, as well as unstructured and unpredictable environments such as disaster-response scenarios. %We propose a multi-mode teleoperation framework for controlling humanoid robots for loco-manipulation tasks. %One mode allows the operator to fully control the robot by wearing a motion capture suit, and thus having the robot replicate human movements in real-time. The other is a semi-autonomous control mode, where the teleoperator can give high-level directives to the robot about the task to be performed. We tested our framework on a real iCub robot for a whole body pick and place demo application.

- Balance of Humanoid Robots in a Mix of Fixed and Sliding Multi-Contact Scenarios

    Author: Samadi, Saeid | University of Montpellier
    Author: Caron, Stephane | ANYbotics AG
    Author: Tanguy, Arnaud | CNRS-UM LIRMM
    Author: Kheddar, Abderrahmane | CNRS-AIST JRL (Joint Robotics Laboratory), UMI3218/CRT
 
    keyword: Humanoid Robots; Dynamics; Force Control

    Abstract : This study deals with the balance of humanoid or multi-legged robots in a multi-contact setting where a chosen subset of contacts is undergoing desired sliding-task motions. One method to keep balance is to hold the center-of-mass (CoM) within an admissible convex area. This area is calculated based on the contact positions and forces. We introduce a methodology to compute this CoM support area (CSA) for multiple fixed and intentionally sliding contacts. To select the most appropriate CoM position within CSA, we account for (i) constraints of multiple fixed and sliding contacts, (ii) desired wrench distribution for contacts, and (iii) desired CoM position (eventually dictated by other tasks). These are formulated as a quadratic programming (QP) optimization problems. We illustrate our approach with pushing against a wall and wiping, and conducted experiments using the HRP-4 humanoid robot.

- Fast Whole-Body Motion Control of Humanoid Robots with Inertia Constraints

    Author: Ficht, Grzegorz | University of Bonn
    Author: Behnke, Sven | University of Bonn
 
    keyword: Humanoid Robots; Kinematics; Dynamics

    Abstract : We introduce a new, analytical method for generating whole body motions for humanoid robots, which approximate the desired Composite Rigid Body (CRB) inertia. Our approach uses a reduced five mass model, where four of the masses are attributed to the limbs and one is used for the trunk. This compact formulation allows for finding an analytical solution that combines the kinematics with mass distribution and inertial properties of a humanoid robot. The positioning of the masses in Cartesian space is then directly used to obtain joint angles with relations based on simple geometry. Motions are achieved through the time evolution of poses generated through the desired foot positioning and CRB inertia properties. As a result, we achieve short computation times in the order of tens of microseconds. This makes the method suited for applications with limited computation resources, or leaving them to be spent on higher-layer tasks such as model predictive control. The approach is evaluated by performing a dynamic kicking motion with an igus Humanoid Open Platform robot.

- SL1M: Sparse L1-Norm Minimization for Contact Planning on Uneven Terrain

    Author: Tonneau, Steve | The University of Edinburgh
    Author: Song, Daeun | Ewha Womans University
    Author: Fernbach, Pierre | Cnrs - Laas
    Author: Mansard, Nicolas | CNRS
    Author: Ta�x, Michel | LAAS-CNRS/Université Paul Sabatier
    Author: Del Prete, Andrea | Max Planck Institute for Intelligent Systems
 
    keyword: Humanoid and Bipedal Locomotion; Optimization and Optimal Control; Humanoid Robots

    Abstract : One of the main challenges of planning legged locomotion in complex environments is the combinatorial contact selection problem. Recent contributions propose to use integer variables to represent which contact surface is selected, and then to rely on modern mixed-integer (MI) optimization solvers to handle this combinatorial issue. To reduce the computational cost of MI, we exploit the sparsity properties of L1 norm minimization techniques to relax the contact planning problem into a feasibility linear program. Our approach accounts for kinematic reachability of the center of mass (COM) and of the contact effectors. We ensure the existence of a quasi-static COM trajectory by restricting our plan to quasi-flat contacts. For planning 10 steps with less than 10 potential contact surfaces for each phase, our approach is 50 to 100 times faster that its MI counterpart, which suggests potential applications for online contact re-planning. The method is demonstrated in simulation with the humanoid robots HRP-2 and Talos over various scenarios.

- Finding Locomanipulation Plans Quickly in the Locomotion Constrained Manifold

    Author: Jorgensen, Steven Jens | The University of Texas at Austin
    Author: Vedantam, Mihir | University of Texas at Austin
    Author: Gupta, Ryan | University of Texas at Austin
    Author: Cappel, Henry | University of Texas at Austin
    Author: Sentis, Luis | The University of Texas at Austin
 
    keyword: Humanoid Robots; Manipulation Planning; Humanoid and Bipedal Locomotion

    Abstract : We present a method that finds locomanipulation plans that perform simultaneous locomotion and manipulation of objects for a desired end-effector trajectory. Key to our approach is to consider an injective locomotion constraint manifold that defines the locomotion scheme of the robot and then using this constraint manifold to search for admissible manipulation trajectories. The problem is formulated as a weighted-A* graph search whose planner output is a sequence of contact transitions and a path progression trajectory to construct the whole-body kinodynamic locomanipulation plan. We also provide a method for computing, visualizing, and learning the locomanipulability region, which is used to efficiently evaluate the edge transition feasibility during the graph search. Numerical simulations are performed with the NASA Valkyrie robot platform that utilizes a dynamic locomotion approach, called the divergent-component-of-motion (DCM), on two example locomanipulation scenarios.

- Force-Based Control of Bipedal Balancing on Dynamic Terrain with the "Tallahassee Cassie" Robotic Platform

    Author: White, Jason | Florida State University
    Author: Swart, Dylan | Florida State University
    Author: Hubicki, Christian | Florida State University
 
    keyword: Legged Robots; Humanoid and Bipedal Locomotion; Humanoid Robots

    Abstract : Out in the field, bipedal robots need to travel on terrain that is uneven, non-rigid, and sometimes moving beneath its feet. We present a simple force-based balancing controller for such dynamic terrain scenarios for bipedal robots, and test it on the robotic bipedal platform ``Tallahassee Cassie.'' The presented controller relies on minimal information about the robot model, requiring its kinematics and overall weight, but not inertias of individual links or components. The controller is pelvis-centric, commanding pelvis positions in Cartesian space, which a model-free PD controller converts to motor torques in joint space. By commanding forces, torques, and a frontal pressure center in this simple fashion, Tallahassee Cassie is capable of balancing on a variety of dynamic terrain scenarios, from a lifting/sliding platform, to soft foam, to a sudden drop. These results show the potential for bipedal control to balance successfully despite minimal model information, the presence of large dynamic impacts (e.g. falling through trap door), and soft series-spring deflections. These results motivate future work for simple walking and running controllers on dynamic terrain with relatively low reliance on modeling information.

- Simultaneous Control Framework for Humanoid Tracking Human Movement with Interacting Wearable Assistive Device

    Author: Ito, Takahiro | University of Tsukuba
    Author: Ayusawa, Ko | AIST
    Author: Yoshida, Eiichi | National Inst. of AIST
    Author: Kobayashi, Hiroshi | Tokyo University of Science
 
    keyword: Humanoid Robots; Physically Assistive Devices; Motion Control

    Abstract : Instead of human subjects, humanoid robots can be used as human dummies to test the human-designed products. We propose a controller that uses wearable assistive devices (also referred to as exoskeletons) to reproduce human movement in the evaluation. The proposed control scheme consists two components: one is the torque controller designed for a simplified interaction model with the device, and the other is the tracking controller based on a vector field to reproduce human motion. We implemented the proposed controller on the human-sized humanoid HRP-4 and validated the feasibility of the human motion reproduction by wearing the assistive device. In the experiment, we tested the commercially available device "Muscle Suit" by using our control scheme. The experimental results showed that while the device applies its supporting strength, the humanoid robot could reproduce human movements. The assistive effect of the device was visualized effectively in our evaluation framework.

## Force Control
- Dynamic Control of a Rigid Pneumatic Gripper

    Author: Romeo, Rocco Antonio | Istituto Italiano Di Tecnologia
    Author: Fiorio, Luca | Istituto Italiano Di Tecnologia
    Author: L'Erario, Giuseppe | Istituto Italiano Di Tecnologia
    Author: Maggiali, Marco | Italian Institute of Technology
    Author: Metta, Giorgio | Istituto Italiano Di Tecnologia (IIT)
    Author: Pucci, Daniele | Italian Institute of Technology
 
    keyword: Force Control; Grippers and Other End-Effectors; Sensor-based Control

    Abstract : Pneumatic grippers are hugely employed in robotic applications. Nonetheless, their control is not easy due to difficulty in managing the pressure inside their air chambers. Pneumatic grippers have often simple structure though the lack of affordable control algorithms complicates their usage. Motivated by these reasons, we wish to deliver a new control architecture for the closed-loop control of pneumatic grippers actuated by pressure regulators. The proposed architecture is composed of a main controller resorting on an optimization algorithm and of a state observer that estimates pressures in both gripper chambers, along with the exerted force. Instead, measured quantities (i.e. physical pressure in the gripper chambers and force recorded by a load cell between the gripper fingers) are used as inputs for the state observer to improve its output. The pneumatic gripper performance benefits from the joint action of the controller and of the state observer, as experimentally demonstrated. The gripper response will be shown for different types of inputs and on different setups.

- A Control Framework Definition to Overcome Position/Interaction Dynamics Uncertainties in Force-Controlled Tasks

    Author: Roveda, Loris | SUPSI-IDSIA
    Author: Castaman, Nicola | University of Padova
    Author: Franceschi, Paolo | CNR-STIIMA
    Author: Ghidoni, Stefano | University of Padova
    Author: Pedrocchi, Nicola | National Research Council of Italy (CNR)
 
    keyword: Force Control; Intelligent and Flexible Manufacturing; RGB-D Perception

    Abstract : Within the Industry 4.0 context, industrial robots have to implement increasing autonomy. The manipulator has to be capable to react to uncertainties/changes in the working environment, displaying a robust behavior. In this paper, a control framework is proposed to perform industrial interaction tasks in uncertain working scenes. The proposed methodology relies on two components: i) a 6D pose estimation algorithm aiming to recognize large and featureless parts; ii) a variable damping impedance controller (inner loop) enhanced by an adaptive saturation PI (outer loop) for high accuracy force control (i.e., zero steady-state force error and force overshoots avoidance). The proposed methodology allows to be robust with respect to task uncertainties (i.e., positioning errors and interaction dynamics). The proposed approach has been evaluated in an assembly task of a side-wall panel to be installed inside the aircraft cabin. As a test platform, the KUKA iiwa 14 R820 has been used, together with the Microsoft Kinect 2.0 as RGB-D sensor. Experiments show the reliability in the 6D pose estimation and the high-performance in the force-tracking task, avoiding force overshoots while achieving the tracking of the reference force.

- Identification of Compliant Contact Parameters and Admittance Force Modulation on a Non-Stationary Compliant Surface

    Author: Wijayarathne, Lasitha | Georgia Institute of Technology
    Author: Hammond III, Frank L. | Georgia Institute of Technology
 
    keyword: Force Control; Robust/Adaptive Control of Robotic Systems; Motion Control of Manipulators

    Abstract : Although autonomous control of robotic manipulators has been studied for several decades, they are not commonly used in safety-critical applications due to lack of safety and performance guarantees - many of them concerning the modulation of interaction forces. This paper presents a mechanical probing strategy for estimating the environmental impedance parameters of compliant environments, independent a manipulator's controller design and configuration. The parameter estimates are used in a position-based adaptive force controller to enable control of interaction forces in compliant, stationary and non-stationary environments. This approach is targeted for applications where the workspace is constrained and non-stationary, and where force control is critical to task success. These applications include surgical tasks involving manipulation of compliant, delicate, moving tissues. Results show fast parameter estimation and successful force modulation that compensates for motion.

- Convex Controller Synthesis for Robot Contact

    Author: Pham, Hung | Nanyang Technological University
    Author: Pham, Quang-Cuong | NTU Singapore
 
    keyword: Force Control; Physical Human-Robot Interaction; Compliance and Impedance Control

    Abstract : Controlling contacts is truly challenging, and this has been a major hurdle to deploying industrial robots into unstructured/human-centric environments. More specifically, the main challenges are: (i) how to ensure stability at all times; (ii) how to satisfy task-specific performance specifications; (iii) how to achieve (i) and (ii) under environment uncertainty, robot parameters uncertainty, sensor and actuator time delays, external perturbations, etc. Here, we propose a new approach -- Convex Controller Synthesis (CCS) -- to tackle the above challenges based on robust control theory and convex optimization. In two physical interaction tasks -- robot hand guiding and sliding on surfaces with different and unknown stiffnesses -- we show that CCS controllers outperform their classical counterparts in an essential way.

- Force Adaptation in Contact Tasks with Dynamical Systems

    Author: Amanhoud, Walid | EPFL
    Author: Khoramshahi, Mahdi | EPFL
    Author: Bonnesoeur, Maxime | EPFL
    Author: Billard, Aude | EPFL
 
    keyword: Force Control; Compliance and Impedance Control; Physical Human-Robot Interaction

    Abstract : In many tasks such as finishing operations, achieving accurate force tracking is essential. However, uncertainties in the robot dynamics and the environment limit the force tracking accuracy. Learning a compensation model for these uncertainties to reduce the force error is an effective approach to overcome this limitation. However, this approach requires an adaptive and robust framework for motion and force generation. In this paper, we use the time-invariant Dynamical System (DS) framework for force adaptation in contact tasks. We propose to improve force tracking accuracy through online adaptation of a state-dependent force correction model encoded with Radial Basis Functions (RBFs). We evaluate our method with a KUKA LWR IV+ robotic arm. We show its efficiency to reduce the force error to a negligible amount with different target forces and robot velocities. Furthermore, we study the effect of the hyper-parameters and provide a guideline for their selection. We showcase a collaborative cleaning task with a human by integrating our method to previous works to achieve force, motion, and task adaptation at the same time. Thereby, we highlight the benefits of using adaptive force control in real-world environments where we need reactive and adaptive behaviours in response to interactions with the environment.

- Sensitivity Ellipsoids for Force Control of Magnetic Robots with Localization Uncertainty (I)

    Author: Slawinski, Piotr | Vanderbilt University
    Author: Simaan, Nabil | Vanderbilt University
    Author: Taddese, Addisu | Vanderbilt University
    Author: Obstein, Keith | Vanderbilt University
    Author: Valdastri, Pietro | University of Leeds
 
    keyword: Force Control; Localization; Medical Robots and Systems

    Abstract : The navigation of magnetic medical robots typically relies on localizing an actuated, intracorporeal, ferromagnetic body and back-computing a necessary field and gradient that would result in a desired wrench on the device. Uncertainty in this localization degrades the precision of force transmission. Reducing applied force uncertainty may enhance tasks such as in-vivo navigation of miniature robots, actuation of magnetically guided catheters, tissue palpation, as well as simply ensuring a bound on forces applied on sensitive tissue. In this paper, we analyzed the effects of localization noise on force uncertainty by using sensitivity ellipsoids of the magnetic force Jacobian and introduced an algorithm for uncertainty reduction. We validated the algorithm in both a simulation study and in a physical experiment. In simulation, we observed reductions in estimated force uncertainty by factors of up to 2.8 and 3.1 when using one and two actuating magnets, respectively. On a physical platform, we demonstrated a force uncertainty reduction by a factor of up to 2.5 as measured using an external sensor. Being the first consideration of force uncertainty resulting from noisy localization, this work provides a strategy for investigators to minimize uncertainty in magnetic force transmission.

## Semantic Scene Understanding

- Highly Parallelizable Plane Extraction for Organized Point Clouds Using Spherical Convex Hulls

    Author: M�ls, Hannes | Intelligent Sensor-Actuator-Systems Lab (ISAS), Karlsruhe Instit
    Author: Li, Kailai | Karlsruhe Institute of Technology (KIT)
    Author: Hanebeck, Uwe D. | Karlsruhe Institute of Technology (KIT)
 
    keyword: Semantic Scene Understanding; Computer Vision for Other Robotic Applications

    Abstract : We present a novel region growing algorithm for plane extraction of organized point clouds using the spherical convex hull. Instead of explicit plane parameterization, our approach interprets potential underlying planes as a series of geometric constraints on the sphere that are refined during region growing. Unlike existing schemes relying on downsampling for sequential execution in real time, our approach enables pixelwise plane extraction that is highly parallelizable. We further test the proposed approach with a fully parallel implementation on a GPU. Evaluation based on public data sets has shown state-of-the-art extraction accuracy and superior speed compared to existing approaches, while guaranteeing real-time processing at full input resolution of a typical RGB-D camera.

- Boosting Real-Time Driving Scene Parsing with Shared Semantics

    Author: Xiang, Zhenzhen | Shanghai Jiao Tong University
    Author: Bao, Anbo | Shanghai Jiao Tong University
    Author: Li, Jie | SAIC Motor
    Author: Su, Jianbo | Shanghai Jiao Tong University
 
    keyword: Semantic Scene Understanding; Autonomous Vehicle Navigation

    Abstract : Real-time scene parsing is a fundamental feature for autonomous driving vehicles with multiple cameras. In this letter we demonstrate that sharing semantics between cameras with different perspectives and overlapping views can boost the parsing performance when compared with traditional methods, which individually process the frames from each camera. Our framework is based on a deep neural network for semantic segmentation but with two kinds of additional modules for sharing and fusing semantics. On the one hand, a semantics sharing module is designed to establish the pixel-wise mapping between the input images. Features as well as semantics are shared by the map to reduce duplicated workload, which leads to more efficient computation. On the other hand, feature fusion modules are designed to combine different modalities of semantic features, which leverages the information from both inputs for better accuracy. To evaluate the effectiveness of the proposed framework, we have applied our network to a dual-camera vision system for driving scene parsing. Experimental results show that our network outperforms the baseline method on the parsing accuracy with comparable computations.

- CNN-Based Lidar Point Cloud De-Noising in Adverse Weather

    Author: Heinzler, Robin | Daimler AG
    Author: Piewak, Florian | Daimler AG
    Author: Schindler, Philipp | Daimler AG
    Author: Stork, Wilhelm | FZI Karlsruhe
 
    keyword: Semantic Scene Understanding; Visual Learning; Computer Vision for Transportation

    Abstract : Lidar sensors are frequently used in environment perception for autonomous vehicles and mobile robotics to com- plement camera, radar, and ultrasonic sensors. Adverse weather conditions are significantly impacting the performance of lidar- based scene understanding by causing undesired measurement points that in turn effect missing detections and false positives. In heavy rain or dense fog, water drops could be misinterpreted as objects in front of the vehicle which brings a mobile robot to a full stop. In this paper, we present the first CNN-based approach to understand and filter out such adverse weather effects in point cloud data. Using a large data set obtained in controlled weather environments, we demonstrate a significant performance improvement of our method over state-of-the-art involving geometric filtering.

- View-Invariant Loop Closure with Oriented Semantic Landmarks

    Author: Li, Jimmy | McGill University
    Author: Koreitem, Karim | McGill University
    Author: Meger, David Paul | McGill University
    Author: Dudek, Gregory | McGill University
 
    keyword: Semantic Scene Understanding; Visual-Based Navigation; SLAM

    Abstract : Recent work on semantic simultaneous localization and mapping (SLAM) have shown the utility of natural objects as landmarks for improving localization accuracy and robustness. In this paper we present a monocular semantic SLAM system that uses object identity and inter-object geometry for view-invariant loop detection and drift correction. Our system's ability to recognize an area of the scene even under large changes in viewing direction allows it to surpass the mapping accuracy of ORB-SLAM, which uses only local appearance-based features that are not robust to large viewpoint changes. Experiments on real indoor scenes show that our method achieves mean drift reduction of 70% when compared directly to ORB-SLAM. Additionally, we propose a method for object orientation estimation, where we leverage the tracked pose of a moving camera under the SLAM setting to overcome ambiguities caused by object symmetry. This allows our SLAM system to produce geometrically detailed semantic maps with object orientation, translation, and scale.

- Semantic Foreground Inpainting from Weak Supervision

    Author: Lu, Chenyang | Eindhoven University of Technology
    Author: Dubbelman, Gijs | Eindhoven University of Technology
 
    keyword: Semantic Scene Understanding; Computer Vision for Transportation

    Abstract : Semantic scene understanding is an essential task for self-driving vehicles and mobile robots. In our work, we aim to estimate a semantic segmentation map, in which the foreground objects are removed and semantically inpainted with background classes, from a single RGB image. This semantic foreground inpainting task is performed by a single-stage convolutional neural network (CNN) that contains our novel max-pooling as inpainting (MPI) module, which is trained with weak supervision, i.e., it does not require manual background annotations for the foreground regions to be inpainted. Our approach is inherently more efficient than the previous two-stage state-of-the-art method, and outperforms it by a margin of 3% IoU for the inpainted foreground regions on Cityscapes. The performance margin increases to 6% IoU, when tested on the unseen KITTI dataset. The code and the manually annotated datasets for testing are shared with the research community at https://github.com/Chenyang-Lu/semantic-foreground-inpainting.

- Fast Panoptic Segmentation Network

    Author: de Geus, Daan | Eindhoven University of Technology
    Author: Meletis, Panagiotis | Eindhoven University of Technology
    Author: Dubbelman, Gijs | Eindhoven University of Technology
 
    keyword: Semantic Scene Understanding; Object Detection, Segmentation and Categorization; Deep Learning in Robotics and Automation

    Abstract : In this work, we present an end-to-end network for fast panoptic segmentation. This network, called Fast Panoptic Segmentation Network (FPSNet), does not require computationally costly instance mask predictions or rule-based merging operations. This is achieved by casting the panoptic task into a custom dense pixel-wise <i>classification</i> task, which assigns a class label or an instance <i>id</i> to each pixel. We evaluate FPSNet on the Cityscapes and Pascal VOC datasets, and find that FPSNet is faster than existing panoptic segmentation methods, while achieving better or similar panoptic segmentation performance. On the Cityscapes validation set, we achieve a Panoptic Quality score of 55.1%, at prediction times of 114 milliseconds for images with a resolution of 1024x2048 pixels. For lower resolutions of the Cityscapes dataset and for the Pascal VOC dataset, FPSNet achieves prediction times as low as 45 and 28 milliseconds, respectively.

- Weakly Supervised Silhouette-Based Semantic Scene Change Detection

    Author: Sakurada, Ken | National Institute of Advanced Industrial Science and Technology
    Author: Shibuya, Mikiya | Tokyo Institute of Technology University
    Author: Wang, Weimin | National Institute of Advanced Industrial Science and Technology
 
    keyword: Semantic Scene Understanding; Object Detection, Segmentation and Categorization; Recognition

    Abstract : This paper presents a novel semantic scene change detection scheme with only weak supervision. A straightforward approach for this task is to train a semantic change detection network directly from a large-scale dataset in an end-to-end manner. However, a specific dataset for this task, which is usually labor-intensive and time-consuming, becomes indispensable. To avoid this problem, we propose to train this kind of network from existing datasets by dividing this task into change detection and semantic extraction. On the other hand, the difference in camera viewpoints, for example, images of the same scene captured from a vehicle-mounted camera at different time points, usually brings a challenge to the change detection task. To address this challenge, we propose a new siamese network structure with the introduction of correlation layer. In addition, we create a publicly available dataset for semantic change detection to evaluate the proposed method. The experimental results verified both the robustness to viewpoint difference in change detection task and the effectiveness for semantic change detection of the proposed networks. Our code and dataset are available at https://github.com/xdspacelab/sscdnet.

- 3DCFS: Fast and Robust Joint 3D Semantic-Instance Segmentation Via Coupled Feature Selection

    Author: Du, Liang | Fudan University
    Author: Tan, Jingang | Shanghai Institute of Microsystem and Information Technology, Uni
    Author: Xue, Xiangyang | Fudan University
    Author: Chen, Lili | Shanghai Institute of Microsystem and Information Technology, Ch
    Author: Wen, Hongkai | University of Warwick
    Author: Feng, Jianfeng | Fudan University
    Author: Li, Jiamao | Shanghai Institute of Microsystem and Information Technology, Chi
    Author: Zhang, Xiaolin | Shanghai Institute of Microsystem and Information Technology, Chi
 
    keyword: Semantic Scene Understanding; RGB-D Perception; Object Detection, Segmentation and Categorization

    Abstract : We propose a novel fast and robust 3D point clouds segmentation framework via coupled feature selection, named 3DCFS, that jointly performs semantic and instance segmentation. Inspired by the human scene perception process, we design a novel coupled feature selection module, named CFSM, that adaptively selects and fuses the reciprocal semantic and instance features from two tasks in a coupled manner. To further boost the performance of the instance segmentation task in our 3DCFS, we investigate a loss function that helps the model learn to balance the magnitudes of the output embedding dimensions during training, which makes calculating the Euclidean distance more reliable and enhances the generalizability of the model. Extensive experiments demonstrate that our 3DCFS outperforms state-of-the-art methods on benchmark datasets in terms of accuracy, speed and computational cost. Codes are available at: https://github.com/Biotan/3DCFS.

- Who2com: Collaborative Perception Via Learnable Handshake Communication

    Author: Liu, Yen-Cheng | Georgia Tech
    Author: Tian, Junjiao | Georgia Institute of Technology
    Author: Ma, Chih-Yao | Georgia Tech
    Author: Glaser, Nathaniel | Georgia Institute of Technology
    Author: Kuo, Chia-Wen | Georgia Institute of Technology
    Author: Kira, Zsolt | Georgia Institute of Technology
 
    keyword: Semantic Scene Understanding; Object Detection, Segmentation and Categorization; Networked Robots

    Abstract : In this paper, we propose the problem of collaborative perception, where robots can combine their local observations with those of neighboring agents in a learnable way to improve accuracy on a perception task. Unlike existing work in robotics and multi-agent reinforcement learning, we formulate the problem as one where learned information must be shared across a set of agents in a bandwidth-sensitive manner to optimize for scene understanding tasks such as semantic segmentation. Inspired by networking communication protocols, we propose a handshake communication mechanism where the neural network can learn to compress relevant information needed for each stage. Specifically, a target agent with degraded sensor data sends a compressed request, the other agents respond with matching scores, and the target agent determines who to connect with(i.e., receive information from). We additionally develop the dataset and metrics based on the AirSim simulator where a group of aerial robots perform navigation and search missions over diverse landscapes, such as roads, grasslands, buildings, lakes, etc. We show that for the semantic segmentation task, our handshake communication method significantly improves accuracy by approximately 20% over decentralized baselines, and is comparable to centralized ones using a quarter of the bandwidth.

- Comparing View-Based and Map-Based Semantic Labelling in Real-Time SLAM

    Author: Landgraf, Zoe | Imperial College London
    Author: Falck, Fabian | Imperial College London
    Author: Bloesch, Michael | Imperial College
    Author: Leutenegger, Stefan | Imperial College London
    Author: Davison, Andrew J | Imperial College London
 
    keyword: Semantic Scene Understanding; RGB-D Perception; SLAM

    Abstract : Generally capable Spatial AI systems must build persistent scene representations where geometric models are combined with meaningful semantic labels. The many approaches to labelling scenes can be divided into two clear groups: emph{view-based} which estimate labels from the input view-wise data and then incrementally fuse them into the scene model as it is built; and emph{map-based} which label the generated scene model. However, there has so far been no attempt to quantitatively compare view-based and map-based labelling. Here, we present an experimental framework and comparison which uses real-time height map fusion as an accessible platform for a fair comparison, opening up the route to further systematic research in this area.

- Generative Modeling of Environments with Scene Grammars and Variational Inference

    Author: Izatt, Gregory | MIT
    Author: Tedrake, Russ | Massachusetts Institute of Technology
 
    keyword: Semantic Scene Understanding

    Abstract : In order to understand how a robot will perform in the open world, we aim to establish a quantitative understanding of the distribution of environments that a robot will face when when it is deployed. However, even restricting attention only to the distribution of objects in a scene, these distributions over environments are nontrivial: they describe mixtures of discrete and continuous variables related to the number, type, poses, and attributes of objects in the scene. We describe a probabilistic generative model that uses scene trees to capture hierarchical relationships between collections of objects, as well as a variational inference algorithm for tuning that model to best match a set of observed environments without any need for tediously labeled parse trees. We demonstrate that this model can accurately capture the distribution of a pair of nontrivial manipulation-relevant datasets and be deployed as a density estimator and outlier detector for novel environments.

- SHOP-VRB: A Visual Reasoning Benchmark for Object Perception

    Author: Nazarczuk, Michal | Imperial College London
    Author: Mikolajczyk, Krystian | University of Surrey
 
    keyword: Semantic Scene Understanding; Object Detection, Segmentation and Categorization; Computer Vision for Automation

    Abstract : In this paper we present an approach and a benchmark for visual reasoning in robotics applications, in particular small object grasping and manipulation. The approach and benchmark are focused on inferring object properties from visual and text data. It concerns small household objects with their properties, functionality, natural language descriptions as well as question-answer pairs for visual reasoning queries along with their corresponding scene semantic representations. We also present a method for generating synthetic data which allows to extend the benchmark to other objects or scenes and propose an evaluation protocol that is more challenging than in the existing datasets. We propose a reasoning system based on symbolic program execution. A disentangled representation of the visual and textual inputs is obtained and used to execute symbolic programs that represent a 'reasoning process' of the algorithm. We perform a set of experiments on the proposed benchmark and compare to results for the state of the art methods. These results expose the shortcomings of the existing benchmarks that may lead to misleading conclusions on the actual performance of the visual reasoning systems.

## Social Human-Robot Interaction
- Simultaneous Learning from Human Pose and Object Cues for Real-Time Activity Recognition

    Author: Reily, Brian | Colorado School of Mines
    Author: Zhu, Qingzhao | Colorado School of Mines
    Author: Reardon, Christopher M. | U.S. Army Research Laboratory
    Author: Zhang, Hao | Colorado School of Mines
 
    keyword: Human-Centered Robotics; Social Human-Robot Interaction; Computer Vision for Other Robotic Applications

    Abstract : Real-time human activity recognition plays an essential role in real-world human-centered robotics applications, such as assisted living and human-robot collaboration. Although previous methods based on skeletal data to encode human poses showed promising results on real-time activity recognition, they lacked the capability to consider the context provided by objects within the scene and in use by the humans, which can provide a further discriminant between human activity categories. In this paper, we propose a novel approach to real-time human activity recognition, through simultaneously learning from observations of both human poses and objects involved in the human activity. We formulate human activity recognition as a joint optimization problem under a unified mathematical framework, which uses a regression-like loss function to integrate human pose and object cues and defines structured sparsity-inducing norms to identify discriminative body joints and object attributes. To evaluate our method, we perform extensive experiments on two benchmark datasets and a physical robot in a home assistance setting. Experimental results have shown that our method outperforms previous methods and obtains real-time performance for human activity recognition with a processing speed of 10<sup>4</sup> Hz.

- Demonstration of Hospital Receptionist Robot with Extended Hybrid Code Network

    Author: Hwang, Eui Jun | The University of Auckland
    Author: Ahn, Byeong-Kyu | Sungkyunkwan University
    Author: MacDonald, Bruce | University of Auckland
    Author: Ahn, Ho Seok | The University of Auckland, Auckland
 
    keyword: Service Robots; Deep Learning in Robotics and Automation; Physical Human-Robot Interaction

    Abstract : Task-oriented dialogue system has a vital role in Human-Robot Interaction (HRI). However, it has been developed based on conventional pipeline approach which has several drawbacks; expensive, time-consuming, and so on. Based on this approach, developers manually define a robot's behaviour such as gestures and facial expressions on the corresponding dialogue states. Recently, end-to-end learning of Recurrent Neural Networks (RNNs) is an attractive solution for the dialogue system. In this paper, we proposed a social robot system using end-to-end dialogue system in the context of hospital receptionist. We utilized Hybrid Code Network (HCN) as an end-to-end dialogue system and extended to select both response and gesture using RNN based gesture selector. We evaluate its performance with human users and compare the results with one of the conventional methods. Empirical result shows that the proposed method has benefits in terms of dialogue efficiency, which indicates how efficient users were in performing the given tasks with the help of the robot. Moreover, we achieved the same performance regarding the robot's gesture with the proposed method compared to manually defined gestures.

- Can I Trust You? a User Study of Robot Mediation of a Support Group

    Author: Birmingham, Chris | University of Southern California
    Author: Hu, Zijian | University of Southern California
    Author: Mahajan, Kartik | University of Southern California
    Author: Reber, Elijah | Penn State University
    Author: Mataric, Maja | University of Southern California
 
    keyword: Social Human-Robot Interaction

    Abstract : Socially assistive robots have the potential to improve group dynamics when interacting with groups of people in social settings. This work contributes to the understanding of those dynamics through a user study of trust dynamics in the novel context of a robot mediated support group. For this study, a novel framework for robot mediation of a support group was developed and validated. To evaluate interpersonal trust in the multi-party setting, a dyadic trust scale was implemented and found to be uni-factorial, validating it as an appropriate measure of general trust. The results of this study demonstrate a significant increase in average interpersonal trust after the group interaction session, and qualitative post-session interview data report that participants found the interaction helpful and successfully supported and learned from one other. The results of the study validate that a robot-mediated support group can improve trust among strangers and allow them to share and receive support for their academic stress.

- Group Split and Merge Prediction with 3D Convolutional Networks

    Author: Wang, Allan | Carnegie Mellon University
    Author: Steinfeld, Aaron | Carnegie Mellon University
 
    keyword: Human-Centered Robotics; Human Detection and Tracking; Social Human-Robot Interaction

    Abstract : Mobile robots in crowds often have limited navigation capability due to insufficient evaluation of pedestrian behavior. We strengthen this capability by predicting splits and merges in multi-person groups. Successful predictions should lead to more efficient planning while also increasing human acceptance of robot behavior. We take a novel approach by formulating this as a video prediction problem, where group splits or merges are predicted given a history of geometric social group shape transformations. We take inspiration from the success of 3D convolution models for video-related tasks. By treating the temporal dimension as a spatial dimension, a modified C3D model successfully captures the temporal features required to perform the prediction task. We demonstrate performance on several datasets and analyze transfer ability to other settings. While current approaches for tracking human motion are not explicitly designed for this task, our approach performs significantly better. We also draw human interpretations from the model's learned features.

- TH�R: Human-Robot Navigation Data Collection and Accurate Motion Trajectories Dataset

    Author: Rudenko, Andrey | Robert Bosch GmbH
    Author: Kucner, Tomasz Piotr | Örebro Universitet
    Author: Swaminathan, Chittaranjan Srinivas | Örebro University
    Author: Chadalavada, Ravi Teja | Örebro University
    Author: Arras, Kai Oliver | Bosch Research
    Author: Lilienthal, Achim J. | Orebro University
 
    keyword: Social Human-Robot Interaction; Motion and Path Planning; Human Detection and Tracking

    Abstract : Understanding human behavior is key for robots and intelligent systems that share a space with people. Accordingly, research that enables such systems to perceive, track, learn and predict human behavior as well as to plan and interact with humans has received increasing attention over the last years. The availability of large human motion datasets that contain relevant levels of difficulty is fundamental to this research. Existing datasets are often limited in terms of information content, annotation quality or variability of human behavior. In this paper, we present TH�R, a new dataset with human motion trajectory and eye gaze data collected in an indoor environment with accurate ground truth for position, head orientation, gaze direction, social grouping, obstacles map and goal coordinates. TH�R also contains sensor data collected by a 3D lidar and involves a mobile robot navigating the space. We propose a set of metrics to quantitatively analyze motion trajectory datasets such as the average tracking duration, ground truth noise, curvature and speed variation of the trajectories. In comparison to prior art, our dataset has a larger variety in human motion behavior, is less noisy, and contains annotations at higher frequencies.

- Socially Assistive Infant-Robot Interaction: Using Robots to Encourage Infant Leg-Motion (I)

    Author: Fitter, Naomi T. | University of Southern California
    Author: Funke, Rebecca | University of Southern California
    Author: Pulido Pascual, Jos' Carlos | Universidad Carlos III De Madrid
    Author: Eisenman, Lauren E. | University of Southern California
    Author: Deng, Weiyang | University of Southern California
    Author: Rosales, Marcelo R. | University of Southern California
    Author: Bradley, Nina | University of Southern California
    Author: Sargent, Barbara | University of Southern California
    Author: Smith, Beth | University of Southern California
    Author: Mataric, Maja | University of Southern California
 
    keyword: Social Human-Robot Interaction; Rehabilitation Robotics; Robot Companions

    Abstract : Early interventions have the potential to positively influence infant movement patterns and support optimal neurodevelopmental outcomes. This work developed and validated a non-contact socially assistive infant-robot interaction system that aimed to use contingent reward learning and imitation to deliver effective early interventions that complement human-delivered therapy. <p>The described study explored if infants demonstrate contingent learning and imitation behavior in response to movements by a similarly-sized NAO humanoid robot. Twelve 6- to 8-month-old infants participated in a within-subjects study that compared different robot contingent reward policies for encouraging leg movement. Nine of the twelve participants learned the contingency. Of these learners, two responded less to the movement and lights reward than other rewards. Nine of the twelve infants imitated the NAO robot during at least one reward condition phase. These imitators displayed different learning rates and sometimes changed their behavior to imitate less during later reward conditions. Infants were generally alert and non-fussy when interacting with the robot. Parents of participants perceived the robot reward involving both movement and sound to be most engaging for their children.</p><p>As the new research area of infant-robot interaction develops, our results aim to inform continued work into targeted robot-assisted infant motion interventions.


- Real-Time Continuous Hand Motion Myoelectric Decoding by Automated Data Labeling

    Author: Hu, Xuhui | Southeast University
    Author: Zeng, Hong | Southeast University
    Author: Chen, Dapeng | Southeast University
    Author: Zhu, Jiahang | Southeast University
    Author: Song, Aiguo | Southeast University
 
    keyword: Social Human-Robot Interaction; Gesture, Posture and Facial Expressions; Prosthetics and Exoskeletons

    Abstract : In this paper an automated data labeling (ADL) neural network is proposed to streamline dataset collecting for real-time predicting the continuous motion of hand and wrist, these gestures are only decoded from a surface electromyography (sEMG) array of eight channels. Unlike collecting both the bio-signals and hand motion signals as samples and labels in supervised learning, this algorithm only collects unlabeled sEMG into an unsupervised neural network, in which the hand motion labels are auto-generated. The coefficient of determination (R^2) for three DOFs, i.e. wrist flex/extension, wrist pro/supination, hand open/close, was 0.86, 0.89 and 0.87 respectively. The comparison between real motion labels and auto-generated labels shows that the latter has earlier response than former. The results of Fitts' law test indicate that ADL has capability of controlling multi-DOFs simultaneously even though the training set only contains sEMG data from single DOF gesture. Moreover, no more hand motion measurement needed which greatly helps upper limb amputee imagine the gesture of residual limb to control a dexterous prosthesis.

- Towards Proactive Navigation: A Pedestrian-Vehicle Cooperation Based Behavioral Model

    Author: Kabtoul, Maria | Univ. Grenoble Alpes, Inria
    Author: Spalanzani, Anne | INRIA / Univ. Grenoble Alpes
    Author: Martinet, Philippe | INRIA
 
    keyword: Social Human-Robot Interaction; Autonomous Vehicle Navigation; Human-Centered Automation

    Abstract : Developing autonomous vehicles capable of navigating safely and socially around pedestrians is a major challenge in intelligent transportation. This challenge cannot be met without understanding pedestrians' behavioral response to an autonomous vehicle, and the task of building a clear and quantitative description of the pedestrian to vehicle interaction remains a key milestone in autonomous navigation research. As a step towards safe proactive navigation in a space shared with pedestrians, this work introduces a pedestrian-vehicle interaction behavioral model. The model estimates the pedestrian's cooperation with the vehicle in an interaction scenario by a quantitative time-varying function. Using this cooperation estimation the pedestrian's trajectory is predicted by a cooperation-based trajectory planning model. Both parts of the model are tested and validated using real-life recorded scenarios of pedestrian-vehicle interaction. The model is capable of describing and predicting agents' behaviors when interacting with a vehicle in both lateral and frontal crossing scenarios.

- Studying Navigation As a Form of Interaction: A Design Approach for Social Robot Navigation Methods

    Author: Scales, Philip | Université Grenoble Alpes
    Author: Aycard, Olivier | University Grenoble
    Author: Aubergé, Véronique | University Grenoble Alps, LIG, UMR CNRS 5217
 
    keyword: Social Human-Robot Interaction; Motion and Path Planning

    Abstract : Social Navigation methods attempt to integrate knowledge from Human Sciences fields such as the notion of Proxemics into mobile robot navigation. They are often evaluated in simulations, or lab conditions with informed participants, and studies of the impact of the robot behavior on humans are rare. Humans communicate and interact through many vectors, of which motion and positioning, which can be related to social hierarchy and the socio-physical context. If a robot is to be deployed among humans, the methods it uses should be designed with this in mind. This work acts as the first step in an ongoing project in which we explore how to design navigation methods for mobile robots destined to be deployed among humans. We aim to consider navigation as more than just a functionality of the robot, and to study the impact of robot motion on humans. In this paper, we focus on the person-following task. We selected a state of the art person-following method as the basis for our method, which we modified and extended in order for it to be more general and adaptable. We conducted pilot experiments using this method on a real mobile robot in ecological contexts. We used results from the experiments to study the Human-Robot Interaction as a whole by analysing both the person-following method and the human behavior. Our preliminary results show that the way in which the robot followed a person had an impact on the interaction that emerged between them.

- Robot Plan Model Generation and Execution with Natural Language Interface

    Author: Yang, Kyon-Mo | Korea Institute of Robot and Convergence
    Author: Seo, Kap-Ho | Korea Institute of Robot and Convergence
    Author: Kang, Sang Hoon | Ulsan National Institute of Science and Technology(UNIST) / U. O
    Author: Lim, Yoonseob | Korea Institute of Science and Technology
 
    keyword: Social Human-Robot Interaction; Cognitive Human-Robot Interaction; Task Planning

    Abstract : Verbal interaction between human and robot may play a key role in conveying suitable directions for a robot to achieve the goal of user's request. However, robot may need to correct task plans or make new decisions with human help, which would make the interaction inconvenient and also increase the interaction time. In this paper, we propose a new verbal interaction based method that can generate plan models and execute proper actions without human involvement in the middle of performing task by robot. To understand verbal behaviors of human when giving instructions to robot, we first conducted a brief user study and found that human user does not explicitly express the required task. To handle such unclear instructions by human, we propose two different algorithms that can generate component of new plan models based on intents and entities parsed from natural language, and can resolve the unclear entities existed in human instructions. Experimental scenario with robot, Cozmo was tried in the lab environment to test whether or not proposed method could generate appropriate plan model. As a result, we found that robot could successfully accomplish the task following human instructions and also found that number of interaction and components in the plan model could be reduced as opposed to general reactive plan model. In the future, we are going to improve the automated process of generating plan models and apply various scenarios under different service environments and robots

- Mapless Navigation among Dynamics with Social-Safety-Awareness: A Reinforcement Learning Approach from 2D Laser Scans

    Author: Jin, Jun | University of Alberta
    Author: Nguyen, Nhat | Huawei Technologies Canada
    Author: Sakib, Nazmus | University of Alberta
    Author: Graves, Daniel | Huawei Technologies Canada, Ltd
    Author: Yao, Hengshuai | Huawei
    Author: Jagersand, Martin | University of Alberta
 
    keyword: Social Human-Robot Interaction; Collision Avoidance; Autonomous Vehicle Navigation

    Abstract : We propose a method to tackle the problem of mapless collision-avoidance navigation where humans are present using 2D laser scans. Our proposed method uses ego-safety to measure collision from the robot's perspective while social-safety to measure the impact of our robot's actions on surrounding pedestrians. Specifically, the social-safety part predicts the intrusion impact of our robot's action into the interaction area with surrounding humans. We train the policy using reinforcement learning on a simple simulator and directly evaluate the learned policy in Gazebo and real robot tests. Experiments show the learned policy can be smoothly transferred without any fine tuning. We observe that our method demonstrates time-efficient path planning behavior with high success rate in mapless navigation tasks. Furthermore, we test our method in a navigation among dynamic crowds task considering both low and high volume traffic. Our learned policy demonstrates cooperative behavior that actively drives our robot into traffic flows while showing respect to nearby pedestrians. Evaluation videos are at https://sites.google.com/view/ssw-batman

- People's Adaptive Side-By-Side Model Evolved to Accompany Groups of People by Social Robots

    Author: Repiso, Ely | Institut De Robòtica I Informàtica Industrial, CSIC-UPC
    Author: Garrell, Anais | UPC-CSIC
    Author: Sanfeliu, Alberto | Universitat Politècnica De Cataluyna
 
    keyword: Social Human-Robot Interaction; Humanoid Robots; Service Robots

    Abstract : The presented method implements a robot accompaniment in an adaptive side-by-side formation of a single person or a group of people. The method enhances our previous robot adaptive side-by-side behavior allowing the robot to accompany a group of people, not only one person. Adaptive means that the robot is capable to adjust its position and velocity to the behavior of the group being accompanied, without bothering other pedestrians in the environment, as well as facilitating the group navigation to avoid static and dynamic obstacles. Furthermore, the robot can deal with the random factor of human behavior in several situations. Firstly, if other people interfere in the path of the companions, the robot leaves space for the person of the group that has to avoid those other people, by approaching the other companion. Also, without invading any personal space. Secondly, if the people of the group changes their physical position inside the group formation, then the robot adapts to them dynamically by changing from the lateral position to the central position of the formation or otherwise. Thirdly, the robot adapts to changes in the velocity of people in the group and other people that interfere in the path of the group, in magnitude and orientation. Fourthly, the robot can deal with occlusions of one accompanied person by the other. The method has been validated using synthetic experiments and real-life experiments with our robot. Finally,we developed an user study comparing the

## Biologically-Inspired Robots

- Coronal Plane Spine Twisting Composes Shape to Adjust the Energy Landscape for Grounded Reorientation

    Author: Caporale, J. Diego | University of Pennsylvania
    Author: McInroe, Benjamin | University of California, Berkeley
    Author: Ning, Chenze | University of Pennsylvania
    Author: Libby, Thomas | University of Washington
    Author: Full, Robert | University of California at Berkeley
    Author: Koditschek, Daniel | University of Pennsylvania
 
    keyword: Biologically-Inspired Robots; Legged Robots

    Abstract : Despite substantial evidence for the crucial role played by an active backbone or spine in animal locomotion,its adoption in legged robots remains limited because the added mechanical complexity and resulting dynamical challenges pose daunting obstacles to characterizing even a partial range of potential performance benefits. This paper takes a next step toward such a characterization by exploring the quasistatic terrestrial self-righting mechanics of a model system with coronal plane spine twisting (CPST). Reduction from a full 3D kinematic model of CPST to a two parameter, two degree of freedom coronal plane representation of body shape affordance predicts a substantial benefit to ground righting by lowering the barrier between stable potential energy basins. The reduced model predicts the most advantageous twist angle for several cross-sectional geometries, reducing the required righting torque by up to an order of magnitude depending on constituent shapes. Experiments with a three actuated degree of freedom physical mechanism corroborate the kinematic model predictions using two different quasistatic reorientation maneuvers for both elliptical and rectangular shaped bodies with a range of eccentricities or aspect ratios. More speculative experiments make intuitive use of the kinematic model in a highly dynamic maneuver to suggest still greater benefits of CPST achievable by coordinating kinetic as well as potential energy, for example as in a future multi-appendage system

- Significance of the Compliance of the Joints on the Dynamic Slip Resistance of a Bioinspired Hoof (I)

    Author: Abad Guaman, Sara Adela | University College London
    Author: Herzig, Nicolas | University of Sheffield
    Author: Sadati, Seyedmohammadhadi | King's College London
    Author: Nanayakkara, Thrishantha | Imperial College London
 
    keyword: Biologically-Inspired Robots; Compliant Joint/Mechanism; Legged Robots

    Abstract : Robust mechanisms for slip resistance are an open challenge in legged locomotion. Animals such as goats show impressive ability to resist slippage on cliffs. It is not fully known what attributes in their body determine this ability. Studying the slip resistance dynamics of the goat may offer insight toward the biologically inspired design of robotic hooves. This article tests how the embodiment of the hoof contributes to solving the problem of slip resistance. We ran numerical simulations and experiments using a passive robotic goat hoof for different compliance levels of its three joints. We established that compliant yaw and pitch and stiff roll can increase the energy required to slide the hoof by ~20% compared to the baseline (stiff hoof). Compliant roll and pitch allow the robotic hoof to adapt to the irregularities of the terrain. This produces an antilock braking system-like behavior of the robotic hoof for slip resistance. Therefore, the pastern and coffin joints have a substantial effect on the slip resistance of the robotic hoof, while the fetlock joint has the lowest contribution. These shed insights into how robotic hooves can be used to autonomously improve slip resistance.

- Motion Design for a Snake Robot Negotiating Complicated Pipe Structures of a Constant Diameter

    Author: Inazawa, Mariko | Kyoto University
    Author: Takemori, Tatsuya | Kyoto University
    Author: Tanaka, Motoyasu | The Univ. of Electro-Communications
    Author: Matsuno, Fumitoshi | Kyoto University
 
    keyword: Biologically-Inspired Robots; Motion and Path Planning; Field Robots

    Abstract : A method for designing the motion of a snake robot negotiating complicated pipe structures having a constant diameter is presented. For such robots moving inside pipes, there are various ``obstacles" such as junctions, bends, shears, and blockages. To surmount these obstacles, we propose a method that enables the robot to adapt to multiple pipe structures of a constant diameter. We designed the target form of the snake robot of two helices connected with an arbitrary shape. This method is applicable to various obstacles by designing a part of the target form conforming to the obstacle. The robot negotiates obstacles under shift control by employing a rolling motion. We demonstrated the effectiveness of the proposed method in various experiments.

- A Neuro-Inspired Computational Model for a Visually Guided Robotic Lamprey Using Frame and Event Based Cameras

    Author: Youssef, Ibrahim | Ecole Polytechnique Fédérale De Lausanne
    Author: Mutlu, Mehmet | École Polytechnique Fédérale De Lausanne (EPFL)
    Author: Bayat, Behzad | EPFL | École Polytechnique Fédérale De Lausanne
    Author: Crespi, Alessandro | Ecole Polytechnique Fédérale De Lausanne
    Author: Hauser, Simon | BIRL, University of Cambridge
    Author: Conradt, Jorg | KTH Royal Institute of Technology
    Author: Bernardino, Alexandre | IST - Técnico Lisboa
    Author: Ijspeert, Auke | EPFL
 
    keyword: Biologically-Inspired Robots; Marine Robotics; Computer Vision for Other Robotic Applications

    Abstract : The computational load associated with computer vision is often prohibitive, and limits the capacity for on-board image analysis in compact mobile robots. Replicating the kind of feature detection and neural processing that animals excel at remains a challenge in most biomimetic aquatic robots. Event-driven sensors use a biologically inspired sensing strategy to eliminate the need for complete frame capture. Systems employing event-driven cameras enjoy reduced latencies, power consumption, bandwidth, and benefit from a large dynamic range. However, to the best of our knowledge, no work has been done to evaluate the performance of these devices in underwater robotics. This work proposes a robotic lamprey design capable of supporting computer vision, and uses this system to validate a computational neuron model for driving anguilliform swimming. The robot is equipped with two different types of cameras: frame-based and event-based cameras. These were used to stimulate the neural network, yielding goal-oriented swimming. Finally, a study is conducted comparing the performance of the computational model when driven by the two different types of camera. It was observed that event-based cameras improved the accuracy of swimming trajectories and led to significant improvements in the rate at which visual inputs were processed by the network.

- Untethered Flight of an At-Scale Dual-Motor Hummingbird Robot with Bio-Inspired Decoupled Wings

    Author: Tu, Zhan | Purdue University
    Author: Fei, Fan | Purdue University
    Author: Deng, Xinyan | Purdue University
 
    keyword: Biologically-Inspired Robots; Biomimetics; Aerial Systems: Mechanics and Control

    Abstract : In this paper, we present the untethered flight of an at-scale tailless hummingbird robot with independently controlled wings. It represents the first untethered stable flight of a two actuator powered bio-inspired Flapping Wing Micro Air Vehicle (FWMAV) in both indoor and outdoor environment. The untethered flight of such FWMAVs is a challenging task due to stringent payload limitation from severe underactuation and power efficiency challenge caused by motor reciprocating motion. In this work, we present the detailed modeling, optimization, and system integration of onboard power, actuation, sensing, and flight control to address these unique challenges of such FWMAV during untethered flight. We performed untethered flight experiments in both indoor and outdoor environment and demonstrate sustained stable flight of the robot.

-  Model-Based Feedback Control of Live Zebrafish Behavior Via Interaction with a Robotic Replica (I)

    Author: De Lellis, Pietro | University of Naples Federico II
    Author: Cadolini, Eduardo | University of Naples Federico II
    Author: Croce, Arrigo | University of Naples Federico II
    Author: Yang, Yanpeng | New York University
    Author: Di Bernardo, Mario | University of Naples Federico II
    Author: Porfiri, Maurizio | New York University Polytechnic School of Engineering


- Steering Control of Magnetic Helical Swimmers in Swirling Flows Due to Confinement

    Author: Caldag, Hakan Osman | Sabanci University
    Author: Yesilyurt, Serhat | Sabanci University
 
    keyword: Biologically-Inspired Robots; Visual Servoing; Micro/Nano Robots

    Abstract : Artificial microswimmers are prospective robotic agents especially in biomedical applications. A rotating magnetic field can actuate a magnetized swimmer with a helical tail and enable propulsion. Such swimmers exhibit several modes of instability. Inside conduits, for example, hydrodynamic interactions with the boundaries lead to helical paths for pusher-mode swimmers; in this mode the helical tail pushes a rotating magnetic head. State-of-the-art in controlled navigation of microswimmers is based on aligning the swimmer orientation according to a reference path, thereby requiring both swimmer orientation and position to be known. Object-orientation is hard to track especially in in vivo scenarios which render orientation-based methods practically unfeasible. Here, we show that the kinematics for a confined swimmer can be linearized by assuming a low wobbling angle. This allows for a control law solely based on the swimmer position. The approach is demonstrated through experiments and two different numerical models: the first is based on the resistive force theory for a swimmer inside a swirling flow represented by a forced vortex and the second is a computational fluid dynamics model, which solves Stokes equations for a swimmer inside a circular channel. Helical pusher-mode trajectories are suppressed significantly for the straight path following problem. The error in real-life experiments remains comparable to those in the state-of-the-art methods.

- Sim2real Gap Is Non-Monotonic with Robot Complexity for Morphology-In-The-Loop Flapping Wing Design

    Author: Rosser, Kent Ashley | University of Vermont, University of South Australia, Defence Sc
    Author: Kok, Jia ming | DST Group
    Author: Chahl, Javaan | University of South Australia
    Author: Bongard, Josh | University of Vermont
 
    keyword: Biologically-Inspired Robots; Soft Robot Materials and Design; Aerial Systems: Mechanics and Control

    Abstract : Morphology of a robot design is important to its ability to achieve a stated goal and therefore applying machine learning approaches that incorporate morphology in the design space can provide scope for significant advantage. Our study is set in a domain known to be reliant on morphology: flapping wing flight. We developed a parameterised morphology design space that draws features from biological exemplars and apply automated design to produce a set of high performance robot morphologies in simulation. By performing sim2real transfer on a selection, for the first time we measure the shape of the reality gap for variations in design complexity. We found for the flapping wing that the reality gap changes non-monotonically with complexity, suggesting that certain morphology details narrow the gap more than others, and that such details could be identified and further optimised in a future end-to-end automated morphology design process.

- A Linearized Model for an Ornithopter in Gliding Flight: Experiments and Simulations

    Author: Lopez Lopez, Ricardo | University of Seville, GRVC
    Author: Perez Sanchez, Vicente | University of Seville, GRVC
    Author: Ramon Soria, Pablo | University of Seville
    Author: Martín-Alcántara, Antonio | University of Seville, GRVC
    Author: Fernandez-Feria, Ramon | University of Malaga
    Author: Arrue, Begoña C. | Universidad De Sevilla
    Author: Ollero, Anibal | University of Seville
 
    keyword: Biologically-Inspired Robots; Dynamics; Aerial Systems: Mechanics and Control

    Abstract : This work studies the accuracy of a simple but effective analytical model for a flapping-wings UAV in longitudinal gliding flight configuration comparing it with experimental results of a real ornithopter. The aerodynamic forces are modeled following the linearized potential theory for a flat plate in gliding configuration, extended to flapping wing episodes modeled also by the (now unsteady) linear potential theory, which are studied numerically. In the gliding configuration, the model reaches a steady-state descent at given terminal velocity and pitching and gliding angles, governed by the wings and tail position. In the flapping-wing configuration, it is noticed that the vehicle can increase its flight velocity and perform climbing episodes. A realistic simulation tool based on Unreal Engine 4 was developed to visualize the effect of the tail position and flapping frequencies and amplitudes on the ornithopter flight in realtime. The paper also includes the experimental validation of the gliding flight and the data has been released for the community.

- Towards Biomimicry of a Bat-Style Perching Maneuver on Structures: The Manipulation of Inertial Dynamics

    Author: Ramezani, Alireza | Northeastern University
 
    keyword: Biologically-Inspired Robots; Aerial Systems: Mechanics and Control; Dynamics

    Abstract : The flight characteristics of bats remarkably have been overlooked in aerial drone designs. Unlike other animals, bats leverage the manipulation of inertial dynamics to exhibit aerial flip turns when they perch. Inspired by this unique maneuver, this work develops and uses a tiny robot called Harpoon to demonstrate that the preparation for upside-down landing is possible through: 1) reorientation towards the landing surface through zero-angular-momentum turns and 2) reaching to the surface through shooting a detachable landing gear. The closed-loop manipulations of inertial dynamics takes place based on a symplectic description of the dynamical system (body and appendage), which is known to exhibit an excellent geometric conservation properties.

- Bioinspired Object Motion Filters As the Basis of Obstacle Negotiation in Micro Aerial Systems

    Author: Zhou, Rui | Imperial College London
    Author: Lin, Huai-Ti | Imperial College London
 
    keyword: Biologically-Inspired Robots; Collision Avoidance; Aerial Systems: Perception and Autonomy

    Abstract : All animals and robots that move in the world must navigate to a goal while clearing obstacles. Using vision to accomplish such task has several advantages in cost and payload, which explains the prevalence of biological visual guidance. However, the computational overhead has been an obvious concern when increasing number of pixels and frames that need to be analyzed in real-time for a machine vision system. The use of motion vision and optic flow has been a popular bio-inspired solution for this problem. However, many early-stage motion detection approaches rely on special hardware (e.g. event-cameras) or extensive computation (e.g. dense optic flow map). Here we demonstrate a method to combine an insect vision inspired object motion filter model with simple visual guidance rules to fly through a cluttered environment. We have implemented a complete feedback control loop in a micro racing drone and achieved proximal-distal object separation through only two object motion filters. We discuss the key constraints and the scalability of this approach for future development.

- Design and Architecture of ARCSnake: Archimedes' Screw-Propelled Serpentine Robot

    Author: Schreiber, Dimitri A. | University of California
    Author: Richter, Florian | University of California, San Diego
    Author: Bilan, Andrew | University of California San Diego
    Author: Gavrilov, Peter | University of California San Diego
    Author: Lam, Hoi Man | University of California San Diego
    Author: Price, Casey | University of California San Diego
    Author: Carpenter, Kalind | Jet Propulsion Laboratory
    Author: Yip, Michael C. | University of California, San Diego
 
    keyword: Biologically-Inspired Robots

    Abstract : This paper presents the design and performance of a screw-propelled serpentine robot. This robot comprises serially linked, identical modules, each incorporating an Archimedes' screw for propulsion and a universal joint (U-Joint) for orientation control. When serially chained, these modules form a versatile serpentine robot platform which enables the robot to reshape its body configuration for varying environments, typical of a snake. Furthermore, the Archimedes' screws allow for novel omni-wheel drive-like motions by speed controlling their screw threads. This paper considers the mechanical and electrical design, as well as the software architecture for realizing a fully integrated system. The system includes 3N actuators for N segments, each controlled using a BeagleBone Black with a customized power-electronics cape, a 9 Degrees of Freedom (DoF) Inertial Measurement Unit (IMU), and a scalable communication channel over ROS. The intended application for this robot is its use as an instrumentation mobility platform on terrestrial planets where the terrain may involve vents, caves, ice, and rocky surfaces. Additional experiments are shown on our website.

## Robotics in Agriculture, Construction and Mining
- GPR-Based Subsurface Object Detection and Reconstruction Using Random Motion and DepthNet

    Author: Feng, Jinglun | City College of New York
    Author: Liang, Yang | Shenyang Institute of Automation, Chinese Academy of Sciences
    Author: Wang, Haiyan | City College of New York
    Author: Song, Yifeng | Chinese Academy of Sciences, Shenyang InstituteofAutomation
    Author: Xiao, Jizhong | The City College of New York
 
    keyword: Robotics in Construction; AI-Based Methods; Deep Learning in Robotics and Automation

    Abstract : Ground Penetrating Radar (GPR) is one of the most important non-destructive evaluation (NDE) devices to detect the subsurface objects (i.e. rebars, utility pipes) and reveal the underground scene. One of the biggest challenges in GPR based inspection is the subsurface targets reconstruction. In order to address this issue, this paper presents a 3D GPR migration and dielectric prediction system to detect and reconstruct underground targets. This system is composed of three modules: 1) visual inertial fusion (VIF) module to generate the pose information of GPR device,	2) deep neural network module (i.e., DepthNet) which detects B-scan of GPR image, extracts hyperbola features to remove the noise in B-scan data and predicts dielectric to determine the depth of the objects, 3) 3D GPR migration module which synchronizes the pose information with GPR scan data processed by DepthNet to reconstruct and visualize the 3D underground targets. Our proposed DepthNet processes the GPR data by removing the noise in B-scan image as well as predicting depth of subsurface objects. In addition, the experimental results verify that our proposed method improve the migration accuracy and performance in generating 3D GPR image compared with the traditional migration methods.

- A Data-Driven Approach to Prediction and Optimal Bucket-Filling Control for Autonomous Excavators
 
    Author: Sandzimier, Ryan | MIT
    Author: Asada, Harry | MIT
 
    keyword: Robotics in Construction; Model Learning for Control; Mining Robotics

    Abstract : We develop a data-driven, statistical control method for autonomous excavators. Interactions between soil and an excavator bucket are highly complex and nonlinear, making traditional physical modeling difficult to use for real-time control. Here, we propose a data-driven method, exploiting data obtained from laboratory tests. We use the data to construct a nonlinear, non-parametric statistical model for predicting the behavior of soil scooped by an excavator bucket. The prediction model is built for controlling the amount of soil collected with a bucket. An excavator collects soil by dragging the bucket along the soil surface and scooping the soil by rotating the bucket. It is important to switch from the drag phase to the scoop phase with the correct timing to ensure an appropriate amount of soil has accumulated in front of the bucket. We model the process as a heteroscedastic Gaussian process (GP) based on the observation that the variance of the collected soil mass depends on the scooping trajectory, i.e. the input, as well as the shape of the soil surface immediately prior to scooping. We develop an optimal control algorithm for switching from the drag phase to the scoop phase at an appropriate time and for generating a scoop trajectory to capture a desired amount of soil with high confidence. We implement the method on a robotic excavator and collect experimental data. Experiments show promising results in terms of being able to achieve a desired bucket fill factor with

- Real-Time Stereo Visual Servoing for Rose Pruning with Robotic Arm

    Author: Cuevas-Velasquez, Hanz | University of Edinburgh
    Author: Gallego, Antonio-Javier | University of Alicante
    Author: Tylecek, Radim | University of Edinburgh
    Author: Hemming, Jochen | Wageningen University and Research Centre
    Author: Van Tuijl, Bart | Wageningen University &amp; Research - WUR
    Author: Mencarelli, Angelo | Wageningen University &amp; Research - WUR
    Author: Fisher, Robert | University of Edinburgh
 
    keyword: Robotics in Agriculture and Forestry; Visual Servoing; Grippers and Other End-Effectors

    Abstract : The paper presents a working pipeline which integrates hardware and software in an automated robotic rose cutter; to the best of our knowledge, the first robot able to prune rose bushes in a natural environment. Unlike similar approaches like tree stem cutting, the proposed method does not require to scan the full plant, have multiple cameras around the bush, or assume that a stem does not move. It relies on a single stereo camera mounted on the end-effector of the robot and real-time visual servoing to navigate to the desired cutting location on the stem. The evaluation of the whole pipeline shows a good performance in a garden with unconstrained conditions, where finding and approaching a specific location on a stem is challenging due to occlusions caused by other stems and dynamic changes caused by the wind.

- Canopy-Based Monte Carlo Localization in Orchards Using Top-View Imagery

    Author: Shalev, Omer | Technion - Israel Institute of Technology
    Author: Degani, Amir | Technion - Israel Institute of Technology
 
    keyword: Robotics in Agriculture and Forestry; Localization; Aerial Systems: Applications

    Abstract : Localization of ground mobile robots in orchards is a complex problem which is yet to be fully addressed. The typical localization approaches are not adjusted to the characteristics of the orchard environment, especially the homogeneous scenery. To alleviate these difficulties, we propose to use top-view images of the orchard acquired in real-time. The top-view observation of the orchard provides a unique signature of every tree formed by the shape of its canopy. This practically changes the homogeneity premise in orchards and paves the way for addressing the kidnapped robot problem. Using computer vision techniques, we build a virtual canopies laser scan around the ground robot which is generated from low-altitude top-view video streams. We apply Monte Carlo Localization on this virtual scan to localize the robot against a high-altitude top-view snapshot image which is used as a map. The suggested approach is examined in numerous offline experiments conducted on data acquired in real orchards and is compared against a typical simulated approach which relies on ground-level trunk observations. The canopy-based approach demonstrated better performance in all measures, including convergence to centimeter-level accuracy.

- In-Field Grape Cluster Size Assessment for Vine Yield Estimation Using a Mobile Robot and a Consumer Level RGB-D Camera

    Author: Kurtser, Polina | Örebro University
    Author: Ringdahl, Ola | Umeå University
    Author: Rotstein, Nati | Ben Gurion University of the Negev
    Author: Berenstein, Ron | Agricultural Research Organization Volcani Center
    Author: Edan, Yael | Ben-Gurion University of the Negev
 
    keyword: Field Robots; RGB-D Perception; Agricultural Automation

    Abstract : Current practice for vine yield estimation is based on RGB cameras and has limited performance. In this paper we present a method for outdoor vine yield estimation using a consumer grade RGB-D camera mounted on a mobile robotic platform. An algorithm for automatic grape cluster size estimation using depth information is evaluated both in controlled outdoor conditions and in commercial vineyard conditions. Ten video scans (3 camera viewpoints with 2 different backgrounds and 2 natural light conditions), acquired from a controlled outdoor experiment and a commercial vineyard setup, are used for analyses. The collected dataset (GRAPES3D) is released to the public. A total of 4542 regions of 49 grape clusters were manually labeled by a human annotator for comparison. Eight variations of the algorithm are assessed, both for manually labeled and auto-detected regions. The effect of viewpoint, presence of an artificial background, and the human annotator are analyzed using statistical tools. Results show 2.8-3.5 cm average error for all acquired data and reveal the potential of using low-cost commercial RGB-D cameras for improved robotic yield estimation.

- Autonomous Excavation of Rocks Using a Gaussian Process Model and Unscented Kalman Filter

    Author: Sotiropoulos, Filippos Edward | Massachusetts Institute of Technology
    Author: Asada, Harry | MIT
 
    keyword: Mining Robotics; Model Learning for Control; Robotics in Construction

    Abstract : In large-scale open-pit mining and construction works, excavators must deal with large rocks mixed with gravel and granular soil. Capturing and moving large rocks with the bucket of an excavator requires a high level of skill that only experienced human operators possess. In an attempt to develop autonomous rock excavators, this paper presents a control method that predicts the rock movement in response to bucket operation and computes an optimal bucket movement to capture the rock. The process is highly nonlinear and stochastic. A Gaussian process model, which is nonlinear, non-parametric and stochastic, is used for describing rock behaviors interacting with the bucket and surrounding soil. Experimental data is used directly for identifying the model. An Unscented Kalman Filter (UKF) is then integrated with the Gaussian process model for predicting the rock movements and estimating the length of the rock. A feedback controller that optimizes a cost function is designed based on the rock motion prediction and implemented on a robotic excavator prototype. Experiments demonstrate encouraging results towards autonomous mining and rock excavation.

## Kinematics
- Slip-Limiting Controller for Redundant Line-Suspended Robots: Application to LineRanger

    Author: Hamelin, Philippe | Hydro-Quebec Research Institute
    Author: Richard, Pierre-Luc | Hydro-Quebec Research Institute
    Author: Lepage, Marco | Hydro-Québec - IREQ
    Author: Lagacé, Marin | Hydro-Quebec Research Institute
    Author: Sartor, Alex | Hydro-Quebec Research Institute
    Author: Lambert, Ghislain | Hydro-Quebec Research Institute
    Author: Hébert, Camille | Hydro-Québec's Research Institute
    Author: Pouliot, Nicolas | IREQ Hydro-Québec Research Institute
 
    keyword: Redundant Robots; Wheeled Robots; Motion Control

    Abstract : In this paper, a slip-limiting controller for redundant line-suspended robots is presented. This kind of robot is usually equipped with v-shaped wheels, which brings uncertainty about the effective wheel radius, particularly when crossing obstacles. The proposed algorithm is able to estimate and limit wheel slippage in the presence of such uncertainty, relying only on wheel angular velocity measurements. Slip limitation occurs in the control allocation algorithm and hence is decoupled from the high-level velocity controller, allowing a broad applicability in centralized control approaches. Experimental results on LineRanger show that it effectively reduces wheel slippage compared to traditional centralized control while being more energy efficient than traditional decentralized control approaches.

- Interval Search Genetic Algorithm Based on Trajectory to Solve Inverse Kinematics of Redundant Manipulators and Its Application

    Author: Wu, Di | Central South University
    Author: Zhang, Wenting | Central South University
    Author: Qin, Mi | Central South University
    Author: Xie, Bin | Central South University
 
    keyword: Redundant Robots; Kinematics; Industrial Robots

    Abstract : In this paper, a new method is proposed to solve the inverse kinematics problem of redundant manipulators. This method demonstrates superior performance on continuous motion by combining interval search genetic algorithm based on trajectory which we propose with parametric joint angle method. In this method, population continuity strategy is utilized to improve search speed and reduce evolutionary generation, interval search strategy is introduced to enhance the search ability and overcome the influence of singularity, and reference point strategy is used to avoid sudden changes of joint variables. By introducing those three strategies, this method is especially suitable for redundant manipulators that perform continuous motion. It can not only obtain solutions of inverse kinematics quickly, but also ensure the motion continuity of manipulator and accuracy of the end effector. Moreover, this algorithm can also perform multi-objective tasks by adjusting the fitness function. Finally, this algorithm is applied to an 8 degree of freedom tunnel shotcrete robot. Field experiments and data analysis show that the algorithm can solve the problem quickly in industrial field, and ensure the motion continuity and accuracy.

- Analytical Expressions of Serial Manipulator Jacobians and Their High-Order Derivatives Based on Lie Theory

    Author: Fu, Zhongtao | Kings College London
    Author: Spyrakos-Papastavridis, Emmanouil | King's College London
    Author: Lin, Yen-Hua | King's College London
    Author: Dai, Jian | School of Natural and Mathematical Sciences, King's College Lond
 
    keyword: Kinematics; Motion Control; Flexible Robots

    Abstract : Serial manipulator kinematics provide a mapping between joint variables in joint-space coordinates, and end-effector configurations in task-space Cartesian coordinates. Velocity mappings are represented via the manipulator Jacobian produced by direct differentiation of the forward kinematics. Acquisition of acceleration, jerk, and snap expressions, typically utilized for accurate trajectory-tracking, requires the computation of high-order Jacobian derivatives. As compared to conventional numerical/D-H approaches, this paper proposes a novel methodology to derive the Jacobians and their high-order derivatives symbolically, based on Lie theory, which requires that the derivatives are calculated with respect to each joint variable and time. Additionally, the technique described herein yields a mathematically sound solution to the high-order Jacobian derivatives, which distinguishes it from other relevant works. Performing computations with respect to the two inertial-fixed and body-fixed frames, the analytical form of the spatial and body Jacobians are derived, as well as their higher-order derivatives, without resorting to any approximations, whose expressions depend explicitly on the joint state and the choice of reference frames. The proposed method provides more tractable computation of higher-order Jacobian derivatives, while its effectiveness has been verified by conducting a comparative analysis based on experimental data extracted from a KUKA LRB iiwa7 R800 manipulator.

- Inverse Kinematics for Serial Kinematic Chains Via Sum of Squares Optimization

    Author: Maric, Filip | University of Toronto Institute for Aerospace Studies
    Author: Giamou, Matthew | University of Toronto
    Author: Khoubyarian, Soroush | University of Toronto
    Author: Petrovic, Ivan | University of Zagreb
    Author: Kelly, Jonathan | University of Toronto
 
    keyword: Kinematics; Optimization and Optimal Control; Manipulation Planning

    Abstract : Inverse kinematics is a fundamental challenge for articulated robots: fast and accurate algorithms are needed for translating task-related workspace constraints and goals into feasible joint configurations. In general, inverse kinematics for serial kinematic chains is a difficult nonlinear problem, for which closed form solutions cannot easily be obtained. Therefore, computationally efficient numerical methods that can be adapted to a general class of manipulators are of great importance. In this paper, we use convex optimization techniques to solve the inverse kinematics problem with joint limit constraints for highly redundant serial kinematic chains with spherical joints in two and three dimensions.This is accomplished through a novel formulation of inverse kinematics as a nearest point problem, and with a fast sum of squares solver that exploits the sparsity of kinematic constraints for serial manipulators. Our method has the advantages of post-hoc certification of global optimality and a runtime that scales polynomially with the number of degrees of freedom. Additionally, we prove that our convex relaxation leads to a globally optimal solution when certain conditions are met, and demonstrate empirically that these conditions are common and represent many practical instances. Finally, we provide an open source implementation of our algorithm.

- Multi-Task Closed-Loop Inverse Kinematics Stability through Semidefinite Programming

    Author: Marti-Saumell, Josep | CSIC-UPC
    Author: Santamaria-Navarro, Angel | NASA Jet Propulsion Laboratory, Caltech
    Author: Ocampo-Martinez, Carlos | Technical University of Catalonia (UPC)
    Author: Andrade-Cetto, Juan | CSIC-UPC
 
    keyword: Kinematics; Redundant Robots; Motion Control

    Abstract : Today's complex robotic designs comprise in some cases a large number of degrees of freedom, enabling for multi-objective task resolution (e.g., humanoid robots or aerial manipulators). This paper tackles the stability problem of a hierarchical closed-loop inverse kinematics algorithm for such highly redundant robots. We present a method to guarantee system stability by performing an online tuning of the closedloop control gains. We define a semi-definite programming problem (SDP) with these gains as decision variables and a discrete-time Lyapunov stability condition as a linear matrix inequality, constraining the SDP optimization problem and guaranteeing the stability of the prioritized tasks. To the best of     Authors' knowledge, this work represents the first mathematical development of an SDP formulation that introduces stability conditions for a multi-objective closed-loop inverse kinematic problem for highly redundant robots. The validity of the proposed approach is demonstrated through simulation case studies, including didactic examples and a Matlab toolbox for the benefit of the community.

- Stable-By-Design Kinematic Control Based on Optimization (I)

    Author: Gon�alves, Vinicius Mariano | UFMG
    Author: Adorno, Bruno Vilhena | Federal University of Minas Gerais (UFMG)
    Author: Crosnier, André | LIRMM
    Author: Fraisse, Philippe | LIRMM
 
    keyword: Kinematics; Optimization and Optimal Control

    Abstract : This paper presents a new kinematic control paradigm for redundant robots based on optimization. The general approach takes into account convex objective functions with inequality constraints and a specific equality constraint resulting from a Lyapunov function, which ensures closed-loop stability by design. Furthermore, we tackle an important particular case by using a convex combination of quadratic and l_{1}-norm objective functions, making possible for the designer to choose different degrees of sparseness and smoothness in the control inputs. We provide a pseudo-analytical solution to this optimization problem and validate the approach by controlling the center of mass of the humanoid robot HOAP3.

## Robot Safety
- Securing Industrial Operators with Collaborative Robots: Simulation and Experimental Validation for a Carpentry Task

    Author: Benhabib, Nassim | Inria
    Author: Padois, Vincent | Inria Bordeaux
    Author: Daney, David | Inria Bordeaux - Sud Ouest
 
    keyword: Robot Safety; Physical Human-Robot Interaction; Physically Assistive Devices

    Abstract : In this work, a robotic assistance strategy is developed to improve the safety in an artisanal task that involves a strong interaction between a machine-tool and an operator. Wood milling is chosen as a pilot task due to its importance in carpentry and its accidentogenic aspect. A physical model of the tooling process including a human is proposed and a simulator is thereafter developed to better understand situations that are dangerous for the craftsman. This simulator is validated with experiments on three subjects using an harmless mock-up. This validation shows the pertinence of the proposed control approach for the collaborative robot used to increase the safety of the task.

- Learning Shape-Based Representation for Visual Localization in Extremely Changing Conditions

    Author: Jeon, Hae-Gon | GIST
    Author: Im, Sunghoon | DGIST
    Author: Oh, Jean | Carnegie Mellon University
    Author: Hebert, Martial | CMU
 
    keyword: Robot Safety; Computer Vision for Other Robotic Applications; Localization

    Abstract : Visual localization is an important task for applications such as navigation and augmented reality, but is a challenging problem when there are changes in scene appearances through day, seasons, or environments. In this paper, we present a convolutional neural network (CNN)-based approach for visual localization across normal to drastic appearance variations such as pre- and post-disaster cases. Our approach aims to address two key challenges: (1) to reduce the biases based on scene textures as in traditional CNNs, our model learns a shape-based representation by training on stylized images; (2) to make the model robust against layout changes, our approach uses the estimated dominant planes of query images as approximate scene coordinates. Our method is evaluated on various scenes including a simulated disaster dataset to demonstrate the effectiveness of our method in significant changes of scene layout. Experimental results show that our method provides reliable camera pose predictions in various changing conditions.

- Trajectory Planning with Safety Guaranty for a Multirotor Based on the Forward and Backward Reachability Analysis

    Author: Seo, Hoseong | Seoul National University
    Author: Son, Clark Youngdong | Seoul National University
    Author: Lee, Dongjae | Seoul National University
    Author: Kim, H. Jin | Seoul National University
 
    keyword: Robot Safety; Motion and Path Planning; Collision Avoidance

    Abstract : Planning a trajectory with guaranteed safety is a core part for a risk-free flight of a multirotor. If a trajectory planner only aims to ensure safety, it may generate trajectories which overly bypass risky regions and prevent the system from achieving specific missions. This work presents a robust trajectory planning algorithm which simultaneously guarantees the safety and reachability to the target state in the presence of unknown disturbances. We first characterize how the forward and backward reachable sets (FRSs and BRSs) are constructed by using Hamilton-Jacobi reachability analysis. Based on the analysis, we present analytic expressions for the reachable sets and then propose minimal ellipsoids which closely approximate the reachable sets. In the planning process, we optimize the reference trajectory to connect the FRSs and BRSs, while avoiding obstacles. By combining the FRSs and BRSs, we can guarantee that any state inside of the initial set reaches the target set. We validate the proposed algorithm through a simulation of traversing a narrow gap.

- A Hamilton-Jacobi Reachability-Based Framework for Predicting and Analyzing Human Motion for Safe Planning

    Author: Bansal, Somil | UC Berkeley
    Author: Bajcsy, Andrea | University of California Berkeley
    Author: Ratner, Ellis | University of California, Berkeley
    Author: Dragan, Anca | University of California Berkeley
    Author: Tomlin, Claire | UC Berkeley
 
    keyword: Robot Safety; Collision Avoidance; Cognitive Human-Robot Interaction

    Abstract : Real-world autonomous systems often employ probabilistic predictive models of human behavior during planning to reason about their future motion. Since accurately modeling human behavior a priori is challenging, such models are often parameterized, enabling the robot to adapt predictions based on observations by maintaining a distribution over the model parameters. Although this enables data and priors to improve the human model, observation models are difficult to specify and priors may be incorrect, leading to erroneous state predictions that can degrade the safety of the robot motion plan. In this work, we seek to design a predictor which is more robust to misspecified models and priors, but can still leverage human behavioral data online to reduce conservatism in a safe way. To do this, we cast human motion prediction as a Hamilton-Jacobi reachability problem in the joint state space of the human and the belief over the model parameters. We construct a new continuous-time dynamical system, where the inputs are the observations of human behavior, and the dynamics include how the belief over the model parameters change. The results of this reachability computation enable us to both analyze the effect of incorrect priors on future predictions in continuous state and time, as well as to make predictions of the human state in the future. We compare our approach to the worst-case forward reachable set and a stochastic predictor which produces full future state distributions.

- Enhancing Privacy in Robotics Via Judicious Sensor Selection

    Author: Eick, Stephen | Georgia Institute of Technology
    Author: Ant�n, Annie | Georgia Institute of Technology
 
    keyword: Ethics and Philosophy; Robot Safety

    Abstract : Roboticists are grappling with how to address privacy in robot design at a time when regulatory frameworks around the world increasingly require systems to be engineered to preserve and protect privacy. This paper surveys the top robotics journals and conferences over the past four decades to identify contributions with respect to privacy in robot design. Our survey revealed that less than half of one percent of the ~89,120 papers in our study even mention the word privacy. Herein, we propose privacy preserving approaches for roboticists to employ in robot design, including, assessing a robot's purpose and environment; ensuring privacy by design by selecting sensors that do not collect information that is not essential to the core objectives of that robot; embracing both privacy and performance as fundamental design challenges to be addressed early in the robot lifecycle; and performing privacy impact assessments.

- Robust Model Predictive Shielding for Safe Reinforcement Learning with Stochastic Dynamics

    Author: Li, Shuo | University of Pennsylvania
    Author: Bastani, Osbert | University of Pennsylvania
 
    keyword: Robot Safety; Robust/Adaptive Control of Robotic Systems; Deep Learning in Robotics and Automation

    Abstract : We propose a framework for safe reinforcement learning that can handle stochastic nonlinear dynamical systems. We focus on the setting where the nominal dynamics are known, and are subject to additive stochastic disturbances with known distribution. Our goal is to ensure the safety of a control policy trained using reinforcement learning, e.g., in a simulated environment. We build on the idea of model predictive shielding (MPS), where a backup controller is used to override the learned policy as needed to ensure safety. The key challenge is how to compute a backup policy in the context of stochastic dynamics. We propose to use a tube-based robust nonlinear model predictive controller (NMPC) as the backup controller. We estimate the tubes using sampled trajectories, leveraging ideas from statistical learning theory to obtain high-probability guarantees. We empirically demonstrate that our approach can ensure safety in stochastic systems, including cart-pole and a non-holonomic particle with random obstacles.

## Swarms
- Segregation of Heterogeneous Swarms of Robots in Curves

    Author: Bernardes Ferreira Filho, Edson | Universidade Federal De Minas Gerais
    Author: Pimenta, Luciano | Universidade Federal De Minas Gerais
 
    keyword: Swarms; Multi-Robot Systems; Cooperating Robots

    Abstract : This paper proposes a decentralized control strategy to reach segregation in heterogeneous robot swarms distributed in curves. The approach is based on a formation control algorithm applied to each robot and a heuristics to compute the distance between the groups, i.e. the distance from the beginning of the curve. We consider that robots can communicate through a fixed underlying topology and also when they are within a certain distance. A convergence proof with a collision avoidance strategy is presented. Simulations and experimental results show that our approach allows a swarm of multiple heterogeneous robots to segregate into groups.

- A Fast, Accurate, and Scalable Probabilistic Sample-Based Approach for Counting Swarm Size

    Author: Wang, Hanlin | Northwestern University
    Author: Rubenstein, Michael | Northwestern University
 
    keyword: Swarms; Multi-Robot Systems; Sensor Networks

    Abstract : This paper describes a distributed algorithm for computing the number of robots in a swarm, only requiring communication with neighboring robots.	The algorithm can adjust the estimated count when the number of robots in the swarm changes, such as the addition or removal of robots. Probabilistic guarantees are given, which show the accuracy of this method, and the trade-off between accuracy, speed, and adaptability to changing numbers. The proposed approach is demonstrated in simulation as well as a real swarm of robots.

- Bayes Bots: Collective Bayesian Decision-Making in Decentralized Robot Swarms

    Author: Ebert, Julia T | Harvard University
    Author: Gauci, Melvin | Harvard University
    Author: Mallmann-Trenn, Frederik | King's College London
    Author: Nagpal, Radhika | Harvard University
 
    keyword: Swarms; Multi-Robot Systems; Autonomous Agents

    Abstract : We present a distributed Bayesian algorithm for robot swarms to classify a spatially distributed feature of an environment. This type of ``go/no-go'' decision appears in applications where a group of robots must collectively choose whether to take action, such as determining if a farm field should be treated for pests. Previous bio-inspired approaches to decentralized decision-making in robotics lack a statistical foundation, while decentralized Bayesian algorithms typically require a strongly connected network of robots. In contrast, our algorithm allows simple, sparsely distributed robots to quickly reach accurate decisions about a binary feature of their environment. We investigate the speed vs. accuracy tradeoff in decision-making by varying the algorithm's parameters. We show that making fewer, less-correlated observations can improve decision-making accuracy, and that a well-chosen combination of prior and decision threshold allows for fast decisions with a small accuracy cost. Both speed and accuracy also improved with the addition of bio-inspired positive feedback. This algorithm is also adaptable to the difficulty of the environment. Compared to a fixed-time benchmark algorithm with accuracy guarantees, our Bayesian approach resulted in equally accurate decisions, while adapting its decision time to the difficulty of the environment.

- Supervisory Control of Robot Swarms Using Public Events

    Author: Kaszubowski Lopes, Yuri | Federal University of Technology - Paran�
    Author: Trenkwalder, Stefan M. | The University of Sheffield
    Author: Leal, André Bittencourt | Santa Catarina State University - UDESC
    Author: Dodd, Tony J | The University of Sheffield
    Author: Gross, Roderich | The University of Sheffield
 
    keyword: Swarms; Distributed Robot Systems; Multi-Robot Systems

    Abstract : Supervisory Control Theory (SCT) provides a formal framework for controlling	discrete event systems. It has recently been used	to generate correct-by-construction controllers for swarm robotics systems. Current SCT	frameworks are limited, as they support only (private) events that are observable within the same robot. In this paper, we propose an extended SCT framework that incorporates (public) events that are shared among robots. The extended framework	allows	to model formally the interactions among the robots. It is evaluated using a case study, where a group of mobile robots need to synchronise their movements in space	and time�a requirement that is specified at the formal level.	We validate our approach through experiments with groups of e-puck robots.

- Planetary Exploration with Robot Teams (I)

    Author: St-Onge, David | Ecole De Technologie Superieure
    Author: Kaufmann, Marcel | Polytechnique Montreal
    Author: Panerati, Jacopo | Polytechnique Montreal
    Author: Ramtoula, Benjamin | École Polytechnique De Montr�al, École Polytechnique Fédérale De
    Author: Cao, Yanjun | École Polytechnique De Montr�al (Université De Montr�al)
    Author: Coffey, Emily | Department of Psychology, Concordia University
    Author: Beltrame, Giovanni | Ecole Polytechnique De Montreal
 
    keyword: Swarms; Cognitive Human-Robot Interaction; Human Factors and Human-in-the-Loop

    Abstract : Since the beginning of space exploration, Mars and the Moon have been explored with orbiters, landers, and rovers. Over forty missions have targeted Mars, and more than a hundred, the Moon. Developing novel strategies and technologies for exploring celestial bodies continues to be a focus of space agencies. Multi-robot systems are particularly promising for planetary exploration, as they are more robust to individual failure and have the potential to explore larger areas; however, there are limits to how many robots an operator can individually control. We recently took part in the European Space Agency's interdisciplinary equipment test campaign (PANGAEA-X) at a Lunar/Mars analogue site in Lanzarote, Spain. We used a heterogeneous fleet of Unmanned Aerial Vehicles(UAVs)---a swarm---to study the interplay of systems operations and human factors. Human operators directed the swarm via ad-hoc networks and data sharing protocols to explore unknown areas under two control modes: one in which the operator instructed each robot separately; and the other in which the operator provided general guidance to the swarm, which self-organized via a combination of distributed decision-making, and consensus building. We assessed cognitive load via pupillometry for each condition, and perceived task demand and intuitiveness via self-report. Our results show that implementing higher autonomy with swarm intelligence can reduce workload, freeing the operator for other tasks.

- Statistics-Based Automated Control for a Swarm of Paramagnetic Nanoparticles in 2D Space (I)

    Author: Yang, Lidong | The Chinese University of Hong Kong
    Author: Yu, Jiangfan | University of Toronto
    Author: Zhang, Li | The Chinese University of Hong Kong
 
    keyword: Micro/Nano Robots; Automation at Micro-Nano Scales; Swarms

    Abstract : Swarm control is one of the primary challenges in microrobotics. For the automated control of such a microrobotic system with small size and large population, conventional methods using precise robot models and robot�robot communications lose effectiveness due to the complex locomotion of micro/nano agents in a swarm and difficult implementation of onboard actuators and sensors for individual motion control and motion feedback. This article proposes a statistics-based approach and reports the fully automated control of a swarm of paramagnetic nanoparticles including the swarm pattern formation, identification, tracking, motion control, and real-time distribution monitoring/control. By establishing the swarm statistics, collective behaviors of a nanoparticle swarm can be quantitatively analyzed by computers. Algorithms are designed based on the statistics to automatically generate and identify the vortex-like paramagnetic nanoparticle swarm (VPNS), which present robustness to the dose and initial distribution of the nanoparticle swarm. In order to robustly track a VPNS, a statistics-based tracking method is proposed, in which 500 boundary points of the VPNS are extracted and the VPNS distribution is optimally recognized. And, with the proposed gathering improvement control, experiments show that over 70% nanoparticles can be gathered in the VPNS. Furthermore, an automated motion control scheme for the VPNS is proposed which shows high-accuracy trajectory tracking performance.

## Simulation and Animation
- Automatic Tool for Gazebo World Construction: From a Grayscale Image to a 3D Solid Model

    Author: Abbyasov, Bulat | Kazan Federal University
    Author: Lavrenov, Roman | Kazan Federal University
    Author: Zakiev, Aufar | Kazan Federal University
    Author: Yakovlev, Konstantin | Federal Research Center "Computer Science and Control" of Russia
    Author: Svinin, Mikhail | Ritsumeikan University
    Author: Magid, Evgeni | Kazan Federal University
 
    keyword: Simulation and Animation; SLAM; Performance Evaluation and Benchmarking

    Abstract : Robot simulators provide an easy way for evaluation of new concepts and algorithms in a simulated physical environment reducing development time and cost. Therefore it is convenient to have a tool that quickly creates a 3D landscape from an arbitrary 2D image or 2D laser range finder data. This paper presents a new tool that automatically constructs such landscapes for Gazebo simulator. The tool converts a grayscale image into a 3D Collada format model, which could be directly imported into Gazebo. We run three different simultaneous localization and mapping (SLAM) algorithms within three varying complexity environments that were constructed with our tool. A real-time factor (RTF) was used as an efficiency benchmark. Successfully completed SLAM missions with acceptable RTF levels demonstrated the efficiency of the tool. The source code is available for free academic use.

- A ROS Gazebo Plugin to Simulate ARVA Sensors

    Author: Cacace, Jonathan | University of Naples
    Author: Mimmo, Nicola | University of Bologna
    Author: Marconi, Lorenzo | University of Bologna
 
    keyword: Simulation and Animation; Sensor-based Control

    Abstract : This paper addresses the problem to simulate ARVA sensors using ROS and Gazebo. ARVA is a French acronym which stands for Appareil de Recherche de Victims en Avalanche and represents the forefront technology adopted in Search &amp; Rescue operations to localize victims of avalanches buried under the snow. The aim of this paper is to describe the mathematical and theoretical background of the transceiver, discussing its implementation and integration with ROS allowing researchers to develop faster and smarter Search &amp; Rescue strategies based on ARVA receiver data. To assess the effectiveness of the proposed sensor model, We present a simulation scenario in which an Unmanned Aerial Vehicle equipped with the transceiver sensor performs a basic S&amp;R pattern using the output of ARVA system.

- Is That a Chair? Imagining Affordances Using Simulations of an Articulated Human Body

    Author: Wu, Hongtao | Johns Hopkins University
    Author: Misra, Deven | Reed College
    Author: Chirikjian, Gregory | Johns Hopkins University
 
    keyword: Simulation and Animation; AI-Based Methods; Humanoid Robots

    Abstract : For robots to exhibit a high level of intelligence in the real world, they must be able to assess objects for which they have no prior knowledge. Therefore, it is crucial for robots to perceive object affordances by reasoning about physical interactions with the object. In this paper, we propose a novel method to provide robots with an ability to imagine object affordances using physical simulations. The class of chair is chosen here as an initial category of objects to illustrate a more general paradigm. In our method, the robot �imagines' the affordance of an arbitrarily oriented object as a chair by simulating a physical sitting interaction between an articulated human body and the object. This object affordance reasoning is used as a cue for object classification (chair vs non-chair). Moreover, if an object is classified as a chair, the affordance reasoning can also predict the upright pose of the object which allows the sitting interaction to take place. We call this type of poses the functional pose. We demonstrate our method in chair classification on synthetic 3D CAD models. Although our method uses only 30 models for training, it outperforms appearance-based deep learning methods, which require a large amount of training data, when the upright orientation is not assumed to be known a priori. In addition, we showcase that the functional pose predictions of our method align well with human judgments on both synthetic models and real objects scanned by a depth camera.

- Toward Sim-To-Real Directional Semantic Grasping

    Author: Iqbal, Shariq | University of Southern California
    Author: Tremblay, Jonathan | Nvidia
    Author: To, Thang | Nvidia Corp
    Author: Cheng, Jia | Nvidia Corp
    Author: Leitch, Erik | Nvidia
    Author: Campbell, Andy | NVIDIA
    Author: Leung, Kirby | Nvidia
    Author: McKay, Duncan | NVIDIA
    Author: Birchfield, Stan | NVIDIA
 
    keyword: Simulation and Animation; Computer Vision for Automation; Deep Learning in Robotics and Automation

    Abstract : We address the problem of directional semantic grasping, that is, grasping a specific object from a specific direction. We approach the problem using deep reinforcement learning via a double deep Q-network (DDQN) that learns to map downsampled RGB input images from a wrist-mounted camera to Q-values, which are then translated into Cartesian robot control commands via the cross-entropy method (CEM). The network is learned entirely on simulated data generated by a custom robot simulator that models both physical reality (contacts) and perceptual quality (high-quality rendering). The reality gap is bridged using domain randomization. The system is an example of end-to-end (mapping input monocular RGB images to output Cartesian motor commands) grasping of objects from multiple pre-defined object-centric orientations, such as from the side or top. We show promising results in both simulation and the real world, along with some challenges faced and the need for future research in this area.

- Learning to Collaborate from Simulation for Robot-Assisted Dressing

    Author: Clegg, Alexander | Georgia Institute of Technology
    Author: Erickson, Zackory | Georgia Institute of Technology
    Author: Grady, Patrick | Georgia Institute of Technology
    Author: Turk, Greg | Georgia Institute of Technology
    Author: Kemp, Charlie | Georgia Institute of Technology
    Author: Liu, Karen | Georgia Tech
 
    keyword: Simulation and Animation; Deep Learning in Robotics and Automation; Physically Assistive Devices

    Abstract : We investigated the application of haptic feedback control and deep reinforcement learning (DRL) to robot-assisted dressing. Our method uses DRL to simultaneously train human and robot control policies as separate neural networks using physics simulations. In addition, we modeled variations in human impairments relevant to dressing, including unilateral muscle weakness, involuntary arm motion, and limited range of motion. Our approach resulted in control policies that successfully collaborate in a variety of simulated dressing tasks involving a hospital gown and a T-shirt. In addition, our approach resulted in policies trained in simulation that enabled a real PR2 robot to dress the arm of a humanoid robot with a hospital gown. We found that training policies for specific impairments dramatically improved performance; that controller execution speed could be scaled after training to reduce the robot's speed without steep reductions in performance; that curriculum learning could be used to lower applied forces; and that multi-modal sensing, including a simulated capacitive sensor, improved performance.

- Realtime Simulation of Thin-Shell Deformable Materials Using CNN-Based Mesh Embedding

    Author: Tan, Qingyang | University of Maryland at College Park
    Author: Pan, Zherong | The University of North Carolina at Chapel Hill
    Author: Gao, Lin | Institute of Computing Technology, Chinese Academy of Sciences
    Author: Manocha, Dinesh | University of Maryland
 
    keyword: Simulation and Animation; Dexterous Manipulation

    Abstract : We address the problem of accelerating thin-shell deformable object simulations by dimension reduction. We present a new algorithm to embed a high-dimensional configuration space of deformable objects in a low-dimensional feature space, where the configurations of objects and feature points have approximate one-to-one mapping. Our key technique is a graph-based convolutional neural network (CNN) defined on meshes with arbitrary topologies and a new mesh embedding approach based on physics-inspired loss term. We have applied our approach to accelerate high-resolution thin shell simulations corresponding to cloth-like materials, where the configuration space has tens of thousands of degrees of freedom. We show that our physics-inspired embedding approach leads to higher accuracy compared with prior mesh embedding methods. Finally, we show that the temporal evolution of the mesh in the feature space can also be learned using a recurrent neural network (RNN) leading to fully learnable physics simulators. After training our learned simulator runs 10&#8722;100� faster and the accuracy is high enough for robot manipulation tasks.

## Reinforcement Learning for Robotics

- Dynamic Actor-Advisor Programming for Scalable Safe Reinforcement Learning

    Author: Zhu, Lingwei | Nara Institute of Science and Technology
    Author: Cui, Yunduan | Nara Institute of Science and Technology
    Author: Matsubara, Takamitsu | Nara Institute of Science and Technology
 
    keyword: Learning and Adaptive Systems; Autonomous Agents

    Abstract : Real-world robots have complex strict constraints. Therefore, safe reinforcement learning algorithms that can simultaneously minimize the total cost and the risk of constraint violation are crucial. However, almost no algorithms exist that can scale to high-dimensional systems to the best of our knowledge. In this paper, we propose Dynamic Actor-Advisor Programming (DAAP), as an algorithm for sample-efficient and scalable safe reinforcement learning. DAAP employs two control policies, actor and advisor. They are updated to minimize total cost and risk of constraint violation intertwiningly and smoothly towards each other's direction by using the other as the baseline policy in the Kullback-Leibler divergence of Dynamic Policy Programming framework. We demonstrate the scalability and sample efficiency of DAAP through its application on simulated and real-robot arm control tasks with performance comparisons to baselines.

- Discrete Deep Reinforcement Learning for Mapless Navigation

    Author: Marchesini, Enrico | University of Verona
    Author: Farinelli, Alessandro | University of Verona
 
    keyword: Learning and Adaptive Systems; Autonomous Agents; Deep Learning in Robotics and Automation

    Abstract : Our goal is to investigate whether discrete state space algorithms are a viable solution to continuous alternatives for mapless navigation. To this end we present an approach based on Double Deep Q-Network and employ parallel asynchronous training and a multi-batch Priority Experience Replay to reduce the training time. Experiments show that our method trains faster and outperforms both the continuous Deep Deterministic Policy Gradient and Proximal Policy Optimization algorithms. Moreover, we train the models in a custom environment built on the recent Unity learning toolkit and show that they can be exported on the TurtleBot3 simulator and to the real robot without further training. Overall our optimized method is 40% faster compared to the original discrete algorithm. This setting significantly reduces the training times with respect to the continuous algorithms, maintaining a similar level of success rate hence being a viable alternative for mapless navigation.

- Learning Multi-Robot Decentralized Macro-Action-Based Policies Via a Centralized Q-Net

    Author: Xiao, Yuchen | Northeastern Univerisity
    Author: Hoffman, Joshua | Northeastern University
    Author: Xia, Tian | Northeastern University
    Author: Amato, Christopher | Northeastern University
 
    keyword: AI-Based Methods; Multi-Robot Systems; Deep Learning in Robotics and Automation

    Abstract : In many real-world multi-robot tasks, high-quality solutions often require a team of robots to perform asynchronous actions under decentralized control. Decentralized multi-agent reinforcement learning methods have difficulty learning decentralized policies because of the environment appearing to be non-stationary due to other agents also learning at the same time. In this paper, we address this challenge by proposing a macro-action-based decentralized multi-agent double deep recurrent Q-net (MacDec-MADDRQN) which trains each decentralized Q-net using a centralized Q-net for action selection. A generalized version of MacDec-MADDRQN with two separate training environments, called Parallel-MacDec- MADDRQN, is also presented to leverage either centralized or decentralized exploration. The advantages and the practical nature of our methods are demonstrated by achieving near- centralized results in simulation and having real robots accomplish a warehouse tool delivery task in an efficient way.

- Robust Model-Free Reinforcement Learning with Multi-Objective Bayesian Optimization

    Author: Turchetta, Matteo | ETH Zurich
    Author: Krause, Andreas | ETH Zurich
    Author: Trimpe, Sebastian | Max Planck Institute for Intelligent Systems
 
    keyword: Learning and Adaptive Systems

    Abstract : In reinforcement learning (RL), an autonomous agent learns to perform complex tasks by maximizing an exogenous reward signal while interacting with its environment. In real-world applications, test conditions may differ substantially from the training scenario and, therefore, focusing on pure reward maximization during training may lead to poor results at test time. In these cases, it is important to trade-off between performance and robustness while learning a policy. While several results exist for robust, model-based RL, the model-free case has not been widely investigated. In this paper, we cast the robust, model-free RL problem as a multi-objective optimization problem. To quantify the robustness of a policy, we use delay margin and gain margin, two robustness indicators that are common in control theory. We show how these metrics can be estimated from data in the model-free setting. We use multi-objective Bayesian optimization (MOBO) to solve efficiently this expensive-to-evaluate, multi-objective optimization problem. We show the benefits of our robust formulation both in sim-to-real and pure hardware experiments to balance a Furuta pendulum.

- Motor Synergy Development in High-Performing Deep Reinforcement Learning Algorithms

    Author: Chai, Jiazheng | Tohoku University
    Author: Hayashibe, Mitsuhiro | Tohoku University
 
    keyword: Deep Learning in Robotics and Automation; Performance Evaluation and Benchmarking

    Abstract : As human motor learning is hypothesized to use the motor synergy concept, we investigate if this concept could also be observed in deep reinforcement learning for robotics. From this point of view, we carried out a joint-space synergy analysis on multi-joint running agents in simulated environments trained using two state-of-the-art deep reinforcement learning algorithms. Although a synergy constraint has never been encoded into the reward function, the synergy emergence phenomenon could be observed statistically in the learning agent. To our knowledge, this is the first attempt to quantify the synergy development in detail and evaluate its emergence process during deep learning motor control tasks. We then demonstrate that there is a correlation between our synergy-related metrics and the performance and energy efficiency of a trained agent. Interestingly, the proposed synergy-related metrics reflected a better learning capability of SAC over TD3. It suggests that these metrics could be additional new indices to evaluate deep reinforcement learning algorithms for motor learning. It also indicates that synergy is required for multi-joints robots to move energy-efficiently.

- Barrier-Certified Adaptive Reinforcement Learning with Applications to Brushbot Navigation (I)

    Author: Ohnishi, Motoya | Paul G. Allen School of Computer Science &amp; Engineering
    Author: Wang, Li | Georgia Institute of Technology
    Author: Notomista, Gennaro | Georgia Institute of Technology
    Author: Egerstedt, Magnus | Georgia Institute of Technology
 
    keyword: Learning and Adaptive Systems; Robot Safety; Model Learning for Control

    Abstract : This paper presents a safe learning framework that employs an adaptive model learning algorithm together with barrier certificates for systems with possibly nonstationary agent dynamics. To extract the dynamic structure of the model, we use a sparse optimization technique. We use the learned model in combination with control barrier certificates that constrain policies (feedback controllers) in order to maintain safety, which refers to avoiding particular undesirable regions of the state space. Under certain conditions, recovery of safety in the sense of Lyapunov stability after violations of safety due to the nonstationarity is guaranteed.	In addition, we reformulate an action-value function approximation to make any kernel-based nonlinear function estimation method applicable to our adaptive learning framework. Lastly, solutions to the barrier-certified policy optimization are guaranteed to be globally optimal, ensuring the greedy policy improvement under mild conditions. The resulting framework is validated via simulations of a quadrotor, which has previously been used under stationarity assumptions in the safe learnings literature, and is then tested on a real robot, the brushbot, whose dynamics is unknown, highly complex, and nonstationary.


- On Simple Reactive Neural Networks for Behaviour-Based Reinforcement Learning

    Author: Pore, Ameya | University of Glasgow
    Author: Aragon-Camarasa, Gerardo | University of Glasgow
 
    keyword: Deep Learning in Robotics and Automation; Dexterous Manipulation; Grasping

    Abstract : We present a behaviour-based reinforcement learning approach, inspired by Brook's subsumption architecture, in which simple fully connected networks are trained as reactive behaviours. Our working assumption is that a pick and place robotic task can be simplified by leveraging domain knowledge of a robotics developer to decompose and train reactive behaviours; namely, approach, grasp, and retract. Then the robot autonomously learns how to combine reactive behaviours via an Actor-Critic architecture. We use an Actor-Critic policy to determine the activation and inhibition mechanisms of the reactive behaviours in a particular temporal sequence. We validate our approach in a simulated robot environment where the task is about picking a block and taking it to a target position while orienting the gripper from a top grasp. The latter represents an extra degree-of-freedom of which current end-to-end reinforcement learning approaches fail to generalise. Our findings suggest that robotic learning can be more effective if each behaviour is learnt in isolation and then combined them to accomplish the task. That is, our approach learns the pick and place task in 8,000 episodes, which represents a drastic reduction in the number of training episodes required by an end-to-end approach (~95,000 episodes) and existing state-of-the-art algorithms.

- Predicting Optimal Value Functions by Interpolating Reward Functions in Scalarized Multi-Objective Reinforcement Learning

    Author: Kusari, Arpan | Ford Motor Company
    Author: How, Jonathan Patrick | Massachusetts Institute of Technology
 
    keyword: Deep Learning in Robotics and Automation; AI-Based Methods; Learning and Adaptive Systems

    Abstract : A common approach for defining a reward function for multi-objective reinforcement learning (MORL) problems is the weighted sum of the multiple objectives. The weights are then treated as design parameters dependent on the expertise (and preference) of the person performing the learning, with the typical result that a new solution is required for any change in these settings. This paper investigates the relationship between the reward function and the optimal value function for MORL; specifically addressing the question of how to approximate the optimal value function well beyond the set of weights for which the optimization problem was actually solved, thereby avoiding the need to recompute for any particular choice. We prove that the value function transforms smoothly given a transformation of weights of the reward function (and thus a smooth interpolation in the policy space). A Gaussian process is used to obtain a smooth interpolation over the reward function weights of the optimal value function for three well-known examples: Gridworld, Objectworld and Pendulum. The results show that the interpolation can provide robust values for sample states and actions in both discrete and continuous domain problems. Significant advantages arise from utilizing this interpolation technique in the domain of autonomous vehicles: easy, instant adaptation of user preferences while driving and true randomization of obstacle vehicle behavior preferences during training.

- Integrated Moment-Based LGMD and Deep Reinforcement Learning for UAV Obstacle Avoidance

    Author: He, Lei | Northwestern Polytechnical University
    Author: Aouf, Nabil | City University of London
    Author: Whidborne, James | Cranfield University
    Author: Song, Bifeng | Northwestern Polytechnical University
 
    keyword: Deep Learning in Robotics and Automation; Visual-Based Navigation; Collision Avoidance

    Abstract : In this paper, a bio-inspired monocular vision perception method combined with a learning-based reaction local planner for obstacle avoidance of micro UAVs is presented. The system is more computationally efficient than other vision-based perception and navigation methods such as SLAM and optical flow because it does not need to calculate accurate distances. To improve the robustness of perception against illuminance change, the input image is remapped using image moment which is independent of illuminance variation. After perception, a local planner is trained using deep reinforcement learning for mapless navigation. The proposed perception and navigation methods are evaluated in some realistic simulation environments. The result shows that this light-weight monocular perception and navigation system works well in different complex environments without accurate depth information.

- Interactive Reinforcement Learning with Inaccurate Feedback

    Author: Kessler Faulkner, Taylor | University of Texas at Austin
    Author: Short, Elaine Schaertl | Tufts University
    Author: Thomaz, Andrea Lockerd | University of Texas at Austin
 
    keyword: Learning and Adaptive Systems; Human Factors and Human-in-the-Loop

    Abstract : Interactive Reinforcement Learning (RL) enables agents to learn from two sources: rewards taken from observations of the environment, and feedback or advice from a secondary critic source, such as human teachers or sensor feedback. The addition of information from a critic during the learning process allows the agents to learn more quickly than non-interactive RL. There are many methods that allow policy feedback or advice to be combined with RL. However, critics can often give imperfect information. In this work, we introduce a framework for characterizing Interactive RL methods with imperfect teachers and propose an algorithm, Revision Estimation from Partially Incorrect Resources (REPaIR), which can estimate corrections to imperfect feedback over time. We run experiments both in simulations and demonstrate performance on a physical robot, and find that when baseline algorithms do not have prior information on the exact quality of a feedback source, using REPaIR matches or improves the expected performance of these algorithms.

- Guided Uncertainty-Aware Policy Optimization: Combining Model-Free and Model-Based Strategies for Sample-Efficient Learning

    Author: Lee, Michelle | Stanford University
    Author: Florensa, Carlos | UC Berkeley
    Author: Tremblay, Jonathan | Nvidia
    Author: Ratliff, Nathan | Lula Robotics Inc
    Author: Garg, Animesh | University of Toronto
    Author: Ramos, Fabio | University of Sydney, NVIDIA
    Author: Fox, Dieter | University of Washington
 
    keyword: Deep Learning in Robotics and Automation; Perception for Grasping and Manipulation; Learning and Adaptive Systems

    Abstract : Traditional robotic approaches rely on an accurate model of the environment, a detailed description of how to perform the task, and a robust perception system to keep track of the current state. On the other hand, Reinforcement Learning (RL) approaches can operate directly from raw sensory inputs with only a reward signal to describe the task, but are extremely sample-inefficient and brittle. In this work we combine the strengths of both to obtain a general method able to overcome inaccuracies of the elements in the traditional pipeline, while requiring minimal interaction with the environment. This is achieved by leveraging uncertainty estimates to divide the space in regions where the given model-based policy is reliable, and regions where it may have flaws or not be well defined. In these hard regions, we show that a local model-free policy can be learned directly from raw sensory inputs. This allows to build robotic systems faster from simple and cheap components, and only a high-level description of the task. We test our algorithm, Guided Uncertainty-Aware Policy Optimization (GUAPO), in a real-world robot performing tight-fitting peg insertion.

- High-Speed Autonomous Drifting with Deep Reinforcement Learning

    Author: Cai, Peide | Hong Kong University of Science and Technology
    Author: Mei, Xiaodong | HKUST
    Author: Tai, Lei | Alibaba Group
    Author: Sun, Yuxiang | Hong Kong University of Science and Technology
    Author: Liu, Ming | Hong Kong University of Science and Technology
 
    keyword: Automation Technologies for Smart Cities; Service Robots; Field Robots

    Abstract : Drifting is a complicated task for autonomous vehicle control. Most traditional methods in this area are based on motion equations derived by the understanding of vehicle dynamics, which is difficult to be modeled precisely. We propose a robust drifting controller without explicit motion equations, which is based on the latest model-free deep reinforcement learning algorithm Soft Actor-Critic. The drift control problem is formulated as a trajectory following task, where error-based state and reward are designed. After trained on tracks with different levels of difficulty, our controller is capable of making the vehicle drift through various sharp corners safely and stably in the tough map. The proposed controller is further proved to have excellent generalization ability, which can directly handle unseen vehicle types with different physics properties, such as mass, tire friction, etc.

## Manipulation Planning

- Non-Prehensile Manipulation in Clutter with Human-In-The-Loop

    Author: Papallas, Rafael | The University of Leeds
    Author: Dogar, Mehmet R | University of Leeds
 
    keyword: Manipulation Planning; Human Factors and Human-in-the-Loop

    Abstract : We propose a human-operator guided planning approach to pushing-based manipulation in clutter. Most recent approaches to manipulation in clutter employs randomized planning. The problem, however, remains a challenging one where the planning times are still in the order of tens of seconds or minutes, and the success rates are low for difficult instances of the problem. We build on these control-based randomized planning approaches, but we investigate using them in conjunction with human-operator input. In our framework, the human operator supplies a high-level plan, in the form of an ordered sequence of objects and their approximate goal positions. We present experiments in simulation and on a real robotic setup, where we compare the success rate and planning times of our human-in-the-loop approach with fully autonomous sampling-based planners. We show that with a minimal amount of human input, the low-level planner can solve the problem faster and with higher success rates.

- PuzzleFlex: Kinematic Motion of Chains with Loose Joints

    Author: Lensgraf, Samuel | Dartmouth College
    Author: Itani, Karim | Dartmouth College
    Author: Zhang, Yinan | Dartmouth College
    Author: Sun, Zezhou | Boston University
    Author: Wu, Yijia | Beihang University
    Author: Quattrini Li, Alberto | Dartmouth College
    Author: Zhu, Bo | Dartmouth College
    Author: Whiting, Emily | Boston University
    Author: Wang, Weifu | University at Albany, SUNY
    Author: Balkcom, Devin | Dartmouth College
 
    keyword: Manipulation Planning; Assembly; Cellular and Modular Robots

    Abstract : This paper presents a method of computing free motions of a planar assembly of rigid bodies connected by loose joints. Joints are modeled using local distance constraints, which are then linearized with respect to con- figuration space velocities, yielding a linear programming formulation that allows analysis of systems with thousands of rigid bodies. Potential applications include analysis of collections of modular robots, structural stability perturbation analysis, tolerance analysis for mechanical systems, and formation control of mobile robots.

- Accurate Vision-Based Manipulation through Contact Reasoning

    Author: Kloss, Alina | Max-Planck-Institute for Intelligent Systems
    Author: Bauza Villalonga, Maria | Massachusetts Institute of Technology
    Author: Wu, Jiajun | Stanford University
    Author: Tenenbaum, Joshua | Massachusetts Institute of Technology
    Author: Rodriguez, Alberto | Massachusetts Institute of Technology
    Author: Bohg, Jeannette | Stanford University
 
    keyword: Manipulation Planning; Contact Modeling; Perception for Grasping and Manipulation

    Abstract : Planning contact interactions is one of the core challenges of many robotic tasks. Optimizing contact locations while taking dynamics into account is computationally costly and, in environments that are only partially observable, executing contact-based tasks often suffers from low accuracy. We present an approach that addresses these two challenges for the problem of vision-based manipulation. First, we propose to disentangle contact from motion optimization. Thereby, we improve planning efficiency by focusing computation on promising contact locations. Second, we use a hybrid approach for perception and state estimation that combines neural networks with a physically meaningful state representation. In simulation and real-world experiments on the task of planar pushing, we show that our method is more efficient and achieves a higher manipulation accuracy than previous vision-based approaches.

- A Probabilistic Framework for Constrained Manipulations and Task and Motion Planning under Uncertainty

    Author: Ha, Jung-Su | University of Stuttgart
    Author: Driess, Danny | University of Stuttgart
    Author: Toussaint, Marc | Tu Berlin
 
    keyword: Manipulation Planning; Optimization and Optimal Control; Robust/Adaptive Control of Robotic Systems

    Abstract : Logic-Geometric Programming (LGP) is a powerful motion and manipulation planning framework, which represents hierarchical structure using logic rules that describe discrete aspects of problems, e.g., touch, grasp, hit, or push, and solves the resulting smooth trajectory optimization. The expressive power of logic allows LGP for handling complex, large-scale sequential manipulation and tool-use planning problems. In this paper, we extend the LGP formulation to stochastic domains. Based on the control-inference duality, we interpret LGP in a stochastic domain as fitting a mixture of Gaussians to the posterior path distribution, where each logic profile defines a single Gaussian path distribution. The proposed framework enables a robot to prioritize various interaction modes and to acquire interesting behaviors such as contact exploitation for uncertainty reduction, eventually providing a composite control scheme that is reactive to disturbance.

- Planning with Selective Physics-Based Simulation for Manipulation among Movable Objects

    Author: Saleem, Muhammad Suhail | Carnegie Mellon University
    Author: Likhachev, Maxim | Carnegie Mellon University
 
    keyword: Manipulation Planning; Motion and Path Planning

    Abstract : Use of physics-based simulation as a planning model enables a planner to reason and generate plans that involve non-trivial interactions with the world. For example, grasping a milk container out of a cluttered refrigerator may involve moving a robot manipulator in between other objects, pushing away the ones that are movable and avoiding interactions with certain fragile containers. A physics-based simulator allows a planner to reason about the effects of interactions with these objects and to generate a plan that grasps the milk container successfully. The use of physics-based simulation for planning however is underutilized. One of the reasons for it being that physics-based simulations are typically way too slow for being used within a planning loop that typically requires tens of thousands of actions to be evaluated within a matter of a second or two. In this work, we develop a planning algorithm that tries to address this challenge. In particular, it builds on the observation that only a small number of actions actually need to be simulated using physics, and the remaining set of actions, such as moving an arm around obstacles, can be evaluated using a much simpler internal planning model, e.g., a simple collision-checking model. Motivated by this, we develop an algorithm called Planning with Selective Physics-based Simulation that automatically discovers what should be simulated with physics and what can utilize an internal planning model for pick-and-place tasks.

- Hybrid Differential Dynamic Programming for Planar Manipulation Primitives

    Author: Doshi, Neel | MIT
    Author: Hogan, Francois | Massachusetts Institute of Technology
    Author: Rodriguez, Alberto | Massachusetts Institute of Technology
 
    keyword: Manipulation Planning; Dexterous Manipulation; Optimization and Optimal Control

    Abstract : We present a hybrid differential dynamic programming (DDP) algorithm for closed-loop execution of manipulation primitives with frictional contact switches. Planning and control of these primitives is challenging as they are hybrid, under-actuated, and stochastic. We address this by developing hybrid DDP both to plan finite horizon trajectories with a few contact switches and to create linear stabilizing controllers. We evaluate the performance and computational cost of our framework in ablations studies for two primitives: planar pushing and planar pivoting. We find that generating pose-to-pose closed-loop trajectories from most configurations requires only a couple (one to two) hybrid switches and can be done in reasonable time (one to five seconds). We further demonstrate that our controller stabilizes these hybrid trajectories on a real pushing system. A video describing our work can be found at https://youtu.be/YGSe4cUfq6Q.


- Human-Like Planning for Reaching in Cluttered Environments

    Author: Hasan, Mohamed | University of Leeds
    Author: Warburton, Matthew | University of Leeds
    Author: Agboh, Wisdom C. | University of Leeds
    Author: Dogar, Mehmet R | University of Leeds
    Author: Leonetti, Matteo | University of Leeds
    Author: Wang, He | University of Leeds
    Author: Mushtaq, Faisal | University of Leeds
    Author: Mon-Williams, Mark | University of Leeds
    Author: Cohn, Anthony | University of Leeds
 
    keyword: Manipulation Planning; Learning from Demonstration

    Abstract : Humans, in comparison to robots, are remarkably adept at reaching for objects in cluttered environments. The best existing robot planners are based on random sampling of configuration space- which becomes excessively high-dimensional with large number of objects. Consequently, most planners often fail to efficiently find object manipulation plans in such environments. We addressed this problem by identifying high-level manipulation plans in humans, and transferring these skills to robot planners. We used virtual reality to capture human participants reaching for a target object on a tabletop cluttered with obstacles. From this, we devised a qualitative representation of the task space to     Abstract the decision making, irrespective of the number of obstacles. Based on this representation, human demonstrations were segmented and used to train decision classifiers. Using these classifiers, our planner produced a list of waypoints in task space. These waypoints provided a high-level plan, which could be transferred to an arbitrary robot model and used to initialise a local trajectory optimiser. We evaluated this approach through testing on unseen human VR data, a physics-based robot simulation, and a real robot (dataset and code are publicly available). We found that the human-like planner outperformed a state-of-the-art standard trajectory optimisation algorithm, and was able to generate effective strategies for rapid planning

- Where to Relocate?: Object Rearrangement Inside Cluttered and Confined Environments for Robotic Manipulation

    Author: Cheong, Sang Hun | Korea University, KIST
    Author: Cho, Brian Younggil | Korea Institute of Science and Technology
    Author: Lee, JinHwi | Hanyang University
    Author: Kim, ChangHwan | Korea Institute of Science and Technology
    Author: Nam, Changjoo | Korea Institute of Science and Technology
 
    keyword: Manipulation Planning; Task Planning; Motion and Path Planning

    Abstract : We present an algorithm determining where to relocate objects inside a cluttered and confined space while rearranging objects to retrieve a target object. Although methods that decide what to remove have been proposed, planning for the placement of removed objects inside a workspace has not received much attention. Rather, removed objects are often placed outside the workspace, which incurs additional laborious work (e.g., motion planning and execution of the manipulator and the mobile base, perception of other areas). Some other methods manipulate objects only inside the workspace but without a principle so the rearrangement becomes inefficient. <p>In this work, we consider both monotone (each object is moved only once) and non-monotone arrangement problems which have shown to be NP-hard. Once the sequence of objects to be relocated is given by any existing algorithm, our method aims to minimize the number of pick-and-place actions to place the objects until the target becomes accessible. From extensive experiments, we show that our method reduces the number of pick-and-place actions and the total execution time (the reduction is up to 23.1% and 28.1% respectively) compared to baseline methods while achieving higher success rates.

- Autonomous Modification of Unstructured Environments with Found Material

    Author: Thangavelu, Vivekanandhan | University at Buffalo
    Author: Saboia Da Silva, Maira | University at Buffalo
    Author: Choi, Jiwon | University at Buffalo
    Author: Napp, Nils | SUNY Buffalo
 
    keyword: Autonomous Agents; Robotics in Construction; Reactive and Sensor-Based Planning

    Abstract : The ability to autonomously modify their environment dramatically increases the capability of robots to operate in unstructured environments. We develop a specialized construction algorithm and robotic system that can autonomously build motion support structures with previously unseen objects. The approach is based on our prior work on adaptive ramp building algorithms, but it eliminates the assumption of having specialized building materials that simplify manipulation and planning for stability. Utilizing irregularly shaped stones makes the problem significantly more challenging since the outcome of individual placements is sensitive to details of contact geometry and friction, which are difficult to observe. To reuse the same high-level algorithm, we develop a new physics-based planner that explicitly considers the uncertainty produced by incomplete in-situ sensing and imprecision during pickup and placement. We demonstrate the approach on a robotic system that uses a newly developed gripper to reliably pick up stones with minimal additional sensors or complex grasp planning. The resulting system can build structures with more than 70 stones, which in turn provide traversable paths to previously inaccessible locations.

- Tethered Tool Manipulation Planning with Cable Maneuvering

    Author: S�nchez, Daniel Enrique | Osaka University
    Author: Wan, Weiwei | Osaka University
    Author: Harada, Kensuke | Osaka University
 
    keyword: Manipulation Planning; Grippers and Other End-Effectors; Grasping

    Abstract : In this paper, we present a planner for manipulating tethered tools using dual-armed robots. The planner generates robot motion sequences to maneuver a tool and its cable while avoiding robot-cable entanglements. Firstly, the planner generates an Object Manipulation Motion Sequence (OMMS) to handle the tool and place it in desired poses. Secondly, the planner examines the tool movement associated with the OMMS and computes candidate positions for a cable slider, to maneuver the tool cable and avoid collisions. Finally, the planner determines the optimal slider positions to avoid entanglements and generates a Cable Manipulation Motion Sequence (CMMS) to place the slider in these positions. The robot executes both the OMMS and CMMS to handle the tool and its cable to avoid entanglements and excess cable bending. Simulations and real-world experiments help validate the proposed method.

- Optimization-Based Posture Generation for Whole-Body Contact Motion by Contact Point Search on the Body Surface

    Author: Murooka, Masaki | The University of Tokyo
    Author: Okada, Kei | The University of Tokyo
    Author: Inaba, Masayuki | The University of Tokyo
 
    keyword: Manipulation Planning; Kinematics; Humanoid Robots

    Abstract : Whole-body contact is an effective strategy for improving the stability and efficiency of the motion of robots. For robots to automatically perform such motions, we propose a posture generation method that employs all available surfaces of the robot links. By representing the contact point on the body surface by two-dimensional configuration variables, the joint positions and contact points are simultaneously determined through a gradient-based optimization. By generating motions with the proposed method, we present experiments in which robots manipulate objects effectively utilizing whole-body contact.

- Real-Time Conflict Resolution of Task-Constrained Manipulator Motion in Unforeseen Dynamic Environments (I)

    Author: Mao, Huitan | University of North Carolina at Charlotte
    Author: Xiao, Jing | Worcester Polytechnic Institute (WPI)
 
    keyword: Manipulation Planning; Natural Machine Motion; Task Planning

    Abstract : This paper introduces conflict resolution in task-constrained real-time adaptive motion planning (RAMP) to enable a robot manipulator performing tasks in an environment with dynamically unknown obstacles.The method continuously improves and maintains diverse task constrained as well as unconstrained robot trajectories to allow the manipulator switching to a better trajectory at any time and seamlessly resolving conflicts between satisfying task constraints and avoiding dynamically unknown obstacles. If dynamic obstacles block all available task-constrained trajectories, the algorithm allows the manipulator to change goals on the fly to be free of task constraints and resume the task whenever there is a collision-free,task-constrained trajectory. The method is validated in different dynamic environments with different task constraints in both simulation and real-world experiments.

## Contact Modeling
- Interaction Stability Analysis from the Input-Output Viewpoints
 
    Author: Huang, Yuancan | Beijing Institute of Technology
    Author: Huang, Qiang | Beijing Institute of Technology
 
    keyword: Contact Modeling; Physical Human-Robot Interaction; Dynamics

    Abstract : Interaction with the environment is arguably one of the necessary actions for many robot applications. Taxonomy of interaction behaviours is classified into three categories: cooperation, collaboration, and competition. In theory, interaction dynamics may be modelled by D'Alembert's principle or nonsmooth mechanics through seeking equality and/or inequality kinematic constraints. However, it is hard to gain these kinematic constraints in practice since they may be variable or be hardly described in a mathematical form. <p>In this paper, passivity and passivity indices with the differential operator are put forward by restricting its domain from the whole extended Hilbert function space to a set of all continuous function with finite derivative, and then the input-output stability condition, in this case, is derived. Next, mechanical impedance and admittance are defined, and a linear spatial impedance representation is given from the energetic point of view. Base on the bond graph theory, an ideal model is presented to model the idealized interaction, and invariance of port functions derived from the ideal interaction model is introduced; An interaction model is then proposed accounting for nonidealized factors and to describe cooperative, collaborative, and competitive interactions in a unified way. Finally, interaction stabilities are analyzed corresponding to different interaction models, and robustness of interaction stability is addressed based on the passivity indices.

- Improving the Contact Instant Detection of Sensing Antennae Using a Super-Twisting Algorithm

    Author: Feliu, Daniel | Robotics, Vision and Control Group at the University of Seville
    Author: Cortez-Vega, Ricardo | CINVESTAV-IPN
    Author: Feliu, Vicente | Escuela T�cnica Superior De IngenierosIndustriales/Universidad D
 
    keyword: Contact Modeling

    Abstract : Sensing antenna devices, that mimic insect antennae or mammal whiskers, is an active field of research that still needs new developments in order to become efficient and reliable components of robotic systems. This work reports a new result in the area of signal processing of these devices that allows to detect the instant of the impact of a flexible antenna with an object faster than other reported methods. Previous methods require the use of filters that introduce delays in the impact detection. A method based on the Super- Twisting algorithm is proposed here that avoids the use of these filters and reduces such delays improving the impact instant estimation. Experiments show that these delays can be reduced in more than 50%, allowing reliable estimation of the impact instant with an error of less than 5 ms in many cases requiring a limited computational effort.

- 6DFC: Efficiently Planning Soft Non-Planar Area Contact Grasps Using 6D Friction Cones

    Author: Xu, Jingyi | Technical University of Munich
    Author: Danielczuk, Michael | UC Berkeley
    Author: Steinbach, Eckehard | Technical University of Munich
    Author: Goldberg, Ken | UC Berkeley
 
    keyword: Contact Modeling; Grasping; Manipulation Planning

    Abstract : Analytic grasp planning algorithms typically approximate compliant contacts with soft point contact models to compute grasp quality, but these models are overly conservative and do not capture the full range of grasps available. While area contact models can reduce the number of false negatives predicted by point contact models, they have been restricted to a 3D analysis of the wrench applied at the contact and so are still overly conservative. We extend traditional 3D friction cones and present an efficient algorithm for calculating the 6D friction cone (6DFC) for a non-planar area contact between a compliant gripper and a rigid object. We introduce a novel sampling algorithm to find the 6D friction limit surface for a non-planar area contact and a linearization method for these ellipsoids that reduces the computation of 6DFC constraints to a quadratic program. We show that constraining the wrench applied at the contact in this way increases recall, a metric inversely related to the number of false negative predictions, by 17% and precision, a metric inversely related to the number of false positive predictions, by 2% over soft point contact models on results from 1500 physical grasps on 12 3D printed non-planar objects with an ABB YuMi robot. The 6DFC algorithm also achieves 6% higher recall with similar precision and 85x faster runtime than a previously proposed area contact model.

- Long-Horizon Prediction and Uncertainty Propagation with Residual Point Contact Learners
 
    Author: Fazeli, Nima | Massachusetts Institute of Technology
    Author: Ajay, Anurag | MIT
    Author: Rodriguez, Alberto | Massachusetts Institute of Technology
 
    keyword: Contact Modeling; Simulation and Animation; Performance Evaluation and Benchmarking

    Abstract : The ability to simulate and predict the outcome of contacts is paramount to the successful execution of many robotic tasks. Simulators are powerful tools for the design of robots and their behaviors, yet the discrepancy between their predictions and observed data limit their usability. In this paper, we propose a self-supervised approach to learning residual models for rigid-body simulators that exploits corrections of contact models to refine predictive performance and propagate uncertainty. We empirically evaluate the framework by predicting the outcomes of planar dice rolls and compare it's performance to state-of-the-art techniques.

- Versatile Trajectory Optimization Using a LCP Wheel Model for Dynamic Vehicle Maneuvers

    Author: Bellegarda, Guillaume | University of California, Santa Barbara
    Author: Byl, Katie | UCSB
 
    keyword: Contact Modeling; Optimization and Optimal Control; Wheeled Robots

    Abstract : Car models have been extensively studied at varying levels of     Abstraction, and planning and executing motions under ideal conditions is well researched and understood. For more aggressive maneuvers, for example when drifting or skidding, empirical and/or discontinuous friction models have been used to explain and approximate real world contact behavior. Separately, contact dynamics have been extensively studied by the robotics community, often times formulated as a linear complementarity problem (LCP) for dynamic multi-rigid-body contact problems with Coulomb friction cone approximations. In this work, we explore the validity of using such an anisotropic Coulomb friction cone to model tire dynamics to plan for vehicle motion, and present a versatile trajectory optimization framework using this model that can both avoid and/or exploit wheel skidding, depending on the cost function and planning horizon. Experimental evidence of planning and executing dynamic drift parking is shown on a 1/16 scale model car.

- A Transition-Aware Method for the Simulation of Compliant Contact with Regularized Friction

    Author: Castro, Alejandro | Toyota Research Institute
    Author: Qu, Ante | Stanford University, Toyota Research Institute
    Author: Kuppuswamy, Naveen | Toyota Research Institute
    Author: Alspach, Alex | Toyota Research Institute
    Author: Sherman, Michael | Toyota Research Institute
 
    keyword: Contact Modeling; Simulation and Animation; Grasping

    Abstract : Multibody simulation with frictional contact has been a challenging subject of research for the past thirty years. Rigid-body assumptions are commonly used to approximate the physics of contact, and together with Coulomb friction, lead to challenging-to-solve nonlinear complementarity problems (NCP). On the other hand, robot grippers often introduce significant compliance. Compliant contact, combined with regularized friction, can be modeled entirely with ODEs, avoiding NCP solves. Unfortunately, regularized friction introduces high-frequency stiff dynamics and even implicit methods struggle with these systems, especially during slip-stick transitions. To improve the performance of implicit integration for these systems we introduce a Transition-Aware Line Search (TALS), which greatly improves the convergence of the Newton-Raphson iterations performed by implicit integrators. We find that TALS works best with semi-implicit integration, but that the explicit treatment of normal compliance can be problematic. To address this, we develop a Transition-Aware Modified Semi-Implicit (TAMSI) integrator that has similar computational cost to semi-implicit methods but implicitly couples compliant contact forces, leading to a more robust method. We evaluate the robustness, accuracy and performance of TAMSI and demonstrate our approach alongside relevant sim-to-real manipulation tasks.


## Robotics in Hazardous Fields
- Single Actuator Peristaltic Robot for Subsurface Exploration and Device Emplacement

    Author: De la Fuente, Juan | University of Calgary
    Author: Shor, Roman | University of Calgary
    Author: Larter, Steve | University of Calgary
 
    keyword: Robotics in Hazardous Fields; Mechanism Design; Mining Robotics

    Abstract : In this work, we present the concept, design, and initial testing of a single actuator peristaltic motion robot for subsurface geological exploration and device emplacement. We are researching unconventional methods, including robotics, for the production of energy from oil reservoirs that do not liberate carbon to the atmosphere. For such application, we are developing autonomous robots for data acquisition and tool transportation inside petroleum reservoirs. The mechanism described in this work is a cam-follower configuration worm robot that utilizes peristaltic displacement. We confirmed that the mechanism works on a plane surface and in non-consolidated media.

- Improving Visual Feature Extraction in Glacial Environments

    Author: Morad, Steven | University of Arizona
    Author: Nash, Jeremy | Jet Propulsion Laboratory
    Author: Higa, Shoya | Jet Propulsion Laboratory
    Author: Smith, Russell G | Jet Propulsion Laboratory
    Author: Parness, Aaron | Nasa Jet Propulsion Laboratory
    Author: Barnard, Kobus | University of Arizona
 
    keyword: Visual-Based Navigation; Robotics in Hazardous Fields; Computer Vision for Other Robotic Applications

    Abstract : Glacial science could benefit tremendously from autonomous robots, but previous glacial robots have had perception issues in these colorless and featureless environments, specifically with visual feature extraction. Glaciologists use near-infrared imagery to reveal the underlying heterogeneous spatial structure of snow and ice, and we theorize that this hidden near-infrared structure could produce more and higher quality features than available in visible light. We took a custom camera rig to Igloo Cave at Mt. St. Helens to test our theory. The camera rig contains two identical machine vision cameras, one which was outfitted with multiple filters to see only near-infrared light. We extracted features from short video clips taken inside Igloo Cave at Mt. St. Helens, using three popular feature extractors (FAST, SIFT, and SURF). We quantified the number of features and their quality for visual navigation using feature correspondence and the epipolar constraint. Our results indicate that near-infrared imagery produces more features that tend to be of higher quality than that of visible light imagery.

- Unmanned Aerial Vehicle Based Hazardous Materials Response: Information-Theoretic Hazardous Source Search and Reconstruction (I)

    Author: Hutchinson, Michael | Loughborough University
    Author: Liu, Cunjia | Loughborough University
    Author: Thomas, Paul | Dstl
    Author: Chen, Wen-Hua | Loughborough University
 
    keyword: Robotics in Hazardous Fields; Reactive and Sensor-Based Planning; Environment Monitoring and Management

    Abstract : This article presents an airborne autonomous system to assist first responders in response to releases of hazardous material into the atmosphere. The system comprises of an Unmanned Aerial Vehicle (UAV), onboard chemical sensors and information-theoretic search and source term reconstruction algorithms. The methods presented have been validated in experiments by the     Authors and then demonstrated in field trials designed by end users and conducted at the UK's Fire Service College.

- Planning Maximum-Manipulability Cutting Paths

    Author: Pardi, Tommaso | University of Birmingham
    Author: Ortenzi, Valerio | University of Birmingham
    Author: Fairbairn, Colin | National Nuclear Laboratory
    Author: Pipe, Tony | University of the West of England
    Author: Ghalamzan Esfahani, Amir Masoud | University of Lincoln
    Author: Stolkin, Rustam | University of Birmingham
 
    keyword: Robotics in Hazardous Fields; Kinematics; Motion and Path Planning

    Abstract : This paper presents a method for constrained motion planning from vision, which enables a robot to move its end-effector over an observed surface, given start and destination points. The robot has no prior knowledge of the surface shape, but observes it from a noisy point cloud. We consider the multi-objective optimisation problem of finding robot trajectories which maximise the robot's manipulability throughout the motion, while also minimising surface-distance travelled between the two points. This work has application in industrial problems of rough robotic cutting, e.g., demolition of legacy nuclear plant, where the cut path needs not be precise as long as it achieves dismantling. We show how detours in the path can be leveraged to increase the manipulability of the robot at all points along the path. This helps to avoid singularities, while maximising the robot's capability to make small deviations during task execution. We show how a sampling-based planner can be projected onto the Riemannian manifold of a curved surface, and extended to include a term which maximises manipulability. We present the results of empirical experiments, with both simulated and real robots, which are tasked with moving over a variety of different surface shapes. Our planner enables successful task completion, while ensuring significantly greater manipulability when compared against a conventional RRT* planner.

- Robot Risk-Awareness by Formal Risk Reasoning and Planning

    Author: Xiao, Xuesu | The University of Texas at Austin
    Author: Dufek, Jan | Texas A&amp;M University
    Author: Murphy, Robin | Texas A&amp;M
 
    keyword: Robotics in Hazardous Fields; Robot Safety; Search and Rescue Robots

    Abstract : This paper proposes a formal robot motion risk reasoning framework and develops a risk-aware path planner that minimizes the proposed risk. While robots locomoting in unstructured or confined environments face a variety of risk, existing risk only focuses on collision with obstacles. Such risk is currently only addressed in ad hoc manners. Without a formal definition, ill-supported properties, e.g. additive or Markovian, are simply assumed. Relied on an incomplete and inaccurate representation of risk, risk-aware planners use ad hoc risk functions or chance constraints to minimize risk. The former inevitably has low fidelity when modeling risk, while the latter conservatively generates feasible path within a probability bound. Using propositional logic and probability theory, the proposed motion risk reasoning framework is formal. Building upon a universe of risk elements of interest, three major risk categories, i.e. locale-, action-, and traverse-dependent, are introduced. A risk-aware planner is also developed to plan minimum risk path based on the newly proposed risk framework. Results of the risk reasoning and planning are validated in physical experiments in a real-world unstructured or confined environment. With the proposed fundamental risk reasoning framework, safety of robot locomotion could be explicitly reasoned, quantified, and compared. The risk-aware planner finds safe path in t

- Experimental Evaluation and Characterization of Radioactive Source Effects on Robot Visual Localization and Mapping

    Author: Lee, Elijah S. | University of Pennsylvania
    Author: Loianno, Giuseppe | New York University
    Author: Thakur, Dinesh | University of Pennsylvania
    Author: Kumar, Vijay | University of Pennsylvania
 
    keyword: Robotics in Hazardous Fields; Aerial Systems: Applications

    Abstract : Robots are ideally suited to performing simple tasks in dangerous environments. In this letter, we address the use of robots for inspection of nuclear reactors which may be contaminated by radiation. The geometry of a reactor vessel is three-dimensional with significant clutter. Accordingly, we propose the use of small-scale, flying robots that are able to localize themselves and autonomously navigate around obstacles. Because of the constraints on size, we rely on cameras which are the best low power and lightweight sensors. However, cameras perform poorly in the presence of radioactivity and the impact of radiation on robotics systems is not well understood. In this letter, we (a) analyze the effects of radioactive sources on camera sensors, affecting localization and mapping algorithms, (b) quantify these effects from a statistical viewpoint according to different source intensities; and (c) compare different solutions to mitigate these effects. Our analysis is supported and validated by experimental data collected on a Commercial-Off-The-Shelf (COTS) camera sensor exposed to radioactive sources in a hot cell.

## Dynamics
- Dynamic Modeling of Robotic Manipulators for Accuracy Evaluation

    Author: Zimmermann, Stefanie Antonia | ABB
    Author: Berninger, Tobias Franz Christian | TU Munich
    Author: Derkx, Jeroen | Jeroen.derkx@se.abb.com
    Author: Rixen, Daniel | Technische Universitét M�nchen
 
    keyword: Dynamics; Flexible Robots; Industrial Robots

    Abstract : In order to fulfill conflicting requirements in the development of industrial robots, such as increased accuracy of a weightreduced manipulator with lower mechanical stiffness, the robot's dynamical behavior must be evaluated early in the development process. This leads to the need of accurate multibody models of the manipulator under development. This paper deals with multibody models that include flexible bodies, which are exported from the corresponding Finite Element model of the structural parts. It is shown that such a flexible link manipulator model, which is purely based on development and datasheet data, is suitable for an accurate description of an industrial robot's dynamic behavior. No stiffness parameters need to be identified by experimental methods, making this approach especially relevant during the development of new manipulators. This paper presents results of experiments in time and frequency domain for analyzing the modeling approach and for validating the model performance against real robot behavior.

- A Real-Robot Dataset for Assessing Transferability of Learned Dynamics Models

    Author: Agudelo-Espa�a, Diego | Max Planck Institute for Intelligent Systems
    Author: Zadaianchuk, Andrii | Max Planck Institute for Intelligent Systems
    Author: Wenk, Philippe | ETH Zuerich
    Author: Garg, Aditya | Max Planck Institute for Intelligent Systems
    Author: Akpo, Joel | Max Planck Institute for Intelligent Systems
    Author: Grimminger, Felix | Max Planck Institute for Intelligent Systems
    Author: Viereck, Julian | Max Planck Institute for Intelligent Systems
    Author: Naveau, Maximilien | LAAS/CNRS
    Author: Righetti, Ludovic | New York University
    Author: Martius, Georg | Max Planck Institute for Intelligent Systems
    Author: Krause, Andreas | ETH Zurich
    Author: Sch�lkopf, Bernhard | Max Planck Institute for Intelligent Systems
    Author: Bauer, Stefan | MPI for Intelligent Systems
    Author: W�thrich, Manuel | Max-Planck-Institute for Intelligent Systems
 
    keyword: Dynamics; Model Learning for Control

    Abstract : In the context of model-based reinforcement learning and control, a large number of methods for learning system dynamics have been proposed in recent years. The purpose of these learned models is to synthesize new control policies. An important open question is how robust current dynamics-learning methods are to shifts in the data distribution due to changes in the control policy. We present a real-robot dataset which allows to systematically investigate this question. This dataset contains trajectories of a 3 degrees-of-freedom (DOF) robot being controlled by a diverse set of policies. For comparison, we also provide a simulated version of the dataset. Finally, we benchmark a few widely-used dynamics-learning methods using the proposed dataset. Our results show that the iid test error of a learned model is not necessarily a good indicator of its accuracy under control policies different from the one which generated the training data. This suggests that it may be important to evaluate dynamics-learning methods in terms of their transfer performance, rather than only their iid error.

- MagNet: Discovering Multi-Agent Interaction Dynamics Using Neural Network

    Author: Saha, Priyabrata | Georgia Institute of Technology
    Author: Ali, Arslan | Georgia Institute of Technology
    Author: Mudassar, Burhan | Georgia Institute of Technology
    Author: Long, Yun | GEORGIA TECH
    Author: Mukhopadhyay, Saibal | Georgia Institute of Technology
 
    keyword: Dynamics; Deep Learning in Robotics and Automation; Learning and Adaptive Systems

    Abstract : We present the MagNet, a neural network-based multi-agent interaction model to discover the governing dynamics and predict evolution of a complex multi-agent system from observations. We formulate a multi-agent system as a coupled non-linear network with a generic ordinary differential equation (ODE) based state evolution, and develop a neural network-based realization of its time-discretized model. MagNet is trained to discover the core dynamics of a multi-agent system from observations, and tuned on-line to learn agent-specific parameters of the dynamics to ensure accurate prediction even when physical or relational attributes of agents, or number of agents change. We evaluate MagNet on a point-mass system in two-dimensional space, Kuramoto phase synchronization dynamics and predator-swarm interaction dynamics demonstrating orders of magnitude improvement in prediction accuracy over traditional deep learning models.

- Modulation of Robot Orientation State Via Leg-Obstacle Contact Positions

    Author: Ramesh, Divya | University of Pennsylvania
    Author: Kathail, Anmol | University of Pennsylvania
    Author: Koditschek, Daniel | University of Pennsylvania
    Author: Qian, Feifei | University of Pennsylvania
 
    keyword: Dynamics; Biologically-Inspired Robots; Contact Modeling

    Abstract : We study a quadrupedal robot traversing a structured (i.e., periodically spaced) obstacle field driven by an open-loop quasi-static trotting walk. Despite complex, repeated collisions and slippage between robot legs and obstacles, the robot's horizontal plane body orientation trajectory can converge in the absence of body level feedback to stable steady state patterns. We classify these patterns into a series of �types' ranging from stable locked equilibria, to stable periodic oscillations, to unstable or mixed period oscillations. We observe that the stable equilibria can bifurcate to stable periodic oscillations and then to mixed period oscillations as the obstacle spacing is gradually increased. Using a 3D-reconstruction method, we experimentally characterize the robot leg-obstacle contact configurations at each step to show that the different steady patterns in robot orientation trajectories result from a self-stabilizing periodic pattern of leg-obstacle contact positions. We present a highly-simplified coupled oscillator model that predicts robot orientation pattern as a function of the leg-obstacle contact mechanism. We demonstrate that the model successfully captures the robot steady state for different obstacle spacing and robot initial conditions. We suggest in simulation that using the simplified coupled oscillator model we can create novel control strategies that allow multi-legged robots to exploit obstacle disturbances to negotiate randomly cluttered environments

- Beyond Basins of Attraction: Quantifying Robustness of Natural Dynamics (I)

    Author: Heim, Steve | Max Planck Institute for Intelligent Systems
    Author: Badri-Spröwitz, Alexander | Max Planck Institute for Intelligent Systems
 
    keyword: Dynamics; Legged Robots; Robust/Adaptive Control of Robotic Systems

    Abstract : Properly designing a system to exhibit favorable natural dynamics can greatly simplify designing or learning the control policy. However, it is still unclear what constitutes favorable natural dynamics and how to quantify its effect. Most studies of simple walking and running models have focused on the basins of attraction of passive limit cycles and the notion of self-stability. We instead emphasize the importance of stepping beyond basins of attraction. In this paper, we show an approach based on viability theory to quantify robust sets in state-action space. These sets are valid for the family of all robust control policies, which allows us to quantify the robustness inherent to the natural dynamics before designing the control policy or specifying a control objective. We illustrate our formulation using spring-mass models, simple low-dimensional models of running systems. We then show an example application by optimizing robustness of a simulated planar monoped, using a gradient-free optimization scheme. Both case studies result in a nonlinear effective stiffness providing more robustness.

- Stable Parking Control of a Robot Astronaut in a Space Station Based on Human Dynamics (I)
 
    Author: Jiang, Zhihong | Beijing Institute of Technology
    Author: Xu, Jiafeng | Beijing Institute of Technology
    Author: Li, Hui | Beijing Institute of Technology
    Author: Huang, Qiang | Beijing Institute of Technology
 
    keyword: Dynamics; Collision Avoidance; Space Robotics and Automation

    Abstract : Controlling a robot astronaut to move in the same way as a human astronaut to realize a wide range of motion in a space station is an important requirement for the robot astronauts that are meant to assist or replace human astronauts. However, a robot astronaut is a nonlinear and strongly coupled multibody dynamic system with multiple degrees of freedom, whose dynamic characteristics are complex. Therefore, implementing a robot astronaut with wide-ranging motion control in a space station is a tremendous challenge for robotic technology. This article presents a wide-ranging stable motion control method for robot astronauts in space stations based on human dynamics. Focusing on the astronauts' parking motion in a space station, a viscoelastic dynamic humanoid model of parking under microgravity environment was established using a mass�spring�damper system. The model was used as the expected model for stable parking control of a robot astronaut, and the complex dynamic characteristics were mapped into the robot astronaut system to control the stable parking of the robot astronaut in a manner similar to a human astronaut. This provides a critical basis for implementing robots that are capable of steady wide-ranging motion in space stations. The method was verified on a dynamic system of a robot astronaut that was constructed for this research. The experimental results showed that the method is feasible and effective and that it is a highly competitive solution for robot astronau

## Product Design, Development and Prototyping
- Development of a Robotic System for Automated Decaking of 3D-Printed Parts

    Author: Nguyen, Huy | Nanyang Technological University
    Author: Adrian, Nicholas | Nanyang Technological University
    Author: Lim, Joyce Xin-Yan | Nanyang Technological University
    Author: Salfity, Jonathan | HP Labs, HP Inc
    Author: Allen, William | HP Inc
    Author: Pham, Quang-Cuong | NTU Singapore
 
    keyword: Product Design, Development and Prototyping; Additive Manufacturing; Factory Automation

    Abstract : With the rapid rise of 3D-printing as a competitive mass manufacturing method, manual "decaking" - i.e. removing the residual powder that sticks to a 3D-printed part - has become a significant bottleneck. Here, we introduce, for the first time to our knowledge, a robotic system for automated decaking of 3D-printed parts. Combining Deep Learning for 3D perception, smart mechanical design, motion planning, and force control for industrial robots, we developed a system that can automatically decake parts in a fast and efficient way. Through a series of decaking experiments performed on parts printed by a Multi Jet Fusion printer, we demonstrated the feasibility of robotic decaking for 3D-printing-based mass manufacturing.

- A Novel Solar Tracker Driven by Waves: From Idea to Implementation

    Author: Xu, Ruoyu | The Chinese University of Hong Kong, Shenzhen
    Author: Liu, Hengli | The Chinese University of Hong Kong, Shenzhen
    Author: Liu, Chongfeng | The Chinese University of Hong Kong, Shenzhen
    Author: Sun, Zhenglong | Chinese University of Hong Kong, Shenzhen
    Author: Lam, Tin Lun | The Chinese University of Hong Kong, Shenzhen
    Author: Qian, Huihuan | The Chinese University of Hong Kong, Shenzhen
 
    keyword: Dynamics; Product Design, Development and Prototyping; Marine Robotics

    Abstract : Traditional solar trackers often adopt motors to automatically adjust the attitude of the solar panels towards the sun for maximum power efficiency. In this paper, a novel design of solar tracker for the ocean environment is introduced. Utilizing the fluctuations due to the waves, electromagnetic brakes are utilized instead of motors to adjust the attitude of the solar panels. Compared with the traditional solar trackers, the proposed one is simpler in hardware while the harvesting efficiency is similar. The desired attitude is calculated out of the local location and time. Then based on the dynamic model of the system, the angular acceleration of the solar panels is estimated and a control algorithm is proposed to decide the release and lock states of the brakes. In such a manner, the adjustment of the attitude of the solar panels can be achieved by using two brakes only. Experiments are conducted to validate the acceleration estimator and the dynamic model. At last, the feasibility of the proposed solar tracker is tested on the real water surface. The results show that the system is able to adjust 40^circ in two dimensions within 28 seconds.

- Design and Implementation of Hydraulic-Cable Driven Manipulator for Disaster Response Operation

    Author: Kim, JungYeong | University of Science and Technology(UST), Korea Institute of In
    Author: Seo, Jaehong | University of Science and Technology
    Author: Park, Sangshin | Korea Institute of Industrial Technology
    Author: Cho, Jungsan | KITECH(Korea Institute of Industrial Technology)
    Author: Han, SangChul | Korea Institute of Industrial Technology
 
    keyword: Product Design, Development and Prototyping; Hydraulic/Pneumatic Actuators; Tendon/Wire Mechanism

    Abstract : This paper introduces a new hydraulic manipulator with hydraulic-cable driven actuation (HCA) modules for disaster response mobile-manipulation. The hydraulic actuation system has the potential to apply disaster-response application, because it has a higher power-to-weight ratio and robustness to external impacts than electric motor actuation. However, using a conventional hydraulic manipulators is inappropriate because the revolute joint uses conventional actuators, such as linear cylinders and vanes, which have some limitations: 1) linear cylinder: small range of motion, 2) vane: low torque-to-weight ratio. To overcome these limitations, we propose new 3DOF manipulator which has a larger workspace than the conventional hydraulic manipulator and comparable payload-to-weight ratio. To this end, we use hydraulic-cable driven actuation modules from our previous research. Experimental results verify the basic performance of the actuator modules and manipulator and their capability to perform various disaster response tasks.

- Designs for an Expressive Mechatronic Chordophone

    Author: Yepez Placencia, Juan Pablo | Victoria University of Wellington
    Author: Carnegie, Dale Anthony | Victoria University of Wellington
    Author: Murphy, James Wassell | Victoria University of Wellington
 
    keyword: Product Design, Development and Prototyping; Mechanism Design; Entertainment Robotics

    Abstract : Plucked strings are an exciting sound generation model for technical and timbral exploration. Mechatronic chordophones take advantage of this model and have been the focus of extensive research and exploration in musical robotics, often used as stand-alone instruments or as part of sound art installations. However, no existing chordophone designs have utilised the expressive potential of plucked strings to their full extent.<p>In this paper, we introduce an expressive mechatronic monochord that serves as a prototyping platform for the construction of a polystring chordophone. This new chordophone has been developed to offer enhanced dynamic range, fast picking speeds, fast pitch shifter displacement, and additional expressive techniques compared to existing systems.

- Multi Directional Piezoelectric Plate Energy Harvesters Designed by Topology Optimization Algorithm

    Author: Homayouni-Amlashi, Abbas | FEMTO-ST Institute, Université Bourgogne Franche
    Author: Mohand Ousaid, Abdenbi | University of Franche-Comte
    Author: Rakotondrabe, Micky | Laboratoire G�nie De Production (LGP)
 
    keyword: Product Design, Development and Prototyping; Energy and Environment-Aware Automation; Optimization and Optimal Control

    Abstract : In this paper, piezoelectric plate energy harvesters are designed by using topology optimization algorithm to harvest the excitation from different directions. The goal is to minimize the volume and weight of the whole structure so the harvesters can be used in small scale applications. To this aim, the profile of polarization is optimized by the topology optimization to overcome charge cancellation which is the main challenge in random direction excitation. Two optimized designs with uniform and non-uniform polarization profiles are obtained. Separated electrodes in the surfaces of the optimized design with non-uniform polarization are used to simulate the polarization profile. Numerical simulations by COMSOL multi-physics software show that the optimized design with separated electrodes can provide 3 times higher voltage and power than those obtained with non-optimized piezoelectric plate. Experimental investigation demonstrated that the same design with separated electrodes can have 2.17 and 1.93 times higher voltage than the full plate for out of plane and in-plane forces respectively.

- OmBURo: A Novel Unicycle Robot with Active Omnidirectional Wheel

    Author: Shen, Junjie | UCLA
    Author: Hong, Dennis | UCLA
 
    keyword: Wheeled Robots; Underactuated Robots; Mechanism Design

    Abstract : A mobility mechanism for robots to be used in tight spaces shared with people requires it to have a small footprint, to move omnidirectionally, as well as to be highly maneuverable. However, currently there exist few such mobility mechanisms that satisfy all these conditions well. Here we introduce Omnidirectional Balancing Unicycle Robot (OmBURo), a novel unicycle robot with active omnidirectional wheel. The effect is that the unicycle robot can drive in both longitudinal and lateral directions simultaneously. Thus, it can dynamically balance itself based on the principle of dual-axis wheeled inverted pendulum. This paper discloses the early development of this novel unicycle robot involving the overall design, modeling, and control, as well as presents some preliminary results including station keeping and path following. With its very compact structure and agile mobility, it might be the ideal locomotion mechanism for robots to be used in human environments in the future.

## Cellular and Modular Robots
- Self-Reconfiguration in Response to Faults in Modular Aerial Systems

    Author: Gandhi, Neeraj | University of Pennsylvania
    Author: Salda�a, David | Lehigh University
    Author: Kumar, Vijay | University of Pennsylvania
    Author: Phan, Linh Thi Xuan | University of Pennsylvania
 
    keyword: Cellular and Modular Robots; Aerial Systems: Applications; Failure Detection and Recovery

    Abstract : We present a self-reconfiguration technique bywhich a modular flying platform can mitigate the impact of rotor failures. In this technique, the system adapts its configuration in response to rotor failures to be able to continue its mission while efficiently utilizing resources. A mixed integer linear program determines an optimal module-to-position allocation in the structure based on rotor faults and desired trajectories. We further propose an efficient dynamic programming algorithm that minimizes the number of disassembly and reassembly steps needed for reconfiguration. Evaluation results show that our technique can substantially increase the robustness of the system while utilizing resources efficiently, and that it can scale well with the number of modules.

- Recognition and Reconfiguration of Lattice-Based Cellular Structures by Simple Robots

    Author: Niehs, Eike | Technische Universitét Braunschweig
    Author: Schmidt, Arne | TU Braunschweig
    Author: Scheffer, Christian | Technische Universitét Braunschweig
    Author: Biediger, Dan | University of Houston
    Author: Yanuzzi, Mike | University of Houston
    Author: Jenett, Benjamin | Massachusetts Institute of Technology
    Author: Abdel-Rahman, Amira | MIT
    Author: Cheung, Kenneth C. | National Aeronautics and Space Administration (NASA)
    Author: Becker, Aaron | University of Houston
    Author: Fekete, S�ndor | Technische Universitét Braunschweig
 
    keyword: Cellular and Modular Robots; Distributed Robot Systems; Swarms

    Abstract : We consider recognition and reconfiguration of lattice-based cellular structures by very simple robots with only basic functionality. The underlying motivation is the construction and modification of space facilities of enormous dimensions, where the combination of new materials with extremely simple robots promises structures of previously unthinkable size and flexibility; this is also closely related to the newly emerging field of programmable matter. Aiming for large-scale scalability, both in terms of the number of the cellular components of a structure, as well as the number of robots that are being deployed for construction requires simple yet robust robots and mechanisms, while also dealing with various basic constraints, such as connectivity of a structure during reconfiguration. To this end, we propose an approach that combines ultra-light, cellular building materials with extremely simple robots. We develop basic algorithmic methods that are able to detect and reconfigure arbitrary cellular structures, based on robots that have only constant-sized memory. As a proof of concept, we demonstrate the feasibility of this approach for specific cellular materials and robots that have been developed at NASA.

- A Fast Configuration Space Algorithm for Variable Topology Truss Modular Robots

    Author: Liu, Chao | University of Pennsylvania
    Author: Yu, Sencheng | University of Pennsylvania
    Author: Yim, Mark | University of Pennsylvania
 
    keyword: Cellular and Modular Robots; Motion and Path Planning; Collision Avoidance

    Abstract : The Variable Topology Truss (VTT) is a new class of self-reconfigurable robot that can reconfigure its truss shape and topology depending on the task or environment requirements. Motion planning and avoiding self-collision are difficult as these systems usually have dozens of degrees-of-freedom with complex intersecting parallel actuation. There are two different types of shape changing actions for a VTT: geometry reconfiguration and topology reconfiguration. This paper focuses on the geometry reconfiguration actions. A new cell decomposition approach is presented based on a fast and complete method to compute the collision-free space of a node in a truss. A simple shape-morphing method is shown to quickly create motion paths for reconfiguration by moving one node at a time.

- ModQuad-DoF: A Novel Yaw Actuation for Modular Quadrotors

    Author: Teles Gabrich, Bruno | University of Pennsylvania
    Author: Li, Guanrui | New York University
    Author: Yim, Mark | University of Pennsylvania
 
    keyword: Cellular and Modular Robots; Aerial Systems: Mechanics and Control; Multi-Robot Systems

    Abstract : In this work we introduce ModQuad-DoF, a modular flying robotic structure with enhanced capabilities for yaw actuation. We propose a new module design that allows a one degree of freedom relative motion between the flying robot and the cage, with a docking mechanism allowing rigid connections between cages. A novel method of yaw actuation that increases the structure control     Authority is also presented. Our new method for the structure yaw control relies on the independent roll angles of each one of the modules, instead of the traditional drag moments from the propellers. In this paper, we propose a controller that allows the ModQuad-DoF to control its position and attitude. In our experiments, we tested a different number of modules flying in cooperation and validated the novel yaw actuation method.

- An Actuation Fault Tolerance Approach to Reconfiguration Planning of Modular Self-Folding Robots

    Author: Yao, Meibao | Jilin University
    Author: Xiao, Xueming | Changchun University of Science and Technology
    Author: Tian, Yang | School of Transportation Science and Engineering, Harbin Institu
    Author: Cui, Hutao | Harbin Institute of Technology
    Author: Paik, Jamie | Ecole Polytechnique Federale De Lausanne
 
    keyword: Cellular and Modular Robots; Failure Detection and Recovery; Redundant Robots

    Abstract : This paper presents a novel approach to fault tolerant reconfiguration of modular self-folding robots. Among various types of faults that probably occur in the modular system, we focus on the tolerance of complete actuation failure of active modules that might cause imprecise robotic motion and even reconfiguration failure. Our approach is to utilize the reconfigurability of modular self-folding robots and investigate intra-module connection to determine initial patterns that are inherently fault tolerant. We exploit the redundancy of actuation and distribute active modules in both layout-based and target-based scenarios, such that reconfiguration schemes with user-specified fault tolerant capability can be generated for an arbitrary input initial pattern or 3D configuration. Our methods are demonstrated in computer-aided simulation on the robotic platform of Mori, a modular origami robot. The simulation results validate that the proposed algorithms yield fault tolerant initial patterns and distribution schemes of active modules for several 2D and 3D configurations with Mori, while retaining generalizability for a large number of modular self-folding robots.

- Parallel Permutation for Linear Full-Resolution Reconfiguration of Heterogeneous Sliding-Only Cubic Modular Robots

    Author: Kawano, Hiroshi | NTT Corporation
 
    keyword: Cellular and Modular Robots

    Abstract : This paper presents a parallel permutation algorithm that achieves linear full-resolution reconfiguration of sliding-only cubic modular robots. We assume the use of a cubic module that can only slide across other modules' surfaces. The idea of a cubic modular robot with sliding-only motion primitive is a new concept that has advantages in simplifying the mechanisms of module hardware and space saving in its heterogeneous operations compared wtih previously studied cubic modules, such as those with sliding and convex motion primitives, or rotating motion primitives. However, because of its limited mobility, there are difficulties in managing the connectivity and scalability of the heterogeneous reconfiguration algorithm for it. To overcome these disadvantages, we introduce a parallel heterogeneous permutation method with linear operating time cost that can be incorporated into our previous full-resolution reconfiguration algorithm. We prove the correctness and completeness of the proposed algorithm. Simulation results show that the full-resolution reconfiguration algorithm that incorporates the proposed permutation algorithm reconfigures the robot structure with sliding-only cubic modules in linear operating-time cost.

## Performance Evaluation and Benchmarking
- Determining and Improving the Localization Accuracy of AprilTag Detection

    Author: Kallwies, Jan | Bundeswehr University Munich
    Author: Forkel, Bianca | Bundeswehr University Munich
    Author: Wuensche, Hans Joachim Joe | Bundeswehr University Munich
 
    keyword: Performance Evaluation and Benchmarking; Calibration and Identification; Computer Vision for Other Robotic Applications

    Abstract : Fiducial markers like AprilTags play an important role in robotics, e.g., for the calibration of cameras or the localization of robots. One of the most important properties of an algorithm for detecting such tags is its localization accuracy.<p>In this paper, we present the results of an extensive comparison of four freely available libraries capable of detecting AprilTags, namely AprilTag 3, AprilTags C++, ArUco as stand- alone libraries, and the OpenCV algorithm based on ArUco. The focus of the comparison is on localization accuracy, but the processing time is also examined. Besides working with pure tags, their extension to checkerboard corners is investigated.</p><p>In addition, we present two new post-processing techniques. Firstly, a method that can filter out very inaccurate detections resulting from partial occlusion, and secondly a new highly accurate method for edge refinement. With this we achieve a median pixel error of 0.017 px, compared to 0.17 px for standard OpenCV corner refinement.</p><p>The dataset used for the evaluation, as well as the developed post-processing techniques, are made publicly available to en- courage further comparison and improvement of the detection libraries.

- Change of Optimal Values: A Pre-Calculated Metric

    Author: Bai, Fang | University of Technology, Sydney
 
    keyword: Performance Evaluation and Benchmarking; Optimization and Optimal Control; SLAM

    Abstract : A variety of optimization problems takes the form of a minimum norm optimization. In this paper, we study the change of optimal values between two incrementally constructed least norm optimization problems, with new measurements included in the second one. We prove an exact equation to calculate the change of optimal values in the linear least norm optimization problem. With the result in this paper, the change of the optimal values can be pre-calculated as a metric to guide online decision makings, without solving the second optimization problem as long the solution and covariance of the first optimization problem are available. The result can be extended to linear least distance optimization problems, and nonlinear least distance optimization with (nonlinear) equality constraints through linearizations. This derivation in this paper provides a theoretically sound explanation to the empirical observations shown in cite{bai2018robust}. As an additional contribution, we propose another optimization problem, i.e. aligning two trajectories at given poses, to further demonstrate how to use the metric. The accuracy of the metric is validated with numerical examples, which is quite satisfactory in general (see the experiments in cite{bai2018robust} as well), unless in some extremely adverse scenarios. Last but not least, calculating the optimal value by the proposed metric is at least one magnitude faster than solving the corresponding optimization problems directly.

- A Flexible Method for Performance Evaluation of Robot Localization

    Author: Scheideman, Sean | University of Alberta
    Author: Ray, Nilanjan | University of Alberta
    Author: Zhang, Hong | University of Alberta
 
    keyword: Performance Evaluation and Benchmarking; Localization; SLAM

    Abstract : An important research issue in mobile robotics is performance assessment of robot SLAM algorithms in terms of their localization accuracy. Typically, SLAM algorithms are evaluated with the help of benchmark datasets or expensive equipment such as motion capture. Benchmark datasets however, are environment-specific, and use of motion capture constrains spatial coverage and affordability. In this paper, we present a novel method for SLAM performance evaluation, which only uses distinctive markers (such as AR tags), randomly placed in the robot navigation environment at arbitrary locations, and observes these markers with a camera onboard of the robot. Formulated as a generative latent optimization (GLO) problem, our method uses the local robot-to-marker poses to evaluate the global robot pose estimates by a SLAM algorithm and therefore its performance. Through extensive experiments on two robots, three localization/SLAM algorithms and both LiDAR and RGB-D sensors, we demonstrate the feasibility and accuracy of our proposed method.

- Quantifying Good Seamanship for Autonomous Surface Vessel Performance Evaluation

    Author: Stankiewicz, Paul | Johns Hopkins University Applied Physics Laboratory
    Author: Heistand, Michael | Johns Hopkins University Applied Physics Laboratory
    Author: Kobilarov, Marin | Johns Hopkins University
 
    keyword: Performance Evaluation and Benchmarking; Marine Robotics

    Abstract : The current state-of-the-art for testing and evaluation of autonomous surface vehicle (ASV) decision-making is currently limited to one-versus-one vessel interactions by determining compliance with the International Regulations for Prevention of Collisions at Sea, referred to as COLREGS. Strict measurement of COLREGS compliance, however, loses value in multi-vessel encounters, as there can be conflicting rules which make determining compliance extremely subjective. This work proposes several performance metrics to evaluate ASV decision-making based on the concept of "good seamanship," a practice which generalizes to multi-vessel encounters. Methodology for quantifying good seamanship is presented based on the criteria of reducing the overall collision risk of the situation and taking early, appropriate actions. Case study simulation results are presented to showcase the seamanship performance criteria against different ASV planning strategies.

- Action-Conditioned Benchmarking of Robotic Video Prediction Models: A Comparative Study

    Author: Serra Nunes, Manuel | Institute for Systems and Robotics
    Author: Dehban, Atabak | Ist-Id 509 830 072
    Author: Moreno, Plinio | IST-ID
    Author: Santos-Victor, Jos' | Instituto Superior Técnico - Lisbon
 
    keyword: Performance Evaluation and Benchmarking; Visual Learning

    Abstract : A defining characteristic of intelligent systems is the ability to make action decisions based on the anticipated outcomes. Video prediction systems have been demonstrated as a solution for predicting how the future will unfold visually, and thus, many models have been proposed that are capable of predicting future frames based on a history of observed frames~(and sometimes robot actions). However, a comprehensive method for determining the fitness of different video prediction models at guiding the selection of actions is yet to be developed. <p>Current metrics assess video prediction models based on human perception of frame quality. In contrast, we argue that if these systems are to be used to guide action, necessarily, the actions the robot performs should be encoded in the predicted frames. In this paper, we are proposing a new metric to compare different video prediction models based on this argument. More specifically, we propose an action inference system and quantitatively rank different models based on how well we can infer the robot actions from the predicted frames. Our extensive experiments show that models with high perceptual scores can perform poorly in the proposed action inference tests and thus, may not be suitable options to be used in robot planning systems.

- Performance Indicators for Wheeled Robots Traversing Obstacles
 
    Author: Nowac, William | McGill University
    Author: Gonzalez, Francisco | University of a Coruna
    Author: MacMahon, Sadhbh | MDA Corporation
    Author: Kovecses, Jozsef | McGill University
 
    keyword: Wheeled Robots; Dynamics; Space Robotics and Automation

    Abstract : An important element of wheeled robot operations on uneven and unstructured terrain is the ability to overcome obstacles. In this paper we deal with a part of this obstacle negotiation problem. We particularly investigate the ability of a wheeled robot, originating from its mechanical design, to successfully negotiate an obstacle. The work reported primarily investigates how the mechanism topologies and the resulting mass and inertia distributions influence obstacle negotiation. The kinematics of the obstacle and ground contact is described using the variables that represent the degrees of freedom of the articulated mechanical system of the robot; this enables the study of the effect of the robot topology on the contact dynamics. Based on this we develop a dynamics formulation that allows us to propose performance indicators to characterize the ability of the wheeled robot to overcome obstacles. This formulation accounts for the unilateral nature	 of interaction between robot, obstacle and ground. We illustrate the work with simulation and experimental results.






## Aerial Systems: Applications

- A Morphable Aerial-Aquatic Quadrotor with Coupled Symmetric Thrust Vectoring

    Author: Tan, Yu Herng | National University of Singapore
    Author: Chen, Ben M. | Chinese University of Hong Kong
 
    keyword: Aerial Systems: Applications; Mechanism Design; Product Design, Development and Prototyping

    Abstract : Hybrid aerial-aquatic vehicles have the unique ability of travelling in both air and water and can benefit from both lower fluid resistance in air and energy efficient position holding in water. However, they have to address the differing requirements which make optimising a single design difficult. While existing examples have shown the possibility of such vehicles, they are mostly structurally identical to normal aerial vehicles with minor adjustments to work underwater. Instead of using rotational acceleration to direct a component of thrust in surge and sway, we propose a quadrotor based vehicle that tilts its rotors about the respective arm so that a larger component of thrust can be directed in the lateral plane and opposite direction without rotating the vehicle body. A small scale prototype of this design is presented here, detailing the design considerations including mechanical actuation, static stability and waterproofing.

- An Autonomous Intercept Drone with Image-Based Visual Servo

    Author: Yang, Kun | School of Automation Science and Electrical Engineering, Beihang
    Author: Quan, Quan | Beihang University
 
    keyword: Aerial Systems: Applications; Visual Servoing

    Abstract : For most people on the ground, facing an unwanted drone buzzing around overhead, there is not a lot that we can do, especially if it is out of gun (radio wave gun or shotgun) range. A solution to this is to use intercept drones that seek out and bring down other drones. In order to make the interception autonomous, an image-based visual servo algorithm is designed with a forward-looking monocular camera. The control command, namely the angular velocity and thrust, is generated for intercept drones to implement accurate and fast interception. The proposed method is demonstrated in both hardware-in-the-loop simulation and demonstrative flight experiments.

- Real-Time Optimal Trajectory Generation and Control of a Multi-Rotor with a Suspended Load for Obstacle Avoidance

    Author: Son, Clark Youngdong | Seoul National University
    Author: Seo, Hoseong | Seoul National University
    Author: Jang, Dohyun | Seoul National University
    Author: Kim, H. Jin | Seoul National University
 
    keyword: Aerial Systems: Applications; Motion and Path Planning; Optimization and Optimal Control

    Abstract : This paper presents real-time optimization algorithms on trajectory generation and control for a multi-rotor with a suspended load. Since the load is suspended through a cable without any actuator, movement of the load must be controlled via maneuvers of the multi-rotor, which brings about difficulties in operating this system. Additionally, the highly nonlinear dynamics of the system exacerbates the difficulties. While trajectory generation and control are essential for safety, energy efficiency, and stability, the aforementioned characteristics of the system add challenges. With this in mind, the     Authors propose real-time path planning and optimal control algorithms for collision-free trajectory generation and trajectory tracking. For the dynamics, simplified dynamic models of the system are proposed by considering time delay in attitude control of the multi-rotor. For collision avoidance, the vehicle, cable, and load are considered as ellipsoids with different sizes and shapes, and collision-free constraints are expressed in an efficient and nonconservative way. The augmented Lagrangian method is applied to solve the nonlinear optimization problem with the nonlinear constraints in real-time. For control of the system, model predictive control with a sequential linear quadratic solver is used. Several simulations and experiments are conducted to validate the proposed algorithm.

- Wildfire Fighting by Unmanned Aerial System Exploiting Its Time-Varying Mass

    Author: Saikin, Diego | Czech Technical University in Prague
    Author: Baca, Tomas | Czech Technical Univerzity in Prague
    Author: Gurtner, Martin | Czech Technical University in Prague, Faculty of Electrical Engi
    Author: Saska, Martin | Czech Technical University in Prague
 
    keyword: Aerial Systems: Applications; Motion and Path Planning; Optimization and Optimal Control

    Abstract : This paper presents an approach for accurately dropping a relatively large amount of fire retardant, water or some other extinguishing agent onto a wildfire from an autonomous unmanned aerial vehicle (UAV), in close proximity to the epicenter of the fire. The proposed approach involves a risky maneuver outside of the safe flight envelope of the UAV. This maneuver exploits the expected weight reduction resulting from the release of the payload, enabling the UAV to recover without impacting the terrain. The UAV is tilted to high pitch angles, at which the thrust may be pointed almost horizontally. The vehicle can therefore achieve higher horizontal speeds than would be allowed by conventional motion planners. This high speed allows the UAV to significantly reduce the time spent close to the fire. As a result, the overall high heat exposure is reduced, and the payload can be dropped closer to the target, minimizing its dispersion. A constrained optimal control problem (OCP) is solved taking into account environmental parameters such as wind and terrain gradients, as well as various payload releasing mechanisms. The proposed approach was verified in simulations and in real experiments. Emphasis was put on the real time recalculation of the solution, which will enable future adaptation into a model predictive controller (MPC) scheme.

- On the Human Control of a Multiple Quadcopters with a Cable-Suspended Payload System

    Author: Prajapati, Pratik | Indian Institute of Technology Gandhinagar
    Author: Parekh, Sagar | Indian Institute of Technology, Gandhinagar
    Author: Vashista, Vineet | Indian Institute of Technology Gandhinagar
 
    keyword: Aerial Systems: Applications; Cooperating Robots; Human Factors and Human-in-the-Loop

    Abstract : A quadcopter is an under-actuated system with only four control inputs for six degrees of freedom, and yet the human control of a quadcopter is simple enough to be learned with some practice. In this work, we consider the problem of human control of a multiple quadcopters system to transport a cable-suspended payload. The coupled dynamics of the system, due to the inherent physical constraints, is used to develop a leader-follower architecture where the leader quadcopter is controlled directly by a human operator and the followers are controlled with the proposed Payload Attitude Controller and Cable Attitude Controller. Experiments, where a human operator flew a two quadcopters system to transport a cable-suspended payload, were conducted to study the performance of proposed controller. The results demonstrated successful implementation of human control in these systems. This work presents the possibility of enabling manual control for on-the-go maneuvering of the quadcopter-payload system which motivates aerial transportation in the unknown environments.

- Dronument: System for Reliable Deployment of Micro Aerial Vehicles in Dark Areas of Large Historical Monuments

    Author: Petráček, Pavel | Czech Technical University in Prague
    Author: Krátký, Vít | Czech Technical University in Prague
    Author: Saska, Martin | Czech Technical University in Prague
 
    keyword: Aerial Systems: Applications; Aerial Systems: Perception and Autonomy; Localization

    Abstract : This letter presents a self-contained system for robust deployment of autonomous aerial vehicles in environments without access to global navigation systems and with limited lighting conditions. The proposed system, application-tailored for documentation in dark areas of large historical monuments, uses a unique and reliable aerial platform with a multi-modal lightweight sensory setup to acquire data in human-restricted areas with adverse lighting conditions, especially in areas that are high above the ground. The introduced localization method relies on an easy-to-obtain 3-D point cloud of a historical building, while it copes with a lack of visible light by fusing active laser-based sensors. The approach does not rely on any external localization, or on a preset motion-capture system. This enables fast deployment in the interiors of investigated structures while being computationally undemanding enough to process data online, onboard an MAV equipped with ordinary processing resources. The reliability of the system is analyzed, is quantitatively evaluated on a set of aerial trajectories performed inside a real-world church, and is deployed onto the aerial platform in the position control feedback loop to demonstrate the reliability of the system in the safety-critical application of historical monuments documentation.

- Robust Real-Time UAV Replanning Using Guided Gradient-Based Optimization and Topological Paths

    Author: Zhou, Boyu | Hong Kong University of Science and Technology
    Author: Gao, Fei | Zhejiang University
    Author: Pan, Jie | Hong Kong University of Science and Technology
    Author: Shen, Shaojie | Hong Kong University of Science and Technology
 
    keyword: Aerial Systems: Applications; Motion and Path Planning; Collision Avoidance

    Abstract : Gradient-based trajectory optimization (GTO) has gained wide popularity for quadrotor trajectory replanning. However, it suffers from local minima, which is not only fatal to safety but also unfavorable for smooth navigation. In this paper, we propose a replanning method based on GTO addressing this issue systematically. A path-guided optimization (PGO) approach is devised to tackle infeasible local minima, which improves the replanning success rate significantly. A topological path searching algorithm is developed to capture a collection of distinct useful paths in 3-D environments, each of which then guides an independent trajectory optimization. It activates a more comprehensive exploration of the solution space and output superior replanned trajectories. Benchmark evaluation shows that our method outplays state-of-the-art methods regarding replanning success rate and optimality.Challenging experiments of aggressive autonomous flight are presented to demonstrate the robustness of our method. We will release our implementation as an open-source package.

- Learning-Based Path Planning for Autonomous Exploration of Subterranean Environments

    Author: Reinhart, Russell | University of Nevada Reno
    Author: Dang, Tung | University of Nevada, Reno
    Author: Hand, Emily | University of Nevada, Reno
    Author: Papachristos, Christos | University of Nevada Reno
    Author: Alexis, Kostas | University of Nevada, Reno
 
    keyword: Aerial Systems: Applications; Aerial Systems: Perception and Autonomy; Field Robots

    Abstract : In this work we present a new methodology on learning-based path planning for autonomous exploration of subterranean environments using aerial robots. Utilizing a recently proposed graph-based path planner as a "training expert" and following an approach relying on the concepts of imitation learning, we derive a trained policy capable of guiding the robot to autonomously explore underground mine drifts and tunnels. The algorithm utilizes only a short window of range data sampled from the onboard LiDAR and achieves an exploratory behavior similar to that of the training expert with a more than an order of magnitude reduction in computational cost, while simultaneously relaxing the need to maintain a consistent and online reconstructed map of the environment. The trained path planning policy is extensively evaluated both in simulation and experimentally within field tests relating to the autonomous exploration of underground mines.

- Visual-Inertial Telepresence for Aerial Manipulation

    Author: Lee, Jongseok | German Aerospace Center
    Author: Balachandran, Ribin | DLR
    Author: Sarkisov, Yuri | Skolkovo Institute of Science and Technology
    Author: De Stefano, Marco | German Aerospace Center (DLR)
    Author: Coelho, Andre | German Aerospace Center (DLR)
    Author: Shinde, Kashmira | German Aerospace Center (DLR)
    Author: Kim, Min Jun | DLR
    Author: Triebel, Rudolph | German Aerospace Center (DLR)
    Author: Kondak, Konstantin | German Aerospace Center
 
    keyword: Aerial Systems: Applications; Telerobotics and Teleoperation; Field Robots

    Abstract : This paper presents a novel vision-based telepresence system for enhancing aerial manipulation capabilities. It involves not only a haptic device, but also a virtual reality technology that provides a 3D visual feedback to a remotely-located teleoperator in real-time. We achieve this by utilizing onboard sensors, an object tracking algorithm and a pre-generated object database. As the virtual reality has to closely match the real remote scene, we propose an extension of a marker tracking algorithm with on-board Visual Inertial Odometry. Both of our indoor and outdoor experiments show benefits of our proposed system in achieving advanced aerial manipulation tasks, namely grasping, placing, pressing and peg-in-hole insertion.

- Distributed Rotor-Based Vibration Suppression for Flexible Object Transport and Manipulation

    Author: Yang, Hyunsoo | Seoul National University
    Author: Kim, Min Seong | Seoul National University
    Author: Lee, Dongjun | Seoul National University
 
    keyword: Aerial Systems: Applications; Flexible Robots; Multi-Robot Systems

    Abstract :  The RVM (Robot-based Vibration Suppression Modules) is proposed for the manipulation and transport of a large flexible object. Since the RVM is easily attachable/detachable to the object, this RVM allows distributing over the manipulated object so that it is scalable to the object size. The composition of the system is partly motivated by the MAGMaS (Multiple Aerial-Ground Manipulator System) [1]-[3], however, since the quadrotor usage is mechanically too complicated and its design is not optimized for manipulation, thus we overcome these limitations using distributed RVMs and newly developed theory. For this, we first provide a constrained optimization problem of RVM design with the minimum number of rotors, so that the feasible thrust force is maximized while it minimizes undesirable wrench and its own weight. Then, we derive the full dynamics and elucidate a controllability condition with multiple distributed RVMs and show that even if multiple, their structures turn out similar to [2] composed with a single quadrotor. We also elucidate the optimal placement of the RVM via the usage of controllability gramian which is not even alluded in [2] and established for the first time here. Experiments are performed to demonstrate the effectiveness of the proposed theory.

- Aerial Manipulation Using Model Predictive Control for Opening a Hinged Door

    Author: Lee, Dongjae | Seoul National University
    Author: Seo, Hoseong | Seoul National University
    Author: Kim, Dabin | Seoul National University
    Author: Kim, H. Jin | Seoul National University
 
    keyword: Aerial Systems: Applications; Optimization and Optimal Control; Motion and Path Planning

    Abstract : Existing studies for environment interaction with an aerial robot have been focused on interaction with static surroundings. However, to fully explore the concept of aerial manipulation, interaction with moving structures should also be considered. In this paper, a multirotor-based aerial manipulator opening a daily-life moving structure, a hinged door, is presented. In order to address the constrained motion of the structure and to avoid collisions during operation, model predictive control (MPC) is applied to the derived coupled system dynamics between the aerial manipulator and the door involving state constraints. By implementing a constrained version of differential dynamic programming (DDP), MPC can generate position setpoints to the disturbance observer (DOB)-based robust controller in real-time, which is validated by our experimental results.

- Integrated Motion Planner for Real-Time Aerial Videography with a Drone in a Dense Environment

    Author: Jeon, Boseong | Seoul National University
    Author: Lee, Yunwoo | Seoul National University
    Author: Kim, H. Jin | Seoul National University
 
    keyword: Reactive and Sensor-Based Planning; Visual Servoing

    Abstract : This work suggests an integrated approach for a drone (or multirotor) to perform an autonomous videography task in a 3-D obstacle environment by following a moving object. The proposed system includes 1) a target motion prediction module which can be applied to dense environments and 2) a hierarchical chasing planner. Leveraging covariant optimization, the prediction module estimates the future motion of the target assuming it efforts to avoid the obstacles. The other module, chasing planner, is in a bi-level structure composed of preplanner and smooth planner. In the first phase, we exploit a graph-search method to preplan a chasing corridor which incorporates safety and visibility of target. In the subsequent phase, we generate a smooth and dynamically feasible path within the corridor using quadratic programming (QP). We validate our approach with multiple complex scenarios and actual experiments.

- Stable Control in Climbing and Descending Flight under Upper Walls Using Ceiling Effect Model Based on Aerodynamics

    Author: Nishio, Takuzumi | The University of Tokyo
    Author: Zhao, Moju | The University of Tokyo
    Author: Shi, Fan | The University of Tokyo
    Author: Anzai, Tomoki | The University of Tokyo
    Author: Kawaharazuka, Kento | The University of Tokyo
    Author: Okada, Kei | The University of Tokyo
    Author: Inaba, Masayuki | The University of Tokyo
 
    keyword: Aerial Systems: Applications; Aerial Systems: Mechanics and Control; Dynamics

    Abstract : Stable flight control under ceilings is difficult for multi-rotor Unmanned Aerial Vehicles (UAVs). The wake interaction between rotors and the upper walls, called the "ceiling effect", causes an increase of rotor thrust. By the thrust increase, multi-rotors are drawn upward abruptly and collide with ceilings. In previous work, several thrust models in the ceiling effect have been proposed for stable flight under ceilings, assuming that the airflow around the rotor is in steady states. However, the airflow around rotors in vertical flight is not in steady states and each model is skillfully determined based on large amounts of experimental data. In this paper, we introduce an aerodynamics based thrust model and a stable control method under ceilings. The model is derived from the momentum theory and relationship between a vertical climbing/descending rate of a rotor and an induced velocity. To confirm the proposed model, we collect thrust data at various vertical rates in flight. Here, we use only onboard sensors to estimate self-state, for structural inspections. Consequently, we demonstrate that the proposed model is in agreement with the experimental results. Based on aerodynamics, we need not collect huge precise experimental data to construct the model. Furthermore, the vertical flight under ceilings demonstrate that the proposed unsteady-state model based controller outperforms the conventional steady-state ones.

- Motion Primitives-Based Path Planning for Fast and Agile Exploration Using Aerial Robots

    Author: Dharmadhikari, Mihir Rahul | Birla Institute of Technology and Science (BITS) - Pilani
    Author: Dang, Tung | University of Nevada, Reno
    Author: Solanka, Lukas | Flyability SA
    Author: Loje, Johannes Brakker | Flyability SA
    Author: Nguyen, Dinh Huan | University of Nevada, Reno
    Author: Khedekar, Nikhil Vijay | University of Nevada, Reno
    Author: Alexis, Kostas | University of Nevada, Reno
 
    keyword: Aerial Systems: Applications; Field Robots; Motion and Path Planning

    Abstract : This paper presents a novel path planning strategy for fast and agile exploration using aerial robots. Tailored to the combined need for large-scale exploration of challenging and confined environments, despite the limited endurance of micro aerial vehicles, the proposed planning employs motion primitives to identify admissible paths that search the configuration space, while exploiting the dynamic flight properties of small aerial robots. Utilizing a computationally efficient volumetric representation of the environment, the planner provides fast collision-free and future-safe paths that maximize the expected exploration gain and ensure continuous fast navigation through the unknown environment. The new method is field-verified in a set of deployments relating to subterranean exploration and specifically, in both modern and abandoned underground mines in Northern Nevada utilizing a 0.55m-wide collision-tolerant flying robot exploring with a speed of up to 2m/s and navigating sections with width as small as 0.8m.

- Unsupervised Anomaly Detection for Self-Flying Delivery Drones
 
    Author: Sindhwani, Vikas | Google Brain, NYC
    Author: Sidahmed, Hakim | Google
    Author: Choromanski, Krzysztof | Google Brain Robotics
    Author: Jones, Brandon | Alphabet
 
    keyword: Aerial Systems: Applications; Robot Safety; Model Learning for Control

    Abstract : We propose a novel anomaly detection framework for a fleet of hybrid aerial vehicles executing high-speed package pickup and delivery missions. The detection is based on machine learning models of normal flight profiles, trained on millions of flight log measurements of control inputs and sensor readings. We develop a new scalable algorithm for robust regression which can simultaneously fit predictive flight dynamics models while identifying and discarding abnormal flight missions from the training set. The resulting unsupervised estimator has a very high breakdown point and can withstand massive contamination of training data to uncover what normal flight patterns look like, without requiring any form of prior knowledge of aircraft aerodynamics or manual labeling of anomalies upfront. Across many different anomaly types, spanning simple 3-sigma statistical thresholds to turbulence and other equipment anomalies, our models achieve high detection rates across the board. Our method consistently outperforms alternative robust detection methods on benchmark problems. To the best of	our knowledge, dynamics modeling of hybrid delivery drones for anomaly detection at the scale of 100 million measurements from 5000 real flight missions in variable flight conditions is unprecedented.

- Keyfilter-Aware Real-Time UAV Object Tracking

    Author: Li, Yiming | Tongji University
    Author: Fu, Changhong | Tongji University
    Author: Huang, Ziyuan | National Universitu of Singapore
    Author: Zhang, Yinqiang | Technical University of Munich
    Author: Pan, Jia | University of Hong Kong
 
    keyword: Aerial Systems: Applications; Visual Tracking; Computer Vision for Other Robotic Applications

    Abstract : Correlation filter-based tracking has been widely applied in unmanned aerial vehicle (UAV) with high efficiency. However, it has two imperfections, i.e., boundary effect and filter corruption. Several methods enlarging the search area can mitigate boundary effect, yet introducing undesired background distraction. Existing frame-by-frame context learning strategies for repressing background distraction nevertheless lower the tracking speed. Inspired by keyframe-based simultaneous localization and mapping, keyfilter is proposed in visual tracking for the first time, in order to handle the above issues efficiently and effectively. Keyfilters generated by periodically selected keyframes learn the context intermittently and are used to restrain the learning of filters, so that 1) context awareness can be transmitted to all the filters via keyfilter restriction, and 2) filter corruption can be repressed. Compared to the state-of-the-art results, our tracker performs better on two challenging benchmarks, with enough speed for UAV real-time applications.

- Aerial Regrasping: Pivoting with Transformable Multilink Aerial Robot

    Author: Shi, Fan | The University of Tokyo
    Author: Zhao, Moju | The University of Tokyo
    Author: Murooka, Masaki | The University of Tokyo
    Author: Okada, Kei | The University of Tokyo
    Author: Inaba, Masayuki | The University of Tokyo
 
    keyword: Aerial Systems: Applications; Dexterous Manipulation; Underactuated Robots

    Abstract : Regrasping is one of the most common and important manipulation skills used in our daily life. However, aerial regrasping has not been seriously investigated yet, since most of the aerial manipulator lacks dexterous manipulation abilities except for the basic pick-and-place. In this paper, we focus on pivoting a long box, which is one of the most classical problems among regrasping researches, using a transformable multilink aerial robot. First, we improve our previous controller by compensating for the external wrench. Second, we optimize the joints configuration of our transformable multilink drone for stable grasping form under the constraints of thrust force and joints effort. Third, we sequentially optimize the grasping force in the pivoting process. The optimization goal is to generate continous grasping force whilst maximizing the friction force in case of the downwash, which would influence the grasped object and is difficult to model. Fourth, we develop the impedance controller in joint space and admittance controller in task space. As far as we know, it is the first research to achieve extrinsic contact-aware regrasping task on aerial robots.

- Grounding Language to Landmarks in Arbitrary Outdoor Environments

    Author: Berg, Matthew | Brown University
    Author: Bayazit, Deniz | Brown University
    Author: Mathew, Rebecca | Brown University
    Author: Rotter-Aboyoun, Ariel | Brown University
    Author: Pavlick, Ellie | Brown University
    Author: Tellex, Stefanie | Brown
 
    keyword: Aerial Systems: Applications; Task Planning

    Abstract : Robots operating in outdoor, urban environments need the ability to follow complex natural language commands which refer to never-before-seen landmarks. Existing approaches to this problem are limited because they require training a language model for the landmarks of a particular environment before a robot can understand commands referring to those landmarks. To generalize to new environments outside of the training set, we present a framework that parses references to landmarks, then assesses semantic similarities between the referring expression and landmarks in a predefined semantic map of the world, and ultimately translates natural language commands to motion plans for a drone. This framework allows the robot to ground natural language phrases to landmarks in a map when both the referring expressions to landmarks and the landmarks themselves have not been seen during training. We test our framework with a 14-person user evaluation demonstrating an end-to-end accuracy of 76.19% in an unseen environment. Subjective measures show that users find our system to have high performance and low workload. These results demonstrate our approach enables untrained users to control a robot in large unseen outdoor environments with unconstrained natural language.

## Learning and Adaptive Systems


- MANGA: Method Agnostic Neural-Policy Generalization and Adaptation

    Author: Bharadhwaj, Homanga | University of Toronto, Canada
    Author: Yamaguchi, Shoichiro | Preferred Networks, Inc
    Author: Maeda, Shin-ichi | Preferred Networks
 
    keyword: Deep Learning in Robotics and Automation; Learning and Adaptive Systems; Robust/Adaptive Control of Robotic Systems

    Abstract : In this paper, we target the problem of transferring policies across multiple environments with different dynamics parameters and motor noise variations, by introducing a framework that decouples the processes of policy learning and system identification. Efficiently transferring learned policies to an unknown environment with changes in dynamics configurations in the presence of motor noise is very important for operating robots in the real world, and our work is a novel attempt in that direction. We introduce MANGA: Method Agnostic Neural-policy Generalization and Adaptation, that trains dynamics conditioned policies and efficiently learns to estimate the dynamics parameters of the environment given off-policy state-transition rollouts in the environment. Our scheme is agnostic to the type of training method used - both reinforcement learning (RL) and imitation learning (IL) strategies can be used. We demonstrate the effectiveness of our approach by experimenting with four different MuJoCo agents and comparing against previously proposed transfer baselines.

- Fast Adaptation of Deep Reinforcement Learning-Based Navigation Skills to Human Preference

    Author: Choi, Jinyoung | NAVERLABS
    Author: Dance, Christopher | NAVER LABS Europe
    Author: Kim, Jung-eun | NAVER LABS
    Author: Park, Kyung-sik | NAVER LABS
    Author: Han, Jae-Hun | NAVER LABS
    Author: Seo, Joonho | NAVER LABS
    Author: Kim, Minsu | NAVERLABS
 
    keyword: Deep Learning in Robotics and Automation; Learning and Adaptive Systems; Service Robots

    Abstract : Deep reinforcement learning (RL) is being actively studied for robot navigation due to its promise of superior performance and robustness. However, most existing deep RL navigation agents are trained using fixed parameters, such as maximum velocities and weightings of reward components. Since the optimal choice of parameters depends on the use-case, it can be difficult to deploy such existing methods in a variety of real-world service scenarios. In this paper, we propose a novel deep RL navigation method that can adapt its policy to a wide range of parameters and reward functions without expensive retraining. Additionally, we explore a Bayesian deep learning method to optimize these parameters that requires only a small amount of preference data. We empirically show that our method can learn diverse navigation skills and quickly adapt its policy to a given performance metric or to human preference. We also demonstrate our method in real-world scenarios

- Model-Based Generalization under Parameter Uncertainty Using Path Integral Control

    Author: Abraham, Ian | Northwestern University
    Author: Handa, Ankur | IIIT Hyderabad
    Author: Ratliff, Nathan | Lula Robotics Inc
    Author: Lowrey, Kendall | University of Washington
    Author: Murphey, Todd | Northwestern University
    Author: Fox, Dieter | University of Washington
 
    keyword: Learning and Adaptive Systems; Optimization and Optimal Control; Reactive and Sensor-Based Planning

    Abstract : This work addresses the problem of robot interaction in complex environments where online control and adaptation is necessary. By expanding the sample space in the free energy formulation of path integral control, we derive a natural extension to the path integral control that embeds uncertainty into action and provides robustness for model-based robot planning. Our algorithm is applied to a diverse set of tasks using different robots and validate our results in simulation and real-world experiments. We further show that our method is capable of running in real-time without loss of performance.

- Memory of Motion for Warm-Starting Trajectory Optimization

    Author: Lembono, Teguh Santoso | Idiap Research Institute
    Author: Paolillo, Antonio | Idiap Research Institute
    Author: Pignat, Emmanuel | Idiap Research Institute, Martigny, Switzerland
    Author: Calinon, Sylvain | Idiap Research Institute
 
    keyword: Learning and Adaptive Systems; Motion and Path Planning

    Abstract : Trajectory optimization for motion planning requires good initial guesses to obtain good performance. In our proposed approach, we build a memory of motion based on a database of robot paths to provide good initial guesses. The memory of motion relies on function approximators and dimensionality reduction techniques to learn the mapping between the tasks and the robot paths. Three function approximators are compared: k-Nearest Neighbor, Gaussian Process Regression, and Bayesian Gaussian Mixture Regression. In addition, we show that the memory can be used as a metric to choose between several possible goals, and using an ensemble method to combine different function approximators results in a significantly improved warm-starting performance. We demonstrate the proposed approach with motion planning examples on the dual-arm robot PR2 and the humanoid robot Atlas.

- Safety Augmented Value Estimation from Demonstrations (SAVED): Safe Deep Model-Based RL for Sparse Cost Robotic Tasks

    Author: Thananjeyan, Brijen | UC Berkeley
    Author: Balakrishna, Ashwin | University of California, Berkeley
    Author: Rosolia, Ugo | 1990
    Author: Li, Felix | UC Berkeley
    Author: McAllister, Rowan | University of California, Berkeley
    Author: Gonzalez, Joseph E. | UC Berkeley
    Author: Levine, Sergey | UC Berkeley
    Author: Borrelli, Francesco | University of California, Berkeley
    Author: Goldberg, Ken | UC Berkeley
 
    keyword: Learning from Demonstration; Learning and Adaptive Systems; Deep Learning in Robotics and Automation

    Abstract : Reinforcement learning (RL) for robotics is challenging due to the difficulty in hand-engineering a dense cost function, which can lead to unintended behavior, and dynamical uncertainty, which makes exploration and constraint satisfaction challenging. We address these issues with a new model-based reinforcement learning algorithm, Safety Augmented Value Estimation from Demonstrations (SAVED), which uses supervision that only identifies task completion and a modest set of suboptimal demonstrations to constrain exploration and learn efficiently while handling complex constraints. We derive iterative improvement guarantees for SAVED under known stochastic nonlinear systems. We then compare SAVED with 3 state-of-the-art model-based and model-free RL algorithms on 6 standard simulation benchmarks involving navigation and manipulation and 2 real-world tasks on the da Vinci surgical robot. Results suggest that SAVED outperforms prior methods in terms of success rate, constraint satisfaction, and sample efficiency, making it feasible to safely learn complex maneuvers directly on a real robot in less than an hour. For tasks on the robot, baselines succeed less than 5% of the time while SAVED has a success rate of over 75% in the first 50 training iterations. Code and supplementary material is available at https://tinyurl.com/saved-rl.

- Variational Inference with Mixture Model Approximation for Applications in Robotics

    Author: Pignat, Emmanuel | Idiap Research Institute, Martigny, Switzerland
    Author: Lembono, Teguh Santoso | Idiap Research Institute
    Author: Calinon, Sylvain | Idiap Research Institute
 
    keyword: Learning and Adaptive Systems

    Abstract : We propose to formulate the problem of representing a distribution of robot configurations (e.g. joint angles) as that of approximating a product of experts. Our approach uses variational inference, a popular method in Bayesian computation, which has several practical advantages over sampling-based techniques. To be able to represent complex and multimodal distributions of configurations, mixture models are used as approximate distribution. We show that the problem of approximating a distribution of robot configurations while satisfying multiple objectives arises in a wide range of problems in robotics, for which the properties of the proposed approach have relevant consequences. Several applications are discussed, including learning objectives from demonstration, planning, and warm-starting inverse kinematics problems. Simulated experiments are presented with a 7-DoF Panda arm and a 28-DoF Talos humanoid.

- Preference-Based Learning for Exoskeleton Gait Optimization

    Author: Tucker, Maegan | California Institute of Technology
    Author: Novoseller, Ellen | California Institute of Technology
    Author: Kann, Claudia | California Institute of Technology
    Author: Sui, Yanan | Tsinghua University
    Author: Yue, Yisong | California Institute of Technology
    Author: Burdick, Joel | California Institute of Technology
    Author: Ames, Aaron | Caltech
 
    keyword: Learning and Adaptive Systems; Humanoid and Bipedal Locomotion; Prosthetics and Exoskeletons

    Abstract : This paper presents a personalized gait optimization framework for lower-body exoskeletons. Rather than optimizing numerical objectives such as the mechanical cost of transport, our approach directly learns from user preferences, e.g., for comfort. Building upon work in preference-based interactive learning, we present the CoSpar algorithm. CoSpar prompts the user to give pairwise preferences between trials and suggest improvements; as exoskeleton walking is a non-intuitive behavior, users can provide preferences more easily and reliably than numerical feedback. We show that CoSpar performs competitively in simulation and demonstrate a prototype implementation of CoSpar on a lower-body exoskeleton to optimize human walking trajectory features. In the experiments, CoSpar consistently found user-preferred parameters of the exoskeleton's walking gait, which suggests that it is a promising starting point for adapting and personalizing exoskeletons (or other assistive devices) to individual users.

- Adaptive Neural Trajectory Tracking Control for Flexible-Joint Robots with Online Learning

    Author: Chen, Shuyang | Rensselaer Polytechnic Institute
    Author: Wen, John | Rensselaer Polytechnic Institute
 
    keyword: Learning and Adaptive Systems; Neural and Fuzzy Control; Deep Learning in Robotics and Automation

    Abstract : Collaborative robots and space manipulators contain significant joint flexibility. It complicates the control design, compromises the control bandwidth, and limits the tracking accuracy. The imprecise knowledge of the flexible joint dynamics compounds the challenge. In this paper, we present a new control architecture for controlling flexible joint robots. Our approach uses a multi-layer neural network to approximate unknown dynamics needed for the feedforward control. The network may be viewed as a linear-in-parameter representation of the robot dynamics, with the nonlinear basis of the robot dynamics connected to the linear output layer. The output layer weights are updated based on the tracking error and the nonlinear basis. The internal weights of the nonlinear basis are updated by online backpropagation to further reduce the tracking error. To use time scale separation to reduce the coupling of the two steps - the update of the internal weights is at a lower rate compared to the update of the output layer weights. With the update of the output layer weights, our controller adapts quickly to the unknown dynamics change and disturbances. The update of the internal weights would continue to improve the converge of the nonlinear basis functions. We show the stability of the proposed scheme under the "outer loop" control. Simulation and physical experiments are conducted to demonstrate the performance of the proposed controller on a Baxter robot.

- BiCF: Learning Bidirectional Incongruity-Aware Correlation Filter for Efficient UAV Object Tracking

    Author: Lin, Fuling | Tongji University
    Author: Fu, Changhong | Tongji University
    Author: He, Yujie | Tongji University
    Author: Guo, Fuyu | Chongqing University
    Author: Tang, Qian | Chongqing University
 
    keyword: Learning and Adaptive Systems; Visual Tracking; Computer Vision for Other Robotic Applications

    Abstract : Correlation filters (CFs) have shown excellent performance in unmanned aerial vehicle (UAV) tracking scenarios due to their high computational efficiency. During the UAV tracking process, viewpoint variations are usually accompanied by changes in the object and background appearance, which poses a unique challenge to CF-based trackers. Since the appearance is gradually changing over time, an ideal tracker can not only forward predict the object position but also backtrack to locate its position in the previous frame. There exist response-based errors in the reversibility of the tracking process containing the information on the changes in appearance. However, some existing methods do not consider the forward and backward errors based on while using only the current training sample to learn the filter. For other ones, the applicants of considerable historical training samples impose a computational burden on the UAV. In this work, a novel bidirectional incongruity-aware correlation filter (BiCF) is proposed. By integrating the response-based bidirectional incongruity error into the CF, BiCF can efficiently learn the changes in appearance and suppress the inconsistent error. Extensive experiments on 243 challenging sequences from three UAV datasets (UAV123, UAVDT, and DTB70) are conducted to demonstrate that BiCF favorably outperforms other 25 stateof- the-art trackers and achieves a real-time speed of 45.4 FPS on a single CPU, which can be applied in UAV efficiently.

- Adaptive Unknown Object Rearrangement Using Low-Cost Tabletop Robot

    Author: Chai, Chun-Yu | National Chiao Tung University
    Author: Peng, Wen-Hsiao | National Chiao Tung University
    Author: Tsao, Shiao-Li | National Chiao Tung University
 
    keyword: Learning and Adaptive Systems; Motion and Path Planning; AI-Based Methods

    Abstract : Studies on object rearrangement planning typically consider known objects. Some learning-based methods can predict the movement of an unknown object after single-step interaction, but require intermediate targets, which are generated manually, to achieve the rearrangement task. In this work, we propose a framework for unknown object rearrangement. Our system &#64257;rst models an object through a small-amount of identi&#64257;cation actions and adjust the model parameters during task execution. We implement the proposed framework based on a low-cost tabletop robot (under 180 USD) to demonstrate the advantages of using a physics engine to assist action prediction. Experimental results reveal that after running our adaptive learning procedure, the robot can successfully arrange a novel object using an average of &#64257;ve discrete pushes on our tabletop environment and satisfy a precise 3.5 cm translation and 5° rotation criterion.

- Unsupervised Learning and Exploration of Reachable Outcome Space

    Author: Paolo, Giuseppe | Sorbonne University
    Author: Coninx, Alexandre | UPMC
    Author: Doncieux, Stéphane | Pierre and Marie Curie University
    Author: Laflaquière, Alban | AI Lab, SoftBank Robotics EU
 
    keyword: Learning and Adaptive Systems; Autonomous Agents; AI-Based Methods

    Abstract : Performing Reinforcement Learning in sparse rewards settings, with very little prior knowledge, is a challenging problem since there is no signal to properly guide the learning process. In such situations, a good search strategy is fundamental. At the same time, not having to adapt the algorithm to every single problem is very desirable. Here we introduce TAXONS, a Task Agnostic eXploration of Outcome spaces through Novelty and Surprise algorithm. Based on a population-based divergent-search approach, it learns a set of diverse policies directly from high-dimensional observations, without any task-specific information. TAXONS builds a repertoire of policies while training an autoencoder on the high-dimensional observation of the final state of the system to build a low-dimensional outcome space. The learned outcome space, combined with the reconstruction error, is used to drive the search for new policies. Results show that TAXONS can find a diverse set of controllers, covering a good part of the ground-truth outcome space, while having no information about such space.

- Context-Aware Cost Shaping to Reduce the Impact of Model Error in Safe, Receding Horizon Control

    Author: McKinnon, Christopher | University of Toronto
    Author: Schoellig, Angela P. | University of Toronto
 
    keyword: Learning and Adaptive Systems; Model Learning for Control; Field Robots

    Abstract : This paper presents a method to enable a robot using stochastic Model Predictive Control (MPC) to achieve high performance on a repetitive path-following task. In particular, we consider the case where the accuracy of the model for robot dynamics varies significantly over the path-motivated by the fact that the models used in MPC must be computationally efficient, which limits their expressive power. Our approach is based on correcting the cost predicted using a simple learned dynamics model over the MPC horizon. This discourages the controller from taking actions that lead to higher cost than would have been predicted using the dynamics model. In addition, stochastic MPC provides a quantitative measure of safety by limiting the probability of violating state and input constraints over the prediction horizon. Our approach is unique in that it combines both online model learning and cost learning over the prediction horizon and is geared towards operating a robot in changing conditions. We demonstrate our algorithm in simulation and experiment on a ground robot that uses a stereo camera for localization.

- Context-Aware Task Execution Using Apprenticeship Learning

    Author: Abdelrahman, Ahmed Faisal | Hochschule Bonn-Rhein-Sieg
    Author: Mitrevski, Alex | Hochschule Bonn-Rhein-Sieg
    Author: Pl�ger, Paul G. | Hochschule Bonn Rhein Sieg
 
    keyword: Learning and Adaptive Systems; Human-Centered Robotics; Domestic Robots

    Abstract : An essential measure of autonomy in assistive service robots is adaptivity to the various contexts of human-oriented tasks, which are subject to subtle variations in task parameters that determine optimal behaviour. In this work, we propose an apprenticeship learning approach to achieving context-aware action generalization on the task of robot-to- human object hand-over. The procedure combines learning from demonstration and reinforcement learning: a robot first imitates a demonstrator's execution of the task and then learns contextualized variants of the demonstrated action through experience. We use dynamic movement primitives as compact motion representations, and a model-based C-REPS algorithm for learning policies that can specify hand-over position, conditioned on context variables. Policies are learned using simulated task executions, before transferring them to the robot and evaluating emergent behaviours. We additionally conduct a user study involving participants assuming different postures and receiving an object from a robot, which executes hand-overs by either imitating a demonstrated motion, or adapting its motion to hand-over positions dictated by the learned policy. The results confirm the hypothesized improvements in the robot's perceived behaviour when it is context-aware and adaptive, and provide useful insights that can inform future developments.

- Hierarchical Interest-Driven Associative Goal Babbling for Efficient Bootstrapping of Sensorimotor Skills

    Author: Rayyes, Rania | TU Braunschweig
    Author: Donat, Heiko | Technical University Braunschweig
    Author: Steil, Jochen J. | Technische Universitét Braunschweig
 
    keyword: Learning and Adaptive Systems; AI-Based Methods; Neurorobotics

    Abstract : We propose a novel hierarchical online learning scheme for fast and efficient bootstrapping of sensorimotor skills. Our scheme permits rapid data-driven robot model learning in a "learning while behaving" fashion. It is updated continuously to adapt to time-dependent changes and driven by an intrinsic motivation signal. It utilizes an online associative radial basis function network, which is the first associative dynamic network to be constructed from scratch with high stability. Moreover, we propose a parameter-sharing technique to increase efficiency, stabilize the online scheme, avoid exhaustive parameter tuning, and speed up the learning process. We apply our proposed algorithms on a 7-DoF physical robot manipulator and demonstrate their performance and efficiency.

- Robot-Supervised Learning for Object Segmentation

    Author: Florence, Victoria | University of Michigan
    Author: Corso, Jason | University of Michigan
    Author: Griffin, Brent | University of Michigan
 
    keyword: Learning and Adaptive Systems; Object Detection, Segmentation and Categorization; Deep Learning in Robotics and Automation

    Abstract : To be effective in unstructured and changing environments, robots must learn to recognize new objects. Deep learning has enabled rapid progress for object detection and segmentation in computer vision; however, this progress comes at the price of human annotators labeling many training examples. This paper addresses the problem of extending learning-based segmentation methods to robotics applications where annotated training data is not available. Our method enables pixelwise segmentation of grasped objects. We factor the problem of segmenting the object from the background into two sub-problems: (1) segmenting the robot manipulator and object from the background and (2) segmenting the object from the manipulator. We propose a kinematics-based foreground segmentation technique to solve (1). To solve (2), we train a self-recognition network that segments the robot manipulator. We train this network without human supervision, leveraging our foreground segmentation technique from (1) to label a training set of images containing the robot manipulator without a grasped object. We demonstrate experimentally that our method outperforms state-of-the-art adaptable in-hand object segmentation. We also show that a training set composed of automatically labelled images of grasped objects improves segmentation performance on a test set of images of the same objects in the environment.

- Gradient and Log-Based Active Learning for Semantic Segmentation of Crop and Weed for Agricultural Robots

    Author: Sheikh, Rasha | University of Bonn
    Author: Milioto, Andres | University of Bonn
    Author: Lottes, Philipp | University of Bonn
    Author: Stachniss, Cyrill | University of Bonn
    Author: Bennewitz, Maren | University of Bonn
    Author: Schultz, Thomas | University of Bonn
 
    keyword: Learning and Adaptive Systems; Robotics in Agriculture and Forestry; Deep Learning in Robotics and Automation

    Abstract : Annotated datasets are essential for supervised learning. However, annotating large datasets is a tedious and time-intensive task. This paper addresses active learning in the context of semantic segmentation with the goal of reducing the human labeling effort. Our application is agricultural robotics and we focus on the task of distinguishing between crop and weed plants from image data. A key challenge in this application is the transfer of an existing semantic segmentation CNN to a new field, in which growth stage, weeds, soil, and weather conditions differ. We propose a novel approach that, given a trained model on one field together with rough foreground segmentation, refines the network on a substantially different field providing an effective method of selecting samples to annotate for supporting the transfer. We evaluated our approach on two challenging datasets from the agricultural robotics domain and show that we achieve a higher accuracy with a smaller number of samples compared to random sampling as well as entropy based sampling, which consequently reduces the required human labeling effort.

- Learning How to Walk: Warm-Starting Optimal Control Solver with Memory of Motion

    Author: Lembono, Teguh Santoso | Idiap Research Institute
    Author: Mastalli, Carlos | University of Edinburgh
    Author: Fernbach, Pierre | Cnrs - Laas
    Author: Mansard, Nicolas | CNRS
    Author: Calinon, Sylvain | Idiap Research Institute
 
    keyword: Learning and Adaptive Systems; Optimization and Optimal Control; Legged Robots

    Abstract : In this paper, we propose a framework to build a memory of motion for warm-starting an optimal control solver for the locomotion task of a humanoid robot. We use HPP Loco3D, a versatile locomotion planner, to generate offline a set of dynamically consistent whole-body trajectory to be stored as the memory of motion. The learning problem is formulated as a regression problem to predict a single-step motion given the desired contact locations, which is used as a building block for producing multi-step motions. The predicted motion is then used as a warm-start for the fast optimal control solver Crocoddyl. We have shown that the approach manages to reduce the required number of iterations to reach the convergence from ~9.5 to only ~3.0 iterations for the single-step motion and from ~6.2 to ~4.5 iterations for the multi-step motion, while maintaining the solution's quality.

- Feedback Linearization for Unknown Systems Via Reinforcement Learning

    Author: Westenbroek, Tyler | University of California, Berkeley
    Author: Fridovich-Keil, David | University of California, Berkeley
    Author: Mazumdar, Eric | University of California, Berkeley
    Author: Arora, Shreyas | Mission San Jose High School
    Author: Prabhu, Valmik | University of California, Berkeley
    Author: Sastry, Shankar | University of California, Berkeley
    Author: Tomlin, Claire | UC Berkeley
 
    keyword: Learning and Adaptive Systems; Model Learning for Control; Deep Learning in Robotics and Automation

    Abstract : We present a novel approach to control design for nonlinear systems which leverages model-free policy optimization techniques to learn a linearizing controller for a physical plant with unknown dynamics. Feedback linearization is a technique from nonlinear control which renders the input-output dynamics of a nonlinear plant emph{linear} under application of an appropriate feedback controller. Once a linearizing controller has been constructed, desired output trajectories for the nonlinear plant can be tracked using a variety of linear control techniques. However, the calculation of a linearizing controller requires a precise dynamics model for the system. As a result, model-based approaches for learning exact linearizing controllers generally require a simple, highly structured model of the system with easily identifiable parameters. In contrast, the model-free approach presented in this paper is able to approximate the linearizing controller for the plant using general function approximation architectures. Specifically, we formulate a continuous-time optimization problem over the parameters of a learned linearizing controller whose optima are the set of parameters which best linearize the plant. We derive conditions under which the learning problem is (strongly) convex and provide guarantees which ensure the true linearizing controller for the plant is recovered. We then discuss how model-free policy optimization algorithms can be used to solve a discrete-time approximation

- Long-Term Robot Navigation in Indoor Environments Estimating Patterns in Traversability Changes

    Author: Nardi, Lorenzo | University of Bonn
    Author: Stachniss, Cyrill | University of Bonn
 
    keyword: Learning and Adaptive Systems; Mapping; Autonomous Vehicle Navigation

    Abstract : Nowadays, mobile robots are deployed in many indoor environments such as offices or hospitals. These environments are subject to changes in the traversability that often happen following patterns. In this paper, we investigate the problem of navigating in such environments over extended periods of time by capturing and exploiting these patterns to make informed decisions for navigation. Our approach uses a probabilistic graphical model to incrementally estimate a model of the traversability changes from the robot's observations and to make predictions at currently unobserved locations. In the belief space defined by the predictions, we plan paths that trade off the risk to encounter obstacles and the information gain of visiting unknown locations. We implemented our approach and tested it in different indoor environments. The experiments suggest that, in the long run, our approach leads robots to navigate along shorter paths compared to following a greedy shortest path policy.

- Sample-And-Computation-Efficient Probabilistic Model Predictive Control with Random Features

    Author: Kuo, Cheng-Yu | Nara Institute of Science and Technology
    Author: Cui, Yunduan | Nara Institute of Science and Technology
    Author: Matsubara, Takamitsu | Nara Institute of Science and Technology
 
    keyword: Learning and Adaptive Systems; Model Learning for Control

    Abstract : Gaussian processes (GPs) based Reinforcement Learning (RL) methods with Model Predictive Control (MPC) have demonstrated their excellent sample efficiency. However, since the computational cost of GPs largely depends on the training sample size, learning an accurate dynamics using GPs result in slow control frequency in MPC. To alleviate this trade-off and achieve a sample-and-computation-efficient nature, we propose a novel model-based RL method with MPC. Our approach employs a linear Gaussian model with randomized features using the Fastfood as an approximated GP dynamics. Then, we derive an analytic moment matching scheme in state prediction with the model and uncertain inputs. Through experiments with simulated and real robot control tasks, the sample efficiency, as well as the computational efficiency of our model-based RL method, are demonstrated.

- Sample-Efficient Robot Motion Learning Using Gaussian Process Latent Variable Models

    Author: Delgado-Guerrero, Juan Antonio | IRI
    Author: Colomé, Adrià | Institut De Robòtica I Informàtica Industrial (CSIC-UPC), Q28180
    Author: Torras, Carme | Csic - Upc
 
    keyword: Learning and Adaptive Systems; Redundant Robots; Learning from Demonstration

    Abstract : Robotic manipulators are reaching a state where we could see them in household environments in the following decade. Nevertheless, such robots need to be easy to instruct by lay people. This is why kinesthetic teaching has become very popular in recent years, in which the robot is taught a motion that is encoded as a parametric function - usually a Movement Primitive (MP)-. This approach produces trajectories that are usually suboptimal, and the robot needs to be able to improve them through trial-and-error. Such optimization is often done with Policy Search (PS) reinforcement learning, using a given reward function. PS algorithms can be classified as model-free, where neither the environment nor the reward function are modelled, or model-based, which can use a surrogate model of the reward function and/or a model for the dynamics of the task. However, MPs can become very high-dimensional in terms of parameters, which constitute the search space, so their optimization often requires too many samples. In this paper, we assume we have a robot motion task characterized with an MP of which we cannot model the dynamics. We build a surrogate model for the reward function, that maps an MP parameter latent space (obtained through a Mutual-information-weighted Gaussian Process Latent Variable Model) into a reward. While we do not model the task dynamics, using mutual information to shrink the task space makes it more consistent with the reward and so the policy improvement is faster.

- Iterative Learning Based Feedforward Control for Transition of a Biplane-Quadrotor Tailsitter UAS

    Author: Raj, Nidhish | Indian Institute of Technology Kanpur
    Author: Simha, Ashutosh | Tallinn University of Technology
    Author: Kothari, Mangal | Indian Institute of Technology Kanpur
    Author: Abhishek, Abhishek | Indian Institute of Technology Kanpur
    Author: Banavar, Ravi N | I. I. T. Bombay
 
    keyword: Learning and Adaptive Systems; Aerial Systems: Mechanics and Control; Aerial Systems: Perception and Autonomy

    Abstract : This paper provides a real time on-board algorithm for a biplane-quadrotor to iteratively learn a forward transition maneuver via repeated flight trials. The maneuver is controlled by regulating the pitch angle and propeller thrust according to feedforward control laws that are parameterized by polynomials. Based on a nominal model with simplified aerodynamics, the optimal coefficients of the polynomials are chosen through simulation such that the maneuver is completed with specified terminal conditions on altitude and air speed. In order to compensate for modeling errors, repeated flight trials are performed by updating the feedforward control paramters according to an iterative learning algorithm until the maneuver is perfected. A geometric attitude controller, valid for all flight modes is employed in order to track the pitch angle according to the feedforward law. Further, a high-fidelity thrust model of the propeller for varying advance-ratio and orientation angle is obtained from wind tunnel data which is captured using a neural network model. This facilitates accurate application of feedforward thrust for varying flow conditions during transition. Experimental flight trials are performed to demonstrate the robustness and rapid convergence of the proposed learning algorithm.

- Reinforcement Learning for Adaptive Illumination with X-Rays

    Author: Betterton, Jean-Raymond | Stanford University
    Author: Ratner, Daniel | SLAC National Accelerator Laboratory
    Author: Webb, Samuel | SLAC National Accelerator Laboratory
    Author: Kochenderfer, Mykel | Stanford University
 
    keyword: Learning and Adaptive Systems; AI-Based Methods

    Abstract : We propose a learning algorithm for automating image sampling in scientific applications. We consider settings where images are sampled by controlling a probe beam's scanning trajectory over the image surface. We explore alternatives to obtaining images by the standard rastering method. We formulate the scanner control problem as a reinforcement learning (RL) problem and train a policy to adaptively sample only the highest value regions of the image, choosing the acquisition time and resolution for each sample position based on an observation of previous readings. We use convolutional neural network (CNN) policies to control the scanner as a way to generalize our approach to larger samples. We show simulation results for a simple policy on both synthetic data and real world data from an archaeological application.

- Efficient Updates for Data Association with Mixtures of Gaussian Processes

    Author: Lee, Ki Myung Brian | University of Technology Sydney
    Author: Martens, Wolfram | Siemens Mobility GmbH
    Author: Khatkar, Jayant | University of Technology Sydney
    Author: Fitch, Robert | University of Technology Sydney
    Author: Mettu, Ramgopal | Tulane University
 
    keyword: Learning and Adaptive Systems; AI-Based Methods; Big Data in Robotics and Automation

    Abstract : Gaussian processes (GPs) enable a probabilistic approach to important estimation and classification tasks that arise in robotics applications. Meanwhile, most GP-based methods are often prohibitively slow, thereby posing a substantial barrier to practical applications. Existing ``sparse'' methods to speed up GPs seek to either make the model more sparse, or find ways to more efficiently manage a large covariance matrix. In this paper, we present an orthogonal approach that memoises (i.e. reuses) previous computations in GP inference. We demonstrate that a substantial speedup can be achieved by incorporating memoisation into applications in which GPs must be updated frequently. Moreover, we also show how memoisation can be used in conjunction with sparse methods and demonstrate a synergistic improvement in performance. Across three robotic vision applications, we demonstrate between 40-100% speed-up over the standard method for inference in GP mixtures.

## Surgical Robotics: Laparascopy I
- Hand-Eye Calibration of Surgical Instrument for Robotic Surgery Using Interactive Manipulation

    Author: Zhong, Fangxun | The Chinese University of Hong Kong
    Author: Wang, Zerui | The Chinese University of Hong Kong
    Author: Chen, Wei | The Chinese University of Hong Kong
    Author: Wang, Yaqing | The Chinese University of Hong Kong
    Author: Liu, Yunhui | Chinese University of Hong Kong
 
    keyword: Surgical Robotics: Laparoscopy; Calibration and Identification

    Abstract : Conventional robot hand-eye calibration methods are impractical for localizing robotic instruments in minimally-invasive surgeries under intra-corporeal workspace after pre-operative set-up. In this letter, we present a new approach to autonomously calibrate a robotic instrument relative to a monocular camera without recognizing calibration objects or salient features. The algorithm leverages interactive manipulation (IM) of the instrument for tracking its rigid-body motion behavior subject to the remote center-of-motion constraint. An adaptive controller is proposed to regulate the IM-induced instrument trajectory, using visual feedback, within a 3D interactive feature plane which is observable from both the robot base and the camera. The eye-to-hand orientation and position is then computed via a dual-stage process allowing parameter estimation in low-dimensional spaces. The method also does not require exact knowledge of the instrument model or large-scale data collection. Results from simulations and experiments on the da Vinci Research Kit are demonstrated via a laparoscopy resembling set-up using the proposed framework.

- Real-Time Data Driven Precision Estimator for RAVEN-II Surgical Robot End Effector Position

    Author: Peng, Haonan | University of Washington
    Author: Yang, Xingjian | University of Washington
    Author: Su, Yun-Hsuan | University of Washington
    Author: Hannaford, Blake | University of Washington
 
    keyword: Surgical Robotics: Laparoscopy; Computer Vision for Medical Robotics; Medical Robots and Systems

    Abstract :     Abstract - Surgical robots have been introduced to operating rooms over the past few decades due to their high sensitivity, small size, and remote controllability. The cable-driven nature of many surgical robots allows the systems to be dexterous and lightweight, with diameters as low as 5mm. However, due to the slack and stretch of the cables and the backlash of the gears, inevitable uncertainties are brought into the kinematics calculation [1]. Since the reported end effector position of surgical robots like RAVEN-II [2] is directly calculated using the motor encoder measurements and forward kinematics, it may contain relatively large error up to 10mm, whereas semi-autonomous functions being introduced into abdominal surgeries require position inaccuracy of at most 1mm. To resolve the problem, a cost-effective, real-time and data-driven pipeline for robot end effector position precision estimation is proposed and tested on RAVEN-II. Analysis shows an improved end effector position error of around 1mm RMS traversing through the entire robot workspace without high-resolution motion tracker. The open source code, data sets, videos, and user guide can be found at //github.com/HaonanPeng/RAVEN_Neural_Network_Estimator.

- Vision-Based Dynamic Virtual Fixtures for Tools Collision Avoidance in Robotic Surgery

    Author: Moccia, Rocco | Université Degli Studi Di Napoli, Federico II
    Author: Iacono, Cristina | Université Degli Studi Di Napoli Federico II
    Author: Siciliano, Bruno | Univ. Napoli Federico II
    Author: Ficuciello, Fanny | Université Di Napoli Federico II
 
    keyword: Surgical Robotics: Laparoscopy; Collision Avoidance; Telerobotics and Teleoperation

    Abstract : In robot-aided surgery, during the execution of typical bimanual procedures such as dissection, surgical tools can collide and create serious damage to the robot or tissues. The da Vinci robot is one of the most advanced and certainly the most widespread robotic system dedicated to minimally invasive surgery. Although the procedures performed by da Vinci-like surgical robots are teleoperated, potential collisions between surgical tools are a very sensitive issue declared by surgeons. Shared control techniques based on Virtual Fixtures (VF) can be an effective way to help the surgeon prevent tools collision.<p>This paper presents a surgical tools collision avoidance method that uses Forbidden Region Virtual Fixtures. Tool clashing is avoided by rendering a repulsive force to the surgeon. To ensure the correct definition of the VF, a marker-less tool tracking method, using deep neural network architecture for tool segmentation, is adopted. The use of direct kinematics for tools collision avoidance is affected by tools position error introduced by robot component elasticity during tools interaction with the environment. On the other hand, kinematics information can help in case of occlusions of the camera. Therefore, this work proposes an Extended Kalman Filter (EKF) for pose estimation which ensures a more robust application of VF on the tool, coupling vision and kinematics information. The entire pipeline is tested in different tasks using the da Vinci Research Kit system.

- An Experimental Comparison towards Autonomous Camera Navigation to Optimize Training in Robot Assisted Surgery

    Author: Mariani, Andrea | Scuola Superiore Sant'Anna
    Author: Colaci, Giorgia | Politecnico Di Milano
    Author: Da Col, Tommaso | Politecnico Di Milano
    Author: Sanna, Nicole | Politecnico Di Milano
    Author: Vendrame, Eleonora | Politecnico Di Milano
    Author: Menciassi, Arianna | Scuola Superiore Sant'Anna - SSSA
    Author: De Momi, Elena | Politecnico Di Milano
 
    keyword: Telerobotics and Teleoperation; Virtual Reality and Interfaces; Surgical Robotics: Laparoscopy

    Abstract : Robot-Assisted Surgery enhances vision and it can restore depth perception, but it introduces the need for learning how to tele-operatively control both the surgical tools and the endoscope. Together with the complexity of selecting the optimal viewpoint to carry out the procedure, this requires distinct training. This work proposes an autonomous camera navigation during the initial stages of training in order to optimize the learning of these skills. A user study involving 26 novice participants was carried out using the master console of the da Vinci Research Kit and a virtual reality training environment. The subjects were randomly divided into two groups: the control group that manually controlled the camera as in the current practice and the experimental group that underwent the autonomous navigation. After training, the time-accuracy metrics of the users who underwent autonomous camera navigation were significantly higher with respect to the control group. Additionally, autonomous camera navigation seemed to be capable to provide an imprinting about endoscope management.

- Temporal Segmentation of Surgical Sub-Tasks through Deep Learning with Multiple Data Sources

    Author: Qin, Yidan | Intuitive Surgical
    Author: Aghajani Pedram, Sahba | University of California, Los Angeles
    Author: Feyzabadi, Seyedshams | UC Merced
    Author: Allan, Max | Intuitive Surgical
    Author: McLeod, Angus Jonathan | Intuitive Surgical
    Author: Burdick, Joel | California Institute of Technology
    Author: Azizian, Mahdi | Intuitive Surgical
 
    keyword: Surgical Robotics: Laparoscopy; Deep Learning in Robotics and Automation; Medical Robots and Systems

    Abstract : Many tasks in robot-assisted surgeries (RAS) can be represented by finite-state machines (FSMs), where each state represents either an action (such as picking up a needle) or an observation (such as bleeding). A crucial step towards the automation of such surgical tasks is the temporal perception of the current surgical scene, which requires a real-time estimation of the states in the FSMs. The objective of this work is to estimate the current state of the surgical task based on the actions performed or events occurred as the task progresses. We propose Fusion-KVE, a unified surgical state estimation model that incorporates multiple data sources including the Kinematics, Vision, and system Events. Additionally, we examine the strengths and weaknesses of different state estimation models in segmenting states with different representative features or levels of granularity. We evaluate our model on the JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS), as well as a more complex dataset involving robotic intra-operative ultrasound (RIOUS) imaging, created using the da Vinci Xi surgical system. Our model achieves a superior frame-wise state estimation accuracy up to 89.4%, which improves the state-of-the-art surgical state estimation models in both JIGSAWS suturing dataset and our RIOUS dataset.

- Controlling Assistive Robots with Learned Latent Actions

    Author: Losey, Dylan | Stanford University
    Author: Srinivasan, Krishnan | Stanford University
    Author: Mandlekar, Ajay Uday | Stanford University
    Author: Garg, Animesh | University of Toronto
    Author: Sadigh, Dorsa | Stanford University
 
    keyword: Physically Assistive Devices; Cognitive Human-Robot Interaction; Human-Centered Robotics

    Abstract : Assistive robotic arms enable users with physical disabilities to perform everyday tasks without relying on a caregiver. Unfortunately, the very dexterity that makes these arms useful also makes them challenging to teleoperate: the robot has more degrees-of-freedom than the human can directly coordinate with a handheld joystick. Our insight is that we can make assistive robots easier for humans to control by leveraging latent actions. Latent actions provide a low-dimensional embedding of high-dimensional robot behavior: for example, one latent dimension might guide the assistive arm along a pouring motion. In this paper, we design a teleoperation algorithm for assistive robots that learns latent actions from task demonstrations. We formulate the controllability, consistency, and scaling properties that user-friendly latent actions should have, and evaluate how different low-dimensional embeddings capture these properties. Finally, we conduct two user studies on a robotic arm to compare our latent action approach to both state-of-the-art shared autonomy baselines and a teleoperation strategy currently used by assistive arms. Participants completed assistive eating and cooking tasks more efficiently when leveraging our latent actions, and also subjectively reported that latent actions made the task easier to perform. The video accompanying this paper can be found at: https://youtu.be/wjnhrzugBj4.


## Surgical Robotics: Laparoscopy II

- SuPer: A Surgical Perception Framework for Endoscopic Tissue Manipulation with Surgical Robotics

    Author: Li, Yang | Zhejiang University
    Author: Richter, Florian | University of California, San Diego
    Author: Lu, Jingpei | University of California, San Diego
    Author: Funk, Emily | University of California, San Diego
    Author: Orosco, Ryan | University of California, San Diego
    Author: Zhu, Jianke | Zhejiang University
    Author: Yip, Michael C. | University of California, San Diego
 
    keyword: Computer Vision for Medical Robotics; Surgical Robotics: Laparoscopy; Perception for Grasping and Manipulation

    Abstract : Traditional control and task automation have been successfully demonstrated in a variety of structured, controlled environments through the use of highly specialized modeled robotic systems in conjunction with multiple sensors. However, the application of autonomy in endoscopic surgery is very challenging, particularly in soft tissue work, due to the lack of high-quality images and the unpredictable, constantly deforming environment. In this work, we propose a novel surgical perception framework, SuPer, for surgical robotic control. This framework continuously collects 3D geometric information that allows for mapping a deformable surgical field while tracking rigid instruments within the field. To achieve this, a model-based tracker is employed to localize the surgical tool with a kinematic prior in conjunction with a model-free tracker to reconstruct the deformable environment and provide an estimated point cloud as a mapping of the environment. The proposed framework was implemented on the da Vinci Surgical System in real-time with an end-effector controller where the target configurations are set and regulated through the framework. Our proposed framework successfully completed soft tissue manipulation tasks with high accuracy. The demonstration of this novel framework is promising for the future of surgical autonomy. In addition, we provide our dataset for further surgical research.

- Multi-Task Recurrent Neural Network for Surgical Gesture Recognition and Progress Prediction

    Author: van Amsterdam, Beatrice | University College London
    Author: Clarkson, Matt | University College London
    Author: Stoyanov, Danail | University College London
 
    keyword: Surgical Robotics: Laparoscopy; Object Detection, Segmentation and Categorization

    Abstract : Surgical gesture recognition is important for surgical data science and computer-aided intervention. Even with robotic kinematic information, automatically segmenting surgical steps presents numerous challenges because surgical demonstrations are characterized by high variability in style, duration and order of actions. In order to extract discriminative features from the kinematic signals and boost recognition accuracy, we propose a multi-task recurrent neural network for simultaneous recognition of surgical gestures and estimation of a novel formulation of surgical task progress. To show the effectiveness of the presented approach, we evaluate its application on the JIGSAWS dataset, that is currently the only publicly available dataset for surgical gesture recognition featuring robot kinematic data. We demonstrate that recognition performance improves in multi-task frameworks with progress estimation without any additional manual labelling and training.

- Neural Network Based Inverse Dynamics Identification and External Force Estimation on the Da Vinci Research Kit

    Author: Yilmaz, Nural | Marmara University
    Author: Wu, Jie Ying | Johns Hopkins University
    Author: Kazanzides, Peter | Johns Hopkins University
    Author: Tumerdem, Ugur | Marmara University
 
    keyword: Surgical Robotics: Laparoscopy; Force and Tactile Sensing; Telerobotics and Teleoperation

    Abstract : Most current surgical robotic systems lack the ability to sense tool/tissue interaction forces, which motivates research in methods to estimate these forces from other available measurements, primarily joint torques. These methods require the internal joint torques, due to the robot inverse dynamics, to be subtracted from the measured joint torques. This paper presents the use of neural networks to estimate the inverse dynamics of the da Vinci surgical robot, which enables estimation of the external environment forces. Experiments with motions in free space demonstrate that the neural networks can estimate the internal joint torques within 10% normalized rootmean-square error (NRMSE), which outperforms model-based approaches in the literature. Comparison with an external force sensor shows that the method is able to estimate environment forces within about 10% NRMSE.

- Visual Servo of a 6-DOF Robotic Stereo Flexible Endoscope Based on Da Vinci Research Kit (dVRK) System

    Author: Ma, Xin | Chinese Univerisity of HongKong
    Author: Song, Chengzhi | Chinese University of Hong Kong,
    Author: Chiu, Philip, Wai-yan | Chinese University of Hong Kong
    Author: Li, Zheng | The Chinese University of Hong Kong
 
    keyword: Surgical Robotics: Laparoscopy; Medical Robots and Systems; Flexible Robots

    Abstract : Endoscopes play an important role in minimally invasive surgery (MIS). Due to the advantages of less occupied motion space and enhanced safety, flexible endoscopes are drawing more and more attention. However, the structure of the flexible section makes it difficult for surgeons to manually rotate and guide the view of endoscopes. To solve these problems, we developed a 6-DOF robotic stereo flexible endoscope (RSFE) based on the da Vinci Research Kit (dVRK). Then an image-based endoscope guidance method with depth information is proposed for the RSFE. With this method, the view and insertion depth of the RSFE can be adjusted by tracking the surgical instruments automatically. Additionally, an image-based view rotation control method is proposed, with which the rotation of the view can be controlled by tracking two surgical instruments. The experimental results show that the proposed methods control the direction and rotation of the view of the flexible endoscope faster than the manual control method. Lastly, an ex vivo experiment is performed to demonstrate the feasibility of the proposed control method and system.

- Reflective-AR Display: An Interaction Methodology for Virtual-To-Real Alignment in Medical Robotics

    Author: Fotouhi, Javad | Johns Hopkins University
    Author: Song, Tianyu | Verb Surgical Inc
    Author: Mehrfard, Arian | Johns Hopkins University
    Author: Taylor, Giacomo | Verb Surgical Inc
    Author: Wang, Qiaochu | Johns Hopkins University
    Author: Xian, Fengfan | Johns Hopkins University
    Author: Martin-Gomez, Alejandro | Technical University of Munich
    Author: Fuerst, Bernhard | Verb Surgical Inc
    Author: Armand, Mehran | Johns Hopkins University Applied Physics Laboratory
    Author: Unberath, Mathias | Johns Hopkins University
    Author: Navab, Nassir | Johns Hopkins University
 
    keyword: Surgical Robotics: Laparoscopy

    Abstract : Robot-assisted minimally invasive surgery has shown to improve patient outcomes, as well as reduce complications and recovery time for several clinical applications. While increasingly configurable robotic arms can maximize reach and avoid collisions in cluttered environments, positioning them appropriately during surgery is complicated because safety regulations prevent automatic driving. We propose a head-mounted display (HMD) based augmented reality (AR) system designed to guide optimal surgical arm set up. The staff equipped with HMD aligns the robot with its planned virtual counterpart. In this user-centric setting, the main challenge is the perspective ambiguities hindering such collaborative robotic solution. To overcome this challenge, we introduce a novel registration concept for intuitive alignment of AR content to its physical counterpart by providing a multi-view AR experience via reflective-AR displays that simultaneously show the augmentations from multiple viewpoints. Using this system, users can visualize different perspectives while actively adjusting the pose to determine the registration transformation that most closely superimposes the virtual onto the real. The experimental results demonstrate improvement in the interactive alignment of a virtual and real robot when using a reflective-AR display. We also present measurements from configuring a robotic manipulator in a simulated trocar placement surgery using the AR guidance methodology.



## Surgical Robotics: Steerable Catheters/Needles
- Aortic 3D Deformation Reconstruction Using 2D X-Ray Fluoroscopy and 3D Pre-Operative Data for Endovascular Interventions

    Author: Zhang, Yanhao | University of Technology Sydney
    Author: Zhao, Liang | University of Technology Sydney
    Author: Huang, Shoudong | University of Technology, Sydney
 
    keyword: Surgical Robotics: Steerable Catheters/Needles; Computer Vision for Medical Robotics; Mapping

    Abstract : Current clinical endovascular interventions rely on 2D guidance for catheter manipulation. Although an aortic 3D surface is available from the pre-operative CT/MRI imaging, it cannot be used directly as a 3D intra-operative guidance since the vessel will deform during the procedure. This paper aims to reconstruct the live 3D aortic deformation by fusing the static 3D model from the pre-operative data and the 2D live imaging from fluoroscopy. In contrast to some existing deformation reconstruction frameworks which require 3D observations such as RGB-D or stereo images, fluoroscopy only presents 2D information. In the proposed framework, a 2D-3D registration is performed and the reconstruction process is formulated as a non-linear optimization problem based on the deformation graph approach. Detailed simulations and phantom experiments are conducted and the result demonstrates the reconstruction accuracy and robustness, as well as the potential clinical value of this framework.

- Design and Kinematic Modeling of a Novel Steerable Needle for Image-Guided Insertion

    Author: Chen, Yuyang | Shanghai Jiao Tong University
    Author: Yang, Haozhe | School of Mechanical Engineering, Shanghai Jiao Tong University,
    Author: Liu, Xu | Shanghai Jiao Tong University
    Author: Xu, Kai | Shanghai Jiao Tong University
 
    keyword: Surgical Robotics: Steerable Catheters/Needles; Medical Robots and Systems

    Abstract : Needle-based procedures, such as biopsy and percutaneous tumor ablation, highly depend on the accuracy of needle placement. The accuracy is significantly affected by the needle-tissue interaction no matter what needles (straight or steerable) are used. Due to the unknown tissue mechanics, it is challenging to achieve high accuracy in practice. This paper hence proposes a needle design with an articulated tip for increased steerability and improved needle path consistency. Due to the passive needle tip articulation, tissue mechanics always plays a dominant role such that the needle creates similar paths with approximately piece-wise constant curvature in different tissues. Kinematics model for the proposed needle is presented. The algorithms of path planning and needle tip pose estimation under external imaging modality are developed. Experimental verifications were conducted to demonstrate the needle's steerability as well as the target-reaching capability with obstacles avoidance.

- Robotic Needle Insertion in Moving Soft Tissues Using Constraint-Based Inverse Finite Element Simulation

    Author: Baksic, Paul | Université De Strasbourg
    Author: Courtecuisse, Hadrien | AVR, CNRS Strasbourg
    Author: Duriez, Christian | INRIA
    Author: Bayle, Bernard | University of Strasbourg
 
    keyword: Surgical Robotics: Steerable Catheters/Needles; Medical Robots and Systems

    Abstract : This paper introduces a method for robotic steering of a flexible needle inside moving and deformable tissues. The method relies on a set of objective functions allowing to automatically steer the needle along a predefined path. In order to follow the desired trajectory, an inverse problem linking the motion of the robot end effector with the objective functions is solved using a Finite Element simulation. The main contribution of the article is the new constraint-based formulation of the objective functions allowing to: 1) significantly reduce the computation time; 2) increase the accuracy and stability of the simulation-guided needle insertion. The method is illustrated, and its performances are characterized in a realistic framework, using a direct simulation of the respiratory motion generated from in vivo data of a pig. Despite the highly non-linear behavior of the numerical simulation and the significant deformations occurring during the insertion, the obtained performances enable the possibility to follow the trajectory with the desired accuracy for medical purpose.

- Collaborative Robot-Assisted Endovascular Catheterization withGenerative Adversarial Imitation Learning

    Author: Chi, Wenqiang | Imperial College London
    Author: Dagnino, Giulio | Imperial College London
    Author: Kwok, Trevor M Y | Imperial College London
    Author: Nguyen, Anh | Imperial College London
    Author: Kundrat, Dennis | Imperial College London
    Author: Abdelaziz, Mohamed Essam Mohamed Kassem | Imperial College London
    Author: Riga, Celia | Imperial College London
    Author: Bicknell, Colin | Imperial College London
    Author: Yang, Guang-Zhong | Shanghai Jiao Tong University
 
    keyword: Surgical Robotics: Planning; Medical Robots and Systems; Learning from Demonstration

    Abstract : Master-slave systems for endovascular catheterization have brought major clinical benefits including reduced radiation doses to the operators, improved precision and stability of the instruments, as well as reduced procedural duration. Emerging deep reinforcement learning (RL) technologies could potentially automate more complex endovascular tasks with enhanced success rates, more consistent motion and reduced fatigue and cognitive workload of the operators. However, the complexity of the pulsatile flows within the vasculature and non-linear behavior of the instruments hinder the use of model-based approaches for RL. This paper describes model-free generative adversarial imitation learning to automate a standard arterial catherization task. The automation policies have been trained in a pre-clinical setting. Detailed validation results show high success rates after skill transfer to a different vascular anatomical model. The quality of the catheter motions also shows less mean and maximum contact forces compared to manual-based approaches.

- A Novel Sensing Method to Detect Tissue Boundaries During Robotic Needle Insertion Based on Laser Doppler Flowmetry

    Author: Virdyawan, Vani | Imperial College London
    Author: Dessi, Orsina | Imperial College London
    Author: Rodriguez y Baena, Ferdinando | Imperial College, London, UK
 
    keyword: Surgical Robotics: Steerable Catheters/Needles

    Abstract : This study investigates the use of Laser Doppler Flowmetry (LDF) as a method to detect tissue transitions during robotic needle insertions. Insertions were performed in gelatin tissue phantoms with different optical and mechanical properties and into an ex-vivo sheep brain. The effect of changing the optical properties of gelatin tissue phantoms was first investigated and it was shown that using gelatin concentration to modify the stiffness of samples was suitable. Needle insertion experiments were conducted into both one-layer and two-layer gelatin phantoms. In both cases, three stages could be observed in the perfusion values: tissue loading, rupture and tissue cutting. These were correlated to force values measured from the tip of the needle during insertion. The insertions into an ex-vivo sheep brain also clearly showed the time of rupture in both force and perfusion values, demonstrating that tissue puncture can be detected using an LDF sensor at the tip of a needle.

- GA3C Reinforcement Learning for Surgical Steerable Catheter Path Planning

    Author: Segato, Alice | Politecnico Di Milano, Milano , Italy
    Author: Sestini, Luca | Politecnico Di Milano
    Author: Castellano, Antonella | Neuroradiology Unit and CERMAC, Vita-Salute San Raffaele Univers
    Author: De Momi, Elena | Politecnico Di Milano
 
    keyword: Surgical Robotics: Steerable Catheters/Needles; Motion and Path Planning; Deep Learning in Robotics and Automation

    Abstract : Path planning algorithms for steerable catheters, must guarantee anatomical obstacles avoidance, reduce the insertion length and ensure the compliance with needle kinematics. The majority of the solutions in literature focuses on graph based or sampling based methods, both limited by the impossibility to directly obtain smooth trajectories. In this work we formulate the path planning problem as a reinforcement learning problem and show that the trajectory planning model, generated from the training, can provide the user with optimal trajectories in terms of obstacle clearance and kinematic constraints. We obtain 2D and 3D environments from MRI images processing and we implement a GA3C algorithm to create a path planning model, able to generalize on different patients anatomies. The curvilinear trajectories obtained from the model in 2D and 3D environments are compared to the ones obtained by A* and RRT* algorithms. Our method achieves state-of-the-art performances in terms of obstacle avoidance, trajectory smoothness and computational time proving this algorithm as valid planning method for complex environments.



## Path Planning for Multiple Mobile Robots or Agents
- Online Trajectory Generation with Distributed Model Predictive Control for Multi-Robot Motion Planning

    Author: Luis, Carlos E. | University of Toronto
    Author: Vukosavljev, Marijan | University of Toronto
    Author: Schoellig, Angela P. | University of Toronto
 
    keyword: Path Planning for Multiple Mobile Robots or Agents; Multi-Robot Systems; Distributed Robot Systems

    Abstract : We present a distributed model predictive control (DMPC) algorithm to generate trajectories in real-time for multiple robots. We adopted the on-demand collision avoidance method presented in previous work to efficiently compute non-colliding trajectories in transition tasks. An event-triggered replanning strategy is proposed to account for disturbances. Our simulation results show that the proposed collision avoidance method can reduce, on average, around 50% of the travel time required to complete a multi-agent point-to-point transition when compared to the well-studied Buffered Voronoi Cells (BVC) approach. Additionally, it shows a higher success rate in transition tasks with a high density of agents, with more than 90% success rate with 30 palm-sized quadrotor agents in a 18 m^3 arena. The approach was experimentally validated with a swarm of up to 20 drones flying in close proximity.

- One-Shot Multi-Path Planning for Robotic Applications Using Fully Convolutional Networks

    Author: Kulvicius, Tomas | University of Goettingen
    Author: Herzog, Sebastian | Department of Computational Neuroscience, University of Goetting
    Author: Lüddecke, Timo | University of Göttingen
    Author: Tamosiunaite, Minija | University of Goettingen
    Author: Wörgötter, Florentin | University of Göttingen
 
    keyword: Path Planning for Multiple Mobile Robots or Agents; Deep Learning in Robotics and Automation

    Abstract : Path planning is important for robot action execution, since a path or a motion trajectory for a particular action has to be defined first before the action can be executed. Most of the current approaches are iterative methods where the trajectory is generated by predicting the next state based on the current state. Here we propose a novel method by utilising a fully convolutional neural network, which allows generation of complete paths, even for several agents without any iterations. We demonstrate that our method is able to successfully generate optimal or close to optimal paths (less than 10% longer) in more than 99% of the cases for single path predictions in 2D and 3D environments. Furthermore, we show that the network is - without specific training on such cases - able to create (close to) optimal paths in 96% of the cases for two and in 84% of the cases for three simultaneously generated paths.

- Walk, Stop, Count, and Swap: Decentralized Multi-Agent Path Finding with Theoretical Guarantees

    Author: Wang, Hanlin | Northwestern University
    Author: Rubenstein, Michael | Northwestern University
 
    keyword: Path Planning for Multiple Mobile Robots or Agents; Distributed Robot Systems; Swarms

    Abstract : For multi-agent path-finding (MAPF) problems, finding the optimal solution has been shown to be NP-Complete. Here we present WSCaS (Walk, Stop, Count, and Swap), a decentralized multi-agent path-finding algorithm that can provide theoretical completeness and optimality guarantees. That is, WSCaS is able to deliver a worst case O(1)-approximate distance-optimal solution to MAPF instances on most grid maps. Moreover, the algorithm's cost is independent of the swarm's size with respect to computation complexity, memory complexity, as well as communication complexity, therefore the algorithm can scale well with the number of agents in practice. The algorithm is executed on 1024 simulated agents as well as 100 physical robots, and the results show that WSCaS is robust to real-world non-idealitys.

- Efficient Iterative Linear-Quadratic Approximations for Nonlinear Multi-Player General-Sum Differential Games

    Author: Fridovich-Keil, David | University of California, Berkeley
    Author: Ratner, Ellis | University of California, Berkeley
    Author: Peters, Lasse | TU Hamburg
    Author: Dragan, Anca | University of California Berkeley
    Author: Tomlin, Claire | UC Berkeley
 
    keyword: Path Planning for Multiple Mobile Robots or Agents; Human-Centered Robotics; Motion and Path Planning

    Abstract : Differential games offer a powerful theoretical framework for formulating safety and robustness problems in optimal control. Unfortunately, numerical solution techniques for general nonlinear dynamical systems scale poorly with state dimension and are rarely used in applications requiring real- time computation. For single-agent optimal control problems, however, local methods based on efficiently solving iterated approximations with linear dynamics and quadratic costs are becoming increasingly popular. We take inspiration from one such method, the iterative linear quadratic regulator (ILQR), and observe that efficient algorithms also exist to solve multi-player linear-quadratic games. Whereas ILQR converges to a local solution of the optimal control problem, if our method converges it returns a local Nash equilibrium of the differential game. We benchmark our method in a three-player general- sum simulated example, in which it takes &lt; 0.75 s to identify a solution and &lt; 50 ms to solve warm-started subproblems in a receding horizon. We also demonstrate our approach in hardware, operating in real-time and following a 10 s receding horizon.

- Online Motion Planning for Deforming Maneuvering and Manipulation by Multilinked Aerial Robot Based on Differential Kinematics

    Author: Zhao, Moju | The University of Tokyo
    Author: Shi, Fan | The University of Tokyo
    Author: Anzai, Tomoki | The University of Tokyo
    Author: Okada, Kei | The University of Tokyo
    Author: Inaba, Masayuki | The University of Tokyo
 
    keyword: Aerial Systems: Applications; Motion and Path Planning; Motion Control

    Abstract : State-of-the-art work on deformable multirotor aerial robots has developed a strong maneuvering ability in such robots, whereas there is no versatile aerial robot that can perform both deforming maneuvering and aerial manipulation yet. However, a novel multilinked aerial robot presented in our previous work, called DRAGON, has both potential because of its serial-link structure. Therefore, an online motion planning method for such a multilinked aerial robot is required. In this paper, we first reveal the general statics model of the multilinked aerial robot, which involves the influence of joint torque, rotor thrust force, external wrench, and gravity, and further discuss the necessary rotor thrust force and joint torque required to compensate for external force and gravity under the quasi-static assumption. Then, we propose a real-time motion planning method, which sequentially solves the differential kinematics problem. This method considers the limitations of rotor thrust force and joint torque, as well as kinematics constraints. Furthermore, we introduce the integrated control framework, which can follow a quasi-static multilinks' trajectory and compensate for the external wrench. Finally, experiments to squeeze a virtual hatch covered by a movable plate are performed with quad-type DRAGON to demonstrate the feasibility of the proposed motion planning method in real-time.

- DDM: Fast Near-Optimal Multi-Robot Path Planning Using Diversified-Path and Optimal Sub-Problem Solution Database Heuristics

    Author: Han, Shuai D. | Rutgers University
    Author: Yu, Jingjin | Rutgers University
 
    keyword: Path Planning for Multiple Mobile Robots or Agents; Planning, Scheduling and Coordination; Multi-Robot Systems

    Abstract : We propose a novel centralized and decoupled algorithm, DDM, for solving multi-robot path planning problems in grid graphs, targeting on-demand and automated warehouse-like settings. Two settings are studied: a traditional one whose objective is to move a set of robots from their respective initial vertices to the goal vertices as quickly as possible, and a dynamic one which requires frequent re-planning to accommodate for goal configuration adjustments. Among other techniques, DDM is mainly enabled through exploiting two innovative heuristics: path diversification and optimal sub-problem solution databases. The two heuristics attack two distinct phases of a decoupling-based planner: while path diversification allows the more effective use of the entire workspace for robot travel, optimal sub-problem solution databases facilitate the fast resolution of local path conflicts. Extensive evaluation demonstrates that DDM achieves high levels of scalability and solution quality close to the optimum.

- UBAT: On Jointly Optimizing UAV Trajectories and Placement of Battery Swap Stations

    Author: Won, Myounggyu | University of Memphis
 
    keyword: Path Planning for Multiple Mobile Robots or Agents; Aerial Systems: Applications; Motion and Path Planning

    Abstract : Unmanned aerial vehicles (UAVs) have been widely used in many applications. The limited flight time of UAVs, however, still remains as a major challenge. Although numerous approaches have been developed to recharge the battery of UAVs effectively, little is known about optimal methodologies to deploy charging stations. In this paper, we address the charging station deployment problem with an aim to find the optimal number and locations of charging stations such that the system performance is maximized. We show that the problem is NP-Hard and propose UBAT, a heuristic framework based on the ant colony optimization (ACO) to solve the problem. Additionally, a suite of algorithms are designed to enhance the execution time and the quality of the solutions for UBAT. Through extensive simulations, we demonstrate that UBAT effectively performs multi-objective optimization of generation of UAV trajectories and placement of charging stations that are within 8.3% and 7.3% of the true optimal solutions, respectively.

- Efficient Multi-Agent Trajectory Planning with Feasibility Guarantee Using Relative Bernstein Polynomial

    Author: Park, Jungwon | Seoul National University
    Author: Kim, Junha | Seoul National University
    Author: Jang, Inkyu | Seoul National University
    Author: Kim, H. Jin | Seoul National University
 
    keyword: Path Planning for Multiple Mobile Robots or Agents; Collision Avoidance; Swarms

    Abstract : This paper presents a new efficient algorithm which guarantees a solution for a class of multi-agent trajectory planning problems in obstacle-dense environments. Our algorithm combines the advantages of both grid-based and optimization-based approaches, and generates safe, dynamically feasible trajectories without suffering from an erroneous optimization setup such as imposing infeasible collision constraints. We adopt a sequential optimization method with dummy agents to improve the scalability of the algorithm, and utilize the convex hull property of Bernstein and relative Bernstein polynomial to replace non-convex collision avoidance constraints to convex ones. The proposed method can compute the trajectory for 64 agents on average 6.36 seconds with Intel Core i7-7700 @ 3.60GHz CPU and 16G RAM, and it reduces more than 50% of the objective cost compared to our previous work. We validate the proposed algorithm through simulation and flight tests.

- Optimal Sequential Task Assignment and Path Finding for Multi-Agent Robotic Assembly Planning

    Author: Brown, Kyle | Stanford University
    Author: Peltzer, Oriana | Stanford University
    Author: Sehr, Martin | Siemens Corporation
    Author: Schwager, Mac | Stanford University
    Author: Kochenderfer, Mykel | Stanford University
 
    keyword: Path Planning for Multiple Mobile Robots or Agents; Multi-Robot Systems; Intelligent and Flexible Manufacturing

    Abstract : We study the problem of sequential task assignment and collision-free routing for large teams of robots in applications with inter-task precedence constraints (e.g., task A and task B must both be completed before task C may begin). Such problems commonly occur in assembly planning for robotic manufacturing applications, in which sub-assemblies must be completed before they can be combined to form the final product. We propose a hierarchical algorithm for computing makespan-optimal solutions to the problem. The algorithm is evaluated on a set of randomly generated problem instances where robots must transport objects between stations in a ``factory'' grid world environment. In addition, we demonstrate in high-fidelity simulation that the output of our algorithm can be used to generate collision-free trajectories for non-holonomic differential-drive robots.

- Cooperative Multi-Robot Navigation in Dynamic Environment with Deep Reinforcement Learning

    Author: Han, Ruihua | Southern University of Science and Technology
    Author: Chen, Shengduo | Southern University of Science and Technology
    Author: Hao, Qi | Southern University of Science and Technology
 
    keyword: Path Planning for Multiple Mobile Robots or Agents; Deep Learning in Robotics and Automation; Multi-Robot Systems

    Abstract : The challenges of multi-robot navigation in dynamic environments lie in uncertainties in obstacle complexities, partially observation of robots, and policy implementation from simulations to the real world. This paper presents a cooperative approach to address the multi-robot navigation problem (MRNP) under dynamic environments using a deep reinforcement learning (DRL) framework, which can help multiple robots jointly achieve optimal paths despite a certain degree of obstacle complexities. The novelty of this work includes threefold: (1) developing a cooperative architecture that robots can exchange information with each other to select the optimal target locations; (2) developing a DRL based framework which can learn a navigation policy to generate the optimal paths for multiple robots; (3) developing a training mechanism based on dynamics randomization which can make the policy generalized and achieve the maximum performance in the real world. The method is tested with Gazebo simulations and 4 differential-driven robots. Both simulation and experiment results validate the superior performance of the proposed method in terms of success rate and travel time when compared with the other state-of-art technologies.

- Adaptive Directional Path Planner for Real-Time, Energy-Efficient, Robust Navigation of Mobile Robots

    Author: Nimmagadda, Mallikarjuna Rao | Intel Corporation
    Author: Dattawadkar, Shreela | Intel
    Author: Muthukumar, Sriram | Intel Corporation
    Author: Honkote, Vinayak | Intel Corporation
 
    keyword: Path Planning for Multiple Mobile Robots or Agents; Distributed Robot Systems; Autonomous Agents

    Abstract : Autonomous navigation through unknown and complex environments is a fundamental capability that is essential in almost all robotic applications. Optimal robot path planning is critical to enable efficient navigation. Path planning is a complex, compute and memory intensive task. Traditional methods employ either graph based search methods or sample based methods to implement path planning, which are sub-optimal and compute/memory-intensive. To this end, an Adaptive Directional Planner (ADP) algorithm is devised to achieve real-time, energy-efficient, memory-optimized, robust local path planning for enabling efficient autonomous navigation of mobile robots. The ADP algorithm ensures that the paths are optimal and kinematically-feasible. Further, the proposed algorithm is tested with different challenging scenarios verifying the functionality and robustness. The ADP algorithm implementation results demonstrate 40&#8722;60X less number of nodes and 40 &#8722; 50X less execution time compared to the standard TP-RRT schemes, without compromising on accuracy. Finally, the algorithm has also been implemented as an accelerator for non-holonomic, multi-shape, small form factor mobile robots to provide a silicon solution with high performance and low memory footprint (28KB).

- Distributed State Estimation Using Intermittently Connected Robot Networks (I)

    Author: Khodayi-mehr, Reza | Duke University
    Author: Kantaros, Yiannis | University of Pennsylvania
    Author: Zavlanos, Michael M. | Duke University
 
    keyword: Path Planning for Multiple Mobile Robots or Agents; Formal Methods in Robotics and Automation; Sensor Fusion

    Abstract : We consider the problem of distributed state estimation using multi-robot systems. The robots have limited communication capabilities and only communicate their measurements intermittently, when they are physically close. To decrease the travel distance needed only to communicate, we divide the robots into small teams that communicate at different locations. Then, we propose a new distributed scheme that combines (i) communication schedules that ensure that the network is intermittently connected, and (ii) sampling-based motion planning for the robots in every team to collect optimal measurements and decide on a meeting time and location. This is the first distributed state estimation framework that relaxes all network connectivity assumptions and controls intermittent communication events so that the estimation uncertainty is minimized. Our results show significant improvement in estimation accuracy compared to methods that maintain end-to-end connection for all time.

## Optimization and Optimal Control
- Whole-Body Motion Tracking for a Quadruped-On-Wheel Robot Via a Compact-Form Controller with Improved Prioritized Optimization

    Author: Du, Wenqian | Sorbonne University, ISIR, Paris 6
    Author: Fnadi, Mohamed | ISIR - Sorbonne University
    Author: Ben Amar, Faiz | Université Pierre Et Marie Curie, Paris 6
 
    keyword: Optimization and Optimal Control; Dynamics; Legged Robots

    Abstract : This paper develops a more general dynamics controller to generate whole-body behaviors for a quadruped-on-wheel robot. To track the quadruped centroidal motion, the wheeled motion is achieved by combining the wheel contact constraints and the centroidal momentum/dynamics model. The dynamics controller is based on a new hybrid hierarchical and prioritized weighted optimization framework. We propose one concept of a recursively updated dynamics model and this model enables to integrate the new prioritized weighted scheme in the hierarchical framework. In contrast with the conventional weighted scheme, we propose to use null-space projections among its sub-tasks. Then the prioritized impedance controller is proposed and integrated in our dynamics model, which enables to influence the hierarchical and prioritized weighted tasks in a decoupled way. The task accelerations in the two schemes are extracted with quadratic forms depending on the actuated torque and the prioritized impedance force using null-space based inverse dynamics. The inequality constraints are modified to ensure the compatibility with the hybrid convex optimization. This dynamics controller is more general and its algorithm is given completely which enables our robot to track the centroidal motion on rough terrain and handle other missions in three simulation scenarios.

- Optimal Control of an Energy-Recycling Actuator for Mobile Robotics Applications

    Author: Krimsky, Erez | Stanford University
    Author: Collins, Steven H. | Stanford University
 
    keyword: Optimization and Optimal Control; Force Control; Prosthetics and Exoskeletons

    Abstract : Actuator power consumption is a limiting factor in mobile robot design. In this paper we introduce the concept of an energy-recycling actuator, which uses an array of springs and clutches to capture and return elastic energy in parallel with an electric motor. Engaging and disengaging clutches appropriately could reduce electrical energy consumption without sacrificing controllability, but presents a challenging control problem. We formulated the optimal control objective of minimizing actuator power consumption as a mixed-integer quadratic program (MIQP) and solved for the global minimum. For a given actuator design and a wide range of simulated torque and rotation patterns, all corresponding to zero net work over one cycle, we compared optimized actuator energy consumption to that of an optimized gear motor with simple parallel elasticity. The simulated energy-recycling actuator consumed less electrical energy: 57% less on average and 80% less in the best case. These results demonstrate an effective approach to optimal control of this type of system, and suggest that energy-recycling actuators could substantially reduce power consumption in some robotics applications.

- Real-Time Nonlinear Model Predictive Control of Robots Using a Graphics Processing Unit

    Author: Hyatt, Phillip | Brigham Young University
    Author: Killpack, Marc | Brigham Young University
 
    keyword: Optimization and Optimal Control; Control Architectures and Programming; Deep Learning in Robotics and Automation

    Abstract : In past robotics applications, Model Predictive Control (MPC) has been limited to linear models and relatively short time horizons. In recent years however, research in optimization, optimal control, and simulation has enabled some forms of nonlinear model predictive control which find locally optimal solutions. The limiting factor for applying nonlinear MPC for robotics remains the computation necessary to solve the optimization, especially for complex systems and for long time horizons. This paper presents a new method which addresses computational concerns related to nonlinear MPC called nonlinear Evolutionary MPC (NEMPC), and then compares it to several existing methods. These comparisons include simulations on torque-limited robots performing a swing-up task and demonstrate that NEMPC is able to discover complex behaviors to accomplish the task. Comparisons with state-of-the-art nonlinear MPC algorithms show that NEMPC finds high quality control solutions very quickly using a global, instead of local, optimization. Finally, an application in hardware (a 24 state pneumatically actuated continuum soft robot) demonstrates that this method is tractable for real-time control of high degree of freedom systems.

- An NMPC Approach Using Convex Inner Approximations for Online Motion Planning with Guaranteed Collision Avoidance

    Author: Schoels, Tobias | University of Freiburg
    Author: Palmieri, Luigi | Robert Bosch GmbH
    Author: Arras, Kai Oliver | Bosch Research
    Author: Diehl, Moritz | Univ. of Heidelberg
 
    keyword: Optimization and Optimal Control; Collision Avoidance; Nonholonomic Motion Planning

    Abstract : Even though mobile robots have been around for decades, trajectory optimization and continuous time collision avoidance remain subject of active research. Existing methods trade off between path quality, computational complexity, and kinodynamic feasibility. This work approaches the problem using a nonlinear model predictive control (NMPC) framework, that is based on a novel convex inner approximation of the collision avoidance constraint. The proposed Convex Inner ApprOximation (CIAO) method finds kinodynamically feasible and continuous time collision free trajectories, in few iterations, typically one. For a feasible initialization, the approach is guaranteed to find a feasible solution, i.e. it preserves feasibility. Our experimental evaluation shows that CIAO outperforms state of the art baselines in terms of planning efficiency and path quality. Experiments show that it also efficiently scales to high-dimensional systems. Furthermore real-world experiments demonstrate its capability of unifying trajectory optimization and tracking for safe motion planning in dynamic environments.

- Multi-Contact Heavy Object Pushing with a Centaur-Type Humanoid Robot: Planning and Control for a Real Demonstrator

    Author: Parigi Polverini, Matteo | Istituto Italiano Di Tecnologia (IIT)
    Author: Laurenzi, Arturo | Istituto Italiano Di Tecnologia
    Author: Mingo Hoffman, Enrico | Fondazione Istituto Italiano Di Tecnologia
    Author: Ruscelli, Francesco | Istituto Italiano Di Tecnologia
    Author: Tsagarakis, Nikos | Istituto Italiano Di Tecnologia
 
    keyword: Optimization and Optimal Control; Humanoid Robots; Mobile Manipulation

    Abstract : Performing a demanding manipulation task with a multi-legged loco-manipulation platform may require the exploitation of multiple external contacts with different environment surfaces for counteracting the manipulation forces. This is the case of the pushing task of a heavy object, where the grip forces at ground may not be adequate and establishing leg contacts against a wall turns out to be an effective solution to the manipulation problem. In order to produce such behaviour, this paper presents a control architecture that is able to freely exploit the environment complexity to perform loco-manipulation actions, e.g. pushing a heavy object, while meeting the implementation requirements to achieve a real demonstrator. The proposed approach, conceived for torque-controlled platforms, combines the planning capabilities of nonlinear optimization over the robot centroidal statics, based on a continuous description of the environment through superquadric functions, with the instantaneous capabilities of hierarchical inverse kinematics and reactive contact force distribution. Experimental validation has been performed on the pushing task of a wooden cabinet loaded with bricks, using the CENTAURO robot developed at Istituto Italiano di Tecnologia (IIT).

- Hierarchical Stochastic Optimization with Application to Parameter Tuning for Electronically Controlled Transmissions

    Author: Karasawa, Hiroyuki | The University of Tokyo
    Author: Kanemaki, Tomohiro | Komatsu Ltd
    Author: Oomae, Kei | Komatsu Ltd
    Author: Fukui, Rui | The University of Tokyo
    Author: Nakao, Masayuki | The University of Tokyo
    Author: Osa, Takayuki | Kyushu Institute of Technology
 
    keyword: Optimization and Optimal Control; AI-Based Methods; Industrial Robots

    Abstract : In mechanical systems, control parameters are often manually tuned by an expert through trial and error, which is labor-intensive and time-consuming. In addition, the difficulty of this problem is that there often exist multiple solutions that provide high returns. As a designed objective function is often not optimal in practice, the solution that provides the highest return may not be the optimal solution. Therefore, it is often necessary to verify the multiple candidates of the solution to identify the one most suitable for the actual system. To address this issue, we propose a parameter optimization system using hierarchical stochastic optimization (HSO) that can handle multimodal objective functions. In a case study of electronically controlled transmissions, the optimizer learns multiple sets of parameters that satisfy all constraints and outperforms the parameters manually designed by human engineers. We demonstrate experimentally that our HSO can identify several modes of the objective function and is more sample-efficient than the existing methods, such as cross-entropy method and covariance matrix adaptation evolution strategy, as well as a human engineer.

- Targeted Drug Delivery: Algorithmic Methods for Collecting a Swarm of Particles with Uniform, External Forces

    Author: Becker, Aaron | University of Houston
    Author: Fekete, S�ndor | Technische Universitét Braunschweig
    Author: Huang, Li | University of Houston
    Author: Keldenich, Phillip | TU Braunschweig
    Author: Kleist, Linda | Technische Universitét Braunschweig
    Author: Krupke, Dominik Michael | TU Braunschweig, IBR, Algorithms Group
    Author: Rieck, Christian | Technische Universitét Braunschweig
    Author: Schmidt, Arne | TU Braunschweig
 
    keyword: Optimization and Optimal Control; Medical Robots and Systems; AI-Based Methods

    Abstract : We investigate algorithmic approaches for targeted drug delivery in a complex, maze-like environment, such as a vascular system. The basic scenario is given by a large swarm of micro-scale particles ("agents") and a particular target region ("tumor") within a system of passageways. Agents are too small to contain on-board power or computation and are instead controlled by a global external force that acts uniformly on all particles, such as an applied fluidic flow or electromagnetic field. The challenge is to deliver all agents to the target region with a minimum number of actuation steps. We provide a number of results for this challenge. We show that the underlying problem is NP-hard, which explains why previous work did not provide provably efficient algorithms. We also develop a number of algorithmic approaches that greatly improve the worst-case guarantees for the number of required actuation steps. We evaluate our algorithmic approaches by a number of simulations, both for deterministic algorithms and searches supported by deep learning, which show that the performance is practically promising.

-  Virtual Point Control Strategy with Power Optimization for Trajectory Planning of Autonomous Mobile Robots

    Author: Merzouki, Rochdi | CRIStAL, CNRS UMR 9189, University of Lille1
    Author: Bensekrane, Ismail | Polytech Lille, University of Lille 1
    Author: Drakunov, Sergey | IHMC

- Enhancing Bilevel Optimization for UAV Time-Optimal Trajectoryusing a Duality Gap Approach

    Author: Tang, Gao | University of Illinois at Urbana-Champaign
    Author: Sun, Weidong | Duke University
    Author: Hauser, Kris | University of Illinois at Urbana-Champaign
 
    keyword: Optimization and Optimal Control; Aerial Systems: Perception and Autonomy; Autonomous Agents

    Abstract : Time-optimal trajectories for dynamic robotic vehicles are difficult to compute even for state-of-the-art nonlinear programming (NLP) solvers, due to nonlinearity and bang-bang control structure. This paper presents a bilevel optimization framework that addresses these problems by decomposing the spatial and temporal variables into a hierarchical optimization. Specifically, the original problem is divided into an inner layer, which computes a time-optimal velocity profile along a given geometric path, and an outer layer, which refines the geometric path by a Quasi-Newton method. The inner optimization is convex and efficiently solved by interior-point methods. The gradients of the outer layer can be analytically obtained using sensitivity analysis of parametric optimization problems. A novel contribution is to introduce a duality gap in the inner optimization rather than solving it to optimality; this lets the optimizer realize warm-starting of the interior-point method, avoids non-smoothness of the outer cost function caused by active inequality constraint switching. Like prior bilevel frameworks, this method is guaranteed to return a feasible solution at any time, but converges faster than gap-free bilevel optimization. Numerical experiments on a drone model with velocity and acceleration limits show that the proposed method performs faster and more robustly than gap-free bilevel optimization and general NLP solvers.

- Constrained Sampling-Based Trajectory Optimization Using StochasticApproximation

    Author: Boutselis, George | Georgia Tech
    Author: Wang, Ziyi | Georgia Institute of Technology
    Author: Theodorou, Evangelos | Georgia Institute of Technology
 
    keyword: Optimization and Optimal Control; Collision Avoidance; Probability and Statistical Methods

    Abstract : We propose a sampling-based trajectory optimiza- tion methodology for constrained problems. We extend recent works on stochastic search to deal with box control constraints, as well as nonlinear state constraints for discrete dynamical systems. Regarding the former, our strategy is to optimize over truncated parameterized distributions on control inputs. Furthermore, we show how non-smooth penalty functions can be incorporated into our framework to handle state constraints. Numerical simulations show that our approach outperforms previous methods on constrained sampling-based optimization, in terms of quality of solutions and sample efficiency.

- Learning Control Policies from Optimal Trajectories

    Author: Zelch, Christoph | Technische Universitét Darmstadt
    Author: Peters, Jan | Technische Universitét Darmstadt
    Author: von Stryk, Oskar | Technische Universitét Darmstadt
 
    keyword: Optimization and Optimal Control; Learning and Adaptive Systems; Probability and Statistical Methods

    Abstract : The ability to optimally control robotic systems offers significant advantages for their performance. While time-dependent optimal trajectories can numerically be computed for high dimensional nonlinear system dynamic models, constraints and objectives, finding optimal feedback control policies for such systems is hard. This is unfortunate, as without a policy, the control of real-world systems requires frequent correction or replanning to compensate for disturbances and model errors. In this paper, a feedback control policy is learned from a set of optimal reference trajectories using Gaussian processes. Information from existing trajectories and the current policy is used to find promising start points for the computation of further optimal trajectories. This aspect is important as it avoids exhaustive sampling of the complete state space, which is impractical due to the high dimensional state space, and to focus on the relevant region. The presented method has been applied in simulation to a swing-up problem of an underactuated pendulum and an energy- minimal point-to-point movement of a 3-DOF industrial robot.

- Crocoddyl: An Efficient and Versatile Framework for Multi-Contact Optimal Control

    Author: Mastalli, Carlos | University of Edinburgh
    Author: Budhiraja, Rohan | LAAS, CNRS
    Author: Merkt, Wolfgang Xaver | The University of Edinburgh
    Author: Saurel, Guilhem | LAAS-CNRS
    Author: Hammoud, Bilal | Max Planck Institute
    Author: Naveau, Maximilien | LAAS/CNRS
    Author: Carpentier, Justin | INRIA
    Author: Righetti, Ludovic | New York University
    Author: Vijayakumar, Sethu | University of Edinburgh
    Author: Mansard, Nicolas | CNRS
 
    keyword: Optimization and Optimal Control; Legged Robots; Humanoid and Bipedal Locomotion

    Abstract : We introduce Crocoddyl (Contact RObot COntrol by Differential DYnamic Library), an open-source framework tailored for efficient multi-contact optimal control. Crocoddyl efficiently computes the state trajectory and the control policy for a given predefined sequence of contacts. Its efficiency is due to the use of sparse analytical derivatives, exploitation of the problem structure, and data sharing. It employs differential geometry to properly describe the state of any geometrical system, e.g. floating-base systems. Additionally, we propose a novel optimal control algorithm called Feasibility-driven Differential Dynamic Programming (FDDP). Our method does not add extra decision variables which often increases the computation time per iteration due to factorization. FDDP shows a greater globalization strategy compared to classical Differential Dynamic Programming (DDP) algorithms. Concretely, we propose two modifications to the classical DDP algorithm. First, the backward pass accepts infeasible state-control trajectories. Second, the rollout keeps the gaps open during the early "exploratory" iterations (as expected in multiple-shooting methods with only equality constraints). We showcase the performance of our framework using different tasks. With our method, we can compute highly-dynamic maneuvers (e.g. jumping, front-flip) within few milliseconds.

- Path-Following Model Predictive Control of Ballbots

    Author: Jespersen, Thomas Kølbæk | APTIV, Formerly NuTonomy
    Author: Al Ahdab, Mohamad | Aalborg University
    Author: Flores-Mendez, Juan de Dios | Aalborg University
    Author: Damgaard, Malte Rørmose | Aalborg University
    Author: Hansen, Karl Damkjær | Aalborg University
    Author: Pedersen, Rasmus | Aalborg University
    Author: Bak, Thomas | Aalborg University
 
    keyword: Optimization and Optimal Control; Underactuated Robots; Motion and Path Planning

    Abstract : This paper introduces a novel approach for model predictive control of ballbots for path-following tasks. Ballbots are dynamically unstable mobile robots which are designed to balance on a single ball. The model presented in this paper is a simplified version of a full quaternion-based model of ballbots' underactuated dynamics which is suited for online implementation. Furthermore, the approach is extended to handle nearby obstacles directly in the MPC formulation. The presented controller is validated through simulation on a high fidelity model as well as through real-world experiments on a physical ballbot system.

- Underactuated Waypoint Trajectory Optimization for Light Painting Photography

    Author: Eilers, Christian | Technische Universitét Darmstadt
    Author: Eschmann, Jonas | Technische Universitét Darmstadt
    Author: Menzenbach, Robin | Technische Universitét Darmstadt
    Author: Belousov, Boris | Technische Universitét Darmstadt
    Author: Muratore, Fabio | TU Darmstadt
    Author: Peters, Jan | Technische Universitét Darmstadt
 
    keyword: Optimization and Optimal Control; Motion and Path Planning; Underactuated Robots

    Abstract : Despite their abundance in robotics and nature, underactuated systems remain a challenge for control engineering. Trajectory optimization provides a generally applicable solution, however its efficiency strongly depends on the skill of the engineer to frame the problem in an optimizer-friendly way. This paper proposes a procedure that automates such problem reformulation for a class of tasks in which the desired trajectory is specified by a sequence of waypoints. The approach is based on introducing auxiliary optimization variables that represent waypoint activations. To validate the proposed method, a letter drawing task is set up where shapes traced by the tip of a rotary inverted pendulum are visualized using long exposure photography.

- Whole-Body Walking Generation Using Contact Parametrization: A Non-Linear Trajectory Optimization Approach

    Author: Dafarra, Stefano | Istituto Italiano Di Tecnologia
    Author: Romualdi, Giulio | Fondazione Istituto Italiano Di Tecnologia
    Author: Metta, Giorgio | Istituto Italiano Di Tecnologia (IIT)
    Author: Pucci, Daniele | Italian Institute of Technology
 
    keyword: Optimization and Optimal Control; Humanoid and Bipedal Locomotion; Motion and Path Planning

    Abstract : In this paper, we describe a planner capable of generating walking trajectories by using the centroidal dynamics and the full kinematics of a humanoid robot model. The interaction between the robot and the walking surface is modeled explicitly through a novel contact parametrization. The approach is complementarity-free and does not need a predefined contact sequence. By solving an optimal control problem we obtain walking trajectories. In particular, through a set of constraints and dynamic equations, we model the robot in contact with the ground. We describe the objective the robot needs to achieve with a set of tasks. The whole optimal control problem is transcribed into an optimization problem via a Direct Multiple Shooting approach and solved with an off-the-shelf solver. We show that it is possible to achieve walking motions automatically by specifying a minimal set of references, such as a constant desired Center of Mass velocity and a reference point on the ground.

- Controlling Fast Height Variation of an Actively Articulated Wheeled Humanoid Robot Using Center of Mass Trajectory

    Author: Otubela, Moyin | Trinity College Dublin
    Author: McGinn, Conor | Trinity College Dublin
 
    keyword: Optimization and Optimal Control; Dynamics; Kinematics

    Abstract : Hybrid wheel-legged robots have begun to demonstrate the ability to adapt to complex terrain traditionally inaccessible to purely wheeled morphologies. Further research is needed into how their dynamics can be optimally controlled for developing highly adaptive behaviours on challenging terrain. Using optimal center of mass (COM) kinematic trajectories, this work examines the nonlinear dynamics control problem for fast height adaptation on the hybrid humanoid platform known as Aerobot. We explore the dynamics control problem through experimentation with an offline trajectory optimisation (TO) method and a task-space inverse dynamics (TSID) controller for varying the robot's height. Our TO approach uses sequential quadratic programming (SQP) to solve optimal 7th order spline coefficients for the robot's kinematics. The nonlinear Zero Moment Point (ZMP) is used to model a stability criterion that is constrained in the TO problem to ensure dynamic stability. Our TSID controller follows motion plans based on using task jacobians and a simplified passive dynamics model of the Aerobot platform. Results exhibit fast height adaptation on the Aerobot platform with significantly differing results between the control methods that prompts new research into how it may be controlled online.

- Contact-Aware Controller Design for Complementarity Systems

    Author: Aydinoglu, Alp | University of Pennsylvania
    Author: Preciado, Victor | University of Pennsylvania
    Author: Posa, Michael | University of Pennsylvania
 
    keyword: Optimization and Optimal Control; Force Control; Contact Modeling

    Abstract : While many robotic tasks, like manipulation and locomotion, are fundamentally based in making and breaking contact with the environment, state-of-the-art control policies struggle to deal with the hybrid nature of multi-contact motion. Such controllers often rely heavily upon heuristics or, due to the combinatoric structure in the dynamics, are unsuitable for real-time control. Principled deployment of tactile sensors offers a promising mechanism for stable and robust control, but modern approaches often use this data in an ad hoc manner, for instance to guide guarded moves. In this work, by exploiting the complementarity structure of contact dynamics, we propose a control framework which can close the loop on rich, tactile sensors. Critically, this framework is non-combinatoric, enabling optimization algorithms to automatically synthesize provably stable control policies. We demonstrate this approach on three different underactuated, multi-contact robotics problems.

-  Trajectory Optimization of Robots with Regenerative Drive Systems: Numerical and Experimental Results (I)

    Author: Khalaf, Poya | Cleveland State University
    Author: Richter, Hanz | Cleveland State University


- Exploiting Sparsity in Robot Trajectory Optimization with Direct Collocation and Geometric Algorithms

    Author: Cardona-Ortiz, Daniel | Cinvestav
    Author: Alvaro Paz, Alveiro | CINVESTAV
    Author: Arechavaleta, Gustavo | CINVESTAV
 
    keyword: Optimization and Optimal Control; Dynamics

    Abstract : This paper presents a robot trajectory optimization formulation that builds upon numerical optimal control and Lie group methods. In particular, the inherent sparsity of direct collocation is carefully analyzed to dramatically reduce the number of floating-point operations to get first-order information of the problem. We describe how sparsity exploitation is employed with both numerical and analytical differentiation. Furthermore, the use of geometric algorithms based on Lie groups and their associated Lie algebras allow to analytically evaluate the state equations and their derivatives with efficient recursive algorithms. We demonstrate the scalability of the proposed formulation with three different articulated robots, such as a finger, a mobile manipulator and a humanoid composed of five, eight and more than twenty degrees of freedom, respectively. The performance of our implementation in C++ is also validated and compared against a state-of-the-art general purpose numerical optimal control solver.

- Bi-Convex Approximation of Non-Holonomic Trajectory Optimization

    Author: Singh, Arun Kumar | Tampere University of Technology, Finland
    Author: Theerthala, Raghu Ram | International Institute of Information Technology, Hyderabad
    Author: Nallana, Mithun Babu | International Institute of Information Technology, Hyderabad
    Author: Krishnan R Nair, Unni | IIITH
    Author: Krishna, Madhava | IIIT Hyderabad
 
    keyword: Optimization and Optimal Control; Nonholonomic Motion Planning; Autonomous Vehicle Navigation

    Abstract : Autonomous cars and fixed-wing aerial vehicles have the so-called non-holonomic kinematics which non-linearly maps control input to states. As a result, trajectory optimization with such a motion model becomes highly non-linear and non-convex. In this paper, we improve the computational tractability of non-holonomic trajectory optimization by reformulating it in terms of a set of bi-convex cost and constraint functions along with a non-linear penalty. The bi-convex part acts as a relaxation for the non-holonomic trajectory optimization while the residual of the penalty dictates how well its output obeys the non-holonomic behavior. We adopt an alternating minimization approach for solving the reformulated problem and show that it naturally leads to the replacement of the challenging non-linear penalty with a globally valid convex surrogate. Along with the common cost functions modeling goal-reaching, trajectory smoothness, etc., the proposed optimizer can also accommodate a class of non-linear costs for modeling goal-sets, while retaining the bi-convex structure. We benchmark the proposed optimizer against off-the-shelf solvers implementing sequential quadratic programming and interior-point methods and show that it produces solutions with similar or better cost as the former while significantly outperforming the latter. Furthermore, as compared to both off-the-shelf solvers, the proposed optimizer achieves more than 20x reduction in computation time.

- Fast, Versatile, and Open-Loop Stable Running Behaviors with Proprioceptive-Only Sensing Using Model-Based Optimization

    Author: Gao, Wei | Florida State University
    Author: Young, Charles | Florida State University
    Author: Nicholson, John | Florida State University
    Author: Hubicki, Christian | Florida State University
    Author: Clark, Jonathan | Florida State University
 
    keyword: Optimization and Optimal Control; Robust/Adaptive Control of Robotic Systems; Legged Robots

    Abstract : As we build our legged robots smaller and cheaper, stable and agile control without expensive inertial sensors becomes increasingly important. We seek to enable versatile dynamic behaviors on robots with limited modes of state feedback, specifically proprioceptive-only sensing. This work uses model-based trajectory optimization methods to design open-loop stable motion primitives. We specifically design running gaits for a single-legged planar robot, and can generate motion primitives in under 3 seconds, approaching online-capable speeds. A direct-collocation-formulated optimization generated axial force profiles for the direct-drive robot to achieve desired running speed and apex height. When implemented in hardware, these trajectories produced open-loop stable running. Further, the measured running achieved the desired speed within 10% of the speed specified for the optimization in spite of having no control loop actively measuring or controlling running speed. Additionally, we examine the shape of the optimized force profile and observe features that may be applicable to open-loop stable running in general.

- Wasserstein Distributionally Robust Motion Planning and Control with Safety Constraints Using Conditional Value-At-Risk

    Author: Hakobyan, Astghik | Seoul National University
    Author: Yang, Insoon | Seoul National University
 
    keyword: Optimization and Optimal Control; Collision Avoidance; Motion Control

    Abstract : In this paper, we propose an optimization-based decision-making tool for safe motion planning and control in an environment with randomly moving obstacles. The unique feature of the proposed method is that it limits the risk of unsafety by a pre-specified threshold even when the true probability distribution of the obstacles' movements deviates, within a Wasserstein ball, from an available empirical distribution. Another advantage is that it provides a probabilistic out-of-sample performance guarantee of the risk constraint. To develop a computationally tractable method for solving the distributionally robust model predictive control problem, we propose a set of reformulation procedures using (i) the Kantorovich duality principle, (ii) the extremal representation of conditional value-at-risk, and (iii) a geometric expression of the distance to the union of halfspaces. The performance and utility of this distributionally robust method are demonstrated through simulations using a 12D quadrotor model in a 3D environment.

- One Robot for Many Tasks: Versatile Co-Design through Stochastic Programming

    Author: Bravo, Gabriel | University of Notre Dame
    Author: Del Prete, Andrea | Max Planck Institute for Intelligent Systems
    Author: Wensing, Patrick M. | University of Notre Dame
 
    keyword: Optimization and Optimal Control; Legged Robots; Mechanism Design

    Abstract : Versatility is one of the main factors driving the adoption of robots on the assembly line and in other applications. Compared to fixed-automation solutions, a single industrial robot can perform a wide range of tasks (e.g., welding, lifting). In other platforms, such as legged robots, versatility is a necessity to negotiate varied terrains. The ability to balance performance across these anticipated scenarios is one of the main challenges to the process of design. To address this challenge, this paper proposes a new framework for the computational design of versatile robots by considering the interplay between mechanical design and control across multiple tasks and environments. The proposed method optimizes morphology parameters while simultaneously adjusting control parameters using trajectory optimization (TO) so that a single design can fulfill multiple tasks. As its main contribution, the paper details an approach to combine methods from stochastic programming (SP) with TO to address the scalability of these multi-task co-design problems. To assess the effects of this contribution, this paper considers the problems of designing a planar manipulator to transport a range of loads and a hopping monopod robot that must jump across a variety of terrains. The proposed formulation achieves faster solution times and improved scalability in comparison to state of the art co-design solutions.

- Inverse Optimal Control for Multiphase Cost Functions (I)
 
    Author: Jin, Wanxin | Purdue University
    Author: Kulic, Dana | Monash University
    Author: Lin, Jonathan Feng-Shun | University of Waterloo
    Author: Mou, Shaoshuai | Purdue University
    Author: Hirche, Sandra | Technische Universitét M�nchen
 
    keyword: Optimization and Optimal Control; Learning from Demonstration

    Abstract : We consider a dynamical system whose trajectory is a result of minimizing a multiphase cost function. The multiphase cost function is assumed to be a weighted sum of specified features (or basis functions) with phase-dependent weights that switch at some unknown phase transition points. A new inverse optimal control approach for recovering the cost weights of each phase and estimating the phase transition points is proposed. The key idea is to use a length-adapted window moving along the observed trajectory, where the window length is determined by finding the minimal observation length that suffices for a successful cost weight recovery. The effectiveness of the proposed method is first evaluated on a simulated robot arm, and then, demonstrated on a dataset of human participants performing a series of squatting tasks. The results demonstrate that the proposed method reliably retrieves the cost function of each phase and segments each phase of motion from the trajectory with a segmentation accuracy above 90%.

## Grasping


- Action Image Representation: Learning Deep Grasping Policies with Zero Real World Data

    Author: Khansari, Mohi | Google X
    Author: Kappler, Daniel | X (Google)
    Author: Luo, Jianlan | UC Berkeley
    Author: Bingham, Jeffrey | X
    Author: Kalakrishnan, Mrinal | X
 
    keyword: Deep Learning in Robotics and Automation

    Abstract : This paper introduces Action Image, a new grasp proposal representation that allows learning an end-to-end deep-grasping policy. Our model achieves 84% grasp success on 172 real world objects while being trained only in simulation on 48 objects with just naive domain randomization. Similar to computer vision problems, such as object detection, Action Image builds on the idea that object features are invariant to translation in image space. Therefore, grasp quality is invariant when evaluating the object-gripper relationship; a successful grasp for an object depends on its local context, but is independent of the surrounding environment. Action Image represents a grasp proposal as an image and uses a deep convolutional network to infer grasp quality. We show that by using an Action Image representation, trained networks are able to extract local, salient features of grasping tasks that generalize across different objects and environments. We show that this representation works on a variety of inputs, including color images (RGB), depth images (D), and combined color-depth (RGB-D). Our experimental results demonstrate that networks utilizing an Action Image representation exhibit strong domain transfer between training on simulated data and inference on real-world sensor streams. Finally, our experiments show that a network trained with Action Image improves grasp success (84% vs. 53%) over a baseline model with the same structure, but using actions encoded as vectors.

- High Accuracy and Efficiency Grasp Pose Detection Scheme with Dense Predictions

    Author: Cheng, Hu | The Chinese University of Hong Kong
    Author: Ho, Danny | The Chinese University of Hong Kong
    Author: Meng, Max Q.-H. | The Chinese University of Hong Kong
 
    keyword: Service Robots; Perception for Grasping and Manipulation; Grasping

    Abstract : Learning-based grasp pose detection algorithms have boosted the performance of robot grasping, but they usually need manually fine-tuning steps to find the balance between detection accuracy and efficiency. In this paper, we discard these intermediate procedures, like sampling grasps and generating grasp proposals, and propose an end-to-end grasp pose detection model. Our model uses the RGB image as the input and predicts the single grasp pose in each small grid of the image. Furthermore, the best grasps are found by non-maximum suppression (NMS) strategy. The clustering and ranking procedures are left for NMS while the network only generates dense grasp predictions, which keeps the network simple and efficient. To achieve dense predictions, the predicted grasps of our detection model are represented by the 6-channel images with each pixel location representing a rated grasp. To the best of our knowledge, our model is the first neural network that attaches a grasp pose in pixel level. The model achieves 96:5% accuracy which costs 14ms for prediction of a 480*360 resolution RGB image in Cornell Grasp Dataset, and 90.4% robot grasping success rate for unknown objects with a parallel plate gripper in the real environment.

- Transferable Active Grasping and Real Embodied Dataset

    Author: Chen, Xiangyu | Cornell University
    Author: Ye, Zelin | SJTU
    Author: Sun, Jiankai | The Chinese University of Hong Kong
    Author: Fan, Yuda | Shanghai Jiao Tong University
    Author: Hu, Fang | Shanghai Jiao Tong University
    Author: Wang, Chenxi | Shanghai Jiaotong University
    Author: Lu, Cewu | ShangHai Jiao Tong University
 
    keyword: Deep Learning in Robotics and Automation; Model Learning for Control; Visual Servoing

    Abstract : Grasping in cluttered scenes is challenging for robot vision systems, as detection accuracy can be hindered by partial occlusion of objects. We adopt a reinforcement learning (RL) framework and 3D vision architectures to search for feasible viewpoints for grasping by the use of hand-mounted RGB-D cameras. To overcome the disadvantages of photo-realistic environment simulation, we propose a large-scale dataset called Real Embodied Dataset (RED), which includes full-viewpoint real samples on the upper hemisphere with amodal annotation and enables a simulator that has real visual feedback. Based on this dataset, a practical 3-stage transferable active grasping pipeline is developed, that is adaptive to unseen clutter scenes. In our pipeline, we propose a novel mask-guided reward to overcome the sparse reward issue in grasping and ensure category-irrelevant behavior. The grasping pipeline and its possible variants are evaluated with extensive experiments both in simulation and on a real-world UR-5 robotic arm.

- PointNet++ Grasping: Learning an End-To-End Spatial Grasp Generation Algorithm from Sparse Point Clouds

    Author: Ni, Peiyuan | Shanghai Jiao Tong University
    Author: Zhang, Wenguang | Shanghai Jiao Tong University
    Author: Zhu, Xiaoxiao | SJTU
    Author: Cao, Qixin | Shanghai Jiao Tong University
 
    keyword: Deep Learning in Robotics and Automation; Grasping; Perception for Grasping and Manipulation

    Abstract : Grasping for novel objects is important for robot manipulation in unstructured environments. Most of current works require a grasp sampling process to obtain grasp candidates, combined with local feature extractor using deep learning. This pipeline is timecost, expecially when grasp points are sparse such as at the edge of a bowl.	In this paper, we propose an end-to-end approach to directly predict the poses, categories and scores (qualities) of all the grasps. It takes the whole sparse point clouds as the input and requires no sampling or search process. Moreover, to generate training data of muti-object scene, we propose a fast multi-object grasp detection algorithm based on Ferrari Canny metrics. A single-object dataset (79 objects from YCB object set, 23.7k grasps) and a multi-object dataset (20k point clouds with annotations and masks) are generated. A PointNet++ based network combined with multi-mask loss is introduced to deal with different training points. The whole weight size of our network is only about 11.6M, which takes about 102ms for a whole prediction process using a GeForce 840M GPU. Our experiment shows our work get 71.43% success rate and 91.60% completion rate, which performs better than current state-of-art works.

- UniGrasp: Learning a Unified Model to Grasp with Multifingered Robotic Hands

    Author: Shao, Lin | Stanford University
    Author: Ferreira, Fabio | Karlsruhe Institute of Technology
    Author: Jorda, Mikael | Stanford University
    Author: Nambiar, Varun | Stanford University
    Author: Luo, Jianlan | UC Berkeley
    Author: Solowjow, Eugen | Siemens Corporation
    Author: Aparicio Ojea, Juan | Siemens
    Author: Khatib, Oussama | Stanford University
    Author: Bohg, Jeannette | Stanford University
 
    keyword: Deep Learning in Robotics and Automation; Grasping; Multifingered Hands

    Abstract : To achieve a successful grasp, gripper attributes such as its geometry and kinematics play a role as important as the object geometry. The majority of previous work has focused on developing grasp methods that generalize over novel object geometry but are specific to a certain robot hand. We propose UniGrasp, an efficient data-driven grasp synthesis method that considers both the object geometry and gripper attributes as inputs. UniGrasp is based on a novel deep neural network architecture that selects sets of contact points from the input point cloud of the object. The proposed model is trained on a large dataset to produce contact points that are in force closure and reachable by the robot hand. By using contact points as output, we can transfer between a diverse set of multifingered robotic hands. Our model produces over 90 percent valid contact points in Top10 predictions in simulation and more than 90 percent successful grasps in real world experiments for various known two-fingered and three-fingered grippers. Our model also achieves 93 percent, 83 percent and 90 percent successful grasps in real world experiments for an unseen two-fingered gripper and two unseen multi-fingered anthropomorphic robotic hands.

- Grasp for Stacking Via Deep Reinforcement Learning

    Author: Zhang, Junhao | Shandong University
    Author: Zhang, Wei | Shandong University
    Author: Song, Ran | Shandong University
    Author: Ma, Lin | Tencent
    Author: Li, Yibin | Shandong University
 
    keyword: Grasping; Perception for Grasping and Manipulation; Visual Learning

    Abstract : Integrated robotic arm system should contain both grasp and place actions. However, most grasping methods focus more on how to grasp objects, while ignoring the placement of the grasped objects, which limits their applications in various industrial environments. In this research, we propose a model-free deep Q-learning method to learn the grasping-stacking strategy end-to-end from scratch. Our method maps the images to the actions of the robotic arm through two deep networks: the grasping network (GNet) using the observation of the desk and the pile to infer the gripper's position and orientation for grasping, and the stacking network (SNet) using the observation of the platform to infer the optimal location when placing the grasped object. To make a long-range planning, the two observations are integrated in the grasping for stacking network (GSN). We evaluate the proposed GSN on a grasping-stacking task in both simulated and real-world scenarios.

- CAGE: Context-Aware Grasping Engine

    Author: Liu, Weiyu | Georgia Institute of Technology
    Author: Daruna, Angel | Georgia Institute of Technology, Atlanta, GA 30332
    Author: Chernova, Sonia | Georgia Institute of Technology
 
    keyword: Grasping; Perception for Grasping and Manipulation; Deep Learning in Robotics and Automation

    Abstract : Semantic grasping is the problem of selecting stable grasps that are functionally suitable for specific object manipulation tasks. In order for robots to effectively perform object manipulation, a broad sense of contexts, including object and task constraints, needs to be accounted for. We introduce the Context-Aware Grasping Engine, which combines a novel semantic representation of grasp contexts with a neural network structure based on the Wide &amp; Deep model, capable of capturing complex reasoning patterns. We quantitatively validate our approach against three prior methods on a novel dataset consisting of 14,000 semantic grasps for 44 objects, 7 tasks, and 6 different object states. Our approach outperformed all baselines by statistically significant margins, producing new insights into the importance of balancing memorization and generalization of contexts for semantic grasping. We further demonstrate the effectiveness of our approach on robot experiments in which the presented model successfully achieved 31 of 32 suitable grasps. The code and data are available at: https://github.com/wliu88/rail_semantic_grasping

- Time Optimal Motion Planning and Admittance Control for Cooperative Grasping

    Author: Kaserer, Dominik | Johannes Kepler University Linz (JKU)
    Author: Gattringer, Hubert | Johannes Kepler University Linz
    Author: Mueller, Andreas | Johannes Kepler University
 
    keyword: Grasping; Dual Arm Manipulation; Compliance and Impedance Control

    Abstract : Cooperative grasping refers to the situation when an object is manipulated by multiple robots and the grasp is achieved by the unilateral contact between the robots and the object. This is different from the cooperation of multiple robots where each robot rigidly grasps the object. Motion planning of cooperative grasping tasks involves active force control of the interaction wrench in order to ensure stable grasp. This becomes particularly challenging when aiming at time optimal motions. It is crucial that the trajectories are continuous up to third-order, in order to satisfy velocity, acceleration, and jerk as well as torque limits of the robots. A solution approach is presented for the time optimal path following of two robots performing cooperative grasping tasks. The time optimal path is determined with a dynamic programing method. An admittance control scheme in task space is proposed and used to generate the contact wrench. The method is applicable to grasping of general objects that are in surface contact with the robot.

- Jamming-Free Immobilizing Grasps Using Dual-Friction Robotic Fingertips

    Author: Golan, Yoav | Ben Gurion University
    Author: Shapiro, Amir | Ben Gurion University of the Negev
    Author: Rimon, Elon | Technion - Israel Institute of Technology
 
    keyword: Grasping; Mechanism Design; Contact Modeling

    Abstract : Successful grasping of objects with robotic hands is still considered a difficult task. One aspect of the grasping problem is the physical contact interaction between the robotic fingertips and the object. Friction at the fingertip contacts can improve grasp robustness, but frictional fingertips may be difficult to precisely place on the object's perimeter. This paper describes a novel fingertip design that can switch from frictionless to frictional modes. The transformation from frictionless to frictional contact is achieved passively by the finger force exerted on the object at the target grasp. A novel swivel mechanism ensures that the force magnitude required to switch friction states is independent on the grasped object's contact normal direction, ensuring robustness. Analysis of the displacement and eventual sliding of the fingertip contacts in response to external torque is presented, taking into account the friction and compliant behavior of the fingertip mechanism. Experiments validate the analytic model and demonstrate the fingertip's ability to change friction modes by the applied force magnitude irrespective of the contact normal direction. In line with the analytic model predictions, the experiments show that when converted to frictional contacts, the fingertips provide a more robust and hence secure grasp in the presence of external disturbances. The robustness of the fingertips is further validated by real-world demonstrations shown in an external video.

- Force-Guided High-Precision Grasping Control of Fragile and Deformable Objects Using sEMG-Based Force Prediction

    Author: Wen, Ruoshi | Harbin Institute of Technology
    Author: Yuan, Kai | University of Edinburgh
    Author: Wang, Qiang | Harbin Institute of Technology
    Author: Heng, Shuai | Harbin Institute of Technology
    Author: Li, Zhibin | University of Edinburgh
 
    keyword: Grasping; Dexterous Manipulation; Human Factors and Human-in-the-Loop

    Abstract : Regulating contact forces with high precision is crucial for grasping and manipulating fragile or deformable objects. We aim to utilize the dexterity of human hands to regulate the contact forces for robotic hands and exploit human sensory-motor synergies in a wearable and non-invasive way. We extracted force information from the electric activities of skeletal muscles during their voluntary contractions through surface electromyography (sEMG). We built a regression model based on a Neural Network to predict the gripping force from the preprocessed sEMG signals and achieved high accuracy (R<sup>2</sup> = 0.982). Based on the force command predicted from human muscles, we developed a force-guided control framework, where force control was realized via an admittance controller that tracked the predicted gripping force reference to grasp delicate and deformable objects. We demonstrated the effectiveness of the proposed method on a set of representative fragile and deformable objects from daily life, all of which were successfully grasped without any damage or deformation.

- Grasp It Like a Pro: Grasp of Unknown Objects with Robotic Hands Based on Skilled Human Expertise

    Author: Gabellieri, Chiara | University of Pisa
    Author: Angelini, Franco | University of Pisa
    Author: Arapi, Visar | Centro E. Piaggio
    Author: Palleschi, Alessandro | University of Pisa
    Author: Catalano, Manuel Giuseppe | Istituto Italiano Di Tecnologia
    Author: Grioli, Giorgio | Istituto Italiano Di Tecnologia
    Author: Pallottino, Lucia | Université Di Pisa
    Author: Bicchi, Antonio | Université Di Pisa
    Author: Bianchi, Matteo | University of Pisa
    Author: Garabini, Manolo | Université Di Pisa
 
    keyword: Grasping; Perception for Grasping and Manipulation

    Abstract : This work proposes a method to grasp unknown objects with robotic hands based on demonstrations by a skilled human operator. We observed that humans not only are obviously better at grasping with their own hands than robots, but are also when using the same hardware hand as the robot, provided they train for some time. We therefore consider how the grasping skills of a human trained in robot hand use can be transferred to a robot using the same physical hand. The method we propose is that a skilled human user manually operates the robotic hand to grasp a number of elementary objects, consisting in different boxes. A Decision Tree Regressor is trained on the data acquired from the human operator so to generate hand poses able to grasp a general box. This is extended to grasp unknown objects leveraging upon the state of the art Minimum Volume Bounding Box (MVBB) decomposition algorithm that approximates with a number of boxes the shape of an unknown object, based on its point cloud. We report on extensive tests of the proposed approach on a Panda manipulator equipped with a Pisa/IIT SoftHand, achieving a success rate of 86.7% over 105 grasps of 21 different objects.

- Learning to Generate 6-DoF Grasp Poses with Reachability Awareness

    Author: Lou, Xibai | University of Minnesota Twin Cities
    Author: Yang, Yang | University of Minnesota
    Author: Choi, Changhyun | University of Minnesota, Twin Cities
 
    keyword: Grasping; Deep Learning in Robotics and Automation; Perception for Grasping and Manipulation

    Abstract : Motivated by the stringent requirements of unstructured real-world where a plethora of unknown objects reside in arbitrary locations of the surface, we propose a voxel-based deep 3D Convolutional Neural Network (3D CNN) that generates feasible 6-DoF grasp poses in unrestricted workspace with reachability awareness. Unlike the majority of works that predict if a proposed grasp pose within the restricted workspace will be successful solely based on grasp pose stability, our approach further learns a reachability predictor that evaluates if the grasp pose is reachable or not from robot's own experience. To avoid the laborious real training data collection, we exploit the power of simulation to train our networks on a large-scale synthetic dataset. To our best knowledge, this work is the first attempt to take into account the reachability when proposing feasible grasp poses. Experimental results in both simulation and real-world demonstrate that our reachability aware 3D CNN grasping outperforms several other approaches and achieves 82.5% grasping success rate on unknown objects.

- Enhancing Grasp Pose Computation in Gripper Workspace Spheres

    Author: Sorour, Mohamed | University of Lincoln
    Author: Elgeneidy, Khaled | University of Lincoln
    Author: Hanheide, Marc | University of Lincoln
    Author: Abdalmjed, Mohamed | Ain Shams University
    Author: Srinivasan, Aravinda Ramakrishnan | University of Lincoln, UK
    Author: Neumann, Gerhard | University of Lincoln
 
    keyword: Grasping; Grippers and Other End-Effectors; Perception for Grasping and Manipulation

    Abstract : In this paper, enhancement to the novel grasp planning algorithm based on gripper workspace spheres is presented. Our development requires a registered point cloud of the target from different views, assuming no prior knowledge of the object, nor any of its properties. This work features a new set of metrics for grasp pose candidates evaluation, as well as exploring the impact of high object sampling on grasp success rates. In addition to gripper position sampling, we now perform orientation sampling about the x, y, and z-axes, hence the grasping algorithm no longer require object orientation estimation. Successful experiments have been conducted on a simple jaw gripper (Franka Panda gripper) as well as a complex, high Degree of Freedom (DoF) hand (Allegro hand) as a proof of its versatility. Higher grasp success rates of 76% and 85.5% respectively has been reported by real world experiments.

- Minimal Work: A Grasp Quality Metric for Deformable Hollow Objects

    Author: Xu, Jingyi | Technical University of Munich
    Author: Danielczuk, Michael | UC Berkeley
    Author: Ichnowski, Jeffrey | University of North Carolina at Chapel Hill
    Author: Mahler, Jeffrey | University of California, Berkeley
    Author: Steinbach, Eckehard | Technical University of Munich
    Author: Goldberg, Ken | UC Berkeley
 
    keyword: Grasping; Manipulation Planning; Task Planning

    Abstract : Robot grasping of deformable hollow objects such as plastic bottles and cups is challenging, as the grasp should resist disturbances while minimally deforming the object so as not to damage it or dislodge liquids. We propose minimal work as a novel grasp quality metric that combines wrench resistance and object deformation. We introduce an efficient algorithm to compute the work required to resist an external wrench for a manipulation task by solving a linear program. The algorithm first computes the minimum required grasp force and an estimation of the gripper jaw displacements based on the object's empirical stiffness at different locations. The work done by the jaws is the product of the grasp force and the displacements. Grasps requiring minimal work are considered to be of high quality. We collect 460 physical grasps with a UR5 robot and a Robotiq gripper. We consider a grasp to be successful if it completes the task without damaging the object or dislodging the content. Physical experiments suggest that the minimal work quality metric reaches 74.2% balanced accuracy, a metric that is the raw accuracy normalized by the number of successful and failed real-world grasps, and is up to 24.2% higher than classical wrench-based quality metrics.

- Hierarchical 6-DoF Grasping with Approaching Direction Selection

    Author: Choi, Yunho | Seoul National University
    Author: Kee, Hogun | Seoul National University
    Author: Lee, Kyungjae | Seoul National University
    Author: Choy, JaeGoo | Seoul National University
    Author: Min, Junhong | Samsung Electronics
    Author: Lee, Sohee | Technische Universitét M�nchen
    Author: Oh, Songhwai | Seoul National University
 
    keyword: Grasping; Perception for Grasping and Manipulation; Deep Learning in Robotics and Automation

    Abstract : In this paper, we tackle the problem of 6-DoF grasp detection which is crucial for robot grasping in cluttered real-world scenes. Unlike existing approaches which synthesize 6-DoF grasp data sets and train grasp quality networks with input grasp representations based on point clouds, we rather take a novel hierarchical approach which does not use any 6-DoF grasp data. We cast the 6-DoF grasp detection problem as a robot arm approaching direction selection problem using the existing 4-DoF grasp detection algorithm, by exploiting a fully convolutional grasp quality network for evaluating the quality of an approaching direction. To select the best approaching direction with the highest grasp quality, we propose an approaching direction selection method which leverages a geometry-based prior and a derivative-free optimization method. Specifically, we optimize the direction iteratively using the cross entropy method with initial samples of surface normal directions. Our algorithm efficiently finds diverse 6-DoF grasps by the novel way of evaluating and optimizing approaching directions. We validate that the proposed method outperforms other selection methods in scenarios with cluttered objects in a physics-based simulator. Finally, we show that our method outperforms the state-of-the-art grasp detection method in real-world experiments with robots.

- Geometric Characterization of Two-Finger Basket Grasps of 2-D Objects: Contact Space Formulation

    Author: Rimon, Elon | Technion - Israel Institute of Technology
    Author: Pokorny, Florian T. | KTH Royal Institute of Technology
    Author: Wan, Weiwei | Osaka University
 
    keyword: Grasping; Multifingered Hands

    Abstract : This paper considers basket grasps, where a two- finger robot hand forms a basket that can safely lift and carry rigid objects in a 2-D gravitational environment. The two-finger basket grasps form special points in a high-dimensional configuration space of the object and two-finger robot hand. This paper establishes that all two- finger basket grasps can be found in a low-dimensional contact space that parametrizes the two-finger contacts along the supported object boundary. Using contact space, each basket grasp is associated with its depth that provides a security measure while carrying the object, as well as its safety margin away from a critical finger opening where the object drops-off into its intended destination. Geometric techniques that compute the depth and drop-off finger opening are described and illustrated with detailed graphical and numerical examples.

- A Multi-Level Optimization Framework for Simultaneous Grasping and Motion Planning

    Author: Zimmermann, Simon | ETH Zurich
    Author: Hakimifard, Ghazal | ETH Zurich
    Author: Zamora, Miguel | ETH Zurich
    Author: Poranne, Roi | ETHZ
    Author: Coros, Stelian | Carnegie Mellon University
 
    keyword: Grasping; Motion and Path Planning; Optimization and Optimal Control

    Abstract : We present an optimization framework for grasp and motion planning in the context of robotic assembly. Typically, grasping locations are provided by higher level planners or as input parameters. In contrast, our mathematical model simultaneously optimizes motion trajectories, grasping locations, and other parameters such as the position of an object during handover operations. The input to our framework consists of a set of objects placed in a known configuration, their target locations, and relative timing information describing when objects need to be picked up, optionally handed over, and dropped off. To allow robots to reason about the way in which grasping locations govern optimal motions, we formulate the problem using a multi-level optimization scheme: the top level optimizes grasping locations; the mid-layer level computes the configurations of the robot for pick, drop and handover states; and the bottom level computes optimal, collision-free motions. We leverage sensitivity analysis to compute derivatives analytically (how do grasping parameters affect IK solutions, and how these, in turn, affect motion trajectories etc.), and devise an efficient numerical solver to generate solutions to the resulting optimization problem. We demonstrate the efficacy of our approach on a variety of assembly and handover tasks performed by a dual-armed robot with parallel grippers.


- Grasping Fragile Objects Using a Stress-Minimization Metric

    Author: Pan, Zherong | The University of North Carolina at Chapel Hill
    Author: Gao, Xifeng | Florida State University
    Author: Manocha, Dinesh | University of Maryland
 
    keyword: Grasping

    Abstract : We present a new method to generate optimal grasps for brittle and fragile objects using a novel stress-minimization (SM) metric. Our approach is designed for objects that are composed of homogeneous isotopic materials. Our SM metric measures the maximal resistible external wrenches that would not result in fractures in the target objects. In this paper, we propose methods to compute our new metric. We also use our SM metric to design optimal grasp planning algorithms. Finally, we compare the performance of our metric and conventional grasp metrics, including Q_1, Q_inf, Q_G11, Q_MSV, Q_VEW. Our experiments show that our SM metric takes into account the material characteristics and object shapes to indicate the fragile regions, where prior methods may not work well. We also show that the computational cost of our SM metric is on par with prior methods. Finally, we show that grasp planners guided by our metric can lower the probability of breaking target objects.

- Grasp Control for Enhancing Dexterity of Parallel Grippers

    Author: Costanzo, Marco | Université Degli Studi Della Campania Luigi Vanvitelli
    Author: De Maria, Giuseppe | Université Degli Studi Della Campania Luigi Vanvitelli
    Author: Lettera, Gaetano | Université Degli Studi Della Campania Luigi Vanvitelli
    Author: Natale, Ciro | Université Degli Studi Della Campania "Luigi Vanvitelli"
 
    keyword: Grasping; Perception for Grasping and Manipulation; Manipulation Planning

    Abstract : A robust grasp controller for both slipping avoidance and controlled sliding is proposed based on force/tactile feedback only. The model-based algorithm exploits a modified LuGre friction model to consider both translational and rotational frictional sliding motions. The modification relies on the Limit Surface concept where a novel computationally efficient method is introduced to compute in real-time the minimum grasping force to balance tangential and torsional loads. The two control modalities are considered by the robot motion planning algorithm that automatically generates robot motions and gripper commands to solve complex manipulation tasks in a material handling application.

- Theoretical Derivation and Realization of Adaptive Grasping Based on Rotational Incipient Slip Detection

    Author: Narita, Tetsuya | Sony Corporation
    Author: Nagakari, Satoko | Sony Corporation
    Author: Conus, William | Sony Corporation
    Author: Tsuboi, Toshimitsu | Sony Corporation
    Author: Nagasaka, Kenichiro | Sony Corporation
 
    keyword: Grasping; Force and Tactile Sensing; Mobile Manipulation

    Abstract : Manipulating objects whose physical properties are unknown remains one of the greatest challenges in robotics. Controlling grasp force is an essential aspect of handling unknown objects without slipping or crushing them. Although extensive research has been carried out on grasp force control, unknown object manipulation is still difficult because conventional approaches assume that object properties (mass, center of gravity, friction coefficient, etc.) are known for grasp force control. One of the approaches to address this issue is incipient slip detection. However, there has been few detailed investigations of robust detection and control of incipient slip on rotational case. This study makes contributions on deriving the theoretical model of incipient slip and proposes a new algorithm to detect incipient slip. Additionally, a novel sensor configuration and a grasp force control algorithm based on the derived theoretical model are proposed. Finally, the proposed algorithm is evaluated by grasping objects with different weights and moments including a fragile pastry (�clair).

- Grasp State Assessment of Deformable Objects Using Visual-Tactile Fusion Perception

    Author: Cui, Shaowei | Institute of Automation, Chinese Academy of Sciences
    Author: Wang, Rui | Institute of Automation, Chinese Academy of Sciences
    Author: Wei, Junhang | Institute of Automation, Chinese Academy of Sciences
    Author: Li, Fanrong | Institute of Automation, Chinese Academy of Sciences
    Author: Wang, Shuo | Chinese Academy of Sciences
 
    keyword: Grasping; Force and Tactile Sensing; Sensor Fusion

    Abstract : Humans can quickly determine the force required to grasp a deformable object to prevent its sliding or excessive deformation through vision and touch, which is still a challenging task for robots. To address this issue, we propose a novel 3D convolution-based visual-tactile fusion deep neural network (C3D-VTFN) to evaluate the grasp state of various deformable objects in this paper. Specifically, we divide the grasp states of deformable objects into three categories of sliding, appropriate and excessive. Also, a dataset for training and testing the proposed network is built by extensive grasping and lifting experiments with different widths and forces on 16 various deformable objects with a robotic arm equipped with a wrist camera and a tactile sensor. As a result, a classification accuracy as high as 99.97% is achieved. Furthermore, some delicate grasp experiments based on the proposed network are implemented in this paper. The experimental results demonstrate that the C3D-VTFN is accurate and efficient enough for grasp state assessment, which can be widely applied to automatic force control, adaptive grasping, and other visual-tactile spatiotemporal sequence learning problems.

- Beyond Top-Grasps through Scene Completion

    Author: Lundell, Jens | Aalto University
    Author: Verdoja, Francesco | Aalto University
    Author: Kyrki, Ville | Aalto University
 
    keyword: Grasping; Perception for Grasping and Manipulation; Deep Learning in Robotics and Automation

    Abstract : Current end-to-end grasp planning methods propose grasps in the order of seconds that attain high grasp success rates on a diverse set of objects, but often by constraining the workspace to top-grasps. In this work, we present a method that allows end-to-end top-grasp planning methods to generate full six-degree-of-freedom grasps using a single RGB-D view as input. This is achieved by estimating the complete shape of the object to be grasped, then simulating different viewpoints of the object, passing the simulated viewpoints to an end-to-end grasp generation method, and finally executing the overall best grasp. The method was experimentally validated on a Franka Emika Panda by comparing 429 grasps generated by the state-of-the-art Fully Convolutional Grasp Quality CNN, both on simulated and real camera images. The results show statistically significant improvements in terms of grasp success rate when using simulated images over real camera images, especially when the real camera viewpoint is angled. Code and video are available at https://irobotics.aalto.fi/beyond-top-grasps-through-scene-completion/.

- Dex-Net AR: Distributed Deep Grasp Planning Using a Commodity Cellphone and Augmented Reality App

    Author: Zhang, Harry Haolun | UC Berkeley
    Author: Ichnowski, Jeffrey | University of North Carolina at Chapel Hill
    Author: Avigal, Yahav | UC Berkeley
    Author: Gonzalez, Joseph E. | UC Berkeley
    Author: Stoica, Ion | UC Berkeley
    Author: Goldberg, Ken | UC Berkeley
 
    keyword: Grasping; Perception for Grasping and Manipulation; Computer Vision for Automation

    Abstract : Consumer demand for augmented reality (AR) in mobile phone applications, such as the Apple ARKit. Such applications have potential to expand access to robot grasp planning systems such as Dex-Net. AR apps use structure from motion methods to compute a point cloud from a sequence of RGB images taken by the camera as it is moved around an object. However, the resulting point clouds are often noisy due to estimation errors. We present a distributed pipeline, Dex-Net AR, that allows point clouds to be uploaded to a server in our lab, cleaned, and evaluated by Dex-Net grasp planner to generate a grasp axis that is returned and displayed as an overlay on the object. We implement Dex-Net AR using the iPhone and ARKit and compare results with those generated with high-performance depth sensors. The success rates with AR on harder adversarial objects are higher than traditional depth images. The server URL is https://sites.google.com/berkeley.edu/dex-net-ar/home

## Omnidirectional Vision
- OmniSLAM: Omnidirectional Localization and Dense Mapping for Wide-Baseline Multi-Camera Systems

    Author: Won, Changhee | Hanyang University
    Author: Seok, Hochang | Hanyang Univ
    Author: Cui, Zhaopeng | ETH Zurich
    Author: Pollefeys, Marc | ETH Zurich
    Author: Lim, Jongwoo | Hanyang University
 
    keyword: Omnidirectional Vision; SLAM; Mapping

    Abstract : In this paper, we present an omnidirectional localization and dense mapping system for a wide-baseline multiview stereo setup with ultra-wide field-of-view (FOV) fisheye cameras, which has a 360&#9702; coverage of stereo observations of the environment. For more practical and accurate reconstruction, we first introduce improved and light-weighted deep neural networks for the omnidirectional depth estimation, which are faster and more accurate than the existing networks. Second, we integrate our omnidirectional depth estimates into the visual odometry (VO) and add a loop closing module for global consistency. Using the estimated depth map, we reproject keypoints onto each other view, which leads to better and more efficient feature matching process. Finally, we fuse the omnidirectional depth maps and the estimated rig poses into the truncated signed distance function (TSDF) volume to acquire a 3D map. We evaluate our method on synthetic datasets with ground-truth and real-world sequences of challenging environments, and the extensive experiments show that the proposed system generates excellent reconstruction results in both synthetic and real-world environments.

- What's in My Room? Object Recognition on Indoor Panoramic Images

    Author: Guerrero-Viu, Julia | University of Zaragoza
    Author: Fernandez-Labrador, Clara | University of Zaragoza
    Author: Demonceaux, C�dric | Université Bourgogne Franche-Comt�
    Author: Guerrero, Josechu | Universidad De Zaragoza
 
    keyword: Omnidirectional Vision; Object Detection, Segmentation and Categorization; Semantic Scene Understanding

    Abstract : In the last few years, there has been a growing interest in taking advantage of the 360� panoramic images potential, while managing the new challenges they imply. While several tasks have been improved thanks to the contextual information these images offer, object recognition in indoor scenes still remains a challenging problem that has not been deeply investigated. This paper provides an object recognition system that performs object detection and semantic segmentation tasks by using a deep learning model adapted to match the nature of equirectangular images. From these results, instance segmentation masks are recovered, refined and transformed into 3D bounding boxes that are placed into the 3D model of the room. Quantitative and qualitative results support that our method outperforms the state of the art by a large margin and show a complete understanding of the main objects in indoor scenes.

- FisheyeDistanceNet: Self-Supervised Scale-Aware Distance Estimation Using Monocular Fisheye Camera for Autonomous Driving

    Author: Ravi Kumar, Varun | Valeo
    Author: Athni Hiremath, Sandesh | Valeo Schalter Und Sensoren
    Author: Bach, Markus | Valeo
    Author: Milz, Stefan | Valeo Schalter Und Sensoren GmbH
    Author: Witt, Christian | Valeo
    Author: Pinard, Cl�ment | Ensta Paris
    Author: Yogamani, Senthil | Home
    Author: M�der, Patrick | Technische Universitét Ilmenau
 
    keyword: Omnidirectional Vision; Computer Vision for Transportation

    Abstract : Fisheye cameras are commonly used in applications like autonomous driving and surveillance to provide a large field of view greater tha 180degrees. However, they come at the cost of strong non-linear distortion which require more complex algorithms. In this paper, we explore Euclidean distance estimation on fisheye cameras for automotive scenes. Obtaining accurate and dense depth supervision is difficult in practice, but self-supervised learning approaches show promising results and could potentially overcome the problem. We present a novel self-supervised scale-aware framework for learning Euclidean distance and ego-motion from raw monocular fisheye videos without applying rectification. While it is possible to perform piece-wise linear approximation of fisheye projection surface and apply standard rectilinear models, it has its own set of issues like re-sampling distortion and discontinuities in transition region. To encourage further research in this area, we will release this dataset as part of our WoodScape dataset. We further evaluated the proposed algorithm on the KITTI dataset and obtained state-of-the-art results comparable to other self-supervised monocular methods.

- 360SD-Net: 360° Stereo Depth Estimation with Learnable Cost Volume

    Author: Wang, Ning-Hsu | National Tsing Hua University
    Author: Solarte, Bolivar | National Tsing Hua University
    Author: Tsai, Yi-Hsuan | NEC Labs America
    Author: Chiu, Wei-Chen | National Chiao Tung University
    Author: Sun, Min | National Tsing Hua University
 
    keyword: Omnidirectional Vision; AI-Based Methods; Visual Learning

    Abstract : Recently, end-to-end trainable deep neural networks have significantly improved stereo depth estimation for perspective images. However, 360� images captured under equirectangular projection cannot benefit from directly adopting existing methods due to distortion introduced (i.e., lines in 3D are not projected onto lines in 2D). To tackle this issue, we present a novel architecture specifically designed for spherical disparity using the setting of top-bottom 360� camera pairs. Moreover, we propose to mitigate the distortion issue by (1) an additional input branch capturing the position and relation of each pixel in the spherical coordinate, and (2) a cost volume built upon a learnable shifting filter. Due to the lack of 360� stereo data, we collect two 360� stereo datasets from Matterport3D and Stanford3D for training and evaluation. Extensive experiments and ablation study are provided to validate our method against existing algorithms. Finally, we show promising results on real-world environments capturing images with two consumer-level cameras. Our project page is at https://albert100121.github.io/360SD-Net-Project-Page.

- Omnidirectional Depth Extension Networks
 
    Author: Cheng, Xinjing | Baidu
    Author: Wang, Peng | Bytedance USA LLC
    Author: Zhou, Yanqi | Google
    Author: Guan, Chenye | Baidu
    Author: Yang, Ruigang | University of Kentucky
 
    keyword: Omnidirectional Vision; RGB-D Perception; Sensor Fusion

    Abstract : Omnidirectional 360&#9702; camera proliferates rapidly for autonomous robots since it significantly enhances the perception ability by widening the field of view (FoV). However, corresponding 360&#9702; depth sensors, which are also critical for the perception system, are still difficult or expensive to have. In this paper, we propose a low-cost 3D sensing system that combines an omnidirectional camera with a calibrated projective depth camera, where the depth from the limited FoV can be automatically extended to the rest of recorded omnidirectional image. To accurately recover the missing depths, we design an omnidirectional depth extension convolutional neural network (ODE-CNN), in which a spherical feature transform layer (SFTL) is embedded at the end of feature encoding layers, and a deformable convolutional spatial propagation network (D-CSPN) is appended at the end of feature decoding layers. The former re-samples the neighborhood of each pixel in the omnidirectional coordination to the projective coordination, which reduce the difficulty of feature learning, and the later automatically finds a proper context to well align the structures in the estimated depths via CNN w.r.t. the reference image, which significantly improves the visual quality. Finally, we demonstrate the effectiveness of proposed ODE-CNN over the popular 360D dataset, and show that ODE-CNN significantly outperforms (relatively 33% reduction in depth error) other state-of-the-art (SoTA) methods.

- 3D Orientation Estimation and Vanishing Point Extraction from Single Panoramas Using Convolutional Neural Network

    Author: Shi, Yongjie | Peking University
    Author: Tong, Xin | Peking University
    Author: Wen, Jingsi | Peking University
    Author: Zhao, He | Peking University
    Author: Ying, Xianghua | Peking University
    Author: Zha, Hongbin | Peking University
 
    keyword: Omnidirectional Vision; Calibration and Identification; Computer Vision for Automation

    Abstract : 3D orientation estimation is a key component of many important computer vision tasks such as autonomous navigation and 3D scene understanding. This paper presents a new CNN architecture to estimate the 3D orientation of an omnidirectional camera with respect to the world coordinate system from a single spherical panorama. To train the proposed architecture, we leverage a dataset of panoramas named VOP60K from Google Street View with labeled 3D orientation, including 50 thousand panoramas for training and 10 thousand panoramas for testing. Previous approaches usually estimate 3D orientation under pinhole cameras. However, for a panorama, due to its larger field of view, previous approaches cannot be suitable. In this paper, we propose an edge extractor layer to utilize the low-level and geometric information of panorama, an attention module to fuse different features generated by previous layers. A regression loss for two column vectors of the rotation matrix and classification loss for the position of vanishing points are added to optimize our network simultaneously. The proposed algorithm is validated on our benchmark, and experimental results clearly demonstrate that it outperforms previous methods.

## Force and Tactile Sensing



- Low-Cost GelSight with UV Markings: Feature Extraction of Objects Using AlexNet and Optical Flow without 3D Image Reconstruction

    Author: Abad, Alexander | Liverpool Hope University
    Author: Ranasinghe, Anuradha | Liverpool Hope University
 
    keyword: Haptics and Haptic Interfaces; Force and Tactile Sensing

    Abstract : GelSight sensor has been used to study microgeometry of objects since 2009 in tactile sensing applications. Elastomer, reflective coating, lighting, and camera were the main challenges of making a GelSight sensor within a short period. The recent addition of permanent markers to the GelSight was a new era in shear/slip studies. In our previous studies, we introduced Ultraviolet (UV) ink and UV LEDs as a new form of marker and lighting respectively. UV ink markers are invisible using ordinary LED but can be made visible using UV LED. Currently, recognition of objects or surface textures using GelSight sensor is done using fusion of camera-only images and GelSight captured images with permanent markings. Those images are fed to Convolutional Neural Networks (CNN) to classify objects. However, our novel approach in using low-cost GelSight sensor with UV markings, the 3D height map to 2D image conversion, and the additional non-Gelsight captured images for training the CNN can be eliminated. AlexNet and optical flow algorithm have been used for feature recognition of five coins without UV markings and shear/slip of the coin in GelSight with UV markings respectively. Our results on confusion matrix show that, on average coin recognition can reach 93.4% without UV markings using AlexNet. Therefore, our novel method of using GelSight with UV markings would be useful to recognize full/partial object, shear/slip, and force applied to the objects without any 3D image reconstruction.

- Evaluation of Non-Collocated Force Feedback Driven by Signal-Independent Noise

    Author: Chua, Zonghe | Stanford University
    Author: Okamura, Allison M. | Stanford University
    Author: Deo, Darrel | Stanford University
 
    keyword: Haptics and Haptic Interfaces; Prosthetics and Exoskeletons; Brain-Machine Interface

    Abstract : Individuals living with paralysis or amputation can operate robotic prostheses using input signals based on their intent or attempt to move. Because sensory function is lost or diminished in these individuals, haptic feedback must be non-collocated. The intracortical brain computer interface (iBCI) has enabled a variety of neural prostheses for people with paralysis. An important attribute of the iBCI is that its input signal contains signal-independent noise. To understand the effects of signal-independent noise on a system with non-collocated haptic feedback and inform iBCI-based prostheses control strategies, we conducted an experiment with a conventional haptic interface as a proxy for the iBCI. Able-bodied users were tasked with locating an indentation within a virtual environment using input from their right hand. Non-collocated haptic feedback of the interaction forces in the virtual environment was augmented with noise of three different magnitudes and simultaneously rendered on users' left hands. We found increases in distance error of the guess of the indentation location, mean time per trial, mean peak absolute displacement and speed of tool movements during localization for the highest noise level compared to the other two levels. The findings suggest that users have a threshold of disturbance rejection and that they attempt to increase their signal-to-noise ratio through their exploratory actions.

- Vibration-Based Multi-Axis Force Sensing: Design, Characterization, and Modeling

    Author: Kuang, Winnie | UCSD
    Author: Yip, Michael C. | University of California, San Diego
    Author: Zhang, Jun | University of Nevada Reno
 
    keyword: Haptics and Haptic Interfaces

    Abstract : It is strongly desirable but challenging to obtain force sensing mechanisms that are low-cost, volumetrically compact, away from contact location, and can be easily integrated into existing and emerging robot systems. For example, having a bulky force sensor near the tip of surgical robot tools may be impractical as it may require a large incision, infect biological tissues, and negatively affect surgeon's operation. In this study, a new vibration-based approach was proposed to measure the force applied to a structure utilizing the structure's acceleration signals. By exciting the structure using a vibration motor, the structure's acceleration signals in time domain showed discernible ellipse-shaped profiles when a force was applied. For the first time, these acceleration profiles were characterized via regression and employed for estimating the direction and magnitude of the applied force. Experimental results showed that, the achieved resolutions with the proposed approach in estimating the direction and magnitude of the applied force were 10{textdegree} and 0.098 N, respectively. The sensing errors were within the range of 8-18%. This force-sensing approach has strong potential for a wide area of robotic applications.

- Tactile Sensing Based on Fingertip Suction Flow for Submerged Dexterous Manipulation

    Author: Nadeau, Philippe | École De Technologie Supérieure
    Author: Abbott, Michael | UC Berkeley
    Author: Melville, Dominic | UC Berkeley
    Author: Stuart, Hannah | UC Berkeley
 
    keyword: Grasping; Force and Tactile Sensing; Dexterous Manipulation

    Abstract : The ocean is a harsh and unstructured environment for robotic systems; high ambient pressures, saltwater corrosion and low-light conditions demand machines with robust electrical and mechanical parts that are able to sense and respond to the environment. Prior work shows that the addition of gentle suction flow to the hands of underwater robots can aid in the handling of objects during mobile manipulation tasks. The current paper explores using this suction flow mechanism as a new modality for tactile sensing; by monitoring orifice occlusion we can get a sense of how objects make contact in the hand. The electronics required for this sensor can be located remotely from the hand and the signal is insensitive to large changes in ambient pressure associated with diving depth. In this study, suction is applied to the fingertips of a two-fingered compliant gripper and suction-based tactile sensing is monitored while an object is pulled out of a pinch grasp. As a proof of concept, a recurrent neural network model was trained to predict external force trends using only the suction signals. This tactile sensing modality holds the potential to enable automated robotic behaviors or to provide operators of remotely operated vehicles with additional feedback in a robust fashion suitable for ocean deployment.

- Discrete Bimanual Manipulation for Wrench Balancing

    Author: Cruciani, Silvia | KTH Royal Institute of Technology
    Author: Almeida, Diogo | Royal Institute of Technology, KTH
    Author: Kragic, Danica | KTH
    Author: Karayiannidis, Yiannis | Chalmers University of Technology &amp; KTH Royal Institute of Techn
 
    keyword: Dual Arm Manipulation; Dexterous Manipulation; Force and Tactile Sensing

    Abstract : Dual-arm robots can overcome grasping force and payload limitations of a single arm by jointly grasping an object. However, if the distribution of mass of the grasped object is not even, each arm will experience different wrenches that can exceed its payload limits. In this work, we consider the problem of balancing the wrenches experienced by a dual-arm robot grasping a rigid tray. The distribution of wrenches among the robot arms changes due to objects being placed on the tray. We present an approach to reduce the wrench imbalance among arms through discrete bimanual manipulation. Our approach is based on sequential sliding motions of the grasp points on the surface of the object, to attain a more balanced configuration. We validate our modeling approach and system design through a set of robot experiments.

- Shear, Torsion and Pressure Tactile Sensor Via Plastic Optofiber Guided Imaging

    Author: Baimukashev, Daulet | Nazarbayev University
    Author: Kappassov, Zhanat | Pierre and Marie Curie University
    Author: Varol, Huseyin Atakan | Nazarbayev University
 
    keyword: Force and Tactile Sensing; Soft Sensors and Actuators; Deep Learning in Robotics and Automation

    Abstract : Object manipulation performed by robots refers to the art of controlling the shape and location of an object through force constraints with robot end-effectors, both robot hands, and grippers. The success of task execution is usually guaranteed by the sense of touch. In this work, we present an optical tactile sensor - incorporating plastic optical fibers, transparent silicone rubber, and an off-the-shelf color camera - that can detect: translational and rotational shear forces, and contact location and its normal force. Contact localization is possible thanks to the shear strain. Specifically, one of the layers stretches so that its thickness decreases. The decrease in the thickness results in the color change at the point of contact. Elastic behavior of the sensing media provides a robust rotational and translational shear detection mechanism when torque and planar force, respectively, are applied onto the sensing surface. Thanks to the plastic optofibers, signal processing electronics are placed away from the sensing surface making the sensor immune to hazardous environments. Machine learning techniques were used to benchmark the sensing performance of the sensor. By implementing a multi-output CNN model, the contact type was classified into normal and shear or torsional deformation and their corresponding continuous contact features were estimated.

- Dynamically Reconfigurable Tactile Sensor for Robotic Manipulation

    Author: Huh, Tae Myung | Stanford University
    Author: Choi, Hojung | Stanford University
    Author: Willcox, Simone | Stanford University
    Author: Moon, Stephanie | Stanford University
    Author: Cutkosky, Mark | Stanford University
 
    keyword: Force and Tactile Sensing; Dexterous Manipulation

    Abstract : We present a new tactile sensor intended for manipulation by mobile robots, for example in the home. The surface consists of an array of small, rounded bumps or "nibs", which provide reliable traction on objects like wet dishes. When the nibs contact a surface they deflect, and capacitive sensors measure the corresponding local normal and shear forces. A key feature of the sensor is the ability to reconfigure dynamically depending on which combinations of sensing elements it samples. By interrogating different combinations of elements the sensor can detect and distinguish between linear and rotational sliding, and other dynamic events such as making and breaking contact. These dynamic events, combined with sensing the grasp and load forces, are useful for acquiring objects and performing simple in-hand manipulations. The proposed slip detection method estimates minimum required grasping force with an error less than 1.5N and uses tactile controlled rotational slips to reorient an unknown weight/surface object with 78% success rate.

- NeuroTac: A Neuromorphic Optical Tactile Sensor Applied to Texture Recognition

    Author: Ward-Cherrier, Benjamin | University of Bristol
    Author: Pestell, Nicholas | University of Bristol
    Author: Lepora, Nathan | University of Bristol
 
    keyword: Force and Tactile Sensing; Biomimetics; Neurorobotics

    Abstract : Developing artificial tactile sensing capabilities that rival human touch is a long-term goal in robotics and prosthetics. Gradually more elaborate biomimetic tactile sensors are being developed and applied to grasping and manipulation tasks to help achieve this goal. Here we present the neuroTac, a novel neuromorphic optical tactile sensor. The neuroTac combines the biomimetic hardware design from the TacTip sensor which mimicks the layered papillae structure of the human glabrous skin, with an event-based camera (DAVIS240, iniVation) and data encoding algorithms which transduce contact information in the form of spike trains. The performance of the neuroTac sensor is evaluated on a texture classification task, with four spike coding methods being implemented and compared: Intensive, Spatial, Temporal and Spatiotemporal. We found the timing-based coding methods performed with the highest accuracy over both artificial and natural textures. The spike-based output of the neuroTac could enable the development of biomimetic tactile perception algorithms in robotics as well as non-invasive and invasive haptic feedback methods in prosthetics.

- Reducing Uncertainty in Pose Estimation under Complex Contacts Via Force Forecast

    Author: Mao, Huitan | University of North Carolina at Charlotte
    Author: Xiao, Jing | Worcester Polytechnic Institute (WPI)
 
    keyword: Assembly; Force and Tactile Sensing; Manipulation Planning

    Abstract : How to reduce uncertainty in object pose estimation under complex contacts is crucial to autonomous robotic manipulation and assembly. In this paper, we introduce an approach through forecasting contact force from simulated complex contacts with calibration based on real force sensing. A constraint-based haptic simulation algorithm is used with sphere-tree representation of contacting objects to compute contact poses and forces, and through matching the computed forces to measured real force data via a regression model, the least-uncertain estimate of the relative contact pose is obtained. Our approach can handle multi-region complex contacts and does not make any assumption about contact types or contact locations. It also does not have restriction on object shapes. We have applied the force forecast approach to reducing uncertainty in estimating object poses in challenging peg-in-hole robotic assembly tasks and demonstrate the effectiveness of the approach by successful completion of contact-rich two-pin and three-pin real peg-in-hole assembly tasks with complex shapes of pins and holes.

- Comparison of Constrained and Unconstrained Human Grasp Forces Using Fingernail Imaging and Visual Servoing

    Author: Fallahinia, Navid | University of Utah
    Author: Mascaro, Stephen | University of Utah
 
    keyword: Force and Tactile Sensing; Grasping; Visual Servoing

    Abstract : Fingernail imaging has been proven to be effective in prior works [1], [2] for estimating the 3D fingertip forces with a maximum RMS estimation error of 7%. In the current research, fingernail imaging is used to perform unconstrained grasp force measurement on multiple fingers to study human grasping. Moreover, two robotic arms with mounted cameras and a visual tracking system have been devised to keep the human fingers in the camera frame during the experiments. Experimental tests have been conducted for six human subjects under both constrained and unconstrained grasping conditions, and the results indicate a significant difference in force collaboration among the fingers between the two grasping conditions. Another interesting result according to the experiments is that in comparison to constrained grasping, unconstrained grasp forces are more evenly distributed over the fingers and there is less force variation (more steadiness) in each finger force. These results validate the importance of measuring grasp forces in an unconstrained manner in order to study how humans naturally grasp objects.

- An ERT-Based Robotic Skin with Sparsely Distributed Electrodes: Structure, Fabrication, and DNN-Based Signal Processing

    Author: Park, Kyungseo | KAIST
    Author: Park, Hyunkyu | Korea Advanced Institute of Science and Technology
    Author: Lee, Hyosang | Max Planck Institute for Intelligent Systems
    Author: Park, Sungbin | Korea Advanced Institute of Science and Technology
    Author: Kim, Jung | KAIST
 
    keyword: Force and Tactile Sensing; Physical Human-Robot Interaction; Soft Robot Materials and Design

    Abstract : Electrical resistance tomography (ERT) has previously been utilized to develop a large-scale tactile sensor because this approach enables the estimation of the conductivity distribution among the electrodes based on a known physical model. Such a sensor made with a stretchable material can conform to a curved surface. However, this sensor cannot fully cover a cylindrical surface because in such a configuration, the edges of the sensor must meet each other. The electrode configuration becomes irregular in this edge region, which may degrade the sensor performance. In this paper, we introduce an ERT-based robotic skin with evenly and sparsely distributed electrodes. For implementation, we sprayed a carbon nanotube (CNT)-dispersed solution to form a conductive sensing domain on a cylindrical surface. The electrodes were firmly embedded in the surface so that the wires were not exposed to the outside. The sensor output images were estimated using a deep neural network (DNN), which was trained with noisy simulation data. An indentation experiment revealed that the localization error of the sensor was 5.2 - 3.3 mm, which is remarkable performance with only 30 electrodes. A frame rate of up to 120 Hz could be achieved with a sensing domain area of 90 cm^2. The proposed approach simplifies the fabrication of 3D-shaped sensors, allowing them to be easily applied to existing robot arms in a seamless and robust manner.

- FBG-Based Triaxial Force Sensor Integrated with an Eccentrically Configured Imaging Probe for Endoluminal Optical Biopsy

    Author: Wu, Zicong | Imperial College London
    Author: Gao, Anzhu | Shanghai Jiao Tong University
    Author: Liu, Ning | Imperial College London
    Author: Jin, Zhu | Imperial College London
    Author: Yang, Guang-Zhong | Shanghai Jiao Tong University
 
    keyword: Force and Tactile Sensing; Surgical Robotics: Steerable Catheters/Needles; Medical Robots and Systems

    Abstract : Accurate force sensing is important for endoluminal interventions in terms of both safety and lesion targeting. This paper develops an FBG-based force sensor for robotic bronchoscopy by configuring three FBG sensors at the lateral side of a conical substrate, which allows a large and eccentric inner lumen for the interventional instrument, like a flexible imaging probe to perform the optical biopsy. The force sensor is embodied with a laser-profiled continuum robot and thermo drift is fully compensated by three temperature sensors that are integrated on the circumference surface of the sensor substrate. Different decoupling approaches are investigated, and nonlinear decoupling is adopted based on the cross-validation SVM and a gaussian kernel function, achieving an accuracy of 10.58 mN, 14.57 mN and 26.32 mN along X, Y and Z axis, respectively. Besides, the tissue test is investigated to further demonstrate the feasibility of the developed triaxial force sensor

- Calibrating a Soft ERT-Based Tactile Sensor with a Multiphysics Model and Sim-To-Real Transfer Learning

    Author: Lee, Hyosang | Max Planck Institute for Intelligent Systems
    Author: Park, Hyunkyu | Korea Advanced Institute of Science and Technology
    Author: Serhat, Gokhan | Max Planck Institute for Intelligent Systems, Haptic Intelligenc
    Author: Sun, Huanbo | Max Planck Institute for Intelligent Systems
    Author: Kuchenbecker, Katherine J. | Max Planck Institute for Intelligent Systems
 
    keyword: Force and Tactile Sensing; Deep Learning in Robotics and Automation; Calibration and Identification

    Abstract : Tactile sensors based on electrical resistance tomography (ERT) have shown many advantages for implementing a soft and scalable whole-body robotic skin; however, calibration is challenging because pressure reconstruction is an ill-posed inverse problem. This paper introduces a method for calibrating soft ERT-based tactile sensors using sim-to-real transfer learning with a finite element multiphysics model. The model is composed of three simple models that together map contact pressure distributions to voltage measurements. We optimized the model parameters to reduce the gap between the simulation and reality. As a preliminary study, we discretized the sensing points into a 6 by 6 grid and synthesized single- and two-point contact datasets from the multiphysics model. We obtained another single-point dataset using the real sensor with the same contact location and force used in the simulation. Our new deep neural network architecture uses a de-noising network to capture the simulation-to-real gap and a reconstruction network to estimate contact force from voltage measurements. The proposed approach showed 82% hit rate for localization and 0.51 N of force estimation error performance in single-contact tests and 78.5% hit rate for localization and 5.0 N of force estimation error in two-point contact tests. We believe this new calibration method has the possibility to improve the sensing performance of ERT-based tactile sensors.

- Sim-To-Real Transfer for Optical Tactile Sensing

    Author: Ding, Zihan | Imperial College London
    Author: Lepora, Nathan | University of Bristol
    Author: Johns, Edward | Imperial College London
 
    keyword: Force and Tactile Sensing; Deep Learning in Robotics and Automation; Soft Sensors and Actuators

    Abstract : Deep learning and reinforcement learning methods have been shown to enable learning of flexible and complex robot controllers. However, the reliance on large amounts of training data often requires data collection to be carried out in simulation, with a number of sim-to-real transfer methods being developed in recent years. In this paper, we study these techniques for tactile sensing using the TacTip optical tactile sensor, which consists of a deformable tip with a camera observing the positions of pins inside this tip. We designed a model for soft body simulation which was implemented using the Unity physics engine, and trained a neural network to predict the locations and angles of edges when in contact with the sensor. Using domain randomisation techniques for sim-to-real transfer, we show how this framework can be used to accurately predict edges with less than 1 mm prediction error in real-world testing, without any real-world data at all.

- Semi-Empirical Simulation of Learned Force Response Models for Heterogeneous Elastic Objects

    Author: Zhu, Yifan | University of Illinois at Urbana-Champaign
    Author: Lu, Kai | Tsinghua Univerisity
    Author: Hauser, Kris | University of Illinois at Urbana-Champaign
 
    keyword: Force and Tactile Sensing; Contact Modeling; Simulation and Animation

    Abstract : This paper presents a semi-empirical method for simulating contact with elastically deformable objects whose force response is learned using entirely data-driven models. A point-based surface representation and an inhomogeneous, nonlinear force response model are learned from a robotic arm acquiring force-displacement curves from a small number of poking interactions. The simulator then estimates displacement and force response when the deformable object is in contact with an arbitrary rigid object. It does so by estimating displacements by solving a Hertzian contact model, and sums the expected forces at individual surface points through querying the learned point stiffness models as a function of their expected displacements. Experiments on a variety of challenging objects show that our approach learns force response with sufficient accuracy to generate plausible contact response for novel rigid objects.

- Low-Cost Fiducial-Based 6-Axis Force-Torque Sensor

    Author: Ouyang, Rui | Harvard University
    Author: Howe, Robert D. | Harvard University
 
    keyword: Force and Tactile Sensing; Computer Vision for Other Robotic Applications; Perception for Grasping and Manipulation

    Abstract : Commercial six-axis force-torque sensors suffer from being some combination of expensive, fragile, and hard-to-use. We propose a new fiducial-based design which addresses all three points. The sensor uses an inexpensive webcam and can be fabricated using a consumer-grade 3D printer. Open-source software is used to estimate the 3D pose of the fiducials on the sensor, which is then used to calculate the applied force-torque. A browser-based (installation free) interface demonstrates ease-of-use. The sensor is very light and can be dropped or thrown with little concern. We characterize our prototype in dynamic conditions under compound loading, finding a mean R^2 of over 0.99 for the F_x, F_y, M_x, and M_y axes, and over 0.87 and 0.90 for the F_z and M_z axes respectively. The open source design files allow the sensor to be adapted for diverse applications ranging from robot fingers to human-computer interfaces, while the simple design principle allows for quick changes with minimal technical expertise. This approach promises to bring six-axis force-torque sensing to new applications where the precision, cost, and fragility of traditional strain-gauge based sensors are not appropriate. The open-source sensor de sign can be viewed at http://sites.google.com/view/ fiducialforcesensor.

- Curvature Sensing with a Spherical Tactile Sensor Based on the Color-Interference of a Marker Array

    Author: Lin, Xi | ISM, CNRS, Aix-Marseille Université
    Author: Willemet, Laurence | ISM, CNRS, Aix-Marseille Université
    Author: Bailleul, Alexandre | ISM, Aix-Marseille Université
    Author: Wiertlewski, Michael | TU Delft
 
    keyword: Force and Tactile Sensing; Soft Robot Materials and Design

    Abstract : It is well accepted that touch is an important sensory channel to consider while planning of robotic manipulation tasks. Touch provides information about the state of contact and the local shape of the object which is central to fine manipulation. In this work, we present an evolution of our distributed tactile sensor which is able to measure the dense 3-dimensional displacement field of an elastic membrane, using the subtractive color-mixing principle. The manufacturing process employed allows us to design and manufacture the features of the sensor on a flat surface, then fold the resulting 2d structure into a spherical shape. The resulting 40mm-diameter spherical sensor has 77 measurement points, each of which gives an estimation of the local 3d displacement, normal and tangential to the surface. Each marker is built around 2 sets of colored patch placed at different depths. The first one reflects magenta light while the second is a translucent yellow filter that converts the magenta into the red. An embedded camera observes the lateral displacement and the resulting hue of the marker. To benchmark the sensor, we compared the measurement obtained while pressing the sensor on a curved surface with Hertz contact theory, which constitutes a classical contact mechanics problem. While Hertz contact assumes frictionless conditions, using the shear and normal sensing, ChromaTouch can estimate the curvature of an object after an indentation of the sensor of less than a millimeter.

- Center-Of-Mass-Based Robust Grasp Planning for Unknown Objects Using Tactile-Visual Sensors

    Author: Feng, Qian | Technical University of Munich
    Author: Chen, Zhaopeng | University of Hamburg
    Author: Deng, Jun | Agile Robots AG
    Author: Gao, Chunhui | Agile Robots AG
    Author: Zhang, Jianwei | University of Hamburg
    Author: Knoll, Alois | Tech. Univ. Muenchen TUM
 
    keyword: Force and Tactile Sensing; Grasping; Deep Learning in Robotics and Automation

    Abstract : An unstable grasp pose can lead to slip, thus an unstable grasp pose can be predicted by slip detection. A regrasp is required afterwards to correct the grasp pose in order to finish the task. In this work, we propose a novel regrasp planner with multi-sensor modules to plan grasp adjustments with the feedback from a slip detector. Then a regrasp planner is trained to estimate the location of center of mass, which helps robots find an optimal grasp pose. The dataset in this work consists of 1 025 slip experiments and 1347 regrasps collected by one pair of tactile sensors, an RGB-D camera and one Franka Emika robot arm equipped with joint force/torque sensors. We show that our algorithm can successfully detect and classify the slip for 5 unknown test objects with an accuracy of 76.88% and a regrasp planner increases the grasp success rate by 31.0% compared to the state-of-the-art vision-based grasping algorithm.

- OmniTact: A Multi-Directional High-Resolution Touch Sensor

    Author: Padmanabha, Akhil | UC Berkeley
    Author: Ebert, Frederik | UC Berkeley
    Author: Tian, Stephen | UC Berkeley
    Author: Calandra, Roberto | Facebook
    Author: Finn, Chelsea | Stanford University
    Author: Levine, Sergey | UC Berkeley
 
    keyword: Force and Tactile Sensing; Perception for Grasping and Manipulation; Soft Sensors and Actuators

    Abstract : Incorporating touch as a sensing modality for robots can enable finer and more robust manipulation skills. Existing tactile sensors are either flat, have small sensitive fields or only provide low-resolution signals. In this paper, we introduce OmniTact, a multi-directional high-resolution tactile sensor. OmniTact is designed to be used as a fingertip for robotic manipulation with robotic hands, and uses multiple micro-cameras to detect multi-directional deformations of a gel-based skin. This provides a rich signal from which a variety of different contact state variables can be inferred using modern image processing and computer vision methods. We evaluate the capabilities of OmniTact on a challenging robotic control task that requires inserting an electrical connector into an outlet, as well as a state estimation problem that is representative of those typically encountered in dexterous robotic manipulation, where the goal is to infer the angle of contact of a curved finger pressing against an object. Both tasks are performed using only touch sensing and convolutional neural networks to process images from the sensor's cameras. We compare with a state-of-the-art tactile sensor that is only sensitive on one side, as well as a state-of-the-art multi-directional tactile sensor, and find that the combination of high-resolution and multi-directional sensing is crucial for reliably inserting the electrical connector and allows for higher accuracy in the state estimation task.

- Highly Sensitive Bio-Inspired Sensor for Fine Surface Exploration and Characterization

    Author: Ribeiro, Pedro | Instituto Superior Tecnico
    Author: Cardoso, Susana | INESC-Microsistemas E Nanotecnologias and In
    Author: Bernardino, Alexandre | IST - Técnico Lisboa
    Author: Jamone, Lorenzo | Queen Mary University London
 
    keyword: Force and Tactile Sensing; Biomimetics; Soft Sensors and Actuators

    Abstract : Texture sensing is one of the types of information sensed by humans through touch, and is thus of interest to robotics that this type of information can be acquired and processed. In this work we present a texture topography sensor based on a ciliary structure, similar to a biological structure found in many organisms. The device consists on up to 9 elastic cilia with permanent magnetization assembled on top of a highly sensitive tunneling magnetoresistance (TMR) sensor, within a compact footprint of 6x6 mm2 . When these cilia brush against some textured surface, their movement and vibrations give rise to a signal that can be correlated to the characteristics of the texture being measured. We also present an electronic signal acquisition board used in this work. Various configurations of cilia sizes are tested, with the most precise being capable of differentiating different types of sandpaper from 9.2 �m to 213 �m average surface roughness with a 7 �m resolution. As a topography scanner the sensor was able to scan a 20 �m high step in a flat surface.

- Implementing Tactile and Proximity Sensing for Crack Detection

    Author: Palermo, Francesca | Queen Mary University of London
    Author: Konstantinova, Jelizaveta | Ocado Technology
    Author: Althoefer, Kaspar | Queen Mary University of London
    Author: Poslad, Stefan | Queen Mary University of London
    Author: Farkhatdinov, Ildar | Queen Mary University of London
 
    keyword: Force and Tactile Sensing; Robotics in Hazardous Fields; Sensor-based Control

    Abstract : Remote characterisation of the environment during physical robot-environment interaction is an important task commonly accomplished in telerobotics. This paper demonstrates how tactile and proximity sensing can be efficiently used to perform automatic crack detection. A custom-designed integrated tactile and proximity sensor is implemented. It measures the deformation of its body when interacting with the physical environment and distance to the environment's objects with the help of fibre optics. This sensor was used to slide across different surfaces and the data recorded during the experiments was used to detect and classify cracks, bumps and undulations. The proposed method uses machine learning techniques (mean absolute value as feature and random forest as classifier) to detect cracks and determine their width. An average crack detection accuracy of 86.46% and width classification accuracy of 57.30% is achieved. Kruskal-Wallis results (p&lt;0.001) indicate statistically significant differences among results obtained when analysing only force data, only proximity data and both force and proximity data. In contrast to previous techniques, which mainly rely on visual modality, the proposed approach based on optical fibres is suitable for operation in extreme environments, such as nuclear facilities in which nuclear radiation may damage the electronic components of video cameras.

- Novel Proximity Sensor for Realizing Tactile Sense in Suction Cups

    Author: Doi, Sayaka | OMRON Corporation
    Author: Koga, Hiroki | Omron Corporation
    Author: Seki, Tomonori | OMRON Corporation
    Author: Okuno, Yutaro | OMRON
 
    keyword: Force and Tactile Sensing; Sensor-based Control; Failure Detection and Recovery

    Abstract : We propose a new capacitive proximity sensor that detects deformations of a suction cup as a tactile sense. We confirmed that one sensor module provides three applications for reliable picking and a simplified setup. The first application is the picking height decision. The second one is the placing height decision for detecting whether the grasped object is placed on the placement surface. These two applications are achieved by detecting the push-in stroke of the suction cup. The final application is detection of whether the suction cup is in partial contact or full contact with the object. This function can correct the picking posture as well as detect whether picking is possible before the pull-up motion. We also demonstrate that the partial contact position can be estimated in real time.

## Visual-Based Navigation

- Exploring Performance Bounds of Visual Place Recognition Using Extended Precision

    Author: Ferrarini, Bruno | Universtiy of Essex
    Author: Waheed, Maria | COMSATS University
    Author: Waheed, Sania | National University of Sciences and Technology
    Author: Ehsan, Shoaib | University of Essex
    Author: Milford, Michael J | Queensland University of Technology
    Author: McDonald-Maier, Klaus | University of Essex
 
    keyword: Visual-Based Navigation; Localization

    Abstract : Recent advances in image description and matching allowed significant improvements in Visual Place Recognition (VPR). The wide variety of methods proposed so far and the increase of the interest in the field have rendered the problem of evaluating VPR methods an important task. As part of the localization process, VPR is a critical stage for many robotic applications and it is expected to perform reliably in any location of the operating environment. To design more reliable and effective localization systems this letter presents a generic evaluation framework based on the new Extended Precision performance metric for VPR. The proposed framework allows assessment of the upper and lower bounds of VPR performance and finds statistically significant performance differences between VPR methods. The proposed evaluation method is used to assess several state-of-the-art techniques with a variety of imaging conditions that an autonomous navigation system commonly encounters on long term runs. The results provide new insights into the behaviour of different VPR methods under varying conditions and help to decide which technique is more appropriate to the nature of the venture or the task assigned to an autonomous robot.

- Deep Reinforcement Learning for Instruction Following Visual Navigation in 3D Maze-Like Environments

    Author: Devo, Alessandro | University of Perugia
    Author: Costante, Gabriele | University of Perugia
    Author: Valigi, Paolo | Universita' Di Perugia
 
    keyword: Visual-Based Navigation; Deep Learning in Robotics and Automation; Visual Learning

    Abstract : In this work, we address the problem of visual navigation by following instructions. In this task, the robot must interpret a natural language instruction in order to follow a predefined path in a possibly unknown environment. Despite different approaches have been proposed in the last years, they are all based on the assumption that the environment contains objects or other elements that can be used to formulate instructions, such as houses or offices. On the contrary, we focus on situations where the environment objects cannot be used to specify a navigation path. In particular, we consider 3D maze-like environments as our test bench because they can be very large and offer very intricate structures. We show that without reference points, visual navigation and instruction following can be rather challenging, and that standard approaches can not be applied successfully. For this reason, we propose a new architecture that explicitly learns both visual navigation and instruction understanding. We demonstrate with simulated experiments that our method can effectively follow instructions and navigate in previously unseen mazes of various sizes.

- Aggressive Perception-Aware Navigation Using Deep Optical Flow Dynamics and PixelMPC

    Author: Lee, Keuntaek | Georgia Institute of Technology
    Author: Gibson, Jason | Georgia Institute of Technology
    Author: Theodorou, Evangelos | Georgia Institute of Technology
 
    keyword: Visual-Based Navigation; Visual Servoing; Visual Tracking

    Abstract : Recently, vision-based control has gained traction by leveraging the power of machine learning. In this work, we couple a model predictive control (MPC) framework to a visual pipeline. We introduce deep optical flow (DOF) dynamics, which is a combination of optical flow and robot dynamics. Using the DOF dynamics, MPC explicitly incorporates the predicted movement of relevant pixels into the planned trajectory of a robot. Our implementation of DOF is memory-efficient, data-efficient, and computationally cheap so that it can be computed in real-time for use in an MPC framework. The suggested Pixel Model Predictive Control (PixelMPC) algorithm controls the robot to accomplish a high-speed racing task while maintaining visibility of the important features (gates). This improves the reliability of vision-based estimators for localization and can eventually lead to safe autonomous flight. The proposed algorithm is tested in a photorealistic simulation with a high-speed drone racing task.

- Visual-Inertial Mapping with Non-Linear Factor Recovery

    Author: Usenko, Vladyslav | TU Munich
    Author: Demmel, Nikolaus | Technische Universitét M�nchen
    Author: Schubert, David | Technical University of Munich
    Author: Stueckler, Joerg | Max-Planck Institute for Intelligent Systems
    Author: Cremers, Daniel | Technical University of Munich
 
    keyword: Visual-Based Navigation; Mapping; Sensor Fusion

    Abstract : Cameras and inertial measurement units are complementary sensors for ego-motion estimation and environment mapping. Their combination makes visual-inertial odometry (VIO) systems more accurate and robust. For globally consistent mapping, however, combining visual and inertial information is not straightforward. To estimate the motion and geometry with a set of images large baselines are required. Because of that, most systems operate on keyframes that have large time intervals between each other. Inertial data on the other hand quickly degrades with the duration of the intervals and after several seconds of integration, it typically contains only little useful information.<p>In this paper, we propose to extract relevant information for visual-inertial mapping from visual-inertial odometry using non-linear factor recovery. We reconstruct a set of non-linear factors that make an optimal approximation of the information on the trajectory accumulated by VIO. To obtain a globally consistent map we combine these factors with loop-closing constraints using bundle adjustment. The VIO factors make the roll and pitch angles of the global map observable, and improve the robustness and the accuracy of the mapping. In experiments on a public benchmark, we demonstrate superior performance of our method over the state-of-the-art approaches.

- Interactive Gibson Benchmark: A Benchmark for Interactive Navigation in Cluttered Environments

    Author: Xia, Fei | Stanford University
    Author: Shen, William B. | Stanford University
    Author: Li, Chengshu | Stanford University
    Author: Kasimbeg, Priya | Stanford University
    Author: Tchapmi, Micael Edmond | Stanford University
    Author: Toshev, Alexander | Google
    Author: Martín-Martín, Roberto | Stanford University
    Author: Savarese, Silvio | Stanford University
 
    keyword: Visual-Based Navigation; Deep Learning in Robotics and Automation; Mobile Manipulation

    Abstract : We present Interactive Gibson Benchmark, the first comprehensive benchmark for training and evaluating Interactive Navigation solutions. Interactive Navigation tasks are robot navigation problems where physical interaction with objects (e.g. pushing) is allowed and even encouraged to reach the goal. Our benchmark comprises two novel elements: 1) a new experimental simulated environment, the Interactive Gibson Environment, that generates photo-realistic images of indoor scenes and simulates realistic physical interactions of robots and common objects found in these scenes; 2) the Interactive Navigation Score, a novel metric to study the interplay between navigation and physical interaction of Interactive Navigation solutions. We present and evaluate multiple learning-based baselines in Interactive Gibson Benchmark, and provide insights into regimes of navigation with different trade-offs between navigation, path efficiency and disturbance of surrounding objects. We make our benchmark publicly available and encourage researchers from related robotics disciplines (e.g. planning, learning, control) to propose, evaluate, and compare their Interactive Navigation solutions in Interactive Gibson Benchmark.

- Highly Robust Visual Place Recognition through Spatial Matching of CNN Features

    Author: Camara, Luis Gomez | CIIRC CTU Prague
    Author: G�bert, Carl | Czech Institute of Informatics, Robotics and Cybernetics
    Author: Preucil, Libor | Czech Technical University in Prague
 
    keyword: Visual-Based Navigation; Localization; Deep Learning in Robotics and Automation

    Abstract : We revise, extend and consolidate the system previously introduced by us and named SSM-VPR (Semantic and Spatial Matching Visual Place Recognition), largely boosting its performance above the current state of the art. The system encodes images of places by employing the activations of different layers of a pre-trained, off-the-shelf, VGG16 Convolutional Neural Network (CNN) architecture. It consists of two stages: given a query image of a place, (1) a list of candidates is selected from a database of places and (2) the candidates are geometrically compared with the query by matching CNN features and, equally important, their spatial locations. The best matching candidate is then deemed as the recognized place. The performance of the system is maximized by finding optimal image resolutions during the second stage and by exploiting temporal correlation between consecutive frames in the employed datasets.

- Robust and Efficient Estimation of Absolute Camera Pose for Monocular Visual Odometry

    Author: Li, Haoang | The Chinese University of Hong Kong
    Author: Chen, Wen | The Chinese University of Hong Kong
    Author: Zhao, Ji | TuSimple
    Author: Bazin, Jean-Charles | KAIST
    Author: Luo, Lei | Wuhan University
    Author: Liu, Zhe | The Chinese University of Hong Kong
    Author: Liu, Yunhui | Chinese University of Hong Kong
 
    keyword: Visual-Based Navigation; Localization; SLAM

    Abstract : Given a set of 3D-to-2D point correspondences corrupted by outliers, we aim to robustly estimate the absolute camera pose. Existing methods robust to outliers either fail to guarantee high robustness and efficiency simultaneously, or require an appropriate initial pose and thus lack generality. In contrast, we propose a novel approach based on the robust �L2-minimizing estimate�(L2E) loss. We first define a novel cost function by integrating the projection constraint into the L2E loss. Then to efficiently obtain the global minimum of this function, we propose a hybrid strategy of a local optimizer and branch-and-bound. For branch-and-bound, we derive effective function bounds. Our approach can handle high outlier ratios, leading to high robustness. It can run reliably regardless of whether the initial pose is appropriate, providing high generality. Moreover, given a decent initial pose, it is suitable for real-time applications. Experiments on synthetic and real-world datasets showed that our approach outperforms state-of-the-art methods in terms of robustness and/or efficiency.

- Robust Vision-Based Obstacle Avoidance for Micro Aerial Vehicles in Dynamic Environments

    Author: Lin, Jiahao | Delft University of Technology
    Author: Zhu, Hai | Delft University of Technology
    Author: Alonso-Mora, Javier | Delft University of Technology
 
    keyword: Visual-Based Navigation; Aerial Systems: Perception and Autonomy; Collision Avoidance

    Abstract : In this paper, we present an on-board vision-based approach for avoidance of moving obstacles in dynamic environments. Our approach relies on an efficient obstacle detection and tracking algorithm based on stereo image pairs, which provides the estimated position, velocity and size of the obstacles. Robust collision avoidance is achieved by formulating a chance-constrained model predictive controller (CC-MPC) to ensure that the collision probability between the micro aerial vehicle (MAV) and each moving obstacle is below a specified threshold. The method takes into account MAV dynamics, state estimation and obstacle sensing uncertainties. The proposed approach is implemented on a quadrotor equipped with a stereo camera and is tested in a variety of environments, showing effective on-line collision avoidance of moving obstacles.

- Proximity Estimation Using Vision Features Computed on Sensor

    Author: Chen, Jianing | The University of Manchester
    Author: Liu, Yanan | University of Bristol
    Author: Carey, Stephen J. | The University of Manchester
    Author: Dudek, Piotr | The University of Manchester
 
    keyword: Visual-Based Navigation; Reactive and Sensor-Based Planning; Collision Avoidance

    Abstract : This paper presents a monocular vision based proximity estimation system using     Abstract features, such as corner points, blobs and edges, as inputs to a neural network. An experimental vehicle was built using a vision system integrating the SCAMP-5 vision chip, a micro-controller, and an RC model car. The vision chip includes image sensor with embedded 256x256 processor SIMD array. The pixel processor array chip was programmed to capture images and run the feature algorithms directly on the focal plane, and then digest them so that only sparse feature description data were read-out in the form of 40 values. By logging the vision output and the output from three infrared proximity sensors, training data were obtained to train three fully connected layer-recurrent neural networks with fewer than 700 parameters each. The trained neural network was able to estimate the proximity to the level of accuracy sufficient for a reactive collision avoidance behaviour to be achieved. The latency of the control system, from image capture to neural network output, was under 4 msec, enabling the vehicles to avoid obstacles of while moving at 0.6 m/s to 1.8 m/s in the experiment.

- Efficient Globally-Optimal Correspondence-Less Visual Odometry for Planar Ground Vehicles

    Author: Gao, Ling | ShanghaiTech University
    Author: Su, Junyan | ShanghaiTech University
    Author: Cui, Jiadi | ShanghaiTech University
    Author: Zeng, Xiangchen | ShanghaiTech University
    Author: Peng, Xin | ShanghaiTech University
    Author: Kneip, Laurent | ShanghaiTech
 
    keyword: Visual-Based Navigation; Localization; Intelligent Transportation Systems

    Abstract : The motion of planar ground vehicles is often non-holonomic, and as a result may be modelled by the 2 DoF Ackermann steering model. We analyse the feasibility of estimating such motion with a downward facing camera that exerts fronto-parallel motion with respect to the ground plane. This turns the motion estimation into a simple image registration problem in which we only have to identify a 2-parameter planar homography. However, one difficulty that arises from this setup is that ground-plane features are indistinctive and thus hard to match between successive views. We encountered this difficulty by introducing the first globally-optimal, correspondence-less solution to plane-based Ackermann motion estimation. The solution relies on the branch-and-bound optimisation technique. Through the low-dimensional parametrisation, a derivation of tight bounds, and an efficient implementation, we demonstrate how this technique is eventually amenable to accurate real-time motion estimation. We prove its property of global optimality and analyse the impact of assuming a locally constant centre of rotation. Our results on real data finally demonstrate a significant advantage over the more traditional, correspondence-based hypothesise-and-test schemes.

- EgoTEB: Egocentric, Perception Space Navigation Using Timed-Elastic-Bands

    Author: Smith, Justin | Georgia Institute of Technology
    Author: Xu, Ruoyang | Georgia Institute of Technology
    Author: Vela, Patricio | Georgia Institute of Technology
 
    keyword: Visual-Based Navigation; Collision Avoidance; Motion and Path Planning

    Abstract : The TEB hierarchical planner for real-time navigation through unknown environments is highly effective at balancing collision avoidance with goal directed motion. Designed over several years and publications, it implements a multi-trajectory optimization based synthesis method for identifying topologically distinct trajectory candidates through navigable space. Unfortunately, the underlying factor graph approach to the optimization problem induces a mismatch between grid-based representations and the optimization graph, which leads to several time and optimization inefficiencies. This paper explores the impact of using egocentric, perception space representations for the local planning map. Doing so alleviates many of the identified issues related to TEB and leads to a new method called egoTEB. Timing experiments and Monte Carlo evaluations in benchmark worlds quantify the benefits of egoTEB for navigation through uncertain environments.

- Graduated Non-Convexity for Robust Spatial Perception: From Non-Minimal Solvers to Global Outlier Rejection

    Author: Yang, Heng | MIT
    Author: Antonante, Pasquale | MIT
    Author: Tzoumas, Vasileios | Massachusetts Institute of Technology
    Author: Carlone, Luca | Massachusetts Institute of Technology
 
    keyword: Visual-Based Navigation; SLAM; Optimization and Optimal Control

    Abstract : Semidefinite Programming (SDP) and Sums-of-Squares (SOS) relaxations have led to certifiably optimal non-minimal solvers for several robotics and computer vision problems. However, most non-minimal solvers rely on least squares formulations, and, as a result, are brittle against outliers. While a standard approach to regain robustness against outliers is to use robust cost functions, the latter typically introduce other non-convexities, preventing the use of existing non-minimal solvers. In this letter, we enable the simultaneous use of non-minimal solvers and robust estimation by providing a general-purpose approach for robust global estimation, which can be applied to any problem where a non-minimal solver is available for the outlier-free case. To this end, we leverage the Black-Rangarajan duality between robust estimation and outlier processes, and show that graduated non-convexity (GNC) can be used in conjunction with non-minimal solvers to compute robust solutions, without requiring an initial guess. We demonstrate the resulting robust non-minimal solvers in applications, including point cloud and mesh registration, pose graph optimization, and image-based object pose estimation (also called shape alignment). Our solvers are robust to 70�80% of outliers, outperform RANSAC, are more accurate than specialized local solvers, and faster than specialized global solvers. We also propose the first certifiably optimal non-minimal solver for shape alignment using SOS relaxation.

- Reliable Frame-To-Frame Motion Estimation for Vehicle-Mounted Surround-View Camera Systems

    Author: Wang, Yifu | Australian National University
    Author: Huang, Kun | ShanghaiTech University
    Author: Peng, Xin | ShanghaiTech University
    Author: Li, Hongdong | Australian National University and NICTA
    Author: Kneip, Laurent | ShanghaiTech
 
    keyword: Visual-Based Navigation; Omnidirectional Vision; Localization

    Abstract : Modern vehicles are often equipped with a surround-view multi-camera system. The current interest in autonomous driving invites the investigation of how to use such systems for a reliable estimation of relative vehicle displacement. Existing camera pose algorithms either work for a single camera, make overly simplified assumptions, are computationally expensive, or simply become degenerate under non-holonomic vehicle motion. In this paper, we introduce a new, reliable solution able to handle all kinds of relative displacements in the plane despite the possibly non-holonomic characteristics. We furthermore introduce a novel two-view optimization scheme which minimizes a geometrically relevant error without relying on 3D point related optimization variables. Our method leads to highly reliable and accurate frame-to-frame visual odometry with a full-size, vehicle-mounted surround-view camera system.

- Enabling Topological Planning with Monocular Vision

    Author: Stein, Gregory | CSAIL, MIT
    Author: Bradley, Christopher | CSAIL, MIT
    Author: Preston, Victoria | Massachusetts Institute of Technology
    Author: Roy, Nicholas | Massachusetts Institute of Technology
 
    keyword: Visual-Based Navigation; Mapping; Motion and Path Planning

    Abstract : Topological strategies for navigation meaningfully reduce the space of possible actions available to a robot, allowing use of heuristic priors or learning to enable computationally efficient, intelligent planning. The challenges in estimating structure with monocular SLAM in low texture or highly cluttered environments have precluded its use for topological planning in the past. We propose a robust sparse map representation that can be built with monocular vision and overcomes these shortcomings. Using a learned sensor, we estimate high-level structure of an environment from streaming images by detecting sparse "vertices" (e.g., boundaries of walls) and reasoning about the structure between them. We also estimate the known free space in our map, a necessary feature for planning through previously unknown environments. We show that our mapping technique can be used on real data and is sufficient for planning and exploration in simulated multi-agent search and learned subgoal planning applications.

- DeepMEL: Compiling Visual Multi-Experience Localization into a Deep Neural Network

    Author: Gridseth, Mona | University of Toronto
    Author: Barfoot, Timothy | University of Toronto
 
    keyword: Visual-Based Navigation; Deep Learning in Robotics and Automation; Localization

    Abstract : Vision-based path following allows robots to autonomously repeat manually taught paths. Stereo Visual Teach and Repeat (VT&amp;R) [1] accomplishes accurate and robust long-range path following in unstructured outdoor environments across changing lighting, weather, and seasons by relying on colour-constant imaging [2] and multi-experience localization [3]. We leverage multi-experience VT&amp;R together with two datasets of outdoor driving on two separate paths spanning different times of day, weather, and seasons to teach a deep neural network to predict relative pose for visual odometry (VO) and for localization with respect to a path. In this paper we run experiments exclusively on datasets to study how the network generalizes across environmental conditions. Based on the results we believe that our system achieves relative pose estimates sufficiently accurate for in-the-loop path following and that it is able to localize radically different conditions against each other directly (i.e. winter to spring and day to night), a capability that our hand-engineered system does not have.

- SnapNav: Learning Mapless Visual Navigationwith Sparse Directional Guidance and Visual Reference

    Author: Xie, Linhai | University of Oxford
    Author: Markham, Andrew | Oxford University
    Author: Trigoni, Niki | University of Oxford
 
    keyword: Visual-Based Navigation; Deep Learning in Robotics and Automation

    Abstract : Learning-based visual navigation still remains a challenging problem in robotics, with two overarching issues: how to transfer the learnt policy to unseen scenarios, and how to deploy the system on real robots. In this paper, we propose a deep neural network based visual navigation system, SnapNav. Unlike map-based navigation or Visual-Teach-and-Repeat (VT&amp;R), SnapNav only receives a few snapshots of the environment combined with directional guidance to allow it to execute the navigation task. Additionally, SnapNav can be easily deployed on real robots due to a two-level hierarchy: a high level commander that provides directional commands and a low level controller that provides real-time control and obstacle avoidance. This also allows us to effectively use simulated and real data to train the different layers of the hierarchy, facilitating robust control. Extensive experimental results show that SnapNav achieves a highly autonomous navigation ability compared to baseline models, enabling sparse, map-less navigation in previously unseen environments.

- Kimera: An Open-Source Library for Real-Time Metric-Semantic Localization and Mapping

    Author: Rosinol, Antoni | MIT
    Author: Abate, Marcus | MIT
    Author: Chang, Yun | MIT
    Author: Carlone, Luca | Massachusetts Institute of Technology
 
    keyword: Visual-Based Navigation; SLAM; Mapping

    Abstract : We provide an open-source C++ library for real-time metric-semantic visual-inertial Simultaneous Localization And Mapping (SLAM). The library goes beyond existing visual and visual-inertial SLAM libraries (e.g., ORB-SLAM, VINS-Mono, OKVIS, ROVIO) by enabling mesh reconstruction and 3D semantic labeling in 3D. Kimera is designed with modularity in mind and has four key components: a visual-inertial odometry (VIO) module for fast and accurate state estimation, a robust pose graph optimizer for global trajectory estimation, a lightweight 3D mesher module for fast mesh reconstruction, and a dense 3D metric-semantic reconstruction module. The modules can be run in isolation or in combination, hence Kimera can easily fall back to a state-of-the-art VIO or a full SLAM system. Kimera runs in real-time on a CPU and produces a 3D metric-semantic mesh from semantically labeled images, which can be obtained by modern deep learning methods. We hope that the flexibility, computational efficiency, robustness, and accuracy afforded by Kimera will build a solid basis for future metric-semantic SLAM and perception research, and will allow researchers across multiple areas (e.g., VIO, SLAM, 3D reconstruction, segmentation) to benchmark and prototype their own efforts without having to start from scratch.

- CityLearn: Diverse Real-World Environments for Sample-Efficient Navigation Policy Learning

    Author: Chanc�n Le�n, Marvin Aldo | Queensland University of Technology
    Author: Milford, Michael J | Queensland University of Technology
 
    keyword: Visual-Based Navigation; Visual Learning; Deep Learning in Robotics and Automation

    Abstract : Visual navigation tasks in real-world environments often require both self-motion and place recognition feedback. While deep reinforcement learning has shown success in solving these perception and decision-making problems in an end-to-end manner, these algorithms require large amounts of experience to learn navigation policies from high-dimensional data, which is generally impractical for real robots due to sample complexity. In this paper, we address these problems with two main contributions. We first leverage place recognition and deep learning techniques combined with goal destination feedback to generate compact, bimodal image representations that can then be used to effectively learn control policies from a small amount of experience. Second, we present an interactive framework, CityLearn, that enables for the first time training and deployment of navigation algorithms across city-sized, realistic environments with extreme visual appearance changes. CityLearn features more than 10 benchmark datasets, often used in visual place recognition and autonomous driving research, including over 100 recorded traversals across 60 cities around the world. We evaluate our approach on two CityLearn environments, training our navigation policy on a single traversal per dataset. Results show our method can be over 2 orders of magnitude faster than when using raw images, and can also generalize across extreme visual changes including day to night and summer to winter transitions.

- Constrained Filtering-Based Fusion of Images, Events, and Inertial Measurements for Pose Estimation

    Author: Jung, jae Hyung | Seoul National University
    Author: Park, Chan Gook | Seoul National University
 
    keyword: Visual-Based Navigation; Localization; Sensor Fusion

    Abstract : In this paper, we propose a novel filtering-based method that fuses events from a dynamic vision sensor (DVS), images, and inertial measurements to estimate camera poses. A DVS is a bio-inspired sensor that generates events triggered by brightness changes. It can cover the drawbacks of a conventional camera by virtual of its independent pixels and high dynamic range. Specifically, we focus on optical flow obtained from both a stream of events and intensity images in which the former is much like a differential quantity, whereas the latter is a pixel difference in a much longer time interval than events. This nature characteristic motivates us to model optical flow estimated from events directly, but feature tracks for images in the filter design. An inequality constraint is considered in our method since the inverse scene-depth is larger than zero by its definition. Furthermore, we evaluate our proposed method in the benchmark DVS dataset and a dataset collected by the     Authors. The results reveal that the presented algorithm has reduced the position error by 49.9% on average and comparable accuracy only using events when compared to the state-of-the-art filtering-based estimator.

- Schmidt-EKF-Based Visual-Inertial Moving Object Tracking

    Author: Eckenhoff, Kevin | University of Delaware
    Author: Geneva, Patrick | University of Delaware
    Author: Merrill, Nathaniel | University of Delaware
    Author: Huang, Guoquan | University of Delaware
 
    keyword: Visual-Based Navigation; Sensor Fusion; Localization

    Abstract : In this paper we investigate the effect of tightly-coupled estimation on the performance of visual-inertial localization and dynamic object pose tracking. In particular, we show that while a joint estimation system outperforms its decoupled counterpart when given a ``proper'' model for the target's motion, inconsistent modeling, such as choosing improper levels for the target's propagation noises, can actually lead to a degradation in ego-motion accuracy. To address the realistic scenario where a good prior knowledge of the target's motion model is not available, we design a new system based on the Schmidt-Kalman Filter (SKF), in which target measurements do not update the navigation states, however all correlations are still properly tracked. This allows for both consistent modeling of the target errors and the ability to update target estimates whenever the tracking sensor receives non-target data such as bearing measurements to static, 3D environmental features. We show in extensive simulation that this system, along with a robot-centric representation of the target, leads to robust estimation performance even in the presence of an inconsistent target motion model. Finally, the system is validated in a real-world experiment, and is shown to offer accurate localization and object pose tracking performance.

- Learning View and Target Invariant Visual Servoing for Navigation

    Author: Li, Yimeng | George Mason University
    Author: Kosecka, Jana | George Mason University
 
    keyword: Visual-Based Navigation; Visual Servoing; Model Learning for Control

    Abstract : The advances in deep reinforcement learning recently revived interest in data-driven learning based approaches to navigation. In this paper we propose to learn viewpoint invariant and target invariant visual servoing for local mobile robot navigation; given an initial view and the goal view or an image of a target, we train deep convolutional network controller to reach the desired goal. We present a new architecture for this task which rests on the ability of establishing correspondences between the initial and goal view and novel reward structure motivated by the traditional feedback control error. The advantage of the proposed model is that it does not require calibration and depth information and achieves robust visual servoing in a variety of environments and targets without any parameter fine tuning. We present comprehensive evaluation of the approach and comparison with other deep learning architectures as well as classical visual servoing methods in visually realistic simulation environment. The presented model overcomes the brittleness of classical visual servoing based methods and achieves significantly higher generalization capability compared to the previous learning approaches.

- Tightly-Coupled Single-Anchor Ultra-Wideband-Aided Monocular Visual Odometry System

    Author: Nguyen, Thien Hoang | Nanyang Technological University
    Author: Nguyen, Thien-Minh | Nanyang Technological University
    Author: Xie, Lihua | NanyangTechnological University
 
    keyword: Visual-Based Navigation; Sensor Fusion; Localization

    Abstract : In this work, we propose a tightly-coupled odometry framework, which combines monocular visual feature observations with distance measurements provided by a single ultra-wideband (UWB) anchor with an initial guess for its location. Firstly, the scale factor and the anchor position in the vision frame will be simultaneously estimated using a variant of Levenberg-Marquardt non-linear least squares optimization scheme. Once the scale factor is obtained, the map of visual features is updated with the new scale. Subsequent ranging errors in a sliding window are continuously monitored and the estimation procedure will be reinitialized to refine the estimates. Lastly, range measurements and anchor position estimates are fused when needed into a pose-graph optimization scheme to minimize both the landmark reprojection errors and ranging errors, thus reducing the visual drift and improving the system robustness. The proposed method is implemented in Robot Operating System (ROS) and can function in real-time. The performance of the proposed system is compared with state-of-the-art methods on both public datasets and real-life experiments.

- Scaling Local Control to Large-Scale Topological Navigation

    Author: Meng, Xiangyun | University of Washington
    Author: Ratliff, Nathan | Lula Robotics Inc
    Author: Xiang, Yu | NVIDIA
    Author: Fox, Dieter | University of Washington
 
    keyword: Visual-Based Navigation; Deep Learning in Robotics and Automation; Motion and Path Planning

    Abstract : Visual topological navigation has been revitalized recently thanks to the advancement of deep learning that substantially improves robot perception. However, the scalability and reliability issue remain challenging due to the complexity and ambiguity of real world images and mechanical constraints of real robots. We present an intuitive solution to show that by accurately measuring the capability of a local controller, large-scale visual topological navigation can be achieved while being scalable and robust. Our approach achieves state-of-the-art results in trajectory following and planning in large-scale environments. It also generalizes well to real robots and new environments without finetuning.

- Zero-Shot Imitation Learning from Demonstrations for Legged Robot Visual Navigation

    Author: Pan, Xinlei | UC Berkeley
    Author: Zhang, Tingnan | Google
    Author: Ichter, Brian | Google Brain
    Author: Faust, Aleksandra | Google Brain
    Author: Tan, Jie | Google
    Author: Ha, Sehoon | Google Brain
 
    keyword: Visual-Based Navigation; Learning from Demonstration; Legged Robots

    Abstract : Imitation learning is a popular approach for training visual navigation policies. However, collecting expert demonstrations for legged robots is challenging as these robots can be hard to control, move slowly, and cannot operate continuously for a long time. Here, we propose a zero-shot imitation learning approach for training a visual navigation policy on legged robots from human (third-person perspective) demonstrations, enabling high-quality navigation and cost-effective data collection. However, imitation learning from third-person demonstrations raises unique challenges. First, these demonstrations are captured from different camera perspectives, which we address via a feature disentanglement network(FDN) that extracts perspective-invariant state features. Second, as transition dynamics vary across systems, we label missing actions by either building an inverse model of the robot's dynamics in the feature space and applying it to the human demonstrations or developing a Graphic User Interface(GUI) to label human demonstrations. To train a navigation policy we use a model-based imitation learning approach with FDN and labeled human demonstrations. We show that our framework can learn an effective policy for a legged robot, Laikago, from human demonstrations in both simulated and real-world environments. Our approach is zero-shot as the robot never navigates the same paths during training as those at testing time. We justify our framework by performing a comparative study.

## Soft Robot Applications

- High Resolution Soft Tactile Interface for Physical Human-Robot Interaction

    Author: Huang, Isabella | UC Berkeley
    Author: Bajcsy, Ruzena | Univ of California, Berkeley
 
    keyword: Soft Robot Applications; Physical Human-Robot Interaction; Modeling, Control, and Learning for Soft Robots

    Abstract : If robots and humans are to coexist and cooperate in society, it would be useful for robots to be able to engage in tactile interactions. Touch is an intuitive communication tool as well as a fundamental method by which we assist each other physically. Tactile abilities are challenging to engineer in robots, since both mechanical safety and sensory intelligence are imperative. Existing work reveals a trade-off between these principles--- tactile interfaces that are high in resolution are not easily adapted to human-sized geometries, nor are they generally compliant enough to guarantee safety. On the other hand, soft tactile interfaces deliver intrinsically safe mechanical properties, but their non-linear characteristics render them difficult for use in timely sensing and control. We propose a robotic system that is equipped with a completely soft and therefore safe tactile interface that is large enough to interact with human upper limbs, while producing high resolution tactile sensory readings via depth camera imaging of the soft interface. We present and validate a data-driven model that maps point cloud data to contact forces, and verify its efficacy by demonstrating two real-world applications. In particular, the robot is able to react to a human finger's pokes and change its pose based on the tactile input. In addition, we also demonstrate that the robot can act as an assistive device that dynamically supports and follows a human forearm from underneath.

- Learning-Based Fingertip Force Estimation for Soft Wearable Hand Robot with Tendon-Sheath Mechanism

    Author: Cho, Kyu-Jin | Seoul National University, Biorobotics Laboratory
    Author: Jo, Sungho | Korea Advanced Institute of Science and Technology (KAIST)
    Author: Kang, Brian Byunghyun | Seoul National University
    Author: Kim, Daekyum | Korea Advanced Institute of Science and Technology
    Author: Choi, Hyungmin | Seoul National University
    Author: Jeong, Useok | Korea Institute of Industrial Technology (KITECH)
    Author: Kim, Kyu Bum | Seoul National University
 
    keyword: Soft Robot Applications; Wearable Robots; Modeling, Control, and Learning for Soft Robots

    Abstract : Soft wearable hand robots with tendon-sheath mechanisms are being actively developed to assist people who have lost their hand mobility. For these robots, accurately estimating fingertip forces can lead to successful object grasping. One way of estimating fingertip forces is to place sensors on the glove. However, directly placing placing sensors on the glove increases bulkiness and does not allow for water resistance. This results in a lack of user mobility when performing daily tasks. While another approach can utilize information like wire tension and motor encoder values, non-linearity and hysteresis with regards to the sheath bending angles and the dynamic changes of the angle displacement hinder accurate fingertip force estimation. This paper proposes a deep learning-based method to estimate fingertip forces by integrating dynamic information of motor encoders, wire tension, and sheath bending angles. The hardware system includes a soft under-actuated wearable robot, complete with an actuation system and a sensing system designed to measure sheath bending angles. The proposed approach was evaluated under criteria ranging from different object sizes, bending angle ranges, and forces. The results show that the system including the bending angle sensors and the proposed model can accurately estimate fingertip forces for the soft wearable hand robot.

- Autonomous and Reversible Adhesion Using Elastomeric Suction Cups for In-Vivo Medical Treatments

    Author: Iwasaki, Haruna | Waseda University
    Author: Lefevre, Flavien | ESEO
    Author: Damian, Dana | University of Sheffield
    Author: Iwase, Eiji | Waseda University
    Author: Miyashita, Shuhei | University of Sheffield
 
    keyword: Soft Robot Applications; Medical Robots and Systems; Grippers and Other End-Effectors

    Abstract : Remotely controllable and reversible adhesion is highly desirable for surgical operations: it can provide the possibility of non-invasive surgery, flexibility in fixing a patch and surgical manipulation via sticking. In our previous work, we developed a remotely controllable, ingestible, and deployable pill for use as a patch in the human stomach. In this study, we focus on magnetically facilitated reversible adhesion and develop a suction-based adhesive mechanism as a solution for non-invasive and autonomous adhesion of patches. We present the design, model, and fabrication of a magnet-embedded elastomeric suction cup. The suction cup can be localised, navigated, and activated or deactivated in an autonomous way; all realised magnetically with a pre-programmed fashion. The use of the adhesion mechanism is demonstrated for anchoring and carrying, for patching an internal organ surface and for an object removal, respectively.

- Design of an Inflatable Wrinkle Actuator with Fast Inflation/Deflation Responses for Wearable Suits

    Author: Park, Junghoon | KAIST
    Author: Choi, Junhwan | KAIST
    Author: Kim, Sangjoon J. | KAIST
    Author: Seo, Kap-Ho | Korea Institute of Robot and Convergence
    Author: Kim, Jung | KAIST
 
    keyword: Soft Robot Applications; Soft Sensors and Actuators; Wearable Robots

    Abstract : In recent years, inflatable actuators have been widely used in wearable suits to assist humans who need help in moving their joints. Despite their lightweight and simple structure, they have long inflation and deflation times, which make their quick use difficult. To resolve this issue, we propose an inflatable wrinkle actuator with fast inflation and deflation responses. First, a theoretical model is proposed to develop an actuator that satisfies the design requirements: the desired assistive torque and the foam factor based on the wearability. Second, we reduce the inflation and deflation times by partially controlling the actuator layers and by designing pneumatic circuits using a vacuum ejector. To validate the usability of the actuator in wearable suits, we applied it to a wearable knee suit, and the inflation and deflation times were 0.40 s and 0.16 s, respectively. As a result, we ensured that the actuator did not interfere with human knee joint movement during walking by creating any residual resistance.

- Design and Validation of a Soft Ankle-Foot Orthosis Exosuit for Inversion and Eversion Support

    Author: Thalman, Carly | Arizona State University
    Author: Lee, Hyunglae | Arizona State University
 
    keyword: Soft Robot Applications; Wearable Robots; Rehabilitation Robotics

    Abstract : This paper presents a soft robotic ankle-foot orthosis (SR-AFO) exosuit designed to provide support to the human ankle in the frontal plane without restricting natural motion in the sagittal plane. The SR-AFO exosuit incorporates inflatable fabric-based actuators with a hollow cylinder design which requires less volume than the commonly used solid cylinder design for the same deflection. The actuators were modeled and characterized using finite element analysis techniques and experimentally validated. The SR-AFO exosuit was evaluated on healthy participants in both a sitting position using a wearable ankle robot and a standing position using a dual-axis robotic platform to characterize the effect of the exosuit on the change of 2D ankle stiffness in the sagittal and frontal planes. For both sitting and standing test protocols, a trend of increasing ankle stiffness in the frontal plane was observed up to 50 kPa while stiffness in the sagittal plane remained relatively constant over pressure levels. During quiet standing, the exosuit could effectively change eversion stiffness at the ankle joint from about 20 to 70 Nm/rad at relatively low-pressure levels (&lt; 30 kPa). Eversion stiffness was 84.9 Nm/rad at 50 kPa, an increase of 387.5% from the original free foot stiffness.

- Vine Robots: Design, Teleoperation, and Deployment for Navigation and Exploration (I)
 
    Author: Coad, Margaret M. | Stanford University
    Author: Blumenschein, Laura | Stanford University
    Author: Cutler, Sadie | Brigham Young University
    Author: Reyna Zepeda, Javier | Stanford University
    Author: Naclerio, Nicholas | University of California, Santa Barbara
    Author: El-Hussieny, Haitham | Faculty of Engineering(Shoubra), Benha University
    Author: Mehmood, Usman | Korea University of Technology and Education
    Author: Ryu, Jee-Hwan | Korea Advanced Institute of Science and Technology
    Author: Hawkes, Elliot Wright | University of California, Santa Barbara
    Author: Okamura, Allison M. | Stanford University
 
    keyword: Soft Robot Applications; Field Robots

    Abstract : A new class of continuum robots has recently been explored, characterized by tip extension, significant length change, and directional control. Here, we call this class of robots "vine robots," due to their similar behavior to plants with the growth habit of trailing. Due to their growth-based movement, vine robots are well suited for navigation and exploration in cluttered environments, but until now, they have not been deployed outside the lab. Portability of these robots and steerability at length scales relevant for navigation are key to field applications. In addition, intuitive human-in-the-loop teleoperation enables movement in unknown and dynamic environments. We present a vine robot system that is teleoperated using a custom designed flexible joystick and camera system, long enough for use in navigation tasks, and portable for use in the field. We report on deployment of this system in two scenarios: a soft robot navigation competition and exploration of an archaeological site. The competition course required movement over uneven terrain, past unstable obstacles, and through a small aperture. The archaeological site required movement over rocks and through horizontal and vertical turns. The robot tip successfully moved past the obstacles and through the tunnels, demonstrating the capability of vine robots to achieve navigation and exploration tasks in the field.

- Pressure-Driven Manipulator with Variable Stiffness Structure

    Author: Sozer, Canberk | Scuola Superiore Sant'Anna
    Author: Patern�, Linda | The BioRobotics Institute, Scuola Superiore Sant'Anna
    Author: Tortora, Giuseppe | Scuola Superiore Sant'Anna
    Author: Menciassi, Arianna | Scuola Superiore Sant'Anna - SSSA
 
    keyword: Soft Robot Applications; Soft Robot Materials and Design; Flexible Robots

    Abstract : The high deformability and compliance of soft robots allow safer interaction with the environment. On the other hand, these advantages bring along controllability and predictability challenges which result in loss of force and stiffness output. Such challenges should be addressed in order to improve the overall functional performance and to meet the requirements of real-scenario applications. In this paper, we present a bidirectional in-plane manipulator which consists of two unidirectional fiber-reinforced actuators (FRAs) and a hybrid soft-rigid stiffness control structure (SCS), all of them controlled by air pressure. Both controllability and predictability of the manipulator are enhanced by the hybrid soft-rigid structure. While the FRAs provide positioning and position dependent stiffness, the SCS increases the stiffness of the manipulator without position dependency. The SCS is able to increase the manipulator stiffness by 35%, 30%, and 18%, when one FRA is pressurized at 150 kPa, 75 kPa, and 0 kPa, respectively. Experiments are carried out to present the feasibility of the proposed manipulator.

- 3D Electromagnetic Reconfiguration Enabled by Soft Continuum Robots

    Author: Gan, Lucia | Stanford University
    Author: Blumenschein, Laura | Stanford University
    Author: Huang, Zhe | University of Illinois at Urbana-Champaign
    Author: Okamura, Allison M. | Stanford University
    Author: Hawkes, Elliot Wright | University of California, Santa Barbara
    Author: Fan, Jonathan | Stanford University
 
    keyword: Soft Robot Applications; Soft Robot Materials and Design

    Abstract : The properties of radio frequency electromagnetic systems can be manipulated by changing the 3D geometry of the system. Most reconfiguration schemes specify different conductive pathways using electrical switches in mechanically static systems, or they actuate and reshape a continuous metallic structure. Here, we demonstrate a novel strategy that utilizes soft continuum robots to both dynamically assemble electrical pathways and mechanically reconfigure 3D electromagnetic devices. Our concept consists of using soft robotic actuation to conductively connect multiple subwavelength-scale metallic building blocks, which form into electromagnetic structures when joined together. Soft robots offer an exciting avenue for electromagnetic device construction because they can form complex, high curvature shapes from low-loss dielectric materials using straightforward manufacturing methods. As a proof of concept, we experimentally implement a helical antenna that can switch chirality through tendon actuation of a soft pneumatic continuum robot. Our work introduces a new paradigm for electromagnetic reconfiguration using soft robotic platforms.

- VaLeNS: Design of a Novel Variable Length Nested Soft Arm

    Author: Uppalapati, Naveen Kumar | University of Illinois at Urbana-Champaign
    Author: Krishnan, Girish | University of Illinois Urbana Champaign
 
    keyword: Soft Robot Applications; Soft Robot Materials and Design; Modeling, Control, and Learning for Soft Robots

    Abstract : Over the last decade, soft continuum arms (SCAs) have successfully demonstrated the compliance needed to operate in unstructured environments and handle fragile objects. However, their inherent soft compliance limits their performance in situations where stiffness and force transfer is required. In this letter, we present a compact design architecture, which is a hybrid between soft arms and rigid links known as Variable Length Nested Soft (VaLeNS) arm. The design architecture involves a novel SCA nested inside a concentric rigid tube. The SCA can undergo a combination of spatial bending (B) and bidirectional axial twist (R^2), and can extrude out or retract back into the rigid tube with varying length. The resulting configuration is shown to modulate stiffness up to a factor of ten and exhibits enhanced workspace and dexterity. Furthermore, the VaLeNS arm mounted on a rigid robotic platform allows for bifurcation of the overall workspace into rigid and soft, and can achieve high reachability in constrained environments. The paper demonstrates the effectiveness of the VaLeNS arm system in manipulation tasks that require both the rigid and soft attributes. This design architecture is deemed useful in agricultural applications and in physical human robot interaction.

- A Programmably Compliant Origami Mechanism for Dynamically Dexterous Robots

    Author: Chen, Wei-Hsi | University of Pennsylvania
    Author: Misra, Shivangi | University of Pennsylvania
    Author: Gao, Yuchong | University of Pennsylvania
    Author: Lee, Young-Joo | University of Pennsylvania
    Author: Koditschek, Daniel | University of Pennsylvania
    Author: Yang, Shu | University of Pennsylvania
    Author: Sung, Cynthia | University of Pennsylvania
 
    keyword: Soft Robot Applications; Soft Robot Materials and Design; Compliant Joint/Mechanism

    Abstract : We present an approach to overcoming challenges in dynamical dexterity for robots through tunable origami structures. Our work leverages a one-parameter family of flat sheet crease patterns that folds into origami bellows, whose axial compliance can be tuned to select desired stiffness. Concentrically arranged cylinder pairs reliably manifest additive stiffness, extending the tunable range by nearly an order of magnitude and achieving bulk axial stiffness spanning 200--1500 N/m using 8 mil thick polyester-coated paper. Accordingly, we design origami energy-storing springs with a stiffness of 1035 N/m each and incorporate them into a three degree-of-freedom (DOF) tendon-driven spatial pointing mechanism that exhibits trajectory tracking accuracy less than 15% rms error within a (~2 cm)^3 volume. The origami springs can sustain high power throughput, enabling the robot to achieve asymptotically stable juggling for both highly elastic (1kg resilient shot put ball) and highly damped (medicine ball) collisions in the vertical direction with apex heights approaching 10 cm. The results demonstrate that �soft'' robotic mechanisms are able to perform a controlled, dynamically actuated task.	

- Human Interface for Teleoperated Object Manipulation with a Soft Growing Robot

    Author: Stroppa, Fabio | Stanford University
    Author: Luo, Ming | Stanford University
    Author: Yoshida, Kyle | Stanford University
    Author: Coad, Margaret M. | Stanford University
    Author: Blumenschein, Laura | Stanford University
    Author: Okamura, Allison M. | Stanford University
 
    keyword: Soft Robot Applications; Human Factors and Human-in-the-Loop; Gesture, Posture and Facial Expressions

    Abstract : Soft growing robots are proposed for use in applications such as complex manipulation tasks or navigation in disaster scenarios. Safe interaction and ease of production promote the usage of this technology, but soft robots can be challenging to teleoperate due to their unique degrees of freedom. In this paper, we propose a human-centered interface that allows users to teleoperate a soft growing robot for manipulation tasks using arm movements. A study was conducted to assess the intuitiveness of the interface and the performance of our soft robot, involving a pick-and-place manipulation task. The results show that users were able to complete the task 97% of the time and achieve placement errors below 2 cm on average. These results demonstrate that our body-movement-based interface is an effective method for control of a soft growing robot manipulator.

## Prosthetics and Exoskeletons

- A Closed-Loop and Ergonomic Control for Prosthetic Wrist Rotation

    Author: Legrand, Mathilde | Institute for Intelligent Systems and Robotics, Sorbonne Univers
    Author: Jarrass�, Nathanael | Sorbonne Université, ISIR UMR 7222 CNRS
    Author: Richer, Florian | Cnrs - Isir
    Author: Morel, Guillaume | Sorbonne Université, CNRS, INSERM
 
    keyword: Prosthetics and Exoskeletons; Rehabilitation Robotics; Physical Human-Robot Interaction

    Abstract : Beyond the ultimate goal of prosthetics, repairing all the capabilities of amputees, the development line of upper-limb prostheses control mainly relies on three aspects: the robustness, the intuitiveness and the reduction of mental fatigue. Many complex structures and algorithms are proposed but no one question a common open-loop nature, where the user is the one in charge of correcting errors. Yet, closing the control loop at the prosthetic level may help to improve the three main lines of research cited above. One major issue to build a closed-loop control is the definition of a reliable error signal; this paper proposes to use body compensations, naturally exhibited by prostheses users when the motion of their device is inaccurate, as such. The described control scheme measures these compensatory movements and makes the prosthesis move in order to bring back the user into an ergonomic posture. The function of the prosthesis is no longer to perform a given motion but rather to correct the posture of its user while s/he focus on performing an endpoint task. This concept was validated and compared to a standard open-loop scheme, for the control of a prosthetic wrist, with five healthy subjects completing a dedicated task with a customized transradial prosthesis. Results show that the presented closed-loop control allows for more intuitiveness and less mental burden without enhancing body compensation.

- Comparison of Online Algorithms for the Tracking of Multiple Magnetic Targets in a Myokinetic Control Interface

    Author: Montero-Arag�n, Jordan | Scuola Superiore Sant'Anna
    Author: Gherardini, Marta | The Biorobotics Institute, Sant'Anna School of Advanced Studies
    Author: Clemente, Francesco | Scuola Superiore Sant'Anna
    Author: Cipriani, Christian | Scuola Superiore Sant'Anna
 
    keyword: Prosthetics and Exoskeletons; Localization; Optimization and Optimal Control

    Abstract : Magnetic tracking algorithms can be used to determine the position and orientation of specially designed magnetic markers or devices. These techniques are particularly interesting for biomedical applications such as teleoperated surgical robots or the control of upper limb prostheses. The performance of different algorithms used for magnetic tracking were compared in the past. However, in most cases, those algorithms were required to track a single MM. Here we investigated the performance of three localization algorithms in tracking up to 9 magnetic markers: two optimization-based (Levenberg-Marquardt algorithm, LMA, and Trust Region Reflective algorithm, TRRA) and one recursion-based (unscented Kalman Filter, UKF) algorithm. The tracking accuracy of the algorithms and their computation time were investigated through simulations. The accuracy of the three algorithms was similar, leading to estimation errors varying from a fraction of a millimeter, to a couple of millimeters. They allowed to accurately track up to six magnets with computation times under 300 ms for the UKF and 45 ms for the LMA/TRRA. The TRRA showed the best tracking performance overall. These outcomes are of interest for a wide range of robotics applications that require remote tracking.

- SIMPA: Soft-Grasp Infant Myoelectric Prosthetic Arm

    Author: De Barrie, Daniel | University of Lincoln
    Author: Margetts, Rebecca | University of Lincoln
    Author: Goher, Khaled | University of Lincoln
 
    keyword: Prosthetics and Exoskeletons; Soft Robot Applications; Additive Manufacturing

    Abstract :     Abstract� Myoelectric prosthetic arms have primarily focused on adults, despite evidence showing the benefits of early adoption. This work presents SIMPA, a low-cost 3D-printed prosthetic arm with soft grippers. The arm has been designed using CAD and 3D-scaning and manufactured using predominantly 3D-printing techniques. A voluntary opening control system utilising an armband based sEMG has been developed concurrently. Grasp tests have resulted in an average effectiveness of 87%, with objects in excess of 400g being securely grasped. The results highlight the effectiveness of soft grippers as an end device in prosthetics, as well as viability of toddler scale myoelectric devices.

- Backdrivable and Fully-Portable Pneumatic Back Support Exoskeleton for Lifting Assistance

    Author: Heo, Ung | KAIST
    Author: Kim, Sangjoon J. | KAIST
    Author: Kim, Jung | KAIST
 
    keyword: Prosthetics and Exoskeletons; Hydraulic/Pneumatic Actuators; Mechanism Design

    Abstract : To reduce the possibility of lower back pain (LBP), which is the most frequent injury in manual labor, several back support exoskeletons have been developed and implemented for lifting motion assistance. Although pneumatic power transmission is attractive due to its inherent compliance and backdrivability, the portability of the pneumatic system is highly limited due to the bulky air compressors that provide compressed air to the system. Therefore, we aimed to develop a fully-portable pneumatic back support exoskeleton by integrating all pneumatic components in the system. The compressed air consumption and generation of pneumatic system were modeled to meet design requirements. The developed exoskeleton was completely stand-alone and provides 80Nm of maximum extension torque for 6 liftings per minute (6l/m). The upper limit of the resistance torque was estimated to be about 2Nm, which implies high backdrivability. Finally, lifting experiments were performed and surface electromyography (sEMG) was measured to validate the physical assistance of the developed exoskeleton system for ten subjects. Compared to the case with no exoskeleton, the back muscle activation was significantly reduced with the assistances.

-  Clinical Readiness of a Myoelectric Postural Control Algorithm for Persons with Transradial Amputation (I)

    Author: Segil, Jacob | University of Colorado
    Author: Kaliki, Rahul | Infinite Biomedical Technologies
    Author: Uellendahl, Jack | Hanger Prosthetics and Orthotics
    Author: Weir, Richard | University of Colorado Denver | Anschutz Medical Campus

- Force Control of SEA-Based Exoskeletons for Multimode Human-Robot Interactions (I)

    Author: Huo, Weiguang | Imperial College London
    Author: Alouane, Mohamed Amine | Université Paris Est Cr�teil, France
    Author: Amirat, Yacine | University of Paris Est Cr�teil (UPEC)
    Author: Mohammed, Samer | University of Paris Est Cr�teil - (UPEC)
 
    keyword: Prosthetics and Exoskeletons; Force Control; Physical Human-Robot Interaction

    Abstract : In this article, a proxy-based force control method is proposed for three important human-robot interaction modes: zero-impedance mode, force assistive mode, and large force mode. A two-mass dynamic model-based nonlinear disturbance observer is used to meet the zero impedance output and accurate force tracking requirements with respect to disturbances from the wearer and environment. Additionally, significant force compliance can be achieved to guarantee the wearer's safety when the interaction torque is large. The proposed method is evaluated via experiments by comparison to the conventional proportional-integral-derivative and proxy-based sliding mode control methods. The results indicate that the proposed approach achieves better force tracking accuracy, robustness, and force compliance in three-mode human-robot interactions.

- Velocity Field Based Active-Assistive Control for Upper Limb Rehabilitation Exoskeleton Robot

    Author: Chia, En-Yu | National Taiwan University
    Author: Chen, Yi-Lian | National Taiwan University
    Author: Chien, Tzu-Chieh | National Taiwan University
    Author: Chiang, Ming-Li | National Taiwan University
    Author: Fu, Li-Chen | National Taiwan University
    Author: Lai, Jin-Shin | National Taiwan University
    Author: Lu, Lu | National Taiwan University
 
    keyword: Rehabilitation Robotics; Physical Human-Robot Interaction; Prosthetics and Exoskeletons

    Abstract : There are limitations of conventional active-assistive control for upper limb rehabilitation with help from exoskeleton robot, such as 1). prior time-dependent trajectories are generally required, 2). task-based rehabilitation exercise involving multi-joint motion is hard to implement, and 3). assistive mechanism normally is so inflexible that the resulting exercise performed by the subjects becomes inefficient. In this paper, we propose a novel velocity field based active-assistive control system to address these issues, which leads to much more efficient and precise rehabilitation compared with the existing schemes. First, we design a Kalman filter based interactive torque observer to obtain subjects' active intention of motion. Next, a joint-position-dependent velocity field which can be automatically generated via the task motion pattern is proposed to provide the time-independent assistance to the subjects. We further propose an integration method that combines the active and assistive motions based on the performance and the involvement of subjects to guide them to perform the task more voluntarily and precisely. The experiment results show that both the execution time and the subjects' torque exertion are reduced while performing both given single joint tasks and task-oriented multi-joint tasks as compared with the related work in the literature.

- Design, Development and Control of a Tendon-Actuated Exoskeleton for Wrist Rehabilitation and Training

    Author: Dragusanu, Mihai | University of Siena
    Author: Lisini Baldi, Tommaso | University of Siena
    Author: Iqbal, Muhammad Zubair | University of Siena
    Author: Prattichizzo, Domenico | Université Di Siena
    Author: Malvezzi, Monica | University of Siena
 
    keyword: Rehabilitation Robotics; Physically Assistive Devices; Health Care Management

    Abstract : Robot rehabilitation is an emerging and promising topic that incorporates robotics with neuroscience and rehabilitation to define new methods for supporting patients with neurological diseases. As a consequence, the rehabilitation process could increase the efficacy exploiting the potentialities of robot-mediated therapies. Nevertheless, nowadays clinical effectiveness is not enough to widely introduce robotic technologies in such social contexts. In this paper we propose a step further, presenting an innovative exoskeleton for wrist flexion/extension and adduction/abduction motion training. It is designed to be wearable and easy to control and manage. It can be used by the patient in collaboration with the therapist or autonomously. The paper introduces the main steps of device design and development and presents some tests conducted with an user with limited wrist mobility.

- Impedance Control of a Transfemoral Prosthesis Using Continuously Varying Ankle Impedances and Multiple Equilibria

    Author: Anil Kumar, Namita | Texas A&amp;M University College Station
    Author: Hong, Woolim | Texas A&amp;M University
    Author: Hur, Pilwon | Texas A&amp;M University
 
    keyword: Prosthetics and Exoskeletons; Compliance and Impedance Control; Rehabilitation Robotics

    Abstract : Impedance controllers are popularly used in the field of lower limb prostheses and exoskeleton development. Such controllers assume the joint to be a spring-damper system described by a discrete set of equilibria and impedance param- eters. These parameters are estimated via a least squares opti- mization that minimizes the difference between the controller's output torque and human joint torque. Other researchers have used perturbation studies to determine empirical values for ankle impedance. The resulting values vary greatly from the prior least squares estimates. While perturbation studies are more credible, they require immense investment. This paper extended the least squares approach to reproduce the results of perturbation studies. The resulting ankle impedance parameters were successfully tested on a powered transfemoral prosthesis, AMPRO II. Further, the paper investigated the effect of multiple equilibria on the least squares estimation and the performance of the impedance controller. Finally, the paper uses the proposed least squares optimization method to estimate knee impedance.

- Towards Variable Assistance for Lower Body Exoskeletons

    Author: Gurriet, Thomas | California Institute of Technology
    Author: Tucker, Maegan | California Institute of Technology
    Author: Duburcq, Alexis | Wandercraft
    Author: Boeris, Guilhem | Wandercraft
    Author: Ames, Aaron | Caltech
 
    keyword: Prosthetics and Exoskeletons; Rehabilitation Robotics; Formal Methods in Robotics and Automation

    Abstract : This paper presents and experimentally demonstrates a novel framework for variable assistance on lower body exoskeletons, based upon safety-critical control methods. Existing work has shown that providing some freedom of movement around a nominal gait, instead of rigidly following it, accelerates the spinal learning process of people with a walking impediment when using a lower body exoskeleton. With this as motivation, we present a method to accurately control how much a subject is allowed to deviate from a given gait while ensuring robustness to patient perturbation. This method leverages control barrier functions to force certain joints to remain inside predefined trajectory tubes in a minimally invasive way. The effectiveness of the method is demonstrated experimentally with able-bodied subjects and the Atalante lower body exoskeleton.

- Offline Assistance Optimization of a Soft Exosuit for Augmenting Ankle Power of Stroke Survivors During Walking

    Author: Siviy, Christopher | Harvard University School of Engineering and Applied Sciences
    Author: Bae, Jaehyun | Apple Inc
    Author: Baker, Lauren | Harvard SEAS
    Author: Porciuncula, Franchino | Harvard SEAS
    Author: Baker, Teresa | Boston University
    Author: Ellis, Terry | Boston University
    Author: Awad, Louis | Harvard University
    Author: Walsh, Conor James | Harvard University
 
    keyword: Prosthetics and Exoskeletons; Rehabilitation Robotics; Wearable Robots

    Abstract : Locomotor impairments afflict more than 80% of people poststroke. Our group has previously developed a unilateral ankle exosuit aimed at assisting the paretic ankle joint of stroke survivors during walking. While studies to date have shown promising biomechanical and physiological changes, there remains opportunity to better understand how changes in plantarflexion (PF) assistance profiles impact wearer response. In healthy populations, studies explicitly varying augmentation power have been informative about how exosuit users are sensitive to changes in PF assistance; however there are challenges in applying existing methods to a medical population where significantly higher gait variability and limited walking capacity exist. This paper details an offline assistance optimization scheme that uses previously-recorded biomechanics data to generate torque profiles designed to deliver either positive or negative augmentation power in PF while being less sensitive to stride-by-stride variability. Additionally, we describe an admittance-control strategy that can effectively deliver PF force with RMS error less than 10 N. A preliminary study on six people poststroke demonstrates that offline assistance optimization can successfully isolate positive and negative augmentation power. Moreover, we show that in people poststroke, positive augmentation power effected changes in total positive ankle power while delivering negative augmentation power had no effect on total negative ankle p

- Gait Patterns Generation Based on Basis Functions Interpolation for the TWIN Lower-Limb Exoskeleton

    Author: Vassallo, Christian | Istituto Italiano Di Tecnologia
    Author: De Giuseppe, Samuele | Istituto Italiano Di Tecnologia
    Author: Piezzo, Chiara | Italian Institute of Technology
    Author: Maludrottu, Stefano | Italian Institute of Technology
    Author: Cerruti, Giulio | IIT - Italian Institute of Technology
    Author: D'Angelo, Maria Laura | Istituto Italiano Di Tecnologia
    Author: Gruppioni, Emanuele | INAIL Prosthesis Center
    Author: Marchese, Claudia | Centro Protesi INAIL, Vigorso Di Budrio
    Author: Castellano, Simona | Centro Protesi INAIL, Vigorso Di Budrio
    Author: Guanziroli, Eleonora | Valduce Hospital - Como
    Author: Molteni, Franco | Hospital Valduce - Villa Beretta, Via Nazario Sauro 17, 23845 Cos
    Author: Laffranchi, Matteo | Istituto Italiano Di Tecnologia
    Author: De Michieli, Lorenzo | Istituto Italiano Di Tecnologia
 
    keyword: Prosthetics and Exoskeletons; Medical Robots and Systems; Wearable Robots

    Abstract : Since the uprising of new biomedical orthotic devices, exoskeletons have been put in the spotlight for their possible use in rehabilitation. Even if these products might share some commonalities among them in terms of overall structure, degrees of freedom and possible actions, they quite often differ in their approach on how to generate a feasible, stable and comfortable gait trajectory pattern. This paper introduces three proposed trajectories that were generated by using a basis function interpolation method and by working closely with two major rehabilitation centers in Italy. The whole procedure has been focused on the concepts of a configurable walk for patients that suffer from spinal cord injuries. We tested the solutions on a group of healthy volunteers and on a spinal-cord injury patient with the use of the new TWIN exoskeleton developed at the Rehab Technologies Lab at the Italian Institute of Technology.

- Modulating Hip Stiffness with a Robotic Exoskeleton Immediately Changes Gait

    Author: Lee, Jongwoo | Massachusetts Institute of Technology (MIT)
    Author: Warren, Haley | University of Vermont
    Author: Agarwal, Vibha | MIT
    Author: Huber, Meghan | University of Massachusetts Amherst
    Author: Hogan, Neville | Massachusetts Institute of Technology
 
    keyword: Prosthetics and Exoskeletons; Wearable Robots; Physical Human-Robot Interaction

    Abstract : Restoring healthy kinematics is a critical component of assisting and rehabilitating impaired locomotion. Here we tested whether spatio-temporal gait patterns can be modulated by applying mechanical impedance to hip joints. Using the Samsung GEMS-H exoskeleton, we emulated a virtual spring (positive and negative) between the user's legs. We found that applying positive stiffness with the exoskeleton decreased stride time and hip range of motion for healthy subjects during treadmill walking. Conversely, the application of negative stiffness increased stride time and hip range of motion. These effects did not vary over long nor short repeated exposures to applied stiffness. In addition, minimal transient behavior was observed in spatio-temporal measures of gait when the stiffness controller transitioned between on and off states. These results suggest that changes in gait behavior induced by applying hip stiffness were purely a mechanical effect. Together, our findings indicate that applying mechanical impedance using lower-limb assistive devices may be an effective, minimally-encumbering intervention to restore healthy gait patterns.

- Swing-Assist for Enhancing Stair Ambulation in a Primarily-Passive Knee Prosthesis

    Author: Lee, Jantzen | Vanderbilt University
    Author: Goldfarb, Michael | Vanderbilt University
 
    keyword: Prosthetics and Exoskeletons; Rehabilitation Robotics; Physically Assistive Devices

    Abstract :     Abstract�This paper presents the design and implementation of a controller for stair ascent and descent in a primarily-passive stance-controlled swing-assist (SCSA) prosthesis. The prosthesis and controller enable users to perform both step-over and step-to stair ascent and descent. The efficacy of the controller and SCSA prosthesis prototype in providing improved stair ambulation was tested on a unilateral transfemoral amputee in experiments that employed motion capture apparatus to compare joint kinematics with the SCSA prosthesis, relative to performing the same activity with a microprocessor-controlled daily-use passive prosthesis. Results suggest that the SCSA knee significantly decreases compensatory motion during stair activity when compared to the passive prosthesis.

- Proof-Of-Concept of a Pneumatic Ankle Foot Orthosis Powered by a Custom Compressor for Drop Foot Correction

    Author: Kim, Sangjoon J. | KAIST
    Author: Park, Junghoon | KAIST
    Author: Shin, Wonseok | KAIST
    Author: Lee, Dong Yeon | Seoul National University Hospital
    Author: Kim, Jung | KAIST
 
    keyword: Prosthetics and Exoskeletons; Hydraulic/Pneumatic Actuators; Human Performance Augmentation

    Abstract : Pneumatic transmission has several advantages in developing powered ankle foot orthosis (AFO) systems, such as the flexibility in placing pneumatic components for mass distribution and providing high back-drivability via simple valve control. However, pneumatic systems are generally tethered to large stationary air compressors that restrict them for being used as daily assistive devices. In this study, we improved a previously developed wearable (untethered) custom compressor that can be worn (1.5 kg) at the waist of the body and can generate adequate amount of pressurized air (maximum pressure of 1050 kPa and a flow rate of 15.1 mL/sec at 550 kPa) to power a unilateral active AFO used to assist the dorsiflexion (DF) motion of drop-foot patients. The finalized system can provide a maximum assistive torque of 10 Nm and induces an average 0.03�0.06 Nm resistive torque when free movement is provided. The system was tested for two hemiparetic drop-foot patients. The proposed system showed an average improvement of 13.6� of peak dorsiflexion angle during the swing phase of the gait cycle.

- Knowledge-Guided Reinforcement Learning Control for Robotic Lower Limb Prosthesis

    Author: Gao, Xiang | Arizona State University
    Author: Si, Jennie | Arizona State University
    Author: Wen, Yue | University of North Carolina at Chapel Hill
    Author: Li, Minhan | North Carolina State University
    Author: Huang, He (Helen) | North Carolina State University and University of North Carolina
 
    keyword: Prosthetics and Exoskeletons; Learning and Adaptive Systems; AI-Based Methods

    Abstract :     Abstract--- Robotic prostheses provide new opportunities to better restore the lost functions than passive prostheses for transfemoral amputees. But controlling a prosthesis device automatically for individual users in different task environments is an unsolved problem. Reinforcement learning (RL) is a naturally promising tool. For prosthesis control with a user in the loop, it is desirable that the controlled prosthesis can adapt to different task environments as quickly and smoothly as possible. However, most RL agents learn or relearn from scratch when the environment changes. To address this issue, we propose the knowledge-guided Q-learning (KG-QL) control method as a principled way for the problem. In this report, we collected and used data from two able-bodied (AB) subjects wearing a RL controlled robotic prosthetic limb walking on level ground. Our ultimate goal is to build an efficient RL controller with reduced time and data requirement and transfer knowledge from AB subjects to amputee subjects. Toward this goal, we demonstrate its feasibility by employing OpenSim, a well-established human locomotion simulator. Our results show the OpenSim simulated amputee subject improved control tuning performance over learning from scratch by utilizing knowledge transfer from AB subjects. Also in this paper, we will explore the possibility of information transfer from AB subjects to help tuning for the amputee subjects.

- Development of a Twisted String Actuator-Based Exoskeleton for Hip Joint Assistance in Lifting Tasks

    Author: Seong, Hyeonseok | Korea University of Technology
    Author: Kim, Do-Hyeong | KAIST
    Author: Gaponov, Igor | Innopolis University
    Author: Ryu, Jee-Hwan | Korea Advanced Institute of Science and Technology
 
    keyword: Prosthetics and Exoskeletons; Physically Assistive Devices; Tendon/Wire Mechanism

    Abstract : This paper presents a study on a compliant cable-driven exoskeleton for hip assistance in lifting tasks that is aimed at preventing low-back pain and injuries in the vocational setting. In the proposed concept, we used twisted string actuator (TSA) to design a light-weight and powerful exoskeleton that benefits from inherent TSA advantages. We have noted that nonlinear nature of twisted strings�transmission ratio (decreasing with twisting) closely matched typical torque-speed requirements for hip assistance during lifting tasks and tried to use this fact in the exoskeleton design and motor selection. Hip-joint torque and speed required to lift a 10-kg load from stoop to stand were calculated, which gave us a baseline that we used to design and manufacture a practical exoskeleton prototype. Preliminary experimental trials demonstrated that the proposed device was capable of generating required torque and speed at the hip joint while weighing under 6 kg,including battery.

- A Novel Portable Lower Limb Exoskeleton for Gravity Compensation During Walking

    Author: Zhou, Libo | Beihang University
    Author: Chen, Weihai | Beihang University
    Author: Chen, Wenjie | Singapore Inst. of Manufacturing Technology
    Author: Bai, Shaoping | Aalborg University
    Author: Wang, Jianhua | Beijing University of Aeronautics and Astronautics
 
    keyword: Prosthetics and Exoskeletons; Physically Assistive Devices; Rehabilitation Robotics

    Abstract : This paper presents a novel portable passive lower limb exoskeleton for walking assistance. The exoskeleton is designed with built-in spring mechanisms at the hip and knee joints to realize gravity balancing of the human leg. A pair of mating gears is used to convert the tension force from the built-in springs into balancing torques at hip and knee joints for overcoming the influence of gravity. Such a design makes the exoskeleton has a compact layout with small protrusion, which improves its safety and user acceptance. In this paper, the design principle of gravity balancing is described. Simulation results show a significant reduction of driving torques at the limb joints. A prototype of single leg exoskeleton has been constructed and preliminary test results show the effectiveness of the exoskeleton.

## Human-Centered Robotics

- Human-Centric Active Perception for Autonomous Observation

    Author: Kent, David | Georgia Institute of Technology
    Author: Chernova, Sonia | Georgia Institute of Technology
 
    keyword: Space Robotics and Automation; Human-Centered Robotics; Planning, Scheduling and Coordination

    Abstract : As robot autonomy improves, robots are increasingly being considered in the role of autonomous observation systems - free-flying cameras capable of actively tracking human activity within some predefined area of interest. In this work, we formulate the autonomous observation problem through multi-objective optimization, presenting a novel Semi-MDP formulation of the autonomous human observation problem that maximizes observation rewards while accounting for both human- and robot-centric costs. We demonstrate that the problem can be solved with both scalarization-based Multi-Objective MDP methods and Constrained MDP methods, and discuss the relative benefits of each approach. We validate our work on activity tracking using a NASA Astrobee robot operating within a simulated International Space Station environment.

- Prediction of Human Full-Body Movements with Motion Optimization and Recurrent Neural Networks

    Author: Kratzer, Philipp | University of Stuttgart
    Author: Toussaint, Marc | University of Stuttgart
    Author: Mainprice, Jim | Max Planck Institute
 
    keyword: Human-Centered Robotics; Optimization and Optimal Control; Deep Learning in Robotics and Automation

    Abstract : Human movement prediction is difficult as humans naturally exhibit complex behaviors that can change drastically from one environment to the next. In order to alleviate this issue, we propose a prediction framework that decouples short-term prediction, linked to internal body dynamics, and long-term prediction, linked to the environment and task constraints. In this work we investigate encoding short-term dynamics in a recurrent neural network, while we account for environmental constraints, such as obstacle avoidance, using gradient-based trajectory optimization. Experiments on real motion data demonstrate that our framework improves the prediction with respect to state-of-the-art motion prediction methods, as it accounts to beforehand unseen environmental structures. Moreover we demonstrate on an example, how this framework can be used to plan robot trajectories that are optimized to coordinate with a human partner.

- Predicting and Optimizing Ergonomics in Physical Human-Robot Cooperation Tasks

    Author: van der Spaa, Linda F | Delft University of Technology
    Author: Gienger, Michael | Honda Research Institute Europe
    Author: Bates, Tamas | Technical University of Delft
    Author: Kober, Jens | TU Delft
 
    keyword: Human Factors and Human-in-the-Loop; Physical Human-Robot Interaction; Human-Centered Robotics

    Abstract : This paper presents a method to incorporate ergonomics into the optimization of action sequences for bi-manual human-robot cooperation tasks with continuous physical interaction. Our first contribution is a novel computational model of the human that allows prediction of an ergonomics assessment corresponding to each step in a task. The model is learned from human motion capture data in order to predict the human pose as realistically as possible. The second contribution is a combination of this prediction model with an informed graph search algorithm, which allows computation of human-robot cooperative plans with improved ergonomics according to the incorporated method for ergonomic assessment. The concepts have been evaluated in simulation and in a small user study in which the subjects manipulate a large object with a 32 DoF bimanual mobile robot as partner. For all subjects, the ergonomic-enhanced planner shows their reduced ergonomic cost compared to a baseline planner.

- Active Reward Learning for Co-Robotic Vision Based Exploration in Bandwidth Limited Environments

    Author: Jamieson, Stewart | Massachusetts Institute of Technology
    Author: How, Jonathan Patrick | Massachusetts Institute of Technology
    Author: Girdhar, Yogesh | Woods Hole Oceanographic Institution
 
    keyword: Human Factors and Human-in-the-Loop; Learning and Adaptive Systems; Marine Robotics

    Abstract : We present a novel POMDP problem formulation for a robot that must autonomously decide where to go to collect new and scientifically relevant images given a limited ability to communicate with its human operator. From this formulation we derive constraints and design principles for the observation model, reward model, and communication strategy of such a robot, exploring techniques to deal with the very high-dimensional observation space and scarcity of relevant training data. We introduce a novel active reward learning strategy based on making queries to help the robot minimize path "regret" online, and evaluate it for suitability in autonomous visual exploration through simulations. We demonstrate that, in some bandwidth-limited environments, this novel regret-based criterion enables the robotic explorer to collect up to 17% more reward per mission than the next-best criterion.

- Characterizing User Responses to Failures in Aerial Autonomous Systems

    Author: Kunde, Siya | University of Nebraska
    Author: Elbaum, Sebastian | University of Virginia
    Author: Duncan, Brittany | University of Nebraska, Lincoln
 
    keyword: Human Factors and Human-in-the-Loop; Human-Centered Automation; Human-Centered Robotics

    Abstract : Users are often the last barrier in the detection and correction of abnormal behavior in autonomous systems, so understanding what can be expected from users in various contexts is crucial to the performance of such systems. This paper presents the first study characterizing a user ability to timely report and correct autonomous system failures in the context of small Unmanned Aerial Vehicles (sUAVs). The study aims to explore the complex tradespace which designers will encounter when developing effective transitions of control in sUAVs. We have analyzed these tradeoffs in terms of accuracy and response time while manipulating several key contextual elements including subtlety of failure, transitions of control, introduction of noise in autonomous paths, and amount of user training. Results indicate that: 1) increased accuracy is achieved under longer deadlines without large delays in responses, 2) increased noise, user training, and user responsibility for correction lead to increased reporting times, but only increased user responsibility increased accuracy, 3) users, particularly those with additional training, wanted to remain engaged in failure correction even when such interactions were not requested, 4) asking users to fix failures that they did not report resulted in increased response times and reduced accuracy.

- VariPath: A Database for Modelling the Variance of Human Pathways in Manual and HRC Processes with Heavy-Duty Robots

    Author: Bdiwi, Mohamad | Fraunhofer Institute for Machine Tools and Forming Technology IW
    Author: Harsch, Ann-Kathrin | Fraunhofer Institute for Machine Tools and Forming Technology
    Author: Reindel, Paul | Fraunhofer Institute for Machine Tools and Forming Technology
    Author: Putz, Matthias | Fraunhofer Institute for Machine Tools and Forming Technology IW
 
    keyword: Human Factors and Human-in-the-Loop; Human-Centered Robotics; Cognitive Human-Robot Interaction

    Abstract : Unlike robots, humans do not have constant movements. Their pathways are individually changeable and influenced by circumstances. This paper presents a method to investigate human pathway variations in a real study. In systematically selected tasks, human pathways are examined for 100 participants in manual and human-robot collaboration (HRC) scenarios. As a result, the variations of pathways are presented depending on various features: e.g. in nearly all cases the variance of women's walking pathways is smaller than that of men. VariPath database can be used in any planning process of manual or HRC scenarios to ensure safety and efficiency.

- Congestion-Aware Evacuation Routing Using Augmented Reality Devices

    Author: Zhang, Zeyu | UCLA
    Author: Liu, Hangxin | University of California, Los Angeles
    Author: Jiao, Ziyuan | University of California, Los Angeles
    Author: Zhu, Yixin | University of California, Los Angeles
    Author: Zhu, Song-Chun | UCLA
 
    keyword: Virtual Reality and Interfaces

    Abstract : We present a congestion-aware routing solution for indoor evacuation, which produces real-time individual-customized evacuation routes among multiple destinations while keeping tracks of all evacuees' locations. A population density map, obtained on-the-fly by aggregating locations of evacuees from user-end Augmented Reality (AR) devices, is used to model the congestion distribution inside a building. To efficiently search the evacuation route among all destinations, a variant of A* algorithm is devised to obtain the optimal solution in a single pass. In a series of simulated studies, we show that the proposed algorithm is more computationally optimized compared to classic path planning algorithms; it generates a more time-efficient evacuation route for each individual that minimizes the overall congestion. A complete system using AR devices is implemented for a pilot study in real-world environments, demonstrating the efficacy of the proposed approach.

- Human-Robot Interaction for Robotic Manipulator Programming in Mixed Reality

    Author: Ostanin, Mikhail | Innopolis University
    Author: Mikhel, Stanislav | Innopolis University
    Author: Evlampiev, Alexey | Innopolis University
    Author: Skvortsova, Valeria | Innopolis University
    Author: Klimchik, Alexandr | Innopolis University
 
    keyword: Virtual Reality and Interfaces; Industrial Robots

    Abstract : The paper presents an approach for interactive programming of the robotic manipulator using mixed reality. The developed system is based on the HoloLens glasses connected through Robotic Operation System to Unity engine and robotic manipulators. The system gives a possibility to recognize the real robot location by the point cloud analysis, to use virtual markers and menus for the task creation, to generate a trajectory for execution in the simulator or on the real manipulator. It also provides the possibility of scaling virtual and real worlds for more accurate planning. The proposed framework has been tested on pick-and-place and contact operations execution by UR10e and KUKA iiwa robots.

- Heart Rate Sensing with a Robot Mounted mmWave Radar

    Author: Zhao, Peijun | University of Oxford
    Author: Lu, Chris Xiaoxuan | University of Oxford
    Author: Wang, Bing | University of Oxford
    Author: Chen, Changhao | University of Oxford
    Author: Xie, Linhai | University of Oxford
    Author: Wang, Mengyu | Peking University
    Author: Trigoni, Niki | University of Oxford
    Author: Markham, Andrew | Oxford University
 
    keyword: Human-Centered Robotics; Service Robots; Human Factors and Human-in-the-Loop

    Abstract : Heart-rate monitoring at home is a useful metric for assessing health e.g. of the elderly or patients in post-operative recovery. Although non-contact heart-rate monitoring has been widely explored, typically using a static, wall-mounted device, measurements are limited to a single room and sensitive to user orientation and position. In this work, we propose mBeats, a robot mounted millimeter wave (mmWave) radar system that provide periodic heart-rate measurements under different user poses, without interfering in a user's daily activities. mBeats contains a mmWave servoing module that adaptively adjusts the sensor angle to the best reflection profile. Furthermore, mBeats features a deep neural network predictor, which can estimate heart rate from the lower leg and additionally provides estimation uncertainty. Through extensive experiments, we demonstrate accurate and robust operation of mBeats in a range of scenarios. We believe by integrating mobility and adaptability, mBeats can empower many downstream healthcare applications at home, such as palliative care, post-operative rehabilitation and telemedicine.

- VibeRo: Vibrotactile Stiffness Perception Interface for Virtual Reality

    Author: Adilkhanov, Adilzhan | Nazarbayev University
    Author: Yelenov, Amir | Nazarbayev University
    Author: Singal Reddy, Ramakanth | ISIR, UPMC, Paris
    Author: Terekhov, Alexander V. | Paris Descartes University
    Author: Kappassov, Zhanat | Pierre and Marie Curie University
 
    keyword: Virtual Reality and Interfaces; Haptics and Haptic Interfaces; Force and Tactile Sensing

    Abstract : Haptic interfaces allow a more realistic experience with Virtual Reality (VR). They are used to manipulate virtual objects. These objects can be rigid and soft. In this letter, we have designed and evaluated a vibrotactile hand-held device (VibeRo) to achieve haptic cues of different soft objects. The proposed method is based on combining the vision-driven displacement produced by the pseudo-haptics effect with the haptic illusion of a limb displacement obtained from force-driven synthesis of vibration of a contact surface. VibeRo features a voice-coil actuator and force-sensitive resistors for generating squeeze forces at fingertips. We present an evaluation of VibeRo's pseudo-haptic and haptic illusion effects to render soft virtual objects. The efficacy of the approach was validated in experiments with human subjects.

- Detachable Body: The Impact of Binocular Disparity and Vibrotactile Feedback in Co-Presence Tasks

    Author: Iwasaki, Yukiko | Waseda University
    Author: Ando, Kozo | Waseda University
    Author: Iizuka, Shuhei | Waseda
    Author: Kitazaki, Michiteru | Toyohashi University of Technology
    Author: Iwata, Hiroyasu | Waseda University
 
    keyword: Virtual Reality and Interfaces; Human Performance Augmentation; Telerobotics and Teleoperation

    Abstract : Detachable Body is a new concept of a robot arm wearable as an extended part of the body. It can be detached from the user's natural body; it can be attached not only to another person but also anywhere in the environment. Humans can eventually perform tasks that involve co-presence, or tasks that are concurrent and performed in two separate places, by utilizing the Detachable Body. In this paper, we design an information presentation interface to concurrently manage both the natural and detached bodies that are located in two separate locations. The interface consists of a vision presentation system that superimposes two environment images with binocular disparity, and a proprioception presentation system that provides somatosensory feedback of the detached arm's position. The usability of the proposed interface was evaluated by measuring work efficiency and subjective evaluation in a task involving co-presence. The results suggest the existence of the effects of the binocular disparity in the vision presentation system and the tactile information provided via feedback.

- Prediction of Gait Cycle Percentage Using Instrumented Shoes with Artificial Neural Networks

    Author: Prado, Antonio | Columbia University
    Author: Cao, Xiya | Peking University
    Author: Ding, Xiangzhuo | Columbia University
    Author: Agrawal, Sunil | Columbia University
 
    keyword: Human Detection and Tracking; Rehabilitation Robotics; Deep Learning in Robotics and Automation

    Abstract : Gait training is widely used to treat gait abnormalities. Traditional gait measurement systems are limited to instrumented laboratories. Even though gait measurements can be made in these settings, it is challenging to estimate gait parameters robustly in real-time for gait rehabilitation, especially when walking over-ground. In this paper, we present a novel approach to track the continuous gait cycle during overground walking outside the laboratory. In this approach, we instrument standard footwear with a sensorized insole and an inertial measurement unit. Artificial neural networks are used on the raw data obtained from the insoles and IMUs to compute the continuous percentage of the gait cycle for the entire walking session. We show in this paper that when tested with novel subjects, we can predict the gait cycle with a Root Mean Square Error (RMSE) of 7.2%. The onset of each cycle can be detected within an RMSE time of 41.5 ms with a 99% detection rate. The algorithm was tested with 18840 strides collected from 24 adults. In this paper, we tested a combination of fully-connected layers, an Encoder-Decoder using convolutional layers, and recurrent layers to identify an architecture that provided the best performance.

- Perception-Action Coupling in Usage of Telepresence Cameras

    Author: Valiton, Alexandra | Worcester Polytechnic Institute
    Author: Li, Zhi | Worcester Polytechnic Institute
 
    keyword: Telerobotics and Teleoperation; Human Factors and Human-in-the-Loop; Human-Centered Robotics

    Abstract :  Telepresence tele-action robots enable human workers to reliably perform difficult tasks in remote, cluttered, and human environments. However, the effort to control co- ordinated manipulation and active perception motions may exhaust and intimidate novice workers. We hypothesize that such cognitive efforts would be effectively reduced if the teleoperators are provided with autonomous camera selection and control aligned with the natural perception-action coupling of the human motor system. Thus, we conducted a user study to investigate the coordination of active perception control and manipulation motions performed with visual feedback from various wearable and standalone cameras in a telepresence scenario. Our study discovered rich information about telepresence camera selection to inform telepresence system configuration and possible teleoperation assistance design for reduced cognitive effort in robot teleoperation.

- A Technical Framework for Human-Like Motion Generation with Autonomous Anthropomorphic Redundant Manipulators

    Author: Averta, Giuseppe | University of Pisa
    Author: Caporale, Danilo | Centro Di Ricerca E. Piaggio
    Author: Della Santina, Cosimo | Massachusetts Institute of Technology
    Author: Bicchi, Antonio | Université Di Pisa
    Author: Bianchi, Matteo | University of Pisa
 
    keyword: Natural Machine Motion; Humanoid Robots; Human-Centered Robotics

    Abstract : The need for users' safety and technology accept- ability has incredibly increased with the deployment of co-bots physically interacting with humans in industrial settings, and for people assistance. A well-studied approach to meet these requirements is to ensure human-like robot motions. Classic solutions for anthropomorphic movement generation usually rely on optimization procedures, which build upon hypotheses devised from neuroscientific literature, or capitalize on learning methods. However, these approaches come with limitations, e.g. limited motion variability or the need for high dimensional datasets. In this work, we present a technique to directly embed human upper limb principal motion modes computed through functional analysis in the robot trajectory optimization. We report on the implementation with manipulators with redundant anthropomorphic kinematic architectures - although dissimilar with respect to the human model used for functional mode extraction - via Cartesian impedance control. In our experiments, we show how human trajectories mapped onto a robotic manipulator still exhibit the main characteristics of human-likeness, e.g. low jerk values. We discuss the results with respect to the state of the art, and their implications for advanced human-robot interaction in industrial co-botics and for human assistance.

- Real-Time Adaptive Assembly Scheduling in Human-Multi-Robot Collaboration According to Human Capability

    Author: Zhang, Shaobo | Chang�an University
    Author: Chen, Yi | Clemson University
    Author: Zhang, Jun | Chang�an University
    Author: Jia, Yunyi | Clemson University
 
    keyword: Assembly; Human Factors and Human-in-the-Loop

    Abstract : Human-multi-robot collaboration is becoming more and more common in intelligent manufacturing. Optimal assembly scheduling of such systems plays a critical role in their production efficiency. Existing approaches mostly consider humans as agents with assumed or known capabilities, which leads to suboptimal performance in realistic applications where human capabilities usually change. In addition, most robot adaptation focuses on human-single-robot interaction and the adaptation in human-multi-robot interaction with changing human capability still remains challenging due to the complexity of the heterogeneous multi-agent interactions. This paper proposes a real-time adaptive assembly scheduling approach for human-multi-robot collaboration by modeling and incorporating changing human capability. A genetic algorithm is also designed to derive implementable solutions for the formulated adaptive assembly scheduling problem. The proposed approaches are validated through different simulated human-multi-robot assembly tasks and the results demonstrate the effectiveness and advantages of the proposed approaches.

- Microscope-Guided Autonomous Clear Corneal Incision

    Author: Xia, Jun | Sun Yat-Sen University
    Author: Bergunder, Sean Joseph | Sun Yat-Sen University
    Author: Lin, Duoru | Sun Yat-Sen University, Zhongshan Ophthalmic Center
    Author: Yan, Ying | Sun Yat-Sen University, Zhongshan Ophthalmic Center
    Author: Lin, Shengzhi | Sun Yat-Sen University
    Author: Nasseri, M. Ali | Technische Universitaet Muenchen
    Author: Zhou, Mingchuan | Technische Universitét M�nchen
    Author: Lin, Haotian | Sun Yat-Sen University, Zhongshan Ophthalmic Center
    Author: Huang, Kai | Sun Yat-Sen University
 
    keyword: Surgical Robotics: Planning; Computer Vision for Medical Robotics; Medical Robots and Systems

    Abstract : Clear Corneal Incision, a challenging step in cataract surgery, and important to the overall quality of the surgery. New surgeons usually spend one full year trying to perfect their incision, but even after such rigorous training de&#64257;cient incisions can still occur. This paper proposes an autonomous robotic system for this self-sealing incision. A conventional ophthalmic microscope system with a monocular camera is utilized to capture the surgical scene, ascertain the robot's position, and estimate depth information. Kinematics with a remote centre of motion (RCM) is designed for a multiaxes robot to perform the incision route. The experimental results on ex-vivo porcine eyes show the autonomous Clear Corneal Incision has a stricter three-plane structure than a surgeon-made incision, which is closer to the ideal incision.

- A Haptic Interface for the Teleoperation of Extensible Continuum Manipulators

    Author: Frazelle, Chase | Clemson University
    Author: Kapadia, Apoorva | Clemson University
    Author: Walker, Ian | Clemson University
 
    keyword: Tendon/Wire Mechanism; Soft Robot Materials and Design; Haptics and Haptic Interfaces

    Abstract : We describe a novel haptic interface designed specifically for the teleoperation of extensible continuum manipulators. The proposed device is based off of, and extends to the haptic domain, a kinematically similar input device for continuum manipulators called the MiniOct. This paper describes the physical design of the new device, the method of creating impedance type haptic feedback to users, and some of the requirements for implementing this device in a bilateral teleoperation scheme. We report a series of initial experiments to validate the operation of the system, including simulated and real-time conditions. The experimental results show that a user can identify the direction of planar obstacles from the feedback for both virtual and physical environments. Finally, we discuss the challenges for providing feedback to an operator about the state of a teleoperated continuum manipulator.

- From Crowd Simulation to Robot Navigation in Crowds
 
    Author: Fraichard, Thierry | INRIA
    Author: Levesy, Valentin | INRIA
 
    keyword: Human-Centered Robotics; Collision Avoidance; Simulation and Animation

    Abstract : This paper presents the result of a study aiming at investigating to what extent the results obtained in the Crowd Simulation domain could be used to control a mobile robot navigating among people. It turns out that Crowd Simulation relies on two assumptions that would not hold for a real mobile robot, a test protocol has therefore been designed in order to thoroughly evaluate how three representative Crowd Simulation techniques would perform when said assumptions are relaxed. The study shows that all those techniques entail safety problems, i.e. they would cause collisions in the real world. The study also highlights the most promising candidate for a transposition on a real mobile robot.

- Are We There Yet? Comparing Remote Learning Technologies in the University Classroom

    Author: Fitter, Naomi T. | University of Southern California
    Author: Raghunath, Nisha | Oregon State University
    Author: Cha, Elizabeth | University of Southern California
    Author: Sanchez, Christopher A. | Oregon State University
    Author: Takayama, Leila | University of California, Santa Cruz
    Author: Mataric, Maja | University of Southern California
 
    keyword: Human-Centered Robotics; Telerobotics and Teleoperation; Social Human-Robot Interaction

    Abstract : Telepresence robots can empower people to work, play, and learn along with others, despite geographic distance. To investigate the use of telepresence robots for remote attendance of university-level classes, we conducted a study in four courses at our university. We compared student experiences attending class during three distinct phases in three different ways: in person, via state-of-the-art university distance learning tools (DLT), and via a telepresence robot. The results from N = 18 student participants revealed that although class attendance method preferences were split between in-person and DLT attendance, students felt more present, self-aware, and expressive when using a telepresence robot than when using DLT. The instructors of the courses uniformly preferred in-person attendance, but they noted that for remote learning, telepresence would be preferable to DLT use. This work can help to inform telepresence robotics and higher education researchers who wish to improve distance learning technologies.

- Bilateral Haptic Collaboration for Human-Robot Cooperative Tasks

    Author: Salvietti, Gionata | University of Siena
    Author: Iqbal, Muhammad Zubair | University of Siena
    Author: Prattichizzo, Domenico | Université Di Siena
 
    keyword: Human-Centered Robotics; Haptics and Haptic Interfaces; Grippers and Other End-Effectors

    Abstract : The aim of this paper is to introduce the concept of bilateral haptic cooperation as a novel paradigm for human-robot cooperative tasks. The approach is demonstrated with a system composed of a soft gripper and a wearable interface. The soft gripper, called CoGripper, has been designed to guarantee a safe interaction giving the possibility to the operator to reconfigure the device according to the object to be grasped. The wearable interface is used to control the open/close motion of the gripper and to feedback information about important task parameters, e.g., the grasp tightness. The result is a bilateral haptic collaboration where human and robot bidirectionally communicate through the interface. The user interaction with the system is extremely intuitive and simple. We performed three user studies to prove the effectiveness of bilateral haptic collaboration involving ten subjects. Results confirmed that the use of the wearable interface reduces the time to accomplish a cooperative task and enables a better control of the grasp tightness.

- A Surgeon-Robot Shared Control for Ergonomic Pedicle Screw Fixation

    Author: Lauretti, Clemente | Université Campus Bio-Medico Di Roma
    Author: Cordella, Francesca | University Campus Biomedico of Rome
    Author: Tamantini, Christian | Campus Bio-Medico University of Rome
    Author: Gentile, Cosimo | Campus Bio-Medico Di Roma
    Author: Scotto di Luzio, Francesco | Université Campus Bio-Medico Di Roma
    Author: Zollo, Loredana | Université Campus Bio-Medico
 
    keyword: Human-Centered Robotics; Physically Assistive Devices; Medical Robots and Systems

    Abstract : Pedicle screw fixation is a fundamental surgical procedure which requires high accuracy and strength from the surgeon who may be exposed to uncomfortable postures and muscular fatigue. The objective of this paper is to propose a novel approach to robot-aided pedicle screw fixation based on a Surgeon-Robot Shared control that makes the tapping procedure, i.e. threading the patient's pedicle, semi-autonomous. The surgeon continues to have a full control over the surgical intervention by i) accurately move the robot end-effector using a hands-on control interface, i.e. the surgical tapper, along a pre-planned axis, ii) continuously controlling the forces exerted onto the patient spine during the tapping phase, iii) modulating the torque about the tapping axis by adequately tuning the tool-bone interaction force along the same axis. Furthermore, the procedure appears to be more comfortable and less tiring for the surgeon. The proposed approach was tested on eight subjects who were asked to perform the tapping procedure onto an anthropomorphic spine phantom. A comparative analysis among the proposed approach and the ones typically adopted in literature to perform pedicle screw placement was carried out. The experimental results demonstrated that proposed approach, with respect to the traditional robot-aided procedure, guarantees comparable accuracy and efficiency in the screw placement and lower fatigue and more comfortable postures for the surgeon.

- Improving Robotic Cooking Using Batch Bayesian Optimization

    Author: Junge, Kai | University of Cambridge
    Author: Hughes, Josie | MIT
    Author: George Thuruthel, Thomas | Bio-Inspired Robotics Lab, University of Cambridge
    Author: Iida, Fumiya | University of Cambridge
 
    keyword: Human-Centered Robotics; Domestic Robots; Optimization and Optimal Control

    Abstract : With advances in the field of robotic manipulation, sensing and machine learning, robotic chefs are expected to become prevalent in our kitchens and restaurants. Robotic chefs are envisioned to replicate human skills in order to reduce the burden of the cooking process. However, the potential of robots as a means to enhance the dining experience is unrecognised. This work introduces the concept of food quality optimization and its challenges with an automated omelette cooking robotic system. The design and control of the robotic system that uses general kitchen tools is presented first. Next, we investigate new optimization strategies for improving subjective food quality rating, a problem challenging because of the qualitative nature of the objective and strongly constrained number of function evaluations possible. Our results show that through appropriate design of the optimization routine using Batch Bayesian Optimization, improvements in the subjective evaluation of food quality can be achieved reliably, with very few trials and with the ability for bulk optimization. This study paves the way towards a broader vision of personalized food for taste-and-nutrition and transferable recipes.

- Adaptive Motion Planning for a Collaborative Robot Based on Prediction Uncertainty to Enhance Human Safety and Work Efficiency (I)

    Author: Kanazawa, Akira | Tohoku University
    Author: Kinugawa, Jun | Tohoku University
    Author: Kosuge, Kazuhiro | Tohoku University
 
    keyword: Human-Centered Automation; Optimization and Optimal Control; Factory Automation

    Abstract : Industrial robots are expected to share the same workspace with human workers and work in cooperation with humans to improve the productivity and maintain the quality of products. In this situation, the worker safety and work-time efficiency must be enhanced simultaneously. In this paper, we extend a task scheduling system proposed in the previous work by installing an online trajectory generation system. On the basis of the probabilistic prediction of the worker motion and the receding horizon scheme for the trajectory planning, the proposed motion planning system calculates an optimal trajectory that realizes collision avoidance and the reduction of waste time simultaneously. Moreover, the proposed system plans the robot trajectory adaptively based on updated predictions and its uncertainty to deal not only with the regular behavior of workers but also with their irregular behavior. We apply the proposed system to an assembly process where a two-link planarmanipulator supports a worker by delivering parts and tools. After implementing the proposed system, we experimentally evaluate the effectiveness of the adaptive motion planning.

## Mechanism Design

- Quadrupedal Locomotion on Uneven Terrain with Sensorized Feet

    Author: Valsecchi, Giorgio | Robotic System Lab, ETH
    Author: Grandia, Ruben | ETH Zurich
    Author: Hutter, Marco | ETH Zurich
 
    keyword: Mechanism Design; Legged Robots; Motion Control

    Abstract : Sensing of the terrain shape is crucial for legged robots deployed in the real world since the knowledge of the local terrain inclination at the contact points allows for an optimized force distribution that minimizes the risk of slipping. In this paper, we present a reactive locomotion strategy for torque controllable quadruped robots based on sensorized feet. Since the present approach works without exteroceptive sensing, it is robust against degraded vision. Inertial and Force/Torque sensors implemented in specially designed feet with articulated passive ankle joints measure the local terrain inclination and interaction forces. The proposed controller exploits the contact null-space in order to minimize the tangential forces to prevent slippage even in case of extreme contact conditions. We experimentally tested the proposed method in laboratory experiments and validated the approach with the quadrupedal robot ANYmal.

- Exploiting Singular Configurations for Controllable, Low-Power, Friction Enhancement on Unmanned Ground Vehicles

    Author: Foris, Adam | Georgia Institute of Technology
    Author: Wagener, Nolan | Georgia Tech
    Author: Boots, Byron | University of Washington
    Author: Mazumdar, Anirban | Georgia Institute of Technology
 
    keyword: Mechanism Design; Field Robots; Wheeled Robots

    Abstract : This paper describes the design, validation, and performance of a new type of adaptive wheel morphology for unmanned ground vehicles. Our adaptive wheel morphology uses a spiral cam to create a system that enables controllable deployment of high friction surfaces. The overall design is modular, battery powered, and can be mounted directly to the wheels of a vehicle without additional wiring. The use of a tailored cam profile exploits a singular configuration to minimize power consumption when deployed and protects the actuator from external forces. Component-level experiments demonstrate that friction on ice and grass can be increased by up to 170%. Two prototypes were also incorporated directly into a 1:5 scale radio-controlled rally car. The devices were able to controllably deploy, increase friction, and greatly improve acceleration capacity on a slippery, synthetic ice surface.

- Flow Compensation for Hydraulic Direct-Drive System with a Single-Rod Cylinder Applied to Biped Humanoid Robot

    Author: Shimizu, Juri | Waseda University
    Author: Otani, Takuya | Waseda University
    Author: Mizukami, Hideki | Waseda University
    Author: Hashimoto, Kenji | Meiji University
    Author: Takanishi, Atsuo | Waseda University
 
    keyword: Hydraulic/Pneumatic Actuators; Humanoid and Bipedal Locomotion; Mechanism Design

    Abstract : Biped robots require massive power on each leg while walking, hopping, and running. We have developed a flow-based control system�called hydraulic direct drive system�that can achieve high output while avoiding spatial limitations. To implement the proposed system with simple equipment configuration, a pump and single-rod cylinder are connected in a closed loop. However, because compensation for flow rate is impossible in a completely closed loop, owing to the difference in the pressure receiving area caused by the rod, a passive flow compensation valve is employed. This valve has a simple structure and is easy to implement. Further, an additional sensor is required to detect the open/close state because the valve state will cause an error in flow control. Therefore, we implemented a model in the controller to predict the state of the flow compensation valve and formulated a method of switching from flow control to pressure control according to the predicted state. Experimental results indicate that the error of the joint angle is reduced to less than 1.6 degrees for walking patterns, and stable walking is realized when the system is installed in biped humanoid robots.

- Development of Visible Manipulator with Multi-Gear Array Mechanism for Laparoscopic Surgery

    Author: Wang, Haibo | Tianjin University
    Author: Wang, Shuxin | Tianjin University
    Author: Zuo, Siyang | Tianjin University
 
    keyword: Mechanism Design; Medical Robots and Systems; Surgical Robotics: Laparoscopy

    Abstract : In recent years, robotic technology has been introduced to medical fields, and many surgical robots have been proposed for minimally invasive surgery (MIS). However, due to the limitations in dexterity imposed by surgical instruments and occlusion area, surgeons experience great difficulties during operations. In this paper, we propose a visible manipulator for laparoscopic surgery. Unlike other multiple degree-of-freedom (DOF) manipulators that utilize compliant parts or tendons and pulleys, our proposed manipulator adopts a multi-gear array mechanism to perform the yaw and pitch motions. The manipulator is integrated with a visualization unit to provide macroscopic images for observation in a constrained cavity. Moreover, flexible surgical tools with different functions can be inserted through the central channel of the manipulator to perform diagnostic or therapeutic procedures. A master-slave system is developed to control the bending motions. Bending characteristics experiments and load capacity experiments are performed. The experimental results demonstrate that the proposed manipulator can perform bending motions with a yaw angle range of -76.8�~76.2� and a pitch angle range of -75.2�~75.6�. The manipulator can lift a workload of 250 g during yaw motion and a workload of 150 g during pitch motion, demonstrating the potential clinical value of the visible manipulator for robot-assisted surgery.

- Mechanically Programmed Miniature Origami Grippers

    Author: Liu, Chang | Northeastern University
    Author: Orlofsky, Alec | Northeastern University
    Author: Kamrava, Soroush | Northeastern University
    Author: Vaziri, Ashkan | Northeastern University
    Author: Felton, Samuel | Northeastern University
 
    keyword: Mechanism Design; Grippers and Other End-Effectors; Grasping

    Abstract : This paper presents a robotic gripper design that can perform customizable grasping tasks at the millimeter scale. The design is based on the origami string, a mechanism with a single degree of freedom that can be mechanically programmed to approximate arbitrary paths in space. By using this concept, we create miniature fingers that bend at multiple joints with a single actuator input. The shape and stiffness of these fingers can be varied to fit different grasping tasks by changing the crease pattern of the string. We show that the experimental behavior of these strings follows their analytical models and that they can perform a variety of tasks including pinching, wrapping, and twisting common objects such as pencils, bottle caps, and blueberries.

- Design of a Novel Multiple-DOF Extendable Arm with Rigid Components Inspired by a Deployable Origami Structure

    Author: Matsuo, Hiroshi | Tokyo Institute of Technology
    Author: Asada, Harry | MIT
    Author: Takeda, Yukio | Tokyo Institute of Technology
 
    keyword: Mechanism Design; Kinematics

    Abstract : An extendable robot inspired by origami is designed, analyzed, and tested. Its deployable origami structure has a large extension ratio, allowing the robot to extend the body length multiple times. The new robot, however, differs from the existing origami structure in two aspects. One is that the robot mechanism consists of all rigid bodies, unlike the prior origami that exploits structural deformation for creating flexible configurations. The other is that new origami-inspired robot has multiple active degrees of freedom, allowing for taking various postures, unlike most deployable mechanisms composed of rigid components having a single DOF. When developing a mechanism based on an origami structure, we often encounter the deformations of parts during the transition from the contracted to the extended configurations. Previously, we analyzed the motion of a deployable origami structure considering the foldings' deformation and showed that they do not have any kinematic roles but give a large effect to constrain the motion. Thus, we come to the idea that by removing such parts, a novel rigid extendable mechanism with multiple DOF can be obtained, which can achieve a large extension ratio and a high transformability only by its kinematic structure, beyond an original origami structure.

- A Compact and Low-Cost Robotic Manipulator Driven by Supercoiled Polymer Actuators

    Author: Yang, Yang | The Hong Kong University of Science and Technology
    Author: Liu, Zhicheng | The Hong Kong University of Science and Technology
    Author: Wang, Yanhan | The Hong Kong University of Science and Technology
    Author: Liu, Shuai | Hong Kong University of Science and Technology
    Author: Wang, Michael Yu | Hong Kong University of Science &amp; Technology
 
    keyword: Mechanism Design; Biologically-Inspired Robots; Grippers and Other End-Effectors

    Abstract : The supercoiled polymer (SCP) actuator is a novel artificial muscle, which is manufactured by twisting and coiling polymer fibers. This new artificial muscle is soft, low-cost and shows good linearity. Being utilized as an actuator, the artificial muscle could generate significant mechanical power in a muscle-like form upon electrical activation by Joule heating. In this study, we adopt this new artificial muscle to actuate a novel designed robotic manipulator, which is composed of two parts. The first part is a robotic arm based on the inspiration of the musculoskeletal system. The arm is fabricated with two ball-and-socket joints as skeleton and SCP actuators as driven muscles. The second part is a Fin Ray Effect inspired soft gripper that can perform grasping tasks on fragile objects. The manipulator prototype is fabricated and experimental tests are conducted including both simple but effective control of the bio-inspired arm as well as characterization of the gripper. Lastly, a pick and place demonstration of a fragile fruit is performed utilizing the proposed manipulator. We envision that the bio-inspired robotic manipulator design driven by SCP actuators could potentially be used in other robotic applications.

- A Wall-Mounted Robot Arm Equipped with a 4-DOF Yaw-Pitch-Yaw-Pitch Counterbalance Mechanism

    Author: Min, Jae-Kyung | Korea University
    Author: Kim, Do-Won | Korea University
    Author: Song, Jae-Bok | Korea University
 
    keyword: Mechanism Design; Tendon/Wire Mechanism; Humanoid Robots

    Abstract : Because industrial robots are relatively heavy, most of motor torque are used to support the weight of a robot. Consequently, high-capacity motors and speed reducers are needed, resulting in a low energy efficiency and an increase in the manufacturing cost. To deal with this problem, a variety of spring-based counterbalance mechanisms (CBM) have been developed to mechanically compensate for the gravitational torque caused by the robot weight and payload. However, conventional CBMs are limited to pitch joints whose axis of rotation is horizontal to the ground and it is difficult to apply them to robot arms with different joint configurations, such as humanoid robot arms. In this study, we propose a CBM with a passive yaw-pitch structure consisting of a spring and wire. Through geometrical analysis and experiments, we demonstrate that the proposed CBM can effectively compensate for the gravitational torque due to robot weight and payload.

- Internally-Balanced Magnetic Mechanisms Using a Magnetic Spring for Producing a Large Amplified Clamping Force

    Author: Shimizu, Tori | Tohoku University
    Author: Tadakuma, Kenjiro | Tohoku University
    Author: Watanabe, Masahiro | Tohoku University
    Author: Takane, Eri | Tohoku University
    Author: Konyo, Masashi | Tohoku University
    Author: Tadokoro, Satoshi | Tohoku University
 
    keyword: Mechanism Design; Grippers and Other End-Effectors; Grasping

    Abstract : To detach a permanent magnet with a control force much smaller than its original attractive force, the Internally-Balanced Magnetic Unit (IB Magnet) was invented and has been applied to magnetic devices such as wall-climbing robots, ceil-dangling drones and modular swarm robots. In contrast to its drastic reduction rate on the control force, the IB Magnet has two major problems on its nonlinear spring which cancels out the internal force on the magnet: complicated design procedure and trade-off relationship between balancing precision and mechanism volume. This paper proposes a principle of a new balancing method for the IB Magnet which uses a like-pole pair of magnets as a magnetic spring, whose repulsive force ideally equals the attractive force of an unlike-pole pair exactly. To verify the proposed principle, the     Authors realized a prototype model of the IB Magnet using magnetic spring and verified through experiments its reduction rate is comparable to those of conventional IB Magnets. Moreover, the     Authors discussed and realized a robotic clamp as an application example containing proposed the proposed IB Magnets as its internal mechanism.

- A Continuum Manipulator with Closed-Form Inverse Kinematics and Independently Tunable Stiffness

    Author: Zhao, Bin | Shanghai Jiao Tong University
    Author: Zeng, Lingyun | Shanghai Jiao Tong University
    Author: Wu, Baibo | Shanghai Jiao Tong University
    Author: Xu, Kai | Shanghai Jiao Tong University
 
    keyword: Mechanism Design; Kinematics; Flexible Robots

    Abstract : Continuum manipulators can accomplish various tasks in confined spaces, benefiting from their compliant structures and improved dexterity. Confined and unstructured spaces may require both enhanced stiffness of a continuum manipulator for precision and payload, as well as compliance for safe interaction. Thus, studies have been consistently dedicated to design continuum or articulated manipulators with tunable stiffness to adapt to different operating conditions. This paper presents a simple continuum manipulator with independently tunable stiffness where the stiffness variation does not affect the movement of the manipulator's end-effector. Moreover, the proposed continuum manipulator is found to have analytical inverse kinematics. The design concept, analytical kinematics, system construction and experimental characterizations are presented. The results showed that the manipulator's stiffness can be increased up to 3.61 times of the minimal value, demonstrating the effectiveness of the proposed idea.

- Shape-Morphing Wheel Mechanism for Step Climbing in High Speed Locomotion

    Author: Ryu, Sijun | Hanyang University
    Author: Lee, Youngjoo | Hanyang University
    Author: Seo, TaeWon | Hanyang University
 
    keyword: Mechanism Design; Wheeled Robots

    Abstract : The ability of wheeled mobile robots to overcome steps is often limited by wheel size. Enhancing the ability of mobile robots to overcome obstacles is essential for extending their operation area, and many previous attempts have been made by using transformable wheels, a linkage mechanism, and a spoke-type wheel-leg mechanism. In this study, we propose a shape-morphing wheel mechanism for step climbing at high speed. In the general case of low speed locomotion, a robot's wheels can be used normally. However, to overcome relatively large obstacles, the robot's wheels can extend its shape by using the proposed morphing mechanism with centrifugal force at high speed locomotion. Two modes of step climbing are analyzed that use kinetic energy conversion or impact on the steps. Detail design issues with comprehensive analyses results are presented. Results demonstrate that a robot with morphing wheels can climb a 46.67 mm obstacle at 1.82 m/s, which is 1.33 times larger than the wheel radius. We expect that this method can be applied to other locomotion modes of wheeled mobile robots.

- Design and Compensation Control of a Flexible Instrument for Endoscopic Surgery

    Author: Hong, Wuzhou | Shanghai Jiao Tong University
    Author: Schmitz, Andreas | Imperial College London
    Author: Bai, Weibang | Imperial College London
    Author: Berthet-Rayne, Pierre | Imperial College London
    Author: Xie, Le | Shanghai Jiao Tong University
    Author: Yang, Guang-Zhong | Shanghai Jiao Tong University
 
    keyword: Mechanism Design; Optimization and Optimal Control; Medical Robots and Systems

    Abstract : Snake-like robots for endoscopic surgery make it possible to reach deep-seated lesions. With the use of small flexible tendon-driven instruments, it is possible to perform bi-manual micro-surgical tasks that are challenging for standard endoscopic surgeries. Existing devices, however, lack articulated wrists and rolling motion of the end-effector. This paper presents a new instrument design with a distal-roll gripper for snake-like robots. The developed 5 DoFs miniaturized instruments with a diameter of 3 mm enable the deployment into narrow endoluminal channels. Issues related to actuation coupling, tendon slack, and backlash are addressed. Experimental results show that the distal-roll gripper can rotate 106�, and the actuated joints can achieve good repeatability and accuracy with the proposed compensation control scheme.

- Steerable Burrowing Robot: Design, Modeling and Experiments

    Author: Barenboim, Moran | Technion - Israel Institute of Technology
    Author: Degani, Amir | Technion - Israel Institute of Technology
 
    keyword: Mechanism Design; Underactuated Robots; Nonholonomic Mechanisms and Systems

    Abstract : This paper investigates a burrowing robot that can maneuver and steer while being submerged in a granular medium. The robot locomotes using an internal vibro-impact mechanism and steers using a rotating bevel-tip head. We formulate and investigate a non-holonomic model for the steering mechanism and a hybrid dynamics model for the thrusting mechanism. We perform a numerical analysis of the dynamics of the robot's thrusting mechanism using a simplified, orientation and depth dependent model for the drag forces acting on the robot. We first show, in simulation, that by carefully tuning various control input parameters, the thrusting mechanism can drive the robot both forward and backward. We present several experiments designed to evaluate and verify the simulative results using a proof-of-concept robot. We show that different input amplitudes indeed affect the direction of motion, as suggested by the simulation. We further demonstrate the ability of the robot to perform a simple S-shaped trajectory. These experiments demonstrate the feasibility of the robot's design and fidelity of the model.

- High Force Density Gripping with UV Activation and Sacrificial Adhesion

    Author: Lee, Esther | North Carolina State University
    Author: Goddard, Zachary | Georgia Institute of Technology
    Author: Ngotiaoco, Joshua | Georgia Institute of Technology
    Author: Monterrosa, Noe | Georgia Institute of Technology
    Author: Mazumdar, Anirban | Georgia Institute of Technology
 
    keyword: Mechanism Design; Mobile Manipulation

    Abstract : This paper presents a novel physical gripping framework intended for controlled, high force density attachment on a range of surfaces. Our framework utilizes a light-activated chemical adhesive to attach to surfaces. The cured adhesive is part of a ``sacrificial layer,'' which is shed when the gripper separates from the surface. In order to control adhesive behavior we utilize ultraviolet (UV) light sensitive acrylics which are capable of rapid curing when activated with 380nm light. Once cured, zero input power is needed to hold load. Thin plastic parts can be used as the sacrificial layers, and these can be released using an electric motor. This new gripping framework including the curing load capacity, adhesive deposition, and sacrificial methods are described in detail. Two proof-of concept prototypes are designed, built, and tested. The experimental results illustrate the response time (15-75s depending on load), high holding force density (10-30), and robustness to material type. Additionally, two drawbacks of this design are discussed: corruption of the gripped surface and a limited number of layers.

- Stiffness Optimization of a Cable Driven Parallel Robot for Additive Manufacturing

    Author: Gueners, Damien | Université Clermont Auvergne/Institut Pascal/Sigma-Clermont
    Author: Chanal, Hélène | SIGMA Clermont
    Author: Bouzgarrou, Chedli | Institut Pascal UMR 6602 - UCA/CNRS/SIGMA
 
    keyword: Mechanism Design; Parallel Robots; Additive Manufacturing

    Abstract : In this paper, the optimization of the anchor points of a cable driven parallel robot (CDPR) for 3D printing is proposed in order to maximize the rigidity. Indeed, in the context of 3D printing, robot stiffness should guarantee a high level of tool path following accuracy. The optimized platform showed a rigidity improvement in simulation, but also experimentally with a first study of vibration modes. In the same time, this study illustrates the influence of preload in cables on the platform rigidity.

- CAMI - Analysis, Design and Realization of a Force-Compliant Variable Cam System

    Author: Mannhart, Dominik | ETH Zurich
    Author: Dubois, Fabio | Eidgen�ssische Technische Hochschule
    Author: Bodie, Karen | ETH Zurich
    Author: Klemm, Victor | ETH Zurich
    Author: Morra, Alessandro | ETH Zurich
    Author: Hutter, Marco | ETH Zurich
 
    keyword: Mechanism Design; Compliant Joint/Mechanism; Legged Robots

    Abstract : This work presents a novel design concept that achieves multi-legged locomotion using a three-dimensional cam system. A computational framework has been developed to analyze and dimension this cam apparatus, that can perform arbitrary end effector motions within its design constraints. The mechanism enables continuous gait transition and inherent force compliance. With only two motors, any trajectory of a continuous set of gaits can be followed. One motor is used to actuate the system and a second one to morph its movement. To illustrate a possible application of this system, a working prototype of a bipedal robot is developed and validated in hardware. It showcases a smooth velocity change by transitioning through different gaits from standing still to walking fast at 124 mm/s within 2.0 s, while following the given end effector trajectory with an error of only 2.47 mm.

- Using Manipulation to Enable Adaptive Ground Mobility

    Author: Kim, Raymond | Georgia Institute of Technology
    Author: DeBate, Alex | Georgia Institute of Technology
    Author: Balakirsky, Stephen | Georgia Tech
    Author: Mazumdar, Anirban | Georgia Institute of Technology
 
    keyword: Mechanism Design; Mobile Manipulation; Wheeled Robots

    Abstract : In order to accomplish various missions, autonomous ground vehicles must operate on a wide range of terrain. While many systems such as wheels and whegs can navigate some types of terrain, none are optimal across all. This creates a need for physical adaptation. This paper presents a broad new approach to physical adaptation that relies on manipulation. Specifically, we explore how multipurpose manipulators can enable ground vehicles to dramatically modify their propulsion system in order to optimize performance across various terrain. While this approach is general and widely applicable, this work focuses on physically switching between wheels and legs. We outline the design of "swappable propulsors" that combine the powerful adhesion forces of permanent magnets with geometric features for easy detachment. We provide analysis on how the swappable propulsors can be manipulated, and use these results to create a functional prototype robot. This robot can use its manipulator to change between wheeled and legged locomotion. Our experimental results illustrate how this approach can enhance energy efficiency and versatility.

- SNIAE-SSE Deformation Mechanism Enabled Scalable Multicopter: Design, Modeling and Flight Performance Validation

    Author: Yang, Tao | Harbin Institute of Technology, Shenzhen
    Author: Zhang, Yujing | Harbin Institute of Technology, Shenzhen
    Author: Li, Peng | Harbin Institute of Technology (ShenZhen)
    Author: Shen, Yantao | University of Nevada, Reno
    Author: Liu, Yunhui | Chinese University of Hong Kong
    Author: Chen, Haoyao | Harbin Institute of Technology
 
    keyword: Mechanism Design; Product Design, Development and Prototyping

    Abstract : This paper focuses on designing, modeling and validating a novel scalable multicopter whose deformation mechanism, called SNIAE-SSE, relies on a combination of simple non-intersecting angulated elements (SNIAEs) and straight scissor-like elements (SSEs). The proposed SNIAE-SSE mechanism has the advantages of single degree-of-freedom, fast actuation capability and large deformation ratio. In this work, enabled by the SNIAE-SSE mechanism, a quadcopter prototype with symmetrical and synchronous deformation is firstly developed, which facilitates a novel and controllably scalable multicopter system for us to analyze its modeling, as well as to validate its flight performance and dynamics during the deformation in several flight missions including hover, throwing, and morphing flying through a narrow window. Experimental results demonstrate that the developed scalable multicopter can maintain its stable flight behavior even both the folding and unfolding body deformations are fast performed, which indicates an excellent capability of the scalable multicopter to rapidly adapt to complex and dynamically changed environments.

## Marine Robotics
- Distance and Steering Heuristics for Streamline-Based Flow Field Planning

    Author: To, Kwun Yiu Cadmus | University of Technology Sydney
    Author: Yoo, Chanyeol | University of Technology Sydney
    Author: Anstee, Stuart David | Defence Science and Technology Group
    Author: Fitch, Robert | University of Technology Sydney
 
    keyword: Marine Robotics; Motion and Path Planning; Field Robots

    Abstract : Motion planning for vehicles under the influence of flow fields can benefit from the idea of streamline-based planning, which exploits ideas from fluid dynamics to achieve computational efficiency. Important to such planners is an efficient means of computing the travel distance and direction between two points in free space, but this is difficult to achieve in strong incompressible flows such as ocean currents. We propose two useful distance functions in analytical form that combine Euclidean distance with values of the stream function associated with a flow field, and with an estimation of the strength of the opposing flow between two points. Further, we propose steering heuristics that are useful for steering towards a sampled point. We evaluate these ideas by integrating them with RRT&#8727; and comparing the algorithm's performance with state-of-the-art methods in an artificial flow field and in actual ocean prediction data in the region of the dominant East Australian Current between Sydney and Brisbane. Results demonstrate the method's computational efficiency and ability to find high-quality paths outperforming state-of-the-art methods, and show promise for practical use with autonomous marine robots.

- Enhancing Coral Reef Monitoring Utilizing a Deep Semi-Supervised Learning Approach

    Author: Modasshir, Md | University of South Carolina
    Author: Rekleitis, Ioannis | University of South Carolina
 
    keyword: Marine Robotics; Computer Vision for Other Robotic Applications; Semantic Scene Understanding

    Abstract : Coral species detection underwater is a challenging problem. There are many cases when even the experts (marine biologists) fail to recognize corals, hence limiting ground truth annotation for training a robust detection system. Identifying coral species is fundamental for enabling the monitoring of coral reefs, a task currently performed by humans, which can be automated with the use of underwater robots. By employing temporal cues using a tracker on a high confidence prediction by a convolutional neural network-based object detector, we augment the collected dataset for the retraining of the object detector. However, using trackers to extract examples also introduces hard or mislabelled samples, which is counterproductive and will deteriorate the performance of the detector. In this work, we show that employing a simple deep neural network to filter out hard or mislabelled samples can help regulate sample extraction. We empirically evaluate our approach in a coral object dataset, collected via an Autonomous Underwater Vehicle (AUV) and human divers, that shows the benefit of incorporating extracted examples obtained from tracking. This work also demonstrates how controlling sample generation by tracking using a simple deep neural network can further improve an object detector.

- DOB-Net: Actively Rejecting Unknown Excessive Time-Varying Disturbances

    Author: Wang, Tianming | University of Technology Sydney
    Author: Lu, Wenjie | University of Technology Sydney
    Author: Yan, Zheng | University of Technology Sydney
    Author: Liu, Dikai | University of Technology, Sydney
 
    keyword: Marine Robotics; Learning and Adaptive Systems

    Abstract : This paper presents an observer-integrated Reinforcement Learning (RL) approach, called Disturbance OBserver Network (DOB-Net), for robots operating in environments where disturbances are unknown and time-varying, and may frequently exceed robot control capabilities. The DOB-Net integrates a disturbance dynamics observer network and a controller network. Originated from conventional DOB mechanisms, the observer is built and enhanced via Recurrent Neural Networks (RNNs), encoding estimation of past values and prediction of future values of unknown disturbances in RNN hidden state. Such encoding allows the controller generate optimal control signals to actively reject disturbances, under the constraints of robot control capabilities. The observer and the controller are jointly learned within policy optimization by advantage actor critic. Numerical simulations on position regulation tasks have demonstrated that the proposed DOB-Net significantly outperforms conventional feedback controllers and classical RL policy.

- Demonstration of Autonomous Nested Search for Local Maxima Using an Unmanned Underwater Vehicle

    Author: Branch, Andrew | Jet Propulsion Laboratory
    Author: McMahon, James | The Naval Research Laboratory
    Author: Xu, Guangyu | Applied Physics Laboratory of University of Washington
    Author: Jakuba, Michael | Woods Hole Oceanographic Institution
    Author: German, Christopher R. | Woods Hole Oceanographic Institution
    Author: Chien, Steve | Jet Propulsion Laboratory
    Author: Kinsey, James | Woods Hole Oceanographic Institution
    Author: Bowen, Andrew D. | Woods Hole Oceanographic Institution
    Author: Hand, Kevin P. | Jet Propulsion Laboratory
    Author: Seewald, Jeffrey S. | Woods Hole Oceanographic Institution
 
    keyword: Marine Robotics; Space Robotics and Automation; Autonomous Agents

    Abstract : Ocean Worlds represent one of the best chances for extra-terrestrial life in our solar system. A new mission concept must be developed to explore these oceans. This mission would require traversing the 10s of km thick icy shell and releasing a submersible into the ocean below. During the transit of the icy shell and the exploration of the ocean, the vehicle(s) will be out of contact with Earth for weeks or potentially months at a time. During this time the vehicle must have sufficient autonomy to locate and study scientific targets of interest. One such target of interest is hydrothermal venting. We have previously developed an autonomous nested search method to locate and investigate sources of hydrothermal venting by locating local maxima in hydrothermal vent emissions. In this work we demonstrate this approach on board an OceanServer Iver2 AUV in Chesapeake Bay, MD using simulated sensor data from a hydrothermal plume model. This represents the first step towards the deployment of this approach in conditions analogous to those that we might expect on an Ocean World.

- Towards Distortion Based Underwater Domed Viewport Camera Calibration

    Author: Iscar, Eduardo | University of Michigan
    Author: Johnson-Roberson, Matthew | University of Michigan
 
    keyword: Marine Robotics; Computer Vision for Other Robotic Applications

    Abstract : Photogrammetry techniques used for 3D reconstructions and motion estimation from images are based on projective geometry that models the image formation process. However, in the underwater setting, refraction of light rays at the housing interface introduce non-linear effects in the image formation. These effects produce systematic errors if not accounted for, and severely degrade the quality of the acquired images. In this paper, we present a novel approach to the calibration of cameras inside spherical domes with large offsets between dome and camera centers. Such large offsets not only amplify the effect of refraction, but also introduce blur in the image that corrupts feature extractors used to establish image-world correspondences in existing refractive calibration methods. We propose using the point spread function (PSF) as a complete description of the optical system and introduce a procedure to recover the camera pose inside the dome based on the measurement of the distortions. Results on a collected dataset show the method is capable of recovering the camera pose with high accuracy.

- A Flapped Paddle-Fin for Improving Underwater Propulsive Efficiency of Oscillatory Actuation

    Author: Simha, Ashutosh | Tallinn University of Technology
    Author: Gkliva, Roza | Tallinn University of Technology
    Author: Kotta, �lle | Tallinn University of Technology
    Author: Kruusmaa, Maarja | Tallinn University of Technology
 
    keyword: Marine Robotics; Biologically-Inspired Robots; Mechanism Design

    Abstract : This paper presents a novel design of an oscillatory fin for thrust-efficient and agile underwater robotic locomotion. We propose a flat paddle-fin comprising a set of overlapping cascaded soft flaps that open in one half of the stroke cycle and close in the other. Consequently, asymmetry in the lateral drag force exerted by the fin during oscillatory actuation is passively achieved. This enables a substantially higher degree of efficiency in force generation than conventional oscillatory fins which rely on weaker longitudinal wake-induced forces. Experimental results show a high degree of improvement in net thrust and propulsive-efficiency over conventional fins. Locomotion with the proposed fin has been demonstrated on an underwater robotic platform. Various gaits were achieved using oscillatory actuation, via angular and phase offsets between the actuators.

- Bio-Inspired Tensegrity Fish Robot

    Author: Shintake, Jun | University of Electro-Communications
    Author: Zappetti, Davide | École Polytechnique Fédérale De Lausanne
    Author: Peter, Timoth�e | École Polytechnique Fédérale De Lausanne
    Author: Ikemoto, Yusuke | Meijo University
    Author: Floreano, Dario | Ecole Polytechnique Federal, Lausanne
 
    keyword: Soft Robot Applications; Biologically-Inspired Robots; Soft Robot Materials and Design

    Abstract : This paper presents a method to create fish-like robots with tensegrity systems and describes a prototype modeled on the body shape of the rainbow trout with a length of 400 mm and a mass of 102 g that is driven by a waterproof servomotor. The structure of the tensegrity robot consists of rigid body segments and elastic cables that represent bone/tissue and muscles of fish, respectively. This structural configuration employing the tensegrity class 2 is much simpler than other tensegrity-based underwater robots. It also allows the tuning of the mechanical stiffness, which is often said to be an important factor in fish swimming. In our robot, the body stiffness can be tuned by changing the cross-section of the cables and their pre-stretch ratio. We characterize the robot in terms of body stiffness, swimming speed, and thrust force while varying the body stiffness i.e., the cross-section of the elastic cables. The results show that the body stiffness of the robot can be designed to approximate that of the real fish and modulate its performance characteristics. The measured swimming speed of the robot is 0.23 m/s (0.58 BL/s), which is comparable to other fish robots of the same type. Strouhal number of the robot 0.54 is close to that of the natural counterpart, suggesting that the presented method is an effective engineering approach to realize the swimming characteristics of real fish.

- A Hybrid Underwater Manipulator System with Intuitive Muscle-Level sEMG Mapping Control

    Author: Zhong, Hua | The University of Hong Kong
    Author: Shen, Zhong | The University of Hong Kong
    Author: Zhao, Yafei | The University of Hong Kong
    Author: Tang, Keke | The University of Hong Kong
    Author: Wang, Wenping | The University of Hong Kong
    Author: Wang, Zheng | The University of Hong Kong
 
    keyword: Soft Robot Applications; Physical Human-Robot Interaction; Marine Robotics

    Abstract : Soft-robotic manipulators, with their closed-chamber elastomeric actuators, natural water-sealing and inherent compliance, are ideal for underwater applications for compact, lightweight, and dexterous manipulation tasks. However, their low structure rigidity makes soft robots highly prone to underwater disturbances, rendering traditional control methods unreliable, substantially increasing the challenges for high-dexterity control. To address this issue, we proposed an intuitive underwater hybrid manipulator system with a muscle-level mapping design concept. The manipulator was designed to construct an actuator-configuration which could directly map to the main muscles group in the human forearm. Exploiting this analogy, an electromyography-based wearable controller was developed using continuous bio-sensory data from the operator's arm to complement the intuitive manipulator control. A prototype of the proposed manipulator was constructed and validated in various experiments, where a human user could effectively use muscle activation to proportionally drive the soft-robotic manipulator in free-space motions, as well as performing object manipulation tasks both in air and underwater, only using visual feedback, with consistent performances under various time delays. The promising results of this work have demonstrated that the muscle-level analogy of soft robotics could lead to intuitive and effective underwater manipulation with simple structure and low control effort.

- Single-Hydrophone Low-Cost Underwater Vehicle Swarming
 
    Author: Fischell, Erin Marie | Woods Hole Oceanographic Institution
    Author: Kroo, Anne R. | Olin College of Engineering
    Author: O'Neill, Brendan W. | WHOI/MIT
 
    keyword: Marine Robotics; Multi-Robot Systems; Swarms

    Abstract : Swarms of robots are starting to appear in aerial and ground robotics across multiple operational domains: be it for search-and-rescue, mapping, or light shows, drones are able to be coordinated in groups. This capability does not currently extend underwater as attenuation of light in water is 10 orders of magnitude greater than that in air, rendering ineffective the navigation and communication technologies used in terrestrial robotics. Autonomous underwater vehicle (AUV) navigation is either expensive or unwieldy, requiring high-power sensors such as inertial navigation sensors that cost hundreds of thousands of dollars, frequent GPS surfacing, or deployment of geo-located acoustic beacons. To do �swarms' of underwater vehicles will require a navigation and communication scheme that allows vehicles to remain together in an area while prosecuting a mission without these constraints. This paper suggests a system that would make underwater swarming possible by using single-transducer, Doppler-based and multi-frequency attenuation-based acoustic navigation without time-synchronization for multi-vehicle swarming. In this solution, a leader with good navigation carries a multi-frequency sound source. Followers equipped with a custom low-cost acoustic package then adapt heading based on Doppler-shifted frequency and range using multi-frequency difference in absorption. The theory and design behind this system is presented and tested under different simulation conditions.

- 2D Estimation of Velocity Relative to Water and Tidal Currents Based on Differential Pressure for Autonomous Underwater Vehicles

    Author: Meurer, Christian | Tallinn University of Technology
    Author: Fuentes-P�rez, Juan Francisco | Tallinn University of Technology
    Author: Schwarzw�lder, Kordula Valerie Anne | Norwegian University of Science and Technology
    Author: Ludvigsen, Martin | Norwegian University of Science and Technology
    Author: S�rensen, Asgeir Johan | Norwegian University of Science and Technology
    Author: Kruusmaa, Maarja | Tallinn University of Technology
 
    keyword: Marine Robotics; Autonomous Vehicle Navigation; Sensor Fusion

    Abstract : Reliable navigation of autonomous underwater vehicles (AUVs) depends on the quality of their state estimation. Providing robust velocity estimation is thus an important role. While water currents are main contributors to the navigational uncertainty of AUVs, they are also an important variable for oceanographic research. For both reasons water current estimation is desirable during AUV operations. State of the art velocity estimation either relies on expensive acoustic sensors with considerable energy requirements and a large form factor such as Doppler Velocity Logs (DVL) and Acoustic Doppler Current Profilers (ADCP), while water currents are either estimated with the same sensors, or with algorithms that require accurate position feedback. We introduce a lightweight and energy efficient sensor to estimate fluid relative velocity in 2D based on differential pressure. The sensor is validated in field trials onboard of an AUV in the presence of tidal currents. We further show that, while moving against the currents, our device is capable of estimating tidal currents in situ with a comparable accuracy to a DVL, given a source for absolute vehicle velocity. Additionally, we establish the limitations of the current design of DPSSv2 while moving with the currents.

- Multi-Sensor Mapping for Low Contrast, Quasi-Dynamic, Large Objects

    Author: Shah, Vikrant | Northeastern University
    Author: Schild, Kristin | University of Maine
    Author: Lindeman, Margaret | Scripps Institution of Oceanography
    Author: Duncan, Daniel | The University of Texas at Austin
    Author: Sutherland, David | University of Oregon
    Author: Cenedese, Claudia | Woods Hole Oceanographic Institution
    Author: Straneo, Fiammetta | Scripps Institution of Oceanography
    Author: Singh, Hanumant | Northeatern University
 
    keyword: Marine Robotics; Mapping; Visual-Based Navigation

    Abstract : This paper proposes a systems level solution for addressing the problem of mapping large moving targets with slow but complicated dynamics with multiple sensing modalities. While this work is applicable to other domains we focus our efforts on mapping rotating and translating icebergs. Our solution involves a rigidly coupled combination of a line scan sensor - a subsurface multibeam sonar, with an area scan sensor - an optical camera. This allows the system to exploit the optical camera information to perform iceberg relative navigation which can directly be used by the multibeam sonar to map the iceberg underwater. This paper details the algorithm required to compute the scale of the navigation solution and corrections to find iceberg centric navigation and thus an accurate iceberg reconstruction. This approach is successfully demonstrated on real world iceberg data collected during the 2018 Sermilik campaign in Eastern Greenland. Due to the availability of iceberg mounted GPS observations during this research expedition we could also groundtruth our navigation and thus our systems level mapping efforts.

- Gaussian-Dirichlet Random Fields for Inference Over High Dimensional Categorical Observations

    Author: San Soucie, John E. | Massachusetts Institute of Technology
    Author: Girdhar, Yogesh | Woods Hole Oceanographic Institution
    Author: Sosik, Heidi M. | Woods Hole Oceanographic Institution
 
    keyword: Probability and Statistical Methods; Marine Robotics; Deep Learning in Robotics and Automation

    Abstract : We propose a generative model for the spatiotemporal distribution of high dimensional categorical observations. Such observations are commonly produced by robots equipped with an imaging sensor such as a camera, paired with an image classifier, potentially producing observations over thousands of categories. The proposed approach combines the use of Dirichlet distributions to model sparse co-occurrence relations between the observed categories using a latent variable, and Gaussian processes to model the spatiotemporal distribution of the latent variable. Experiments in this paper show that the resulting model is able to efficiently and accurately approximate the temporal distribution of high dimensional categorical measurements such as taxonomic observations of microscopic organisms in the ocean, even in unobserved (held out) locations, far from other samples. This work's primary motivation is to enable deployment of informative path planning techniques over high dimensional categorical fields, which until now have been limited to scalar or low dimensional vector observations.

- Cooperative Autonomy and Data Fusion for Underwater Surveillance with Networked AUVs

    Author: Ferri, Gabriele | NATO Centre for Maritime Research and Experimentation
    Author: Stinco, Pietro | Nato Sto Cmre
    Author: De Magistris, Giovanni | IBM Research AI
    Author: Tesei, Alessandra | Nato Sto Cmre
    Author: LePage, Kevin | NATO Undersea Research Centre
 
    keyword: Marine Robotics; Autonomous Agents; Networked Robots

    Abstract : Cooperative autonomy and data sharing can largely improve the mission performance of robotic networks in un- derwater surveillance applications. In this paper, we describe the cooperative autonomy used to control the Autonomous Underwater Vehicles (AUVs) acting as sonar receiver nodes in the CMRE Anti-Submarine Warfare (ASW) network. The paper focuses on a track management module that was integrated in the robot autonomy software for enabling the share of information. Track to track (T2T) associations are used for improving track classification and for creating a common tactical picture, necessary for AUV cooperative strategies. We also present a new cooperative data-driven AUV behaviour that exploits the spatial diversity of multiple robots for improving target tracking and for facilitating T2T associations. We report results with real data collected at sea that validate the approach. The reported results are one of the first examples that show the potential of cooperative autonomy and data fusion in realistic underwater surveillance scenarios characterised by limited communications.

- Bidirectional Resonant Propulsion and Localization for AUVs

    Author: Secord, Thomas | University of St. Thomas
    Author: Louwagie, Troy | University
 
    keyword: Marine Robotics; Compliant Joint/Mechanism; Localization

    Abstract : Battery life, reliability, and localization are prominent challenges in the design of autonomous underwater vehicles (AUVs). This work aims to address facets of these challenges using a single system. We describe the design of a bidirectional resonant pump that uses a single electromagnetic voice coil motor (VCM) capable of rotation around a central two degree-of-freedom flexure stage axis. This actuator design produces highly efficient resonant motion that drives two orthogonally oriented diaphragms simultaneously. The operation of this diaphragm pump mechanism produces both adjustable thrust vectors at the aft surface of the AUV and a monotonic relationship between thrust vectors and operating frequency. We propose using the unique frequency to thrust relationship to enhance AUV localization capabilities. We construct a prototype and use it to experimentally demonstrate the feasibility of the directionally-tunable resonance concept.

- Hierarchical Planning in Time-Dependent Flow Fields for Marine Robots

    Author: Lee, James Ju Heon | University of Technology Sydney
    Author: Yoo, Chanyeol | University of Technology Sydney
    Author: Anstee, Stuart David | Defence Science and Technology Group
    Author: Fitch, Robert | University of Technology Sydney
 
    keyword: Marine Robotics; Motion and Path Planning; Field Robots

    Abstract : We present an efficient approach for finding shortest paths in flow fields that vary as a sequence of flow predictions over time. This approach is applicable to motion planning for slow marine robots that are subject to dynamic ocean currents. Although the problem is NP-hard in general form, we incorporate recent results from the theory of finding shortest paths in time-dependent graphs to construct a polynomial-time algorithm that finds continuous trajectories in time-dependent flow fields. The algorithm has a hierarchical structure where a graph is constructed with time-varying edge costs that are derived from sets of continuous trajectories in the underlying flow field. We show that the continuous algorithm retains the time complexity and path quality properties of the discrete graph solution, and demonstrate its application to surface and underwater vehicles including a traversal along the East Australian Current with an autonomous surface vehicle. Results show that the algorithm performs efficiently in practice and can find paths that adapt to changing ocean currents. These results are significant to marine robotics because they allow for efficient use of time-varying ocean predictions for motion planning.

- Navigation in the Presence of Obstacles for an Agile Autonomous Underwater Vehicle

    Author: Xanthidis, Marios | University of South Carolina
    Author: Karapetyan, Nare | University of South Carolina
    Author: Damron, Hunter | University of South Carolina
    Author: Rahman, Sharmin | University of South Carolina
    Author: Johnson, James | University of South Carolina
    Author: O'Connell, Allison | Vassar College
    Author: O'Kane, Jason | University of South Carolina
    Author: Rekleitis, Ioannis | University of South Carolina
 
    keyword: Marine Robotics; Motion Control; Nonholonomic Motion Planning

    Abstract : Navigation underwater traditionally is done by keeping a safe distance from obstacles, resulting in "fly-overs" of the area of interest. Movement of an autonomous underwater vehicle (AUV) through a cluttered space, such as a shipwreck or a decorated cave, is an extremely challenging problem that has not been addressed in the past. This paper proposes a novel navigation framework utilizing an enhanced version of Trajopt for fast 3D path-optimization planning for AUVs. A sampling-based correction procedure ensures that the planning is not constrained by local minima, enabling navigation through narrow spaces. Two different modalities are proposed: planning with a known map results in efficient trajectories through cluttered spaces; operating in an unknown environment utilizes the point cloud from the visual features detected to navigate efficiently while avoiding the detected obstacles. The proposed approach is rigorously tested, both on simulation and in-pool experiments, proven to be fast enough to enable safe real-time 3D autonomous navigation for an AUV.

- Underwater Image Super-Resolution Using Deep Residual Multipliers

    Author: Islam, Md Jahidul | University of Minnesota-Twin Cities
    Author: Enan, Sadman Sakib | University of Minnesota, Twin Cities
    Author: Luo, Peigen | University of Minnesota, Twin Cities
    Author: Sattar, Junaed | University of Minnesota
 
    keyword: Marine Robotics; Deep Learning in Robotics and Automation; Computer Vision for Automation

    Abstract : We present a deep residual network-based generative model for single image super-resolution (SISR) of underwater imagery for use by autonomous underwater robots. We also provide an adversarial training pipeline for learning SISR from paired data. In order to supervise the training, we formulate an objective function that evaluates the perceptual quality of an image based on its global content, color, and local style information. Additionally, we present USR-248, a large-scale dataset of three sets of underwater images of 'high' (640x480) and 'low' (80x60, 160x120, and 320x240) resolution. USR-248 contains paired instances for supervised training of 2x, 4x, or 8x SISR models. Furthermore, we validate the effectiveness of our proposed model through qualitative and quantitative experiments and compare the results with several state-of-the-art models' performances. We also analyze its practical feasibility for applications such as scene understanding and attention modeling in noisy visual conditions.

- Nonlinear Synchronization Control for Short-Range Mobile Sensors Drifting in Geophysical Flows

    Author: Wei, Cong | University of Delaware
    Author: Tanner, Herbert G. | University of Delaware
    Author: Hsieh, M. Ani | University of Pennsylvania
 
    keyword: Marine Robotics; Cooperating Robots; Multi-Robot Systems

    Abstract : This paper presents a synchronization controller for mobile sensors that are minimally actuated and can only communicate with each other over a very short range. Thiswork is motivated by ocean monitoring applications wherelarge-scale sensor networks consisting of drifters with minimalactuation capabilities,i.e.,activedrifters, are employed. We assume drifters are tasked to monitor regions consisting of gyre flows where their trajectories are periodic. As driftersin neighboring regions move into each other's proximity, itpresents an opportunity for data exchange and synchronization to ensure future rendezvous. We present a nonlinearsynchronization control strategy to ensure that drifters willperiodically rendezvous and maximize the time they are intheir rendezvous regions. We present numerical simulations andsmall-scale experiments to validat the efficacy of the controlstrategy and discuss the extension to large-scale mobile sensornetworks.

## Compliant Joint/Mechanism
- Energy-Based Safety in Series Elastic Actuation

    Author: Roozing, Wesley | University of Twente
    Author: Groothuis, Stefan S. | University of Twente
    Author: Stramigioli, Stefano | University of Twente
 
    keyword: Compliant Joint/Mechanism; Compliance and Impedance Control; Robot Safety

    Abstract : This work presents the concept of energy-based safety for series-elastic actuation. Generic actuation passivity and safety is treated, defining several energy storage and power flow properties related to passivity. Safe behaviour is not guaranteed by passivity, but can be guaranteed by energy and power limits that adapt the nominal behaviour of an impedance controller. A discussion on power flows in series-elastic actuation is presented and an appropriate controller is developed. Experimental results validate the effectiveness of the energy-based safety in elastic actuation.

- Safe High Impedance Control of a Series-Elastic Actuator with a Disturbance Observer

    Author: Haninger, Kevin | Fraunhofer IPK
    Author: Asignacion, Abner Jr | Daegu Gyeongbuk Institute of Science and Technology
    Author: Oh, Sehoon | DGIST (Daegu Gyeongbuk Institute of Science and Technology)
 
    keyword: Compliant Joint/Mechanism; Compliance and Impedance Control; Force Control

    Abstract : In many series-elastic actuator applications, the ability to safely render a wide range of impedance is important. Advanced torque control techniques such as the disturbance observer (DOB) can improve torque tracking performance, but their impact on safe impedance range is not established. Here, safety is defined with load port passivity, and passivity conditions are developed for two variants of DOB torque control. These conditions are used to determine the maximum safe stiffness and Z-region of the DOB controllers, which are analyzed and compared with the no DOB case. A feedforward controller is proposed which increases the maximum safe stiffness of the DOB approaches. The results are experimentally validated by manual excitation and in a high-stiffness environment.

- Variable Stiffness Springs for Energy Storage Applications

    Author: Kim, Sung | Vanderbilt University
    Author: Tiange, Zhang | Vanderbilt University
    Author: Braun, David | Vanderbilt University
 
    keyword: Compliant Joint/Mechanism; Human Performance Augmentation; Hydraulic/Pneumatic Actuators

    Abstract : Theory suggests an inverse relation between the stiffness and the energy storage capacity for linear helical springs: reducing the active length of the spring by 50% increases its stiffness by 100%, but reduces its energy storage capacity by 50%. State-of-the-art variable stiffness actuators used to drive robots are characterized by a similar inverse relation, implying reduced energy storage capacity for increased spring stiffness. This relation limits the potential of the variable stiffness actuation technology when it comes to human performance augmentation in natural tasks, e.g., jumping, weight-bearing and running, which may necessitate a spring exoskeleton with large stiffness range and high energy storage capacity. In this paper, we theoretically show that the trade-off between stiffness range and energy storage capacity is not fundamental; it is possible to develop variable stiffness springs with simultaneously increasing stiffness and energy storage capacity. Consistent with the theory, we experimentally show that a controllable volume air spring, has a direct relation between its stiffness range and energy storage capacity. The mathematical conditions presented in this paper may be used to develop actuators that could bypass the limited energy storage capacity of current variable stiffness spring technology.

- Parallel-Motion Thick Origami Structure for Robotic Design

    Author: Liu, Shuai | Hong Kong University of Science and Technology
    Author: Wu, Huajie | University of Science and Technology of China
    Author: Yang, Yang | The Hong Kong University of Science and Technology
    Author: Wang, Michael Yu | Hong Kong University of Science &amp; Technology
 
    keyword: Compliant Joint/Mechanism; Flexible Robots; Soft Robot Materials and Design

    Abstract : Structures with origami design enable objects to transform into various three-dimensional shapes. Traditionally origami structures are designed with zero-thickness flat paper sheets. However, the thickness and intersection of origami facets are non-negligible in most cases, especially when origami design is integrated with robotic design because of the more efficient force transfer between thick plates compared with zero-thickness paper-sheets. Meanwhile, the single-layer-paper oriented initial design limited the shape transformation potential as multiple layer origami structures could conduct more variety of deformation. In this article, we are proposing a general design method of parallel-motion thick origami structures which could be used in robotic design like a parallel-motion gripper.

- Gyroscopic Tensegrity Robots

    Author: Goyal, Raman | Texas A&amp;M University
    Author: Chen, Muhao | Texas A&amp;M University
    Author: Majji, Manoranjan | Texas A&amp;M University
    Author: Skelton, Robert | Texas A&amp;M University
 
    keyword: Dynamics; Modeling, Control, and Learning for Soft Robots; Space Robotics and Automation

    Abstract : Mechanics and control of innovative gyroscopic structural systems are detailed in the paper. By adding controllable spinning wheels to a network of controllable, axially loaded strings and bars, it is shown that the mobility and manipulation of the structural system are enhanced. Using principles of mechanics, a nonlinear dynamic model is presented to modulate the torque produced by the network of spatially distributed gyroscopes. Equations of motion, formulated as a second-order matrix differential equation, provide a trajectory for the nodal displacement of the bars, along with the wheel's spin degree of freedom. While the gyroscopic robotics concept is scalable to an arbitrarily large network, this research aims to identify elemental modules to override fundamental design principles of the innovative structural systems. Dynamic simulation and experimental verification on a planar D-bar tensegrity structure are used to demonstrate the utility of one such fundamental building block of the gyroscopic robotic system.

## Search and Rescue Robots
- Real-Time Simulation of Non-Deformable Continuous Tracks with Explicit Consideration of Friction and Grouser Geometry

    Author: Okada, Yoshito | Tohoku University
    Author: Kojima, Shotaro | Tohoku University
    Author: Ohno, Kazunori | Tohoku University
    Author: Tadokoro, Satoshi | Tohoku University
 
    keyword: Search and Rescue Robots; Simulation and Animation; Field Robots

    Abstract : In this study, we developed a real-time simulation method for non-deformable continuous tracks having grousers for rough terrain by explicitly considering the collision and friction between the tracks and the ground. In the proposed simulation method, an arbitrary trajectory of a track is represented with multiple linear and circular segments, each of which is a link connected to a robot body. The proposed method sets velocity constraints between each segment link and the robot body, to simulate the track rotation around the body. To maintain the shape of a track, it also restores the positions of the segment links when required. Experimental comparisons with other existing real-time simulation methods demonstrated that while the proposed method considered the grousers and the friction with the ground, it was comparable to them in terms of the computational speed. Experimental comparison of the simulations based on the proposed method and a physical robot exhibited that the former was comparable to the precise motion of the robot on rough or uneven terrain.

- Test Your SLAM! the SubT-Tunnel Dataset and Metric for Mapping

    Author: Rogers III, John G. | US Army Research Laboratory
    Author: Gregory, Jason M. | US Army Research Laboratory
    Author: Fink, Jonathan | US Army Research Laborator
    Author: Stump, Ethan | US Army Research Laboratory
 
    keyword: Performance Evaluation and Benchmarking; SLAM; Search and Rescue Robots

    Abstract : This paper presents an approach and introduces new open-source tools which can be used to evaluate robotic mapping algorithms, in addition to an extensive subterranean mine rescue dataset based upon the DARPA Subterranean challenge including professionally surveyed ground truth. Finally, some commonly available approaches are evaluated using this metric.

- Uncertainty Measured Markov Decision Process in Dynamic Environments

    Author: Dutta, Sourav | University at Albany
    Author: Rekabdar, Banafsheh | Southern Illinois University Carbondale
    Author: Ekenna, Chinwe | University at Albany
 
    keyword: Surveillance Systems; Search and Rescue Robots; Localization

    Abstract : Successful robot path planning is challenging in the presence of visual occlusions and moving targets. Classical methods to solve this problem have used visioning and perception algorithms in addition to partially observable markov decision processes to aid in path planning for pursuit-evasion and robot tracking.<p>We present a predictive path planning process that measures and utilizes the uncertainty present during robot motion planning. We develop a variant of subjective logic in combination with the Markov decision process (MDP) and provide a measure for belief, disbelief, and uncertainty in relation to feasible trajectories being generated. We then model the MDP to identify the best path planning method from a list of possible choices. Our results show a high percentage accuracy based on the closest acquired proximity between a target and a tracking robot and a simplified pursuer trajectory in comparison with related work.

- A Minimally Actuated Reconfigurable Continuous Track Robot

    Author: Kislassi, Tal | Ben Gurion University of the Negev
    Author: Zarrouk, David | Ben Gurion University

- Cooperative Mapping and Target Search Over an Unknown Occupancy Graph Using Mutual Information

    Author: Wolek, Artur | University of Maryland
    Author: Cheng, Sheng | University of Maryland, College Park
    Author: Goswami, Debdipta | University of Maryland
    Author: Paley, Derek | University of Maryland
 
    keyword: Search and Rescue Robots; Cooperating Robots; Sensor Networks

    Abstract : A cooperative mapping and target-search algorithm is presented for detecting a single moving ground target in an urban environment that is initially unknown to a team of autonomous quadrotors equipped with noisy, range-limited sensors. The target moves according to a biased random-walk model, and search agents (quadrotors) build a target state graph that encodes past and present target positions. A track-before-detect algorithm assimilates target measurements into the log-likelihood ratio and anisotropic kriging interpolation predicts the location of occupancy nodes in unexplored regions. Mutual information evaluated at each location in the search area defines a sampling-priority surface that is partitioned by a weighted Voronoi algorithm into candidate waypoint tasks. Tasks are assigned to each agent by iteratively solving a utility-maximizing assignment problem. Numerical simulations show that the proposed approach compares favorably to non-adaptive lawnmower and random coverage strategies. The proposed strategy is also demonstrated experimentally through an outdoor flight test using two real and two virtual quadrotors.

- Flexible Disaster Response of Tomorrow - Final Presentation and Evaluation of the CENTAURO System (I)

    Author: Klamt, Tobias | University of Bonn
    Author: Rodriguez, Diego | University of Bonn
    Author: Baccelliere, Lorenzo | Istituto Italiano Di Tecnologia
    Author: Chen, Xi | KTH
    Author: Chiaradia, Domenico | Scuola Superiore Sant'Anna, TeCIP Institute, PERCRO Laboratory,
    Author: Cichon, Torben | RWTH Aachen University
    Author: Gabardi, Massimiliano | Scuola Superiore Sant'Anna PERCRO
    Author: Guria, Paolo | Istituto Italiano Di Tecnologia
    Author: Holmquist, Karl | Link�ping University
    Author: Kamedula, Malgorzata | Istituto Italiano Di Tecnologia
    Author: Karaoguz, Hakan | Royal Institute of Technology KTH
    Author: Kashiri, Navvab | Istituto Italiano Di Tecnologia
    Author: Laurenzi, Arturo | Istituto Italiano Di Tecnologia
    Author: Lenz, Christian | University of Bonn
    Author: Leonardis, Daniele | Scuola Superiore Sant'Anna - TeCIP Institute
    Author: Mingo, Enrico | Istituto Italiano Di Tecnologia
    Author: Muratore, Luca | Istituto Italiano Di Tecnologia
    Author: Pavlichenko, Dmytro | University of Bonn
    Author: Porcini, Francesco | PERCRO Laboratory, TeCIP Institute, Sant�Anna School of Advanced
    Author: Ren, Zeyu | Istituto Italiano Di Tecnologia
    Author: Schilling, Fabian | EPFL
    Author: Schwarz, Max | University Bonn
    Author: Solazzi, Massimiliano | Scuola Superiore Sant'Anna, TeCIP Institute
    Author: Felsberg, Michael | Link�ping University
    Author: Frisoli, Antonio | TeCIP Institute, Scuola Superiore Sant'Anna
    Author: Gustmann, Michael | Kerntechnische Hilfsdienst GmbH
    Author: Jensfelt, Patric | KTH - Royal Institute of Technology
    Author: Nordberg, Klas | Link�ping University
    Author: Rossmann, Juergen | RWTH Aachen University
    Author: Suess, Uwe | Kerntechnische Hilfsdienst GmbH
    Author: Tsagarakis, Nikos | Istituto Italiano Di Tecnologia
    Author: Behnke, Sven | University of Bonn
 
    keyword: Search and Rescue Robots; Mobile Manipulation; Robotics in Hazardous Fields

    Abstract : Mobile manipulation robots have high potential to support rescue forces in disaster-response missions. Despite the difficulties imposed by real-world scenarios, robots are promising to perform mission tasks from a safe distance. In the CENTAURO project, we developed a disaster-response system which consists of the highly flexible Centauro robot and suitable control interfaces including an immersive tele-presence suit and support-operator controls on different levels of autonomy. In this article, we give an overview of the final CENTAURO system. In particular, we explain several high-level design decisions and how those were derived from requirements and extensive experience of Kerntechnische Hilfsdienst GmbH, Karlsruhe, Germany (KHG). We focus on components which were recently integrated and report about a systematic evaluation which demonstrated system capabilities and revealed valuable insights.

## Human Detection and Tracking
- Natural Scene Facial Expression Recognitionwith Dimension Reduction Network

    Author: Hu, Shenhua | Institute of Automation, Chinese Academy of Sciences
    Author: Yiming, Hu | CASIA
    Author: Li, Jianquan | Institute of Automation, Chinese Academy of Sciences
    Author: Long, Xianlei | Institute of Automation, Chinese Academy of Sciences
    Author: Chen, Mengjuan | University of Chinese Academy of Sciences
    Author: Gu, Qingyi | Institute of Automation, Chinese Academy of Sciences
 
    keyword: Gesture, Posture and Facial Expressions; Recognition; Cognitive Human-Robot Interaction

    Abstract : As an external manifestation of human emotions, expression recognition plays an important role in human-computer interaction. Although existing expression recognition methods performs perfectly on constrained frontal faces, there are still many challenges in expression recognition in natural scenes due to different unrestricted conditions.Expression classification belongs to a pattern recognition problem where intra-class distance is greater than the inter-class distance, which leads to severe over-fitting when using neural networks for expression recognition. This paper proposes a novel network structure called Dimension Reduction Network which can effectively reduce generalization error. By adding a data dimension reduction module before the general classification network, a lot of redundant information is filtered, and only useful information is left.This can reduce the interference by irrelevant information when performing classification tasks and reduce generalization error. The proposed method does not require any modification to the classification network, only a small dimension reduction module needs to be added in front of the classification network. However, it can effectively reduce generalization error. We designed big and tiny versions of Dimension Reduction Network, both exceeds our baseline on AffectNet data set. The big version of our proposed method surpassed the state-of-the-art methods by more than 1.2% on AffectNet data set.

- Hand Pose Estimation for Hand-Object Interaction Cases Using Augmented Autoencoder

    Author: Li, Shile | Technische Universitét M�nchen
    Author: Wang, Haojie | Technische Universitét M�nchen
    Author: Lee, Dongheui | Technical University of Munich
 
    keyword: Human Detection and Tracking; RGB-D Perception; Deep Learning in Robotics and Automation

    Abstract : Hand pose estimation with objects is challenging due to object occlusion and the lack of large annotated datasets. To tackle these issues, we propose an Augmented Autoencoder based deep learning method using augmented clean hand data. Our method takes 3D point cloud of a hand with an augmented object as input and encodes the input to latent representation of the hand. From the latent representation, our method decodes 3D hand pose and we propose to use an auxiliary point cloud decoder to assist the formation of the latent space. Through quantitative and qualitative evaluation on both synthetic dataset and real captured data containing objects, we demonstrate state-of-the-art performance for hand pose estimation with objects.

- Accurate Detection and 3D Localization of Humans Using a Novel YOLO-Based RGB-D Fusion Approach and Synthetic Training Data

    Author: Linder, Timm | Robert Bosch GmbH
    Author: Pfeiffer, Kilian Yutaka | RWTH Aachen University
    Author: Vaskevicius, Narunas | Robert Bosch GmbH
    Author: Schirmer, Robert | Robert Bosch GmbH
    Author: Arras, Kai Oliver | Bosch Research
 
    keyword: Human Detection and Tracking; RGB-D Perception; Object Detection, Segmentation and Categorization

    Abstract : While 2D object detection has made significant progress, robustly localizing objects in 3D space under presence of occlusion is still an unresolved issue. Our focus in this work is on real-time detection of human 3D centroids in RGB-D data. We propose an image-based detection approach which extends the YOLOv3 architecture with a 3D centroid loss and mid-level feature fusion to exploit complementary information from both modalities. We employ a transfer learning scheme which can benefit from existing large-scale 2D object detection datasets, while at the same time learning end-to-end 3D localization from our highly randomized, diverse synthetic RGB-D dataset with precise 3D groundtruth. We further propose a geometrically more accurate depth-aware crop augmentation for training on RGB-D data, which helps to improve 3D localization accuracy. In experiments on our challenging intralogistics dataset, we achieve state-of-the-art performance even when learning 3D localization just from synthetic data.

- Pedestrian Planar LiDAR Pose (PPLP) Network for Oriented Pedestrian Detection Based on Planar LiDAR and Monocular Images

    Author: Bu, Fan | University of Michigan
    Author: Le, Trinh | University of Michigan
    Author: Du, Xiaoxiao | University of Michigan
    Author: Vasudevan, Ram | University of Michigan
    Author: Johnson-Roberson, Matthew | University of Michigan
 
    keyword: Human Detection and Tracking; Computer Vision for Automation; Recognition

    Abstract : Pedestrian detection is an important task for human-robot interaction and autonomous driving applications. Most previous pedestrian detection methods rely on data collected from three-dimensional (3D) Light Detection and Ranging (LiDAR) sensors in addition to camera imagery, which can be expensive to deploy. In this paper, we propose a novel Pedestrian Planar LiDAR Pose Network (PPLP Net) based on two-dimensional (2D) LiDAR data and monocular camera imagery, which offers a far more affordable solution to the oriented pedestrian detection problem. The proposed PPLP Net consists of three sub-networks: an orientation detection network (OrientNet), a Region Proposal Network (RPN), and a PredictorNet. The OrientNet leverages state-of-the-art neural-network-based 2D pedestrian detection algorithms, including Mask R-CNN and ResNet, to detect the Bird's Eye View (BEV) orientation of each pedestrian. The RPN transfers 2D LiDAR point clouds into occupancy grid map and uses a frustum-based matching strategy for estimating non-oriented 3D pedestrian bounding boxes. Outputs from both OrientNet and RPN are passed through the PredictorNet for a final regression. The overall outputs of our proposed network are 3D bounding box locations and orientation values for all pedestrians in the scene. We present oriented pedestrian detection results on two datasets, the CMU Panoptic Dataset and a newly collected FCAV M-Air Pedestrian (FMP) Dataset, and show that our proposed PPLP network based on 2D L

- Wide-Range Load Sensor Using Vacuum Sealed Quartz Crystal Resonator for Simultaneous Biosignals Measurement on Bed
 
    Author: Murozaki, Yuichi | Nagoya University
    Author: Arai, Fumihito | Nagoya University
 
    keyword: Human Detection and Tracking; Product Design, Development and Prototyping

    Abstract : Monitoring of biosignals on a daily basis plays important roles for the health management of elderly. The monitoring system for the daily life, the system should not require the subjects to take special effort like wearing a sensor. We propose biosignals measurement using wide-range load sensor on the bed. The sensing system can detect the body weight, heartbeat and respiration simultaneously by just lying on the bed. We have developed load sensor using quartz crystal resonator (QCR load sensor) as wide-range load sensor. However, the measurement range was not sufficient for the simultaneous measurement of biosgnals on bed. To realize such sensing system, we propose a QCR load sensor utilizing vacuum sealing technology for expanding the measurement range. We improved the oscillation characteristics of the QCR by the vacuum sealing to stabilize the sensor output. Accordingly, the resolution of the sensor was improved. Moreover, the load capacity of the sensor was increased by improving the bonding strength of sensor structure. The fabricated sensor had a measurement range of 0.27 mN - 1180 N (4.4 - 10^6). This wide enough compared with the conventional force sensor (10^3 - 10^4). Also, we developed mechanically robust jig of QCR load sensor for practical use of QCR load sensor. We succeed in simultaneous measurement of weight, heart rate, and respiration rate using fabricated QCR load sensing system. The accuracy of heart rate and respiration measurement are 0.6 % and 6.1 %,

- Joint Pedestrian Detection and Risk-Level Prediction with Motion-Representation-By-Detection

    Author: Kataoka, Hirokatsu | National Institute of Advanced Industrial Science and Technology
    Author: Suzuki, Teppei | Denso IT Laboratory, INC
    Author: Nakashima, Kodai | University of Tsukuba
    Author: Satoh, Yutaka | AIST
    Author: Aoki, Yoshimitsu | Keio University
 
    keyword: Human Detection and Tracking; Computer Vision for Other Robotic Applications; Object Detection, Segmentation and Categorization

    Abstract : The paper presents a pedestrian near-miss detector with temporal analysis that provides both pedestrian detection and risk-level predictions which are demonstrated on a self-collected database. Our work makes three primary contributions: (i) The framework of pedestrian near-miss detection is proposed by providing both a pedestrian detection and risk-level assignment. Specifically, we have created a Pedestrian Near-Miss (PNM) dataset that categorizes traffic near-miss incidents based on their risk levels (high-, low-, and no-risk). Unlike existing databases, our dataset also includes manually localized pedestrian labels as well as a large number of incident-related videos. (ii) Single-Shot MultiBox Detector with Motion Representation (SSD-MR) is implemented to effectively extract motion-based features in a detected pedestrian. (iii) Using the self-collected PNM dataset and SSD-MR, our proposed method achieved +19.38% (on risk-level prediction) and +13.00% (on joint pedestrian detection and risk-level prediction) higher scores than that of the baseline SSD and LSTM. Additionally, the running time of our system is over 50 fps on a graphics processing unit (GPU).

## Omnidirectional Vision and Audition
- Robust Sound Source Localization Considering Similarity of Back-Propagation Signals

    Author: An, Inkyu | KAIST
    Author: Jo, Byeongho | Korea Advanced Institute of Science and Technology
    Author: Kwon, Youngsun | KAIST
    Author: Choi, Jung-Woo | KAIST
    Author: Yoon, Sung-eui | KAIST
 
    keyword: Robot Audition; Localization

    Abstract : We present a novel, robust sound source localization algorithm considering back-propagation signals. Sound propagation paths are estimated by generating direct and reflection acoustic rays based on ray tracing in a backward manner. We then compute the back-propagation signals by designing and using the impulse response of the backward sound propagation based on the acoustic ray paths. For identifying the 3D source position, we use a well-established Monte Carlo localization method. Candidates for a source position are determined by identifying convergence regions of acoustic ray paths. Those candidates are validated by measuring similarities between back-propagation signals, under the assumption that the back-propagation signals of different acoustic ray paths should be similar near the ground-truth sound source position. Thanks to considering similarities of back-propagation signals, our approach can localize a source position with an averaged error of 0.55m in a room of 7m by 7m area with 3m height in tested environments. We also place additional 67dB and 77dB white noise at the background, to test the robustness of our approach. Overall, we observe a 7% to 100% improvement in accuracy over the state-of-the-art method.

- BatVision: Learning to See 3D Spatial Layout with Two Ears

    Author: Christensen, Jesper | Technical University of Denmark, ATLAS MARIDAN ApS
    Author: Hornauer, Sascha | International Computer Science Institute Berkeley
    Author: Yu, Stella | UC Berkeley / ICSI
 
    keyword: Robot Audition; Biologically-Inspired Robots; Deep Learning in Robotics and Automation

    Abstract : Images showing the 3D spatial layout of space ahead of a mobile agent can be generated by purely listening to the reflections of chirping sounds. Many species have evolved sophisticated non-visual perception while artificial systems fall behind. While radar and ultrasound are used where cameras fail, they either provide very limited information or require large, complex and expensive sensors. Sound, on the other hand, is used effortlessly by dolphins, bats, whales and humans as a sensor modality with many advantages over vision. However, it is challenging to harness useful and detailed information for machine perception. We train a network to generate representations of the world in 2D and 3D only from sounds, sent by one speaker and captured by two microphones. Inspired by examples from nature, we emit short frequency modulated sound chirps and record returning echoes through an artificial human pinnae pair. We then learn to generate disparity-like depth maps and grayscale images from the echoes in an end-to-end fashion. With only low-cost equipment, our models show good reconstruction performance while being robust to errors and even overcoming limitations of our vision-based ground truth. Finally, we introduce a large dataset consisting of binaural sound signals synchronized in time with both RGB images and depth maps.

- Self-Supervised Learning for Alignment of Objects and Sound

    Author: Liu, Xinzhu | Tsinghua University
    Author: Liu, XiaoYu | BeiJing Institute of Technology
    Author: Guo, Di | Tsinghua University
    Author: Liu, Huaping | Tsinghua University
    Author: Sun, Fuchun | Tsinghua Univerisity
    Author: Min, Haibo | Tsinghua University
 
    keyword: Robot Audition; Computer Vision for Other Robotic Applications

    Abstract : The sound source separation problem has many useful applications in the field of robotics, such as human-robot interaction, scene understanding, etc. However, it remains a very challenging problem. In this paper, we utilize both visual and audio information of videos to perform the sound source separation task. A self-supervised learning framework is proposed to implement the object detection and sound separation modules simultaneously. Such an approach is designed to better find the alignment between the detected objects and separated sound components. Our experiments, conducted on both the synthetic and real datasets, validate this approach and demonstrate the effectiveness of the proposed model in the task of object and sound alignment.

- Variational Fisheye Stereo

    Author: Roxas, Menandro | The University of Tokyo
    Author: Oishi, Takeshi | The University of Tokyo
 
    keyword: Omnidirectional Vision; Mapping

    Abstract : Dense 3D maps from wide-angle cameras is beneficial to robotics applications such as navigation and autonomous driving. In this work, we propose a real-time dense 3D mapping method for fisheye cameras without explicit rectification and undistortion. We extend the conventional variational stereo method by constraining the correspondence search along the epipolar curve using a trajectory field induced by camera motion. We also propose a fast way of generating the trajectory field without increasing the processing time compared to conventional rectified methods. With our implementation, we were able to achieve real-time processing using modern GPUs. Our results show the advantages of our non-rectified dense mapping approach compared to rectified variational methods and non-rectified discrete stereo matching methods.

- The OmniScape Dataset

    Author: Sekkat, Ahmed Rida | LITIS Lab, Université De Rouen Normandie
    Author: Dupuis, Yohan | ESIGELEC
    Author: Vasseur, Pascal | Université De Rouen
    Author: Honeine, Paul | LITIS Lab, Université De Rouen Normandie
 
    keyword: Omnidirectional Vision; Object Detection, Segmentation and Categorization; RGB-D Perception

    Abstract : Despite the utility and benefits of omnidirectional images in robotics and automotive applications, there are no dataset of omnidirectional images available with semantic segmentation, depth map, and dynamic properties. This is due to the time cost and human effort required to annotate ground truth images. This paper presents a framework for generating omnidirectional images using images that are acquired from a virtual environment. For this purpose, we demonstrate the relevance of the proposed framework on two well-known simulators: CARLA simulator, which is an open-source simulator for autonomous driving research, and Grand Theft Auto V (GTA V), which is a very high quality video game. We explain in details the generated OmniScape dataset, which includes stereo fisheye and catadioptric images acquired from the two front sides of a motorcycle, including semantic segmentation, depth map, intrinsic parameters of the cameras and the dynamic parameters of the motorcycle. It is worth noting that the case of two-wheeled vehicles is more challenging than cars due to the specific dynamic of these vehicles.

- Corners for Layout: End-To-End Layout Recovery from 360 Images

    Author: Fernandez-Labrador, Clara | University of Zaragoza
    Author: F�cil, Jos' M. | Universidad De Zaragoza
    Author: Perez-Yus, Alejandro | Universidad De Zaragoza
    Author: Demonceaux, C�dric | Université Bourgogne Franche-Comt�
    Author: Civera, Javier | Universidad De Zaragoza
    Author: Guerrero, Josechu | Universidad De Zaragoza
 
    keyword: Omnidirectional Vision; Semantic Scene Understanding; Computer Vision for Other Robotic Applications

    Abstract : The problem of 3D layout recovery in indoor scenes has been a core research topic for over a decade. However, there are still several major challenges that remain unsolved. Among the most relevant ones, a major part of the state-of-the-art methods make implicit or explicit assumptions on the scenes �e.g. box-shaped or Manhattan layouts. Also, current methods are computationally expensive and not suitable for real-time applications like robot navigation and AR/VR. In this work we present CFL (Corners for Layout), the first end-to-end model that predicts layout corners for 3D layout recovery on 360� images. Our experimental results show that we outperform the state of the art, making less assumptions on the scene than other works, and with lower cost. We also show that our model generalizes better to camera position variations than conventional approaches by using EquiConvs, a convolution applied directly on the spherical projection and hence invariant to the equirectangular distortions.


## Hydraulic/Pneumatic Actuators
- How Far Are Pneumatic Artificial Muscles from Biological Muscles?

    Author: Mohseni, Omid | University of Tehran
    Author: Gagey, Ferr�ol | École Normale Paris-Saclay
    Author: Zhao, Guoping | Technical University of Darmstadt
    Author: Seyfarth, Andre | TU Darmstadt
    Author: Ahmad Sharbafi, Maziar | Technical University of Darmstadt
 
    keyword: Hydraulic/Pneumatic Actuators

    Abstract : There is a long history demonstrating humans' tendency to create artificial copies of living creatures. For moving machines called robots, actuators play a key role in developing human-like movements. Among different types of actuation, PAMs (pneumatic artificial muscles) are known as the most similar ones to biological muscles. In addition to similarities in force generation mechanism (tension based), the well-accepted argumentation from Klute et al., states that the PAM force-length (<i>f<sub>l</sub></i>) behavior is close to biological muscles, while the force-velocity (<i>f<sub>v</sub></i>) pattern is different. Using the multiplicative formulation of the pressure (as an activation term), <i>f<sub>l</sub></i> and <i>f<sub>v</sub></i> beside an additive passive parallel elastic element, we present a new model of PAM. This muscle-based model can predict PAM dynamic behaviors with high precision. With a second experiment in a two-segmented leg, the proposed model is verified to predict the generated forces of PAMs in an antagonistic arrangement. Such a dynamic muscle-like model of artificial muscles can be used for the design and control of legged robots to generate robust, efficient and versatile gaits.

- Optically Sensorized Elastomer Air Chamber for Proprioceptive Sensing of Soft Pneumatic Actuator

    Author: Jung, Jaewoong | Seoul National University
    Author: Park, Myungsun | Seoul National University
    Author: Kim, DongWook | Seoul National University
    Author: Park, Yong-Lae | Seoul National University
 
    keyword: Hydraulic/Pneumatic Actuators; Soft Sensors and Actuators; Soft Robot Materials and Design

    Abstract : Soft robotics has proven the capability of robots interacting with their environments including humans by taking advantage of the property of high compliance in recent years. Soft pneumatic actuators are one of the most commonly used actuation systems in soft robotics. However, control of a highly compliant actuation system remains as a challenging issue due to its nonlinearity and hysteresis. Addressing this problem requires integration of a soft sensing mechanism with the actuator for proprioceptive feedback. A soft optical waveguide with a reflective metal coating is a promising sensing mechanism with high compliance and low hysteresis. In this paper, we propose design and fabrication of a soft pneumatic actuator integrated with an optical waveguide that can provide the proprioceptive information of the actuator. We describe the de- sign and fabrication, and present experimental characterization results of the proposed system. We also provide applications of the proposed system.

- A Compact McKibben Muscle Based Bending Actuator for Close-To-Body Application in Assistive Wearable Robots

    Author: Tschiersky, Martin | University of Twente
    Author: Hekman, Edsko E.G. | University of Twente
    Author: Brouwer, Dannis M. | University of Twente
    Author: Herder, Just | Delft University of Technology
    Author: Suzumori, Koichi | Tokyo Institute of Technology
 
    keyword: Hydraulic/Pneumatic Actuators; Wearable Robots; Physically Assistive Devices

    Abstract : In this letter we demonstrate a pneumatic bending actuator for upper-limb assistive wearable robots which uses thin McKibben muscles in combination with a flexure strip. The actuator features both active soft actuation and passive gravity support, and in terms of force transmission bridges the gap between the classic rigid type actuators and the emerging soft actuator technologies. Its flexure strip leverages the high-force low-displacement properties of McKibben muscles towards a large rotational range of motion and reduces localized forces at the attachments. We explain the synthesis method by which these actuators can be obtained and optimized for high specific moment output. Physical specimens of three optimized actuator designs are built and tested on a dedicated experimental setup, verifying the computational models. Furthermore, a proof-of-concept upper-limb assistive wearable robot is presented to illustrate a practical application of this actuator and its potential for close-to-body alignment. We found that based on our currently available components actuators can be built which, given a width of 80 mm, are able to produce a moment exceeding 4 Nm at an arm elevation of 90 deg.

- Proposal and Prototyping of Self-Excited Pneumatic Actuator Using Automatic-Flow-Path-Switching-Mechanism

    Author: Tani, Kosuke | Tokyo Institute of Technology
    Author: Nabae, Hiroyuki | Tokyo Institute of Technology
    Author: Endo, Gen | Tokyo Institute of Technology
    Author: Suzumori, Koichi | Tokyo Institute of Technology
 
    keyword: Hydraulic/Pneumatic Actuators; Additive Manufacturing; Mechanism Design

    Abstract : Robots currently have a wide range of practical applications. However, their widespread use is limited by long design and manufacturing times as well as increasingly complex drive system electronics and software, which have led to high development costs. Therefore, simpler manufacturing, driving, and control methods are required. In this study, we design a pneumatic actuator drive system that combines the printing technique and self-excited vibration. In the proposed actuator, a mechanism for automatically switching the airflow path is used to induce self-excited vibration. Moreover, the actuator is integrally molded by a 3D printer; therefore, no assembly process is required. This actuator can be used to easily build robots in a short time, contributing to more widespread use of robots. In this study, we also calculate the theoretical value of the moving frequency by modeling the actuator and verify the validity of this value through experiments using a prototype actuator. Based on the results, we were able to freely design the operating frequency of the actuator; by using this knowledge, we designed a flapping robot. The robot is also integrally molded by a 3D printer. Finally, we validate its motion through experiments, in order to illustrate one of the many applications of the proposed actuator.

- Development of Backdrivable Servovalve with Feedback Spring for Enhanced Electro-Hydraulic Torque Actuator

    Author: Nam, Seokho | POSTECH
    Author: Lee, Woongyong | POSTECH
    Author: Yoo, Sunkyum | POSTECH
    Author: Kim, Keehoon | POSTECH, Pohang University of Science and Technology
    Author: Chung, Wan Kyun | POSTECH
 
    keyword: Hydraulic/Pneumatic Actuators; Physical Human-Robot Interaction; Product Design, Development and Prototyping

    Abstract : This paper proposes a novel backdrivable servovalve to implement a torque-controlled electro-hydraulic actuator. The proposed backdrivable servovalve simultaneously contains the characteristics of a flow-control servo valve (= feedback spring) and a pressure-control servovalve (= pressure feedback port). Consequently, the torque control performance of electrohydraulic torque actuators (EHTAs), which consist of the backdrivable servovalve and rotary vane-type hydraulic actuators, can be enhanced. First, the effective torque bandwidth, which represents the region where the torque output remains constant within a 90deg phase lag, is improved. Second, torque-based control algorithms developed for electric motors are realized in a wide frequency region. Finally, although the effect of viscous friction increases, the effect of static friction is reduced. With these advantages, we achieved an enhanced EHTA with calculated torque output of -372~355Nm; this could facilitate in the development of a high-performance interactive robot system. The proposed backdrivable servovalve and enhanced EHTA were evaluated through experiments.

- Passivity-Based Robust Compliance Control of Electro-Hydraulic Robot Manipulators with Joint Angle Limit

    Author: Lee, Woongyong | POSTECH
    Author: Yoo, Sunkyum | POSTECH
    Author: Nam, Seokho | POSTECH
    Author: Kim, Keehoon | POSTECH, Pohang University of Science and Technology
    Author: Chung, Wan Kyun | POSTECH
 
    keyword: Hydraulic/Pneumatic Actuators; Compliance and Impedance Control; Robust/Adaptive Control of Robotic Systems

    Abstract : This paper presents a robust compliance control scheme for an electro-hydraulic robot manipulator with an electro-hydraulic torque actuators (EHTAs) and joint torque sensors. The EHTA, a torque-sourced hydraulic actuator, consists of electro-hydraulic backdrivable servovalve and a rotary hydraulic vane actuator and it allows us to design controllers similar to those for robot manipulators with electric motors. However, unlike in electric motors, the EHTA has a limited rotational angle and this may lead to instability when using a non-passive robust controller that generates the energy. As a solution to this problem, this paper proposes a robust two-loop control structure that has a passivity-based disturbance observer as an inner-loop controller and a nominal state feedback compliance controller as an outer-loop controller. The proposed control method was evaluated through single-degree-of-freedom experiments.

## Service Robots
- Shared Control Templates for Assistive Robotics

    Author: Quere, Gabriel | DLR
    Author: Hagengruber, Annette | German Aerospace Center
    Author: Iskandar, Maged | German Aerospace Center - DLR
    Author: Bustamante, Samuel | German Aeroespace Center (DLR), Robotics and Mechatronics Center
    Author: Leidner, Daniel | German Aerospace Center (DLR)
    Author: Stulp, Freek | DLR - Deutsches Zentrum F�r Luft Und Raumfahrt E.V
    Author: Vogel, J�rn | German Aerospace Center
 
    keyword: Service Robots; Control Architectures and Programming; Rehabilitation Robotics

    Abstract : Light-weight robotic manipulators can be used to restore the manipulation capability of people with motor disability. However, manipulating the environment poses a complex task, especially when the control interface is of low bandwidth, as may be the case for users with impairments. Therefore, we propose a constraint-based shared control scheme to define skills which provide support during task execution. This is achieved by representing a skill as a sequence of states, with specific user command mappings and different sets of constraints being applied in each state. New skills can be defined based on different types of constraints and conditions for state transition in a human readable manner. We demonstrate its versatility in a pilot experiment with three activities of daily living. Results show that even complex, high-dimensional tasks can be performed with a low-dimensional interface using our shared control approach.

- Enabling Robots to Understand Incomplete Natural Language Instructions Using Commonsense Reasoning

    Author: Chen, Haonan | University of North Carolina at Chapel Hill
    Author: Tan, Hao | UNC Chapel Hill
    Author: Kuntz, Alan | University of Utah
    Author: Bansal, Mohit | Unc Chapel Hill
    Author: Alterovitz, Ron | University of North Carolina at Chapel Hill
 
    keyword: Service Robots

    Abstract : Enabling robots to understand instructions provided via spoken natural language would facilitate interaction between robots and people in a variety of settings in homes and workplaces. However, natural language instructions are often missing information that would be obvious to a human based on environmental context and common sense, and hence does not need to be explicitly stated. In this paper, we introduce Language-Model-based Commonsense Reasoning (LMCR), a new method which enables a robot to listen to a natural language instruction from a human, observe the environment around it, and automatically fill in information missing from the instruction using environmental context and a new commonsense reasoning approach. Our approach first converts an instruction provided as unconstrained natural language into a form that a robot can understand by parsing it into verb frames. Our approach then fills in missing information in the instruction by observing objects in its vicinity and leveraging commonsense reasoning. To learn commonsense reasoning automatically, our approach distills knowledge from large unstructured textual corpora by training a language model. Our results show the feasibility of a robot learning commonsense knowledge automatically from web-based textual corpora, and the power of learned commonsense reasoning models in enabling a robot to autonomously perform tasks based on incomplete natural language instructions.

- A Holistic Approach in Designing Tabletop Robot's Expressivity

    Author: Gomez, Randy | Honda Research Institute Japan Co., Ltd
    Author: Nakamura, Keisuke | Honda Research Institute Japan Co., Ltd
    Author: Szapiro, Deborah | University of Technology Sydney
    Author: Merino, Luis | Universidad Pablo De Olavide
 
    keyword: Robot Companions; Gesture, Posture and Facial Expressions

    Abstract : Defining a robot's expressivity is a difficult task that requires thoughtful consideration of the potential of various robot modalities and a model of communication that humans understand. Humanoid and zoomorphic-designed robots can easily take cues from human and animals, respectively when designing their expressivity. However, a robot design that is neither human nor animal-like does not have a clear model to follow in terms of designing expressivity. Animation presents a potential model in these circumstances as animated characters in movies take various forms, sizes, shapes and styles, and are successful in defining expressivity that is widely accepted across different languages and cultures. In this paper, we discuss the development and design of the expressivity of a table top robot that is neither human nor animal-like and the application of animation expertise to the holistic treatment of the different modalities. The method maximises animation techniques and expertise normally applied to movies to generate expressivity that is then transferred to the robot hardware. Experimental results show that the robot's expressivity generated using our method is easily understood and are preferred than the conventional approach of generating expressions

- DirtNet: Visual Dirt Detection for Autonomous Cleaning Robots

    Author: Bormann, Richard | Fraunhofer IPA
    Author: Wang, Xinjie | Fraunhofer IPA
    Author: Xu, Jiawen | Fraunhofer IPA
    Author: Schmidt, Joel | University of Stuttgart
 
    keyword: Service Robots; Object Detection, Segmentation and Categorization; Computer Vision for Other Robotic Applications

    Abstract : Visual dirt detection is becoming an important capability for modern professional cleaning robots both for optimizing their wet cleaning results and for facilitating demand-oriented daily vacuum cleaning. This paper presents a robust, fast, and reliable dirt and office item detection system for these tasks based on an adapted YOLOv3 framework. Its superiority over state-of-the-art dirt detection systems is demonstrated in several experiments. The paper furthermore features a dataset generator for creating any number of realistic training images from a small set of real scene, dirt, and object examples.

- Semantic Linking Maps for Active Visual Object Search

    Author: Zeng, Zhen | University of Michigan
    Author: Röfer, Adrian | University of Bremen
    Author: Jenkins, Odest Chadwicke | University of Michigan
 
    keyword: Service Robots; Autonomous Agents; Domestic Robots 

    Abstract : We aim for mobile robots to function in a variety of common human environments. Such robots need to be able to reason about the locations of previously unseen target objects. Landmark objects can help this reasoning by narrowing down the search space significantly. More specifically, we can exploit background knowledge about common spatial relations between landmark and target objects. For example, seeing a table and knowing that cups can often be found on tables aids the discovery of a cup. Such correlations can be expressed as distributions over possible pairing relationships of objects. In this paper, we propose an active visual object search strategy method through our introduction of the Semantic Linking Maps (SLiM) model. SLiM simultaneously maintains the belief over a target object's location as well as landmark objects' locations, while accounting for probabilistic inter-object spatial relations. Based on SLiM, we describe a hybrid search strategy that selects the next best view pose for searching for the target object based on the maintained belief. We demonstrate the efficiency of our SLiM-based search strategy through comparative experiments in simulated environments. We further demonstrate the real-world applicability of SLiM-based search in scenarios with a Fetch mobile manipulation robot.

- ALTER-EGO: A Mobile Robot with Functionally Anthropomorphic Upper Body Designed for Physical Interaction (I)

    Author: Lentini, Gianluca | University of Pisa
    Author: Settimi, Alessandro | Université Di Pisa
    Author: Caporale, Danilo | Centro Di Ricerca E. Piaggio
    Author: Garabini, Manolo | Université Di Pisa
    Author: Grioli, Giorgio | Istituto Italiano Di Tecnologia
    Author: Pallottino, Lucia | Université Di Pisa
    Author: Catalano, Manuel Giuseppe | Istituto Italiano Di Tecnologia
    Author: Bicchi, Antonio | Université Di Pisa
 
    keyword: Humanoid Robots; Service Robots; Telerobotics and Teleoperation

    Abstract : In this work we present ALTER-EGO, an open-source mobile robot with a functionally anthropomorphic upper body, designed to operate in different environments, and equipped with soft robotics technologies to enable safe physical interactions with humans and the environment, to guarantee robustness and to allow versatility. ALTER-EGO is powered by Variable Stiffness Actuators and each arm mounts an anthropomorphic synergistically actuated artificial hand. The upper body is integrated with a two-wheels self-balancing mobile base to minimize the robot footprint and increase agility. ALTEREGO features also sensors and a computational system which, together with a modular pilot station, make the robot able to function either autonomously or in an, optionally immersive, teleoperation mode. Finally, a plausible use case scenario - a robot avatar in a domestic environment - is described and investigated through a preliminary experimental session.

## Robot Perception
- Active Depth Estimation: Stability Analysis and Its Applications

    Author: T. Rodrigues, R�mulo | Faculty of Engineering, University of Porto
    Author: Miraldo, Pedro | Instituto Superior Técnico, Lisboa
    Author: Dimarogonas, Dimos V. | KTH Royal Institute of Technology
    Author: Aguiar, A. Pedro | Faculty of Engineering, University of Porto (FEUP)
 
    keyword: Visual Servoing; Sensor-based Control; Mapping

    Abstract : Recovering the 3D structure of the surrounding environment is one of the more important tasks in any vision-controlled Structure-from-Motion (SfM) scheme. This paper focuses on the theoretical properties of the SfM known as the incremental active depth estimation. The term incremental stands for estimating the 3D structure of the scene over a chronological sequence of image frames. Active means that the camera actuation is such that it improves estimation performance. Starting from a known depth estimation filter, this paper presents the stability analysis of the filter in terms of the control inputs of the camera. By analyzing the convergence of the estimator using Lyapunov theory, we relax the constraints on the projection of the 3D point in the image plane when compared to previous results. The main results are validated through experiments with simulated data.

- VALID: A Comprehensive Virtual Aerial Image Dataset

    Author: Chen, Lyujie | Tsinghua University
    Author: Liu, Feng | Tsinghua University
    Author: Zhao, Yan | Tsinghua University
    Author: Wang, Wufan | Tsinghua University
    Author: Yuan, Xiaming | Tsinghua University
    Author: Zhu, Jihong | Tsinghua University
 
    keyword: Performance Evaluation and Benchmarking; Big Data in Robotics and Automation; Object Detection, Segmentation and Categorization

    Abstract : Aerial imagery plays an important role in land-use planning, population analysis, precision agriculture, and unmanned aerial vehicle tasks. However, existing aerial image datasets generally suffer from the problem of inaccurate labeling, single ground truth type, and few category numbers. In this work, we implement a simulator that can simultaneously acquire diverse visual ground truth data in the virtual environment. Based on that, we collect a comprehensive Virtual AeriaL Image Dataset named VALID, consisting of 6690 highresolution images, all annotated with panoptic segmentation on 30 categories, object detection with oriented bounding box, and binocular depth maps, collected in 6 different virtual scenes and 5 various ambient conditions (sunny, dusk, night, snow and fog). To our knowledge, VALID is the &#64257;rst aerial image dataset that can provide panoptic level segmentation and complete dense depth maps. We analyze the characteristics of VALID and evaluate state-of-the-art methods for multiple tasks to provide reference baselines. The experiment results demonstrate that VALID is well presented and challenging. The dataset is available at https://sites.google.com/view/valid-dataset/.

- Multiple Sound Source Position Estimation by Drone Audition Based on Data Association between Sound Source Localization and Identification

    Author: Wakabayashi, Mizuho | Kumamoto University
    Author: Okuno, Hiroshi G. | Waseda University
    Author: Kumon, Makoto | Kumamoto University
 
    keyword: Robot Audition; Aerial Systems: Perception and Autonomy; Aerial Systems: Applications

    Abstract : Drone audition, or auditory processing for drones equipped with a microphone array, is expected to compensate for problems affecting drones' visual processing, in particular occlusion and poor-illumination conditions. The current state of drone audition still assumes a single sound source. When a drone hears sounds originating from multiple sound sources, its sound-source localization function determines their directions. If two sources are very close to each other, the localization function cannot determine whether they are crossing or approaching-then-departing. This ambiguity in tracking multiple sound sources is resolved by data association. Typical methods of data association use each label of the separated sounds, but are prone to errors due to identification failures. Instead of labeling by classification, this study uses a set of classification measures determined by support vector machines (SVM) to avoid labeling failures and deal with unknown signals. The effectiveness of the proposed approach is validated through simulations and experiments conducted in the field.

- Augmented LiDAR Simulator for Autonomous Driving

    Author: Fang, Jin | Baidu
    Author: Zhou, Dingfu | BAIDU
    Author: Yan, Feilong | Baidu
    Author: Tongtong, Zhao | Baidu
    Author: Zhang, Feihu | University of Oxford
    Author: Ma, Yu | Baidu
    Author: Wang, Liang | Baidu USA
    Author: Yang, Ruigang | University of Kentucky
 
    keyword: Simulation and Animation; Computer Vision for Automation; Object Detection, Segmentation and Categorization

    Abstract : In Autonomous Driving (AD), detection and tracking of obstacles on the roads is a critical task. Deep-learning based methods using annotated LiDAR data have been the most widely adopted approach for this. Unfortunately, annotating 3D point cloud is a very challenging, time- and money-consuming task. In this paper, we propose a novel LiDAR simulator that augments real point cloud with synthetic obstacles (e.g., vehicles, pedestrians, and other movable objects). Unlike previous simulators that entirely rely on CG (Computer Graphics) models and game engines, our augmented simulator bypasses the requirement to create high-fidelity background CAD (Computer Aided Design) models. Instead, we can simply deploy a vehicle with a LiDAR scanner to sweep the street of interests to obtain the background point cloud, based on which annotated point cloud can be automatically generated. This unique "scan-and-simulate" capability makes our approach scalable and practical, ready for large-scale industrial applications. In this paper, we describe our simulator in detail, in particular the placement of obstacles that is critical for performance enhancement. We show that detectors with our simulated LiDAR point cloud alone can perform comparably (within two percentage points) with these trained with real data. Mixing real and simulated data can achieve over 95% accuracy.

- Purely Image-Based Pose Stabilization of Nonholonomic Mobile Robots with a Truly Uncalibrated Overhead Camera (I)

    Author: Liang, Xinwu | Shanghai Jiao Tong University
    Author: Wang, Hesheng | Shanghai Jiao Tong University
    Author: Liu, Yunhui | Chinese University of Hong Kong
    Author: Liu, Zhe | University of Cambridge
    Author: You, Bing | Fujian Fuqing Nuclear Power Co., Ltd
    Author: Jing, Zhongliang | Shanghai Jiao Tong University
    Author: Chen, Weidong | Shanghai Jiao Tong University
 
    keyword: Visual Servoing; Nonholonomic Mechanisms and Systems; Sensor-based Control

    Abstract : Though many vision-based control methods have been proposed for nonholonomic mobile robots, in their implementation, it is usually necessary to calibrate the camera intrinsic and/or extrinsic parameters using offline/online parameter estimation algorithms or online adaptation laws. To avoid the tediousness of camera calibration and to make the system performance highly robust to camera parameter uncertainties, in this paper, we propose novel image-based pose stabilization control approaches for nonholonomic mobile robots with a truly uncalibrated overhead fixed camera. In the proposed approaches, only image position information of three feature points from an overhead camera is used for controller design, while information from other sensors (such as wheel encoders) is not required. Furthermore, either offline or online camera calibration is not necessary, and no knowledge about the camera intrinsic and extrinsic parameters is needed, which also can greatly simplify the controller implementation. Simulation and experimental results are given to demonstrate the feasibility and effectiveness of the proposed purely image-based pose stabilization approaches

## Distributed Robot Systems
- Distributed Attack-Robust Submodular Maximization for Multi-Robot Planning

    Author: Zhou, Lifeng | Virginia Tech
    Author: Tzoumas, Vasileios | Massachusetts Institute of Technology
    Author: Pappas, George J. | University of Pennsylvania
    Author: Tokekar, Pratap | University of Maryland
 
    keyword: Distributed Robot Systems; Path Planning for Multiple Mobile Robots or Agents; Multi-Robot Systems

    Abstract : We aim to guard swarm-robotics applications against denial-of-service (DoS) attacks that result in withdrawals of robots. We focus on applications requiring the selection of actions for each robot, among a set of available ones, e.g., which trajectory to follow. Such applications are central in large-scale robotic applications, e.g., multi-robot motion planning for target tracking. But the current attack-robust algorithms are centralized, and scale quadratically with the problem size (e.g., number of robots). In this paper, we propose a general-purpose distributed algorithm towards robust optimization at scale, with local communications only. We name it distributed robust maximization (DRM). DRM proposes a divide-and-conquer approach that distributively partitions the problem among K cliques of robots. The cliques optimize in parallel, independently of each other. That way, DRM also offers computational speed-ups up to 1/K^2 the running time of its centralized counterparts. K depends on the robot’ communication range, which is given as input to DRM. DRM also achieves a close-to-optimal performance. We demonstrate DRM's performance in Gazebo and MATLAB simulations, in scenarios of active target tracking with multiple robots. We observe DRM achieves significant computational speed-ups (it is 3 to 4 orders faster) and, yet, nearly matches the tracking performance of its centralized counterparts.

- Multirobot Patrolling against Adaptive Opponents with Limited Information

    Author: Diaz Alvarenga, Carlos | University of California at Merced
    Author: Basilico, Nicola | University of Milan
    Author: Carpin, Stefano | University of California, Merced
 
    keyword: Surveillance Systems; Multi-Robot Systems; Planning, Scheduling and Coordination

    Abstract : We study a patrolling problem where multiple agents are tasked with protecting an environment where one or more adversaries are trying to compromise targets of varying value. The objective of the patrollers is to move between targets to quickly spot when an attack is taking place and then diffuse it. Differently from most related literature, we do not assume that attackers have full knowledge of the strategies followed by the patrollers, but rather build a model at run time through repeated observations of how often they visit certain targets. We study three different solutions to this problem. The first two partition the environment using either a fast heuristic or an exact method that is significantly more time consuming. The third method, instead does not partition the environment, but rather lets every patroller roam over the entire environment. After having identified strengths and weaknesses of each method, we contrast their performances against attackers using different algorithms to decide whether to attack or not.

- Distributed Optimization of Nonlinear, Non-Gaussian, Communication-Aware Information Using Particle Methods

    Author: Moon, Sangwoo | University of Colorado Boulder
    Author: Frew, Eric W. | University of Colorado
 
    keyword: Distributed Robot Systems; Networked Robots; Multi-Robot Systems

    Abstract : This paper presents a distributed optimization framework and its local utility design for communication-aware information gathering by mobile robotic sensor networks. The main idea of the optimization is that each robot decides based on its local utility that considers the decisions of other neighbor robots higher in a given hierarchy. The local utility is designed as conditional mutual information that captures sensing and communication properties. Sampling procedures using a specific measurement set and particle methods are applied to compute the designed utility, which allows nonlinear, non-Gaussian properties of targets, sensing, and communication. Simulation results describe the presented distributed optimization shows more improved estimates and entropy reduction than another approach that does not consider communication properties. Simulation results also verify the presented distributed optimization using the described approach for information computation has better results than using other approaches that simplify the communication-aware information.

- Experimental Comparison of Decentralized Task Allocation Algorithms under Imperfect Communication

    Author: Nayak, Sharan | University of Maryland, College Park
    Author: Yeotikar, Suyash | University of Maryland, College Park
    Author: Carrillo, Estefany | Department of Aerospace Engineering, University of Maryland
    Author: Rudnick-Cohen, Eliot | University of Maryland, College Park
    Author: M Jaffar, Mohamed Khalid | University of Maryland, College Park
    Author: Patel, Ruchir | University of Maryland, College Park
    Author: Azarm, Shapour | University of Maryland
    Author: Herrmann, Jeffrey | University of Maryland
    Author: Xu, Huan | University of Maryland
    Author: Otte, Michael W. | University of Maryland
 
    keyword: Distributed Robot Systems; Task Planning; Networked Robots

    Abstract : We compare the performance of five state of the art decentralized task allocation algorithms under imperfect communication conditions. The decentralized algorithms considered are CBAA, ACBBA, DHBA, HIPC and PI. All algorithms are evaluated using three different models of communication, including the Bernoulli model, the Gilbert-Elliot model, and the Rayleigh Fading model. All 15 of the resulting combinations of an algorithm with a communication model are evaluated in two different problem scenarios: (1)Collaborative visit scenario where the agents have to collaboratively visit known stationary targets. (2)Collaborative search and visit scenario where the agents have to collaboratively search and visit unknown stationary target locations. We use two performance measures to evaluate algorithms: (1)max distance traveled by any agent (2)max number of messages sent by any agent. Real-time experimental simulations show the trade offs that exist between these five algorithms at different communication conditions.

-  Parallel Self-Assembly with SMORES-EP, a Modular Robot

    Author: Liu, Chao | University of Pennsylvania
    Author: Lin, Qian | Tsinghua University
    Author: Kim, Hyun | University of Pennsylvania
    Author: Yim, Mark | University of Pennsylvania


###　Scalable Cooperative Transport of Cable-Suspended Loads with UAVs Using Distributed Trajectory Optimization

    Author: Jackson, Brian | Stanford University
    Author: Howell, Taylor | Stanford University
    Author: Shah, Kunal | Stanford University
    Author: Schwager, Mac | Stanford University
    Author: Manchester, Zachary | Stanford University


## Range Sensing
- Super-Pixel Sampler: A Data-Driven Approach for Depth Sampling and Reconstruction

    Author: Wolff, Adam | Technion
    Author: Praisler, Shachar | Technion
    Author: Tcenov, Ilya | Technion
    Author: Gilboa, Guy | Technion
 
    keyword: Range Sensing; Sensor Fusion

    Abstract : Depth acquisition, based on active illumination, is essential for autonomous and robotic navigation. LiDARs (Light Detection And Ranging) with mechanical, fixed, sampling templates are commonly used in today's autonomous vehicles. An emerging technology, based on solid-state depth sensors, with no mechanical parts, allows fast and adaptive scans. <p>In this paper, we propose an adaptive, image-driven, fast, sampling and reconstruction strategy. First, we formulate a piece-wise planar depth model and estimate its validity for indoor and outdoor scenes. Our model and experiments predict that, in the optimal case, adaptive sampling strategies with about 20-60 piece-wise planar structures can approximate well a depth map. This translates to requiring a single depth sample for every 1200 RGB samples (less than 0.1%), providing strong motivation to investigate an adaptive framework. Second, we introduce SPS (Super-Pixel Sampler), a simple, generic, sampling and reconstruction algorithm, based on super-pixels. Our sampling improves grid and random sampling, consistently, for a wide variety of reconstruction methods. Third, we propose an extremely simple and fast reconstruction for our sampler. It achieves state-of-the-art results, compared to complex image-guided depth completion algorithms, reducing the required sampling rate by a factor of 3-4. A single-pixel prototype sampler built in our lab illustrates the concept.

- Physics-Based Simulation of Continuous-Wave LIDAR for Localization, Calibration and Tracking

    Author: Heiden, Eric | University of Southern California
    Author: Liu, Ziang | University of Southern California
    Author: Ramachandran, Ragesh Kumar | University Southern California
    Author: Sukhatme, Gaurav | University of Southern California
 
    keyword: Range Sensing; Simulation and Animation; Learning and Adaptive Systems

    Abstract : Light Detection and Ranging (LIDAR) sensors play an important role in the perception stack of autonomous robots, supplying mapping and localization pipelines with depth measurements of the environment. While their accuracy outperforms other types of depth sensors, such as stereo or time-of-flight cameras, the accurate modeling of LIDAR sensors requires laborious manual calibration that typically does not take into account the interaction of laser light with different surface types, incidence angles and other phenomena that significantly influence measurements. In this work, we introduce a physically plausible model of a 2D continuous-wave LIDAR that accounts for the surface-light interactions and simulates the measurement process in the Hokuyo URG-04LX LIDAR. Through automatic differentiation, we employ gradient-based optimization to estimate model parameters from real sensor measurements.

- A Spatial-Temporal Multiplexing Method for Dense 3D Surface Reconstruction of Moving Objects

    Author: Sui, Congying | The Chinese University of Hong Kong
    Author: He, Kejing | Chinese University of Hong Kong
    Author: Wang, Zerui | The Chinese University of Hong Kong
    Author: Lyu, Congyi | Beijing Institute of Technology
    Author: Guo, Huiwen | Smarteye Technique
    Author: Liu, Yunhui | Chinese University of Hong Kong
 
    keyword: Range Sensing; Computer Vision for Other Robotic Applications; Computer Vision for Automation

    Abstract : Three-dimensional reconstruction of dynamic objects is important for robotic applications, for example, the robotic recognition and manipulation. In this paper, we present a novel 3D surface reconstruction method for moving objects. The proposed method combines the spatial-multiplexing and time-multiplexing structured-light techniques that have advantages of less image acquisition time and accurate 3D reconstruction, respectively. A set of spatial-temporal encoded patterns are designed, where a spatial-encoded texture map is embedded into the temporal-encoded three-step phase-shifting fringes. The specifically designed spatial-coded texture assigns high-uniqueness codeword to any window on the image which helps to eliminate the phase ambiguity. In addition, the texture is robust to noise and image blur. Combining this texture with high-frequency phase-shifting fringes, high reconstruction accuracy would be ensured. This method only requires 3 patterns to uniquely encode a surface, which facilitates the fast image acquisition for each reconstruction step. A filtering stereo matching algorithm is proposed for the spatial-temporal multiplexing method to improve the matching reliability. Moreover, the reconstruction precision is further enhanced by a correspondence refinement algorithm. Experiments validate the performance of the proposed method including the high accuracy, the robustness to noise and the ability to reconstruct moving objects.

- Modeling of Architectural Components for Large-Scale Indoor Spaces from Point Cloud Measurement

    Author: Lim, Gahyeon | Korea University
    Author: Oh, Youjin | Korea University
    Author: Kim, Dongwoo | Korea University
    Author: Jun, ChangHyun | Korea University
    Author: Kang, Jaehyeon | Korea Institute of Industrial Technology
    Author: Doh, Nakju | Korea University
 
    keyword: Range Sensing; Object Detection, Segmentation and Categorization; Robotics in Construction

    Abstract : In this paper, we propose a method to model architectural components in large-scale indoor spaces from point cloud measurements. The proposed method enables the modeling of curved surfaces, cylindrical pillars, and slanted surfaces, which cannot be modeled using existing approaches. It operates by constructing the architectural points from the raw point cloud after removing non-architectural (objects) points and filling in the holes caused by their exclusion. Then, the architectural points are represented using a set of piece-wise planar segments. Finally, the adjacency graph of the planar segments is constructed to verify the fact that every planar segment is closed. This ensures a watertight mesh model generation. Experimentation using 14 different real-world indoor space datasets and 2 public datasets, comprising spaces of various sizes---from room-scale to large-scale (12,557m^2), verify the accuracy of the proposed method in modeling environments with curved surfaces, cylindrical pillars, and slanted surfaces.

- PhaRaO: Direct Radar Odometry Using Phase Correlation

    Author: Park, Yeong Sang | KAIST
    Author: Shin, Young-Sik | KAIST
    Author: Kim, Ayoung | Korea Advanced Institute of Science Technology
 
    keyword: Range Sensing; SLAM; Autonomous Vehicle Navigation

    Abstract : Recent studies in radar-based navigation present promising navigation performance using scanning radars. These scanning radar-based odometry methods are mostly feature-based; they detect and match salient features within a radar image. Differing from existing feature-based methods, this paper reports on a method using direct radar odometry, PhaRaO, which infers relative motion from a pair of radar scans via phase correlation. Specifically, we apply the Fourier Mellin transform (FMT) for Cartesian and log-polar radar images to sequentially estimate rotation and translation. In doing so, we decouple rotation and translation estimations in a coarse-to-fine manner to achieve real-time performance. The proposed method is evaluated using large-scale radar data obtained from various environments. The inferred trajectory yields a 2.34% (translation) and 2.93 (rotation) Relative Error (RE) over a 4 km path length on average for the odometry estimation.

- DeepTemporalSeg: Temporally Consistent Semantic Segmentation of 3D LiDAR Scans

    Author: Dewan, Ayush | University of Freibug
    Author: Burgard, Wolfram | Toyota Research Institute
 
    keyword: Range Sensing; Semantic Scene Understanding; Deep Learning in Robotics and Automation

    Abstract : Understanding the semantic characteristics of the environment is a key enabler for autonomous robot operation. In this paper, we propose a deep convolutional neural network (DCNN) for semantic segmentation of a LiDAR scan into the classes car, pedestrian and bicyclist. This architecture is based on dense blocks and efficiently utilizes depth separable convolutions to limit the number of parameters while still maintaining the state-of-the-art performance. To make the predictions from the DCNN temporally consistent, we propose a Bayes filter based method. This method uses the predictions from the neural network to recursively estimate the current semantic state of a point in a scan. This recursive estimation uses the knowledge gained from previous scans, thereby making the predictions temporally consistent and robust towards isolated erroneous predictions. We compare the performance of our proposed architecture with other state-of-the-art neural network architectures and report substantial improvement. For the proposed Bayes filter approach, we shows results on various sequences in the KITTI tracking benchmark.

## Transfer Learning
- Self-Supervised Sim-To-Real Adaptation for Visual Robotic Manipulation

    Author: Jeong, Rae | DeepMind
    Author: Aytar, Yusuf | Massachusetts Institute of Technology
    Author: Khosid, David | DeepMind
    Author: Zhou, Yuxiang | Google Uk, Ltd
    Author: Kay, Jackie | DeepMind
    Author: Lampe, Thomas | Google UK Ltd
    Author: Bousmalis, Konstantinos | Google
    Author: Nori, Francesco | DeepMind
 
    keyword: Deep Learning in Robotics and Automation; Simulation and Animation; AI-Based Methods

    Abstract : Collecting and automatically obtaining reward signals from real robotic visual data for the purposes of training reinforcement learning algorithms can be quite challenging and time-consuming. Methods for utilizing unlabeled data can have a huge potential to further accelerate robotic learning. We consider here the problem of performing manipulation tasks from pixels. In such tasks, choosing an appropriate state representation is crucial for planning and control. This is even more relevant with real images where noise, occlusions and resolution affect the accuracy and reliability of state estimation. In this work, we learn a latent state representation implicitly with deep reinforcement learning in simulation, and then adapt it to the real domain using unlabeled real robot data. We propose to do so by optimizing sequence-based self-supervised objectives. These use the temporal nature of robot experience, and can be common in both the simulated and real domains, without assuming any alignment of underlying states in simulated and unlabeled real images. We further propose a novel such objective, the textit{Contrastive Forward Dynamics} loss, which combines dynamics model learning with time-contrastive techniques. The learned state representation that results from our methods can be used to robustly solve a manipulation task in simulation and to successfully transfer the learned skill on a real system.

- Meta Reinforcement Learning for Sim-To-Real Domain Adaptation

    Author: Arndt, Karol | Aalto University
    Author: Hazara, Murtaza | KU Leuven
    Author: Ghadirzadeh, Ali | KTH Royal Institute of Technology, Aalto University
    Author: Kyrki, Ville | Aalto University
 
    keyword: Deep Learning in Robotics and Automation; Learning and Adaptive Systems

    Abstract : Modern reinforcement learning methods suffer from low sample efficiency and unsafe exploration, making it infeasible to train robotic policies entirely on real hardware. In this work, we propose to address the problem of sim-to-real domain transfer by using meta learning to train a policy that can adapt to a variety of dynamic conditions, and using a task-specific trajectory generation model to provide an action space that facilitates quick exploration. We evaluate the method by performing domain adaptation in simulation and analyzing the structure of the latent space during adaptation. We then deploy this policy on a KUKA LBR 4+ robot and evaluate its performance on a task of hitting a hockey puck to a target. Our method shows more consistent and stable domain adaptation than the baseline, resulting in better overall performance.

- Variational Auto-Regularized Alignment for Sim-To-Real Control

    Author: Hwasser, Martin | KTH / Northvolt
    Author: Kragic, Danica | KTH
    Author: Antonova, Rika | KTH Stockholm
 
    keyword: Learning and Adaptive Systems; Deep Learning in Robotics and Automation; Model Learning for Control

    Abstract : General-purpose simulators can be a valuable data source for flexible learning and control approaches. However, training models or control policies in simulation and then directly applying to hardware can yield brittle control. Instead, we propose a novel way to use simulators as regularizers. Our approach regularizes a decoder of a variational autoencoder to a black-box simulation, with the latent space bound to a subset of simulator parameters. This enables successful encoder training from a small number of real-world trajectories (10 in our experiments), yielding a latent space with simulation parameter distribution that matches the real-world setting. We use a learnable mixture for the latent prior/posterior, which implies a highly flexible class of densities for the posterior fit. Our approach is scalable and does not require restrictive distributional assumptions. We demonstrate ability to recover matching parameter distributions on a range of benchmarks, challenging custom simulation environments and several real-world scenarios. Our experiments using ABB YuMi robot hardware show ability to help reinforcement learning approaches overcome cases of severe sim-to-real mismatch.

- Experience Selection Using Dynamics Similarity for Efficient Multi-Source Transfer Learning between Robots

    Author: Sorocky, Michael | University of Toronto
    Author: Zhou, Siqi | University of Toronto
    Author: Schoellig, Angela P. | University of Toronto
 
    keyword: Learning and Adaptive Systems; Model Learning for Control

    Abstract : In the robotics literature, different knowledge transfer approaches have been proposed to leverage the experience from a source task or robot---real or virtual---to accelerate the learning process on a new task or robot. A commonly made but infrequently examined assumption is that incorporating experience from a source task or robot will be beneficial. For practical applications, inappropriate knowledge transfer can result in negative transfer or unsafe behaviour. In this work, inspired by a system gap metric from robust control theory, the nu-gap, we present a data-efficient algorithm for estimating the similarity between pairs of robot systems. In a multi-source inter-robot transfer learning setup, we show that this similarity metric allows us to predict relative transfer performance and thus informatively select experiences from a source robot before knowledge transfer. We demonstrate our approach with quadrotor experiments, where we transfer an inverse dynamics model from a real or virtual source quadrotor to enhance the tracking performance of a target quadrotor on arbitrary hand-drawn trajectories. We show that selecting experiences based on the proposed similarity metric effectively facilitates the learning of the target quadrotor, improving performance by 62% compared to a poorly selected experience.

- DeepRacer: Autonomous Racing Platform for Experimentation with Sim2Real Reinforcement Learning

    Author: Balaji, Bharathan | Amazon
    Author: Mallya, Sunil | Amazon Artificial Intelligence
    Author: Genc, Sahika | Amazon Artificial Intelligence
    Author: Gupta, Saurabh | Amazon
    Author: Dirac, Leo | Amazon
    Author: Khare, Vineet | Amazon
    Author: Roy, Gourav | Amazon
    Author: Sun, Tao | Amazon
    Author: Tao, Yunzhe | Amazon Web Services
    Author: Townsend, Brian | Amazon
    Author: Calleja, Eddie | Amazon
    Author: Muralidhara, Sunil | Amazon
    Author: Karuppasamy, Dhanasekar | Amazon
 
    keyword: AI-Based Methods; Autonomous Vehicle Navigation; Education Robotics

    Abstract : DeepRacer is a platform for end-to-end experimentation with RL and can be used to systematically investigate the key challenges in developing intelligent control systems. Using the platform, we demonstrate how a 1/18th scale car can learn to drive autonomously using RL with a monocular camera. It is trained in simulation with no additional tuning in physical world and demonstrates: 1) formulation and solution of a robust reinforcement learning algorithm, 2) narrowing the reality gap through joint perception and dynamics, 3) distributed on-demand compute architecture for training optimal policies, and 4) a robust evaluation method to identify when to stop training. It is the first successful large-scale deployment of deep reinforcement learning on a robotic control agent that uses only raw camera images as observations and a model-free learning method to perform robust path planning.

- Cross-Domain Motion Transfer Via Safety-Aware Shared Latent Space Modeling

    Author: Choi, Sungjoon | Disney Research
    Author: Kim, Joohyung | University of Illinois at Urbana-Champaign
 
    keyword: Deep Learning in Robotics and Automation; Motion and Path Planning; Collision Avoidance

    Abstract : This paper presents a data-driven motion retargeting method with safety considerations. In particular, we focus on handling self-collisions while transferring poses between different domains. To this end, we &#64257;rst propose leveraged Wasserstein auto-encoders (LWAE) which leverage both positive and negative data where negative data consist of self-collided poses. Then, we extend this idea to multiple domains to have a shared latent space to perform motion retargeting. We also present an effective self-collision handling method based on solving inverse kinematics with augmented targets that is used to collect collision-free poses. The proposed method is extensively evaluated in a diverse set of motions from human subjects and an animation character where we show that incorporating negative data dramatically reduces self-collisions while preserving the quality of the original motion.

## Flexible Robots
- Investigation of a Multistable Tensegrity Robot Applied As Tilting Locomotion System

    Author: Schorr, Philipp | TU Ilmenau
    Author: Schale, Florian | Ilmenau University of Technology
    Author: Otterbach, Jan Marc | TU Ilmenau
    Author: Zentner, Lena | TU Ilmenau
    Author: Zimmermann, Klaus | TU Ilmenau, Germany
    Author: Boehm, Valter | OTH Regensburg
 
    keyword: Flexible Robots; Soft Robot Applications; Dynamics

    Abstract : This paper describes the development of a tilting locomotion system based on a compliant tensegrity structure with multiple stable equilibrium configurations. A tensegrity structure featuring 4 stable equilibrium states is considered. The mechanical model of the structure is presented and the according equations of motion are derived. The variation of the length of selected structural members allows to influence the prestress state and the corresponding shape of the tensegrity structure. Based on bifurcation analyses a reliable actuation strategy to control the current equilibrium state is designed. In this work, the tensegrity structure is assumed to be in contact with a horizontal plane due to gravity. The derived actuation strategy is utilized to generate tilting locomotion by successively changing the equilibrium state. Numerical simulations are evaluated considering the locomotion characteristics. In order to validate this theoretical approach a prototype is developed. Experiments regarding to the equilibrium configurations, the actuation strategy and the locomotion characteristics are evaluated using image processing tools and motion capturing. The results verify the theoretical data and confirm the working principle of the investigated tilting locomotion system. This approach represents a feasible actuation strategy to realize a reliable tilting locomotion utilizing the multistability of compliant tensegrity structures.

- A Novel Articulated Soft Robot Capable of Variable Stiffness through Bistable Structure

    Author: Zhong, Yong | South China University of Technology
    Author: Du, Ruxu | The Chinese University of Hong Kong
    Author: Wu, Liao | University of New South Wales
    Author: Yu, Haoyong | National University of Singapore
 
    keyword: Flexible Robots; Kinematics; Mechanism Design

    Abstract : Soft robot has demonstrated promise in unstructured and dynamic environments due to unique advantages, such as safe interaction, adaptiveness, easy to actuate, and easy fabrication. However, the highly dissipative nature of elastic materials results in small stiffness of soft robot which limits certain functions, such as force transmission, position accuracy, and load capability. In this paper, we present a novel articulated soft robot with variable stiffness. The robot is constructed by rigid joints and compliant bistable structures in series. Each joint can be independently locked through triggering the bistable structure to touch the mechanical constrain. Thus, the bending stiffness of the joint can be magnified which increases the stiffness of the articulated soft robot. Through this construction method, even driven by only one servomotor, the robot demonstrates variable workspace and stiffness which have the potential of dexterous manipulation and maintaining shape under tip load.

- Modeling and Experiments on the Swallowing and Disgorging Characteristics of an Underwater Continuum Manipulator

    Author: Wang, Haihang | Harbin Engineering University
    Author: Xu, He | College of Mechanical and Electrical Engineering, Harbin Enginee
    Author: Yu, Fengshu | Harbin Engineering University
    Author: Li, Xin | Harbin Engineering University
    Author: Yang, Chen | Harbin Engineering University
    Author: Chen, Siqing | Harbin Engineering University
    Author: Chen, JunLong | Harbin Engineering University
    Author: Zhang, Yonghui | Harbin Engineering University
    Author: Zhou, Xueshan | Harbin Engineering University
 
    keyword: Flexible Robots; Hydraulic/Pneumatic Actuators; Soft Robot Applications

    Abstract : Soft robots apply compliant materials to perform motions and behaviors not typically achievable by rigid robots. An underwater, compliant, multi-segment continuum manipulator that can bend, swallow, disgorge is developed in this study. The manipulator is driven by McKibben water hydraulic artificial muscle (WHAM). The mechanical properties of the WHAM are tested and analyzed experimentally. The kinematics model, which concerns about the variable diameter structure of the soft grippers, are established to simulate the behaviors of the manipulator among the bending, swallowing and disgorging procedure. A mouth-tongue collaborative soft robot assembled with another single-segment soft robot arm is presented. And its functions are experimentally testified. The distinctive functions were verified according to the experimental results.

- Salamanderbot: A Soft-Rigid Composite Continuum Mobile Robotto Traverse Complex Environments

    Author: Sun, Yinan | Worcester Polytechnic Institute
    Author: Jiang, Yuqi | Worcester Polytechnic Institute
    Author: Yang, Hao | Worcester Polytechnic Institute
    Author: Walter, Louis-Claude | Ecole Nationale Supérieure d'Electricité Et De Mécanique
    Author: Santoso, Junius | WPI
    Author: Skorina, Erik | Worcester Polytechnic Institute
    Author: Onal, Cagdas | WPI
 
    keyword: Flexible Robots; Search and Rescue Robots; Soft Robot Applications

    Abstract : Soft robots are theoretically well-suited to rescueand exploration	applications where their flexibility allows forthe traversal	of highly cluttered environments. However, mostexisting mobile soft robots are not	fast or powerful enoughto effectively traverse three dimensional environments. In thispaper,	we introduce a new mobile robot with a continuouslydeformable slender body structure, the SalamanderBot, whichcombines the flexibility and maneuverability of soft robots, withthe speed	and power of traditional mobile robots. It consistsof a cable-driven bellows-like origami modules based on theYoshimura crease pattern mounted	between sets of poweredwheels.	The origami structure allows the body to deform asnecessary to adapt to complex environments and terrains, whilethe wheels allow the robot to reach speeds of up to 303.1 mm/s(2.05 body-length/s). Salamanderbot can climb up to 60-degreeslopes and perform sharp turns with a minimum turning radiusof 79.9 mm (0.54 body-length).

- Flexure Hinge-Based Biomimetic Thumb with a Rolling-Surface Metacarpal Joint

    Author: Pulleyking, Spenser | University of Tulsa
    Author: Schultz, Joshua | University of Tulsa
 
    keyword: Flexible Robots; Underactuated Robots; Tendon/Wire Mechanism

    Abstract : The human thumb's state contribution to grasping and dexterous manipulation of objects is a function of the kinematic multiplicity of joints and structure of the bones, joints, and ligaments. This paper looks at the design and evaluation of a human-like thumb for use in a robotic hand, where the thumb's state contribution to grasping and dexterous manipulation is a function of a simplified kinematic model based on that of the human thumb, but also on empirical trials of surgical techniques to retain functionality while reducing the number of joints in the thumb. Motion Capture Data of the End Effector is analyzed with the measured excursion of the tendons to determine the relationship between tendon velocities and task-space velocities. We propose a simplified metric to represent this data, after validating the procedure experimentally, and show that our prototype is predicted to have a relatively smooth mapping between tendon excursion velocity and end effector velocity.

- Stretchable Kirigami Components for Composite Meso-Scale Robots

    Author: Firouzeh, Amir | Seoul National University
    Author: Higashisaka, Tatsuya | The University of Tokyo
    Author: Nagato, Keisuke | The University of Tokyo
    Author: Cho, Kyu-Jin | Seoul National University, Biorobotics Laboratory
    Author: Paik, Jamie | Ecole Polytechnique Federale De Lausanne
 
    keyword: Flexible Robots; Soft Robot Materials and Design; Soft Sensors and Actuators

    Abstract : Layer-by-layer manufacturing of composite mechanisms allows fast and cost-effective fabrication of customized robots in millimeter and centimeter scales which is promising for research fields that rely on frequent and numerous physical iterations. Due to the limited number of components that can be directly integrated in composite structures, however, often an assembly step is necessary which diminishes the benefits of this manufacturing method. Inspired by the Japanese craft of cutting (kiri-) paper (-gami), Kirigami, we introduce quasi-2D and highly stretchable functional Kirigami layers for direct integration into the composite mechanisms. Depending on the material and geometrical design; functional Kirigami layers can perform as flat springs, stretchable electronics, sensors or actuators. These components will facilitate the design and manufacturing of composite robots for different applications. To illustrate the effectiveness of these components, we designed and realized a foldable composite inchworm robot with three Kirigami layers serving as actuator, sensor and contact pad with directional friction. We elaborate on the working principle of each layer and report on their combined performance in the robot.

## Field and Space Robots
- Ibex: A Reconfigurable Ground Vehicle with Adaptive Terrain Navigation Capability

    Author: Raj, Senthur | National Institute of Technology, Tiruchirappalli
    Author: Aatitya R P, Manu | National Institute of Technology, Tiruchirapalli
    Author: Samuel, Jack | NATIONAL INSTITUTE of TECHNOLOGY, Tiruchirapalli
    Author: Karthik, Veejay | National Institute of Technology Tiruchirappalli
    Author: D, Ezhilarasi | National Institute of Technology Tiruchirappalli
 
    keyword: Field Robots; Wheeled Robots; Compliance and Impedance Control

    Abstract : This paper presents a unique unmanned ground vehicle with a dynamic wheelbase and an adaptive thrust based friction optimization scheme that aids in the traversal of steep slopes and slippery surfaces. The vehicle is capable of adapting itself to the surface topography using an impedance-based stabilization module to minimize the mechanical oscillatory transients induced during its motion. A detailed analysis of its modules has been elucidated in this paper based on the vehicle parameters. The proposed methodologies have been integrated and tested on a customized prototype. Experimental validation and simulation for the proposed modules at various terrain conditions have been carried out to authenticate its performance.

- Day and Night Collaborative Dynamic Mapping in Unstructured Environment Based on Multimodal Sensors

    Author: Yue, Yufeng | Nanyang Technological University
    Author: Yang, Chule | Nanyang Technological University
    Author: Zhang, Jun | Nanyang Technological University
    Author: Wen, Mingxing | Nanyang Technological University
    Author: Wu, Zhenyu | Nanyang Technological University
    Author: Zhang, Haoyuan | Nanyang Technological University
    Author: Wang, Danwei | Nanyang Technological University
 
    keyword: Field Robots; Mapping; Sensor Fusion

    Abstract : Enabling long-term operation during day and night for collaborative robots requires a comprehensive understanding of the unstructured environment. Besides, in the dynamic environment, robots must be able to recognize dynamic objects and collaboratively build a global map. This paper proposes a novel approach for dynamic collaborative mapping based on multimodal environmental perception. For each mission, robots first apply heterogeneous sensor fusion model to detect humans and separate them to acquire static observations. Then, the collaborative mapping is performed to estimate the relative position between robots and local 3D maps are integrated into a globally consistent 3D map. The experiment is conducted in the day and night rainforest with moving people. The results show the accuracy, robustness, and versatility in 3D map fusion missions.

- Generating Locomotion with Effective Wheel Radius Manipulation

    Author: Hojnik, Tim | CSIRO
    Author: Pond, Lachlan | QUT
    Author: Dungavell, Ross | CSIRO
    Author: Flick, Paul | CSIRO
    Author: Roberts, Jonathan | Queensland University of Technology
 
    keyword: Field Robots; Space Robotics and Automation; Intelligent Transportation Systems

    Abstract : Travel over sloped terrain is difficult as an incline changes the interaction between each wheel and the ground resulting in an unbalanced load distribution which can lead to loss of traction and instability. This paper presents a novel approach to generating wheel rotation for primary locomotion by only changing its centre of rotation, or as a complimentary locomotion source to increase versatility of a plain centre hub drive. This is done using linear actuators within a wheel to control the position of the centre hub and induce a moment on the wheel from gravity. In doing so our platform allows for active ride height selection and individual wheel pose control. We present the system with calculations outlining the theoretical properties and perform experiments to validate the concept under loading via multiple gaits to show motion on slopes, and sustained motion over extended distance. We envision applications in conjunction to assist current motor drives and increasing slope traversability by allowing body pose and centre of gravity manipulation, or as a primary locomotion system.

- Where to Map? Iterative Mars Helicopter-Rover Path Planning for Long-Range Autonomous Exploration

    Author: Sasaki, Takahiro | Japan Aerospace Exploration Agency
    Author: Otsu, Kyohei | California Institute of Technology
    Author: Thakker, Rohan | Nasa's Jet Propulsion Laboratory, Caltech
    Author: Haesaert, Sofie | Eindhoven University of Technology
    Author: Agha-mohammadi, Ali-akbar | NASA-JPL, Caltech
 
    keyword: Space Robotics and Automation; Path Planning for Multiple Mobile Robots or Agents

    Abstract : Besides the conventional ground-crawling vehicles, the Mars 2020 mission decided to send a helicopter to Mars. The copter's high-resolution data should help the rover to identify smaller hazards and avoid small structural components such as rocks or pebbles. We consider a three-agent system composed of a Mars rover, copter, and orbiter. The objective is to compute an optimal rover path that minimizes the localization uncertainty accumulation after a traverse. To achieve such a goal, we primarily focus on the localizability, which is the goodness measure, and conduct a joint-space search over rover's path and copter's perceptive actions before a traverse. Then, we jointly address where to map by the copter and where to drive by the rover to minimize the uncertainty accumulation in rover localization using the proposed iterative copter-rover path planner. Numerical simulations demonstrate the effectiveness of the proposed planner.

- A GNC Architecture for Planetary Rovers with Autonomous Navigation

    Author: Azkarate, Martin | European Space Agency (ESA) - ESTEC
    Author: Gerdes, Levin | ESA/ESTEC
    Author: Perez-del-Pulgar, Carlos | Universidad De Málaga
    Author: Joudrier, Luc | ESA
 
    keyword: Space Robotics and Automation; Autonomous Agents; Visual-Based Navigation

    Abstract : This paper proposes a Guidance, Navigation, and Control (GNC) architecture for planetary rovers targeting the conditions of upcoming Mars exploration missions such as Mars 2020 and the Sample Fetching Rover (SFR). The navigation requirements of these missions demand a control architecture featuring autonomous capabilities to achieve a fast and long traverse. The proposed solution presents a two-level architecture where the efficient navigation (low) level is always active and the full navigation (upper) level is enabled according to the difficulty of the terrain. The first level is an efficient implementation of the basic functionalities for autonomous navigation based on hazard detection, local path replanning, and trajectory control with visual odometry. The second level implements an adaptive SLAM algorithm that improves the relative localization, evaluates the traversability of the terrain ahead for a more optimal path planning, and performs global (absolute) localization that corrects the pose drift during longer traverses. The architecture provides a solution for long range, low supervision and fast planetary exploration. Both navigation levels have been validated on planetary analogue field test campaigns.

- Mine Tunnel Exploration Using Multiple Quadrupedal Robots

    Author: Miller, Ian | University of Pennsylvania
    Author: Cladera, Fernando | University of Pennsylvania
    Author: Cowley, Anthony | University of Pennsylvania
    Author: Skandan, Shreyas | University of Pennsylvania
    Author: Lee, Elijah S. | University of Pennsylvania
    Author: Lipschitz, Laura | UPenn
    Author: Bhat, Akhilesh | University of Pennsylvania
    Author: Rodrigues, Neil | University of Pennsylvania
    Author: Zhou, Alex | University of Pennsylvania
    Author: Cohen, Avraham | Technion, Robotics Laboratory
    Author: Kulkarni, Adarsh | University of Pennsylvania
    Author: Laney, James | Ghost Robotics
    Author: Taylor, Camillo Jose | University of Pennsylvania
    Author: Kumar, Vijay | University of Pennsylvania, School of Engineering and Applied Sc
 
    keyword: Mining Robotics; Field Robots; Legged Robots

    Abstract : Robotic exploration of underground environments is a particularly challenging problem due to communication, endurance, and traversability constraints which necessitate high degrees of autonomy and agility. These challenges are further exacerbated by the need to minimize human intervention forpractical applications. While legged robots have the ability to traverse extremely challenging terrain, they also engender newchallenges for planning, estimation, and control. In this work, we describe a fully autonomous system for multi-robot mine exploration and mapping using legged quadrupeds, as well as a distributed database mesh networking system for reporting data. In addition, we show results from the DARPA Subterranean Challenge (SubT) Tunnel Circuit demonstrating localization of artifacts after traversals of hundreds of meters. These experiments describe fully autonomous exploration of an unknown Global Navigation Satellite System (GNSS)-denied environment undertaken by legged robots.

## Recognition
- Learning Face Recognition Unsupervisedly by Disentanglement and Self-Augmentation

    Author: Lee, Yi-Lun | National Chiao Tung University
    Author: Tseng, Min-Yuan | National Chiao Tung University
    Author: Yu, Dung Ru | National Chiao Tung University
    Author: Lo, Yu-Cheng | National Chiao-Tung University
    Author: Chiu, Wei-Chen | National Chiao Tung University
 
    keyword: Recognition

    Abstract : As the growth of smart home, healthcare, and home robot applications, learning a face recognition system which is specific for a particular environment and capable of self-adapting to the temporal changes in appearance (e.g., caused by illumination or camera position) is nowadays an important topic. In this paper, given a video of a group of people, which simulates the surveillance video in a smart home environment, we propose a novel approach which unsupervisedly learns a face recognition model based on two main components: (1) a triplet network that extracts identity-aware feature from face images for performing face recognition by clustering, and (2) an augmentation network that is conditioned on the identity-aware features and aims at synthesizing more face samples. Particularly, the training data for the triplet network is obtained by using the spatiotemporal characteristic of face samples within a video, while the augmentation network learns to disentangle a face image into identity-aware and identity-irrelevant features thus is able to generate new faces of the same identity but with variance in appearance. With taking the richer training data produced by augmentation network, the triplet network is further fine-tuned and achieves better performance in face recognition. Extensive experiments not only show the efficacy of our model in learning an environment-specific face recognition model unsupervisedly, but also verify its adaptability to various appearance changes.

- PARC: A Plan and Activity Recognition Component for Assistive Robots

    Author: Massardi, Jean | Université Du Québec à Montréal
    Author: Gravel, Mathieu | University of Quebec at Montreal
    Author: Beaudry, Eric | Université Du Québec à Montréal
 
    keyword: RGB-D Perception; Human Detection and Tracking; Recognition

    Abstract : Mobile robot assistants have many applications, such as providing help for people in their daily living activities. These robots have to detect and to recognize the actions and goals of the assisted humans. While several plan and activity recognition solutions are widely spread for controlled environments with many built-in sensors, like smart-homes, there is a lack of such systems for mobile robots operating in open settings, such as an apartment. We propose a module for the recognition of the activities and goals for daily living on mobile robots, in real time and for complex activities. Our approach recognizes human-object interaction using an RGB-D camera to infer low-level actions which are sent to a goal recognition algorithm. Results show that our approach is both real time and requires little computational resources, which facilitates its deployment on a mobile and low-cost robotics platform.

- Image-Based Place Recognition on Bucolic Environment across Seasons from Semantic Edge Description

    Author: Benbihi, Assia | Umi 2958 Gt-Cnrs
    Author: Aravecchia, Stephanie | Georgia Tech Lorraine - UMI 2958 GT-CNRS
    Author: Geist, Matthieu | Université De Lorraine
    Author: Pradalier, Cedric | GeorgiaTech Lorraine
 
    keyword: Recognition; Semantic Scene Understanding; Localization

    Abstract : Most of the research effort on image-based place recognition is designed for urban environments. In bucolic environments such as natural scenes with low texture and little semantic content, the main challenge is to handle the variations in visual appearance across time such as illumination, weather, vegetation state or viewpoints. The nature of the variations is different and this leads to a different approach to describing a bucolic scene. We introduce a global image descriptor computed from its semantic and topological information. It is built from the wavelet transforms of the image semantic edges. Matching two images is then equivalent to matching their semantic edge descriptors. We show that this method reaches state-of-the-art image retrieval performance on two multi-season environment-monitoring datasets: the CMU-Seasons and the Symphony Lake dataset. It also generalises to urban scenes on which it is on par with the current baselines NetVLAD and DELF.

- A Multilayer-Multimodal Fusion Architecture for Pattern Recognition of Natural Manipulations in Percutaneous Coronary Interventions

    Author: Zhou, Xiao-Hu | Institute of Automation Chinese Academy of Sciences
    Author: Xie, Xiaoliang | Institutation of Automation, Chinese Academy of Sciences
    Author: Feng, Zhen-Qiu | Institute of Automation, Chinese Academy of Sciences
    Author: Hou, Zeng-Guang | Chinese Academy of Science
    Author: Bian, Gui-Bin | Institute of Automation, Chinese Academy of Sciences
    Author: Li, Rui-Qi | Institute of Automation, Chinese Academy of Sciences
    Author: Ni, ZhenLiang | Chinese Academy of Sciences
    Author: Liu, Shiqi | School of Automation, Harbin University of Science and Technolog
    Author: Zhou, Yan-Jie | Institute of Automation, Chinese Academy of Sciences
 
    keyword: Recognition; Sensor Fusion; Surgical Robotics: Steerable Catheters/Needles

    Abstract : The increasingly-used robotic systems can provide precise delivery and reduce X-ray radiation to medical staff in percutaneous coronary interventions (PCI), but natural manipulations of interventionalists are forgone in most robot-assisted procedures. Therefore, it is necessary to explore natural manipulations to design more advanced human-robot interfaces (HRI). In this study, a multilayer-multimodal fusion architecture is proposed to recognize six typical subpatterns of guidewire manipulations in conventional PCI. The synchronously acquired multimodal behaviors from ten subjects are used as the inputs of the fusion architecture. Six classification-based and two rule-based fusion algorithms are evaluated for performance comparisons. Experimental results indicate that the multimodal fusion brings significant accuracy improvement in comparison with single-modal schemes. Furthermore, the proposed architecture can achieve the overall accuracy of 96.90%, much higher than that of a single-layer recognition architecture (92.56%). These results have indicated the potential of the proposed method for facilitating the development of HRI for robot-assisted PCI.

- Action Description from 2D Human Postures in Care Facilities

    Author: Takano, Wataru | Osaka University
    Author: Haeyeon, Lee | Toyota Motor Corporation
 
    keyword: Recognition

    Abstract : This paper describes a novel approach to classification of whole-body motions from estimated human postures in 2D camera images and subsequent generation of their relevant descriptions. The motions are encoded into stochastic motion models referred to as motion primitives. Words are connected to the motion primitives, and word n-grams are represented stochastically. More specifically, the motion observation is classified into the motion primitive, from which its relevant words are generated. These words are arranged in a grammatically correct order to make the descriptions for the observation. This approach was tested on actions performed by older adults in the care facility and its validity was demonstrated.

- CoHOG: A Light-Weight, Compute-Efficient and Training-Free Visual Place Recognition Technique for Changing Environments

    Author: Zaffar, Mubariz | University of Essex
    Author: Ehsan, Shoaib | University of Essex
    Author: Milford, Michael J | Queensland University of Technology
    Author: McDonald-Maier, Klaus | University of Essex
 
    keyword: Recognition; SLAM; Computer Vision for Automation

    Abstract : This paper presents a novel, compute-efficient and training-free approach based on Histogram-of-Oriented-Gradients (HOG) descriptor for achieving state-of-the-art performance-per-compute-unit in Visual Place Recognition (VPR). The inspiration for this approach (namely CoHOG) is based on the convolutional scanning and regions-based feature extraction employed by Convolutional Neural Networks (CNNs). By using image entropy to extract regions-of-interest (ROI) and regional-convolutional descriptor matching, our technique performs successful place recognition in changing environments. We use viewpoint- and appearance-variant public VPR datasets to report this matching performance, at lower RAM commitment, zero training requirements and 20 times lesser feature encoding time compared to state-of-the-art neural networks. We also discuss the image retrieval time of CoHOG and the effect of CoHOG's parametric variation on its place matching performance and encoding time.

## Aerial Systems: Multi-Robots
- Distributed Consensus Control of Multiple UAVs in a Constrained Environment

    Author: Wang, Gang | University of Nevada
    Author: Yang, Weixin | University of Nevada, Reno
    Author: Zhao, Na | University of Nevada, Reno
    Author: Ji, Yunfeng | University of Shanghai for Science and Technology
    Author: Shen, Yantao | University of Nevada, Reno
    Author: Xu, Hao | University of Nevada, Reno
    Author: Li, Peng | Harbin Institute of Technology (ShenZhen)
 
    keyword: Autonomous Agents; Distributed Robot Systems

    Abstract : In this paper, we investigate the consensus problem of multiple unmanned aerial vehicles (UAVs) in the presence of environmental constraints under a general communication topology containing a directed spanning tree. First, based on a position transformation function, we propose a novel dynamic reference position and yaw angle for each UAV to cope with both the asymmetric topology and the constraints. Then, the backstepping-like design methodology is presented to derive a local tracking controller for each UAV such that its position and yaw angle can converge to the reference ones. The proposed protocol is distributed in the sense that, the input update of each UAV dynamically relies only on local state information from its neighborhood set and the constraints, and it does not require any additional centralized information. It is demonstrated that under the proposed protocol, all UAVs reach consensus without violation of the environmental constraints. Finally, simulation and experimental results are provided to demonstrate the performance of the protocol.

- Neural-Swarm: Decentralized Close-Proximity Multirotor Control Using Learned Interactions

    Author: Shi, Guanya | California Institute of Technology
    Author: Hoenig, Wolfgang | California Institute of Technology
    Author: Yue, Yisong | California Institute of Technology
    Author: Chung, Soon-Jo | Caltech
 
    keyword: Aerial Systems: Mechanics and Control; Deep Learning in Robotics and Automation; Multi-Robot Systems

    Abstract : In this paper, we present Neural-Swarm, a nonlinear decentralized stable controller for close-proximity flight of multirotor swarms. Close-proximity control is challenging due to the complex aerodynamic interaction effects between multirotors, such as downwash from higher vehicles to lower ones. Conventional methods often fail to properly capture these interaction effects, resulting in controllers that must maintain large safety distances between vehicles, and thus are not capable of close-proximity flight. Our approach combines a nominal dynamics model with a regularized permutation-invariant Deep Neural Network (DNN) that accurately learns the high-order multi-vehicle interactions. We design a stable nonlinear tracking controller using the learned model. Experimental results demonstrate that the proposed controller significantly outperforms a baseline nonlinear tracking controller with up to four times smaller worst-case height tracking errors. We also empirically demonstrate the ability of our learned model to generalize to larger swarm sizes.

- Line Coverage with Multiple Robots

    Author: Agarwal, Saurav | University of North Carolina at Charlotte
    Author: Akella, Srinivas | University of North Carolina at Charlotte
 
    keyword: Aerial Systems: Applications; Path Planning for Multiple Mobile Robots or Agents; Multi-Robot Systems

    Abstract : The <i>line coverage problem</i> is the coverage of linear environment features (e.g., road networks, power lines), modeled as 1D segments, by one or more robots while respecting resource constraints (e.g., battery capacity, flight time) for each of the robots. The robots incur direction dependent costs and resource demands as they traverse the edges. We treat the line coverage problem as an optimization problem, with the total cost of the tours as the objective, by formulating it as a mixed integer linear program (MILP). The line coverage problem is NP-hard and hence we develop a heuristic algorithm, Merge-Embed-Merge (MEM). We compare it against the optimal MILP approach and a baseline heuristic algorithm, Extended Path Scanning. We show the MEM algorithm is fast and suitable for real-time applications. To tackle large-scale problems, our approach performs graph simplification and graph partitioning, followed by robot tour generation for each of the partitioned subgraphs. We demonstrate our approach on a large graph with 4,658 edges and 4,504 vertices that represents an urban region of about 16 sq. km. We compare the performance of the algorithms on several small road networks and experimentally demonstrate the approach using UAVs on the UNC Charlotte campus road network.

- Visual Coverage Maintenance for Quadcopters Using Nonsmooth Barrier Functions

    Author: Funada, Riku | The University of Texas at Austin
    Author: Santos, Mar�a | Georgia Institute of Technology
    Author: Gencho, Takuma | Tokyo Institute of Technology
    Author: Yamauchi, Junya | Tokyo Institute of Technology
    Author: Fujita, Masayuki | Tokyo Institute of Technology
    Author: Egerstedt, Magnus | Georgia Institute of Technology
 
    keyword: Cooperating Robots; Multi-Robot Systems; Sensor Networks

    Abstract : This paper presents a coverage control algorithm for teams of quadcopters with downward facing visual sensors that prevents the appearance of coverage holes in-between the monitored areas while maximizing the coverage quality as much as possible. We derive necessary and sufficient conditions for preventing the appearance of holes in-between the fields of views among trios of robots. Because this condition can be expressed as logically combined constraints, control nonsmooth barrier functions are implemented to enforce it. An algorithm which extends control nonsmooth barrier functions to hybrid systems is implemented to manage the switching among barrier functions caused by the changes of the robots composing trio. The performance and validity of the proposed algorithm are evaluated in simulation as well as on a team of quadcopters.

- Autonomous Reflectance Transformation Imaging by a Team of Unmanned Aerial Vehicles

    Author: Kr�tk�, V�t | Czech Technical University in Prague
    Author: Petr�&#269;ek, Pavel | Czech Technical University in Prague
    Author: Spurny, Vojtech | Czech Technical University in Prague
    Author: Saska, Martin | Czech Technical University in Prague
 
    keyword: Aerial Systems: Applications; Cooperating Robots; Multi-Robot Systems

    Abstract : A Reflectance Transformation Imaging technique (RTI) realized by multi-rotor Unmanned Aerial Vehicles (UAVs) with a focus on deployment in difficult to access buildings is presented in this paper. RTI is a computational photographic method that captures a surface shape and color of a subject and enables its interactive re-lighting from any direction in a software viewer, revealing details that are not visible with the naked eye. The input of RTI is a set of images captured by a static camera, each one under illumination from a different known direction. We present an innovative approach applying two multi-rotor UAVs to perform this scanning procedure in locations that are hardly accessible or even inaccessible for people. The proposed system is designed for its safe deployment within real-world scenarios in historical buildings with priceless historical value.

-  Localization of Ionizing Radiation Sources by Cooperating Micro Aerial Vehicles with Pixel Detectors in Real-Time

    Author: Stibinger, Petr | Czech Technical University in Prague
    Author: Baca, Tomas | Czech Technical Univerzity in Prague
    Author: Saska, Martin | Czech Technical University in Prague


## Biological Cell Manipulation
- Design and Control of a Piezo Drill for Robotic Piezo-Driven Cell Penetration

    Author: Dai, Changsheng | University of Toronto
    Author: Xin, Liming | University of Toronto
    Author: Zhang, Zhuoran | University of Toronto
    Author: Shan, Guanqiao | University of Toronto
    Author: Wang, Tiancong | University of Toronto
    Author: Zhang, Kaiwen | University of Toronto
    Author: Wang, Xian | University of Toronto
    Author: Chu, Lap-Tak | University of Toronto
    Author: Ru, Changhai | Soochow University
    Author: Sun, Yu | University of Toronto
 
    keyword: Automation at Micro-Nano Scales; Biological Cell Manipulation

    Abstract : Cell penetration is an indispensable step in many cell surgery tasks. Conventionally, cell penetration is achieved by passively indenting and eventually puncturing the cell membrane, during which undesired large cell deformation is induced. Piezo drills have been developed to penetrate cells with less deformation. However, existing piezo drills suffer from large lateral vibration or are incompatible with standard clinical setup. Furthermore, it is challenging to accurately determine the time instance of cell membrane puncturing; thus, the time delay to stop piezo pulsing causes cytoplasm stirring and cell damage. This paper reports a new robotic piezo-driven cell penetration technique, in which the piezo drill device induces small lateral vibrations and is fully compatible with standard clinical setup. Techniques based on corner-feature probabilistic data association filter and motion history images were developed to automatically detect cell membrane breakage by piezo drilling. Experiments on hamster oocytes confirmed that the system is capable of achieving a small cell deformation of 5.68�2.74 �m (vs. 54.29�10.21 �m by conventional passive approach) during cell penetration. Automated detection of membrane breakage had a success rate of 95.0%, and the time delay to stop piezo vibration was 0.51�0.27 s vs. 2.32�0.98 s manually. This reduced time delay together with smaller cell deformation led to higher oocyte post-penetration survival rate (92.5% vs. 77.5% passively)

- Model-Based Robotic Cell Aspiration: Tackling Nonlinear Dynamics and Varying Cell Sizes

    Author: Shan, Guanqiao | University of Toronto
    Author: Zhang, Zhuoran | University of Toronto
    Author: Dai, Changsheng | University of Toronto
    Author: Wang, Xian | University of Toronto
    Author: Chu, Lap-Tak | University of Toronto
    Author: Sun, Yu | University of Toronto
 
    keyword: Biological Cell Manipulation; Automation at Micro-Nano Scales

    Abstract : Aspirating a single cell from the outside to the inside of a micropipette is widely used for cell transfer and manipulation. Due to the small volume of a single cell (picoliter) and nonlinear dynamics involved in the aspiration process, it is challenging to accurately and quickly position a cell to the target position inside a micropipette. This paper reports the first mathematical model that describes the nonlinear dynamics of cell motion inside a micropipette, which takes into account oil compressibility and connecting tube's deformation. Based on the model, an adaptive controller was designed to effectively compensate for the cell position error by estimating the time-varying cell medium length and speed in real time. In experiments, small-sized cells (human sperm, head width: ~3 �m), medium-sized cells (T24 cancer cells, diameter: ~15 �m), and large-sized cells (mouse embryos, diameter: ~90 �m) were aspirated using different-sized micropipettes for evaluating the performance of the model and the controller. Based on aspirating 150 cells, the model-based adaptive control method was able to complete the positioning of a cell inside a micropipette within 6 seconds with a positioning accuracy of �3 pixels and a success rate higher than 94%.

- Automated High-Productivity Microinjection System for Adherent Cells

    Author: Pan, Fei | City University of Hong Kong
    Author: Chen, Shuxun | City University of Hong Kong
    Author: Jiao, Yang | City University of Hong Kong
    Author: Guan, Zhangyan | City University of Hong Kong
    Author: Shakoor, Adnan | City University of Hong Kong
    Author: Sun, Dong | City University of Hong Kong
 
    keyword: Biological Cell Manipulation

    Abstract : Automated microinjection systems for suspension cells have been studied for years. Nevertheless, microinjection systems for adherent cells still suffer from laborious manual operations and low productivity. This paper presents a new automated microinjection system with high productivity for adherent cells. This system enhances productivity through four approaches. First, cells are detected automatically to replace manual selections. Second, the injection paths of detected cells are optimized rapidly to save time. Third, the penetration depth is adjusted adaptively according to the moving plane of the dish holder plate. Finally, constant outflow-based injection is adopted to minimize clogging. The first three approaches aim to improve the injection speed, and the last one aims to extend the usage time of micropipettes. Experiments of massive injections on MC3T3-E1 cells are performed to evaluate cell detection efficiency, injection speed, success rate, and survival rate. Results confirm that the system allows injections of over 1500 cells in one hour without much training and preparation a priori.

- High Fidelity Force Feedback Facilitates Manual Injection in Biological Samples

    Author: Mohand Ousaid, Abdenbi | University of Franche-Comte
    Author: Haliyo, Dogan Sinan | Sorbonne Université
    Author: R�gnier, Stéphane | Sorbonne University
    Author: Hayward, Vincent | Université Pierre Et Marie Curie
 
    keyword: Biological Cell Manipulation; Telerobotics and Teleoperation; Human Performance Augmentation

    Abstract : Micro-teleoperated interaction with biological cells is of special interest. The low fidelity of previous systems aimed at such small scale tasks prompted the design of a novel manual bilateral cell injection system. This systems employed the coupling of a null-displacement active force sensor with a haptic device having negligible effective inertia. This combination yielded a bilateral interaction system that was unconditionally stable even when the scaling gains were high. To demonstrate the capability of this system, two experiments were performed. A hard trout egg was delicately punctured and a small dye amount was injected in an embryo within a zebra fish egg without causing other forms of damage. The results demonstrate that the system let an operator dextrously interact with reduced reliance on visual feedback.

- Dynamic Response of Swimming Paramecium Induced by Local Stimulation Using a Threadlike-Microtool

    Author: Ahmad, Belal | FEMTO-ST Institute
    Author: Maeda, Hironobu | Kyushu Institute of Technology
    Author: Kawahara, Tomohiro | Kyushu Institute of Technology
 
    keyword: Biological Cell Manipulation; Automation at Micro-Nano Scales; Micro/Nano Robots

    Abstract : In this paper, an approach for realizing local area stimulation of single motile microorganism (Paramecium) by a microtool is described. In order to overcome the hydrodynamic drag force acting on the thin and long tool in the fluidic environment, a magnetic compensation approach to improve the positioning accuracy of the metallic microtool is introduced. The permanent magnets' arrangement that reduced the vertical component and enhanced the horizontal component of the magnetic force is modeled and clarified through numerical simulations and actual experiments on the microtool with a diameter of 50 �m. As a result, the positioning accuracy of the microtool using the magnetic compensation is improved to approximately 200 �m. Finally, the performance and practicality of the integrated platform are confirmed by conducting experiments on a freely swimming Paramecium. By virtue of the low fluidic disturbance generated by the microtool, the stimulation did not cause a tracking failure and the dynamic reaction of the Paramecium is confirmed without any immobilization manners for the first time ever. The avoiding reactions in response to mechanical stimulation are evaluated by analysing the captured image data with a spatial resolution of less than 5 �m and a time resolution of less than 5 ms.

- Injection of a Fluorescent Microsensor into a Specific Cell by Laser Manipulation and Heating with Multiple Wavelengths of Light

    Author: Maruyama, Hisataka | Nagoya University
    Author: Hashim, Hairulazwan | Universiti Tun Hussein Onn Malaysia
    Author: Yangawa, Ryota | Nagoya University
    Author: Arai, Fumihito | Nagoya University
 
    keyword: Micro/Nano Robots; Biological Cell Manipulation

    Abstract : In this study, we propose the manipulation and cell injection of a fluorescent microsensor using multiple wavelengths of light. The fluorescent microsensor is made of a 1-�m polystyrene particle containing infrared (IR: 808 nm) absorbing dye and Rhodamine B. The polystyrene particle can be manipulated in water using a 1064-nm laser because the refractive index of the polystyrene is 1.6 (refractive index of water: 1.3). The IR absorbing dye absorbs 808-nm light but does not absorb the 1064-nm laser. Rhodamine B is a temperature-sensitive fluorescent dye (excitation wavelength: 488 nm, emission wavelength: 560 nm). The functions of manipulation, heating for injection, and temperature measurement are achieved by different wavelengths of 1064 nm, 808 nm, and 488 nm, respectively. The temperature increase of fluorescent microsensor with 808-nm (40 mW, 10 s) laser was approximately 15�C, and enough for injection of fluorescent microsensor. We demonstrated manipulation and injection of the microsensor into Madin-Darby canine kidney cell using 1064-nm and 808-nm lasers. These results confirmed the effectiveness of our proposed cell injection of a fluorescent microsensor using multiple wavelengths of light.

## Cooperating Robots
- Correspondence Identification in Collaborative Robot Perception through Maximin Hypergraph Matching

    Author: Gao, Peng | Colorado School of Mines
    Author: Zhang, Ziling | Colorado School of Mines
    Author: Guo, Rui | Toyota InfoTechnology Center USA
    Author: Lu, Hongsheng | Toyota Motor North America
    Author: Zhang, Hao | Colorado School of Mines
 
    keyword: Cooperating Robots; RGB-D Perception

    Abstract : Correspondence identification is an essential problem for collaborative multi-robot perception, with the objective of deciding the correspondence of objects that are observed in the field of view of each robot. In this paper, we introduce a novel maximin hypergraph matching approach that formulates correspondence identification as a hypergraph matching problem. The proposed approach incorporates both spatial relationships and appearance features of objects to improve representation capabilities. It also integrates the maximin theorem to optimize the worst case scenario in order to address distractions caused by non-covisible objects. In addition, we design an optimization algorithm to address the formulated non-convex non-continuous optimization problem. We evaluate our approach and compare it with seven previous techniques in two application scenarios, including multi-robot coordination on real robots and connected autonomous driving in simulations. Experimental results have validated the effectiveness of our approach in identifying object correspondence from partially overlapped views in collaborative perception, and have shown that the proposed maximin hypergraph matching approach outperforms previous techniques and obtains state-of-the-art performance.

- Scalable Target-Tracking for Autonomous Vehicle Fleets

    Author: Shorinwa, Ola | Stanford University
    Author: Yu, Javier | Stanford University
    Author: Halsted, Trevor | Stanford University
    Author: Koufos, Alex | Stanford University
    Author: Schwager, Mac | Stanford University
 
    keyword: Sensor Networks; Distributed Robot Systems; Multi-Robot Systems

    Abstract : We present a scalable and distributed target tracking algorithm based on the Alternating Direction Method of Multipliers (ADMM), which is well-suited for a fleet of autonomous cars communicating over a vehicle-to-vehicle network. Each sensor executes iterations of a Kalman filter-like update followed by a local communication round with local neighbors, such that each agent's estimate converges to the joint textit{maximum a posteriori} solution of the corresponding estimation problem without requiring the communication of measurements or measurement models. We show that, given a fixed communication bandwidth, our method outperforms the Consensus Kalman Filter in recovering the centralized estimate.	We also demonstrate the algorithm in a high fidelity urban driving simulator (CARLA), in which 50 autonomous cars connected on a time-varying communication network track the locations of 50 target vehicles using a simulated segmented vision sensor.

- A Dynamic Weighted Area Assignment Based on a Particle Filter for Active Cooperative Perception

    Author: Acevedo, Jose Joaqu�n | University of Seville
    Author: Teixeira de Sousa Messias, Jo�o Vicente | Latent Logic
    Author: Capitan, Jesus | University of Seville
    Author: Ventura, Rodrigo | Instituto Superior Técnico
    Author: Merino, Luis | Universidad Pablo De Olavide
    Author: Lima, Pedro U. | Instituto Superior Técnico - Institute for Systems and Robotics
 
    keyword: Cooperating Robots; Path Planning for Multiple Mobile Robots or Agents; Motion and Path Planning

    Abstract : This paper addresses an Active Cooperative Perception problem for Networked Robots Systems. Given a team of networked robots, the goal is finding a target using their inherent uncertain sensor data. The paper proposes a particle filter to model the probability distribution of the position of the target, which is updated using detection measurements from all robots. Then, an information-theoretic approach based on the RRT* algorithm is used to determine the optimal robots trajectories that maximize the information gain while surveying the map. Finally, a dynamic area weighted allocation approach based on particle distribution and coordination variables is proposed to coordinate the networked robots in order to cooperate efficiently in this active perception problem. Simulated and real experimental results are provided to analyze, evaluate and validate the proposed approach.

- Flying Batteries: In-Flight Battery Switching to Increase Multirotor Flight Time

    Author: Jain, Karan | UC Berkeley
    Author: Mueller, Mark Wilfried | University of California, Berkeley
 
    keyword: Cooperating Robots; Mechanism Design; Aerial Systems: Applications

    Abstract : We present a novel approach to increase the flight time of a multirotor via mid-air docking and in-flight battery switching. A main quadcopter flying using a primary battery has a docking platform attached to it. A `flying battery' -- a small quadcopter carrying a secondary battery -- is equipped with docking legs that can mate with the main quadcopter's platform. Connectors between the legs and the platform establish electrical contact on docking, and enable power transfer from the secondary battery to the main quadcopter. A custom-designed circuit allows arbitrary switching between the primary battery and secondary battery. We demonstrate the concept in a flight experiment involving repeated docking, battery switching, and undocking. This is shown in the video attachment. The experiment increases the flight time of the main quadcopter by a factor of 4.7x compared to solo flight, and 2.2x a theoretical limit for that given multirotor. Importantly, this increase in flight time is not associated with a large increase in overall vehicle mass or size, leaving the main quadcopter in fundamentally the same safety class.

- Sensor Assignment Algorithms to Improve Observability While Tracking Targets (I)

    Author: Zhou, Lifeng | Virginia Tech
    Author: Tokekar, Pratap | University of Maryland
 
    keyword: Cooperating Robots; Planning, Scheduling and Coordination; Sensor-based Control

    Abstract : In this paper, we study two sensor assignment problems for multitarget tracking with the goal of improving the observability of the underlying estimator. We consider various measures of the observability matrix as the assignment value function. We first study the general version where the sensors must form teams to track individual targets. If the value function is monotonically increasing and submodular, then a greedy algorithm yields a 1/2�approximation. We then study a restricted version where exactly two sensors must be assigned to each target. We present a 1/3�approximation algorithm for this problem, which holds for arbitrary value functions (not necessarily submodular or monotone). In addition to approximation algorithms, we also present various properties of observability measures. We show that the inverse of the condition number of the observability matrix is neither monotone nor submodular, but present other measures that are. Specifically, we show that the trace and rank of the symmetric observability matrix are monotone and submodular and the log determinant of the symmetric observability matrix is monotone and submodular when the matrix is nonsingular. If the target's motion model is not known, the inverse cannot be computed exactly. Instead, we present a lower bound for distance sensors. In addition to theoretical results, we evaluate our results empirically through simulations.

- Coordinated Bayesian-Based Bioinspired Plume Source Term Estimation and Source Seeking for Mobile Robots (I)

    Author: Bourne, Joseph R. | University of Utah Robotics Center
    Author: Pardyjak, Eric | University of Utah
    Author: Leang, Kam K. | University of Utah
 
    keyword: Cooperating Robots; Multi-Robot Systems; Probability and Statistical Methods

    Abstract : A new nonparametric Bayesian-based motion planning algorithm for autonomous plume source term estimation (STE) and source seeking (SS) is presented. The algorithm is designed for mobile robots equipped with gas concentration sensors. Specifically, robots coordinate and utilize a Gaussian-plume likelihood model in a Bayesian-based STE process, then they simultaneously search for and navigate toward the source through model based, bioinspired SS methods such as biased-random-walk and surge-casting. Compared with the state-of-the-art Bayesian- and sensor-based STE/SS motion planners, the strategy described takes advantage of coordination between multiple robots and the estimated plume model for faster and more robust SS, rather than rely on direct or filtered sensor measurements. A set of Monte Carlo simulation studies are conducted to compare the performance between the uncoordinated and coordinated algorithms for different robot team sizes and starting conditions. Additionally, the algorithms are validated experimentally through a laboratory-safe, realistic humid-air plume that behaves similar to a gas plume, to test STE and SS using mobile ground robots equipped with humidity sensors. Simulation and experimental results show consistently that the algorithm involving coordination outperforms traditional bioinspired SS algorithms and it is approximately twice as fast as the uncoordinated case. Finally, the plume source is distorted to study the algorithm's limitations.

## RGB-D Perception
- ClearGrasp: 3D Shape Estimation of Transparent Objects for Manipulation

    Author: Sajjan, Shreeyak | Synthesis.ai
    Author: Moore, Matthew | Synthesis.ai
    Author: Pan, Mike | Synthesis.ai
    Author: Nagaraja, Ganesh | Synthesis.ai
    Author: Lee, Johnny | Google
    Author: Zeng, Andy | Google
    Author: Song, Shuran | Columbia University
 
    keyword: Perception for Grasping and Manipulation; RGB-D Perception; Deep Learning in Robotics and Automation

    Abstract : Transparent objects are a common part of everyday life, yet they possess unique visual properties that make them incredibly difficult for standard 3D sensors to produce accurate depth estimates for, and often appear as noisy or distorted approximations of the surfaces that lie behind them. To address these challenges, we present ClearGrasp -- a deep learning approach for estimating accurate 3D geometry of transparent objects from a single RGB-D image for robotic manipulation. Given a single RGB-D image of transparent objects, ClearGrasp uses deep convolutional networks to infer a set of information from the color image (surface normals, masks of transparent surfaces, and occlusion boundaries), then uses these outputs to refine the initial depth estimates for all transparent surfaces in the scene. To train and test ClearGrasp, we construct a large-scale synthetic dataset of over 40,000 RGB-D images, as well as a real-world test benchmark with 286 RGB-D images of transparent objects and their ground truth geometries. The experiments demonstrate that ClearGrasp is substantially better than monocular depth estimation baselines and is capable of generalizing to real-world images and novel objects. We also demonstrate that ClearGrasp can be applied out-of-the-box to improve state-of-the-art grasping algorithms' performance on transparent objects. Code, data, and benchmarks will be released. Supplementary materials: https://sites.google.com/view/cleargrasp

- 6D Object Pose Regression Via Supervised Learning on Point Clouds

    Author: Gao, Ge | University of Hamburg
    Author: Lauri, Mikko | University of Hamburg
    Author: Wang, Yulong | Tsinghua University
    Author: Hu, Xiaolin | Tsinghua University
    Author: Zhang, Jianwei | University of Hamburg
    Author: Frintrop, Simone | University of Hamburg
 
    keyword: RGB-D Perception; Perception for Grasping and Manipulation

    Abstract : This paper addresses the task of estimating the 6 degrees of freedom pose of a known 3D object from depth information represented by a point cloud. Deep features learned by convolutional neural networks from color information have been the dominant features to be used for inferring object poses, while depth information receives much less attention. However, depth information contains rich geometric information of the object shape, which is important for inferring the object pose. We use depth information represented by point clouds as the input to both deep networks and geometry-based pose refinement and use separate networks for rotation and translation regression. We argue that the axis-angle representation is a suitable rotation representation for deep learning, and use a geodesic loss function for rotation regression. Ablation studies show that these design choices outperform alternatives such as the quaternion representation and L2 loss, or regressing translation and rotation with the same network. Our simple yet effective approach clearly outperforms state-of-the-art methods on the YCB-video dataset.

- YCB-M: A Multi-Camera RGB-D Dataset for Object Recognition and 6DoF Pose Estimation

    Author: Grenzd�rffer, Till | Osnabrueck University
    Author: G�nther, Martin | DFKI
    Author: Hertzberg, Joachim | University of Osnabrueck
 
    keyword: RGB-D Perception; Object Detection, Segmentation and Categorization; Computer Vision for Other Robotic Applications

    Abstract : While a great variety of 3D cameras have been introduced in recent years, most publicly available datasets for object recognition and pose estimation focus on one single camera. In this work, we present a dataset of 32 scenes that have been captured by 7 different 3D cameras, totaling 49,294 frames. This allows evaluating the sensitivity of pose estimation algorithms to the specifics of the used camera and the development of more robust algorithms that are more independent of the camera model. Vice versa, our dataset enables researchers to perform a quantitative comparison of the data from several different cameras and depth sensing technologies and evaluate their algorithms before selecting a camera for their specific task. The scenes in our dataset contain 20 different objects from the common benchmark YCB object and model set. We provide full ground truth 6DoF poses for each object, per-pixel segmentation, 2D and 3D bounding boxes and a measure of the amount of occlusion of each object. We have also performed an initial evaluation of the cameras using our dataset on a state-of-the-art object recognition and pose estimation system (DOPE).

- Depth Based Semantic Scene Completion with Position Importance Aware Loss

    Author: Liu, Yu | The University of Adelaide
    Author: Li, Jie | Nanjing University of Science and Technology
    Author: Yuan, Xia | Nanjing University of Science and Technology
    Author: Zhao, Chunxia | Nanjing University of Science and Technology
    Author: Siegwart, Roland | ETH Zurich
    Author: Reid, Ian | University of Adelaide
    Author: Cadena Lerma, Cesar | ETH Zurich
 
    keyword: RGB-D Perception; Semantic Scene Understanding; Object Detection, Segmentation and Categorization

    Abstract : Semantic Scene Completion (SSC) refers to the task of inferring the 3D semantic segmentation of a scene while simultaneously completing the 3D shapes. We propose PALNet, a novel hybrid network for SSC based on single depth. PALNet utilizes a two-stream network to extract both 2D and 3D features from multi-stages using fine-grained depth information to efficiently captures the context, as well as the geometric cues of the scene. Current methods for SSC treat all parts of the scene equally causing unnecessary attention to the interior of objects. To address this problem, we propose Position Aware Loss(PA-Loss) which is position importance aware while training the network. Specifically, PA-Loss considers Local Geometric Anisotropy to determine the importance of different positions within the scene. It is beneficial for recovering key details like the boundaries of objects and the corners of the scene. Comprehensive experiments on two benchmark datasets demonstrate the effectiveness of the proposed method and its superior performance. Code and demo are avaliable at: https://github.com/UniLauX/PALNet.

- Self-Supervised 6D Object Pose Estimation for Robot Manipulation

    Author: Deng, Xinke | University of Illinois at Urbana-Champaign
    Author: Xiang, Yu | NVIDIA
    Author: Mousavian, Arsalan | NVIDIA
    Author: Eppner, Clemens | NVIDIA
    Author: Bretl, Timothy | University of Illinois at Urbana-Champaign
    Author: Fox, Dieter | University of Washington
 
    keyword: Perception for Grasping and Manipulation; RGB-D Perception; Deep Learning in Robotics and Automation

    Abstract : To teach robots to learn skills, it is crucial to obtain data with supervision. Since annotating real world data is time-consuming and expensive, enabling robots to learn in a self-supervised way is important. In this work, we introduce a robot system for self-supervised 6D object pose estimation. Starting from modules trained in simulation, our system is able to label real world images with accurate 6D object poses for self-supervised learning. In addition, the robot interacts with objects in the environment to change the object configuration by grasping or pushing objects. In this way, our system is able to continuously collect data and improve its pose estimation modules. We show that the self-supervised learning improves object segmentation and 6D pose estimation performance, and consequently enables the system to grasp objects robustly.

- Panoptic 3D Mapping and Object Pose Estimation Using Adaptively Weighted Semantic Information

    Author: Hoang, Dinh-Cuong | Orebro University
    Author: Lilienthal, Achim J. | Orebro University
    Author: Stoyanov, Todor | Örebro University
 
    keyword: RGB-D Perception; Object Detection, Segmentation and Categorization

    Abstract : We present a system capable of reconstructing highly detailed object-level models and estimating the 6D pose of objects by means of an RGB-D camera. In this work, we integrate deep-learning-based semantic segmentation, instance segmentation, and 6D object pose estimation into a state of the art RGB-D mapping system. We leverage the pipeline of ElasticFusion as a backbone and propose modifications of the registration cost function to make full use of the semantic class labels in the process. The proposed objective function features tunable weights for the depth, appearance, and semantic information channels, which are learned from data. A fast semantic segmentation and registration weight prediction convolutional neural network (Fast-RGBD-SSWP) suited to efficient computation is introduced. In addition, our approach explores performing 6D object pose estimation from multiple viewpoints supported by the high-quality reconstruction system. The developed method has been verified through experimental validation on the YCB-Video dataset and a dataset of warehouse objects. Our results confirm that the proposed system performs favorably in terms of surface reconstruction, segmentation quality, and accurate object pose estimation in comparison to other state-of-the-art systems. Our code and video are available at https://sites.google.com/view/panoptic-mope.

## Task Planning
- Online Trajectory Planning through Combined Trajectory Optimization and Function Approximation: Application to the Exoskeleton Atalante

    Author: Duburcq, Alexis | Wandercraft
    Author: Chevaleyre, Yann | Univ. Paris Dauphine
    Author: Bredeche, Nicolas | Université Pierre Et Marie Curie
    Author: Boeris, Guilhem | Wandercraft
 
    keyword: Task Planning; Optimization and Optimal Control; Humanoid and Bipedal Locomotion

    Abstract : Autonomous robots require online trajectory planning capability to operate in the real world. Efficient offline trajectory planning methods already exist, but are computationally demanding, preventing their use online. In this paper, we present a novel algorithm called Guided Trajectory Learning that learns a function approximation of solutions computed through trajectory optimization while ensuring accurate and reliable predictions. This function approximation is then used online to generate trajectories. This algorithm is designed to be easy to implement, and practical since it does not require massive computing power. It is readily applicable to any robotics systems and effortless to set up on real hardware since robust control strategies are usually already available. We demonstrate the computational performance of our algorithm on flat-foot walking with a self-balanced exoskeleton.

- Act, Perceive, and Plan in Belief Space for Robot Localization

    Author: Colledanchise, Michele | IIT - Italian Institute of Technology
    Author: Malafronte, Damiano | Istituto Italiano Di Tecnologia
    Author: Natale, Lorenzo | Istituto Italiano Di Tecnologia
 
    keyword: Task Planning; Reactive and Sensor-Based Planning; Visual-Based Navigation

    Abstract : In this paper, we outline an interleaved acting and planning technique to rapidly reduce the uncertainty of the estimated robot's pose by perceiving relevant information from the environment, as recognizing an object or asking someone for a direction. Generally, existing localization approaches rely on low-level geometric features such as points, lines, and planes. While these approaches provide the desired accuracy, they may require time to converge, especially with incorrect initial guesses. In our approach, a task planner computes a sequence of action and perception tasks to actively obtain relevant information from the robot's perception system. We validate our approach in large state spaces, to show how the approach scales, and in real environments, to show the applicability of our method on real robots. We prove that our approach is sound, probabilistically complete, and tractable in practical cases.

- Decentralized Task Allocation in Multi-Agent Systems Using a Decentralized Genetic Algorithm

    Author: Patel, Ruchir | University of Maryland, College Park
    Author: Rudnick-Cohen, Eliot | University of Maryland, College Park
    Author: Azarm, Shapour | University of Maryland
    Author: Otte, Michael W. | University of Maryland
    Author: Xu, Huan | University of Maryland
    Author: Herrmann, Jeffrey | University of Maryland
 
    keyword: Task Planning; Cooperating Robots; Multi-Robot Systems

    Abstract : In multi-agent collaborative search missions, task allocation is required to determine which agents will perform which tasks. We propose a new approach for decentralized task allocation based on a decentralized genetic algorithm (GA). The approach parallelizes a genetic algorithm across the team of agents, making efficient use of their computational resources. In the proposed approach, the agents continuously search for and share better solutions during task execution. We conducted simulation experiments to compare the decentralized GA approach and several existing approaches. Two objectives were considered: a min-sum objective (minimizing the total distance traveled by all agents) and a min-time objective (minimizing the time to visit all locations of interest). The results showed that the decentralized GA approach yielded task allocations that were better on the min-time objective than those created by existing approaches and solutions that were reasonable on the min-sum objective. The decentralized GA improved min-time performance by an average of 5.6% on the larger instances. The results indicate that decentralized evolutionary approaches have a strong potential for solving the decentralized task allocation problem.

- Fast and Resilient Manipulation Planning for Target Retrieval in Clutter

    Author: Nam, Changjoo | Korea Institute of Science and Technology
    Author: Lee, JinHwi | Hanyang University
    Author: Cheong, Sang Hun | Korea University, KIST
    Author: Cho, Brian Younggil | Korea Institute of Science and Technology
    Author: Kim, ChangHwan | Korea Institute of Science and Technology
 
    keyword: Task Planning; Manipulation Planning; Motion and Path Planning

    Abstract : This paper presents a task and motion planning (TAMP) framework for a robotic manipulator in order to retrieve a target object from clutter. We consider a configuration of objects in a confined space with a high density so no collision-free path to the target exists. The robot must relocate some objects to retrieve the target without collisions. For fast completion of object rearrangement, the robot aims to optimize the number of pick-and-place actions which often determines the efficiency of a TAMP framework.<p>We propose a task planner incorporating motion planning to generate executable plans which aims to minimize the number of pick-and-place actions. In addition to fully known and static environments, our method can deal with uncertain and dynamic situations incurred by occluded views. Our method is shown to reduce the number of pick-and-place actions compared to baseline methods (e.g., at least 28.0% of reduction in a known static environment with 20 objects).

- Multi-Robot Task and Motion Planning with Subtask Dependencies

    Author: Motes, James | University of Illinois Urbana-Champaign
    Author: Sandstrom, Read | Texas A&amp;M University
    Author: Lee, Hannah | Colorado School of Mines
    Author: Thomas, Shawna | Texas A&amp;M University
    Author: Amato, Nancy | University of Illinois
 
    keyword: Task Planning; Motion and Path Planning; Multi-Robot Systems

    Abstract : We present a multi-robot integrated task and motion method capable of handling sequential subtask dependencies within multiply decomposable tasks. We map the multi-robot pathfinding method, Conflict Based Search, to task planning and integrate this with motion planning to create TMP-CBS. TMP-CBS couples task decomposition, allocation, and planning to support cases where the optimal solution depends on robot availability and inter-team conflict avoidance. We show improved planning time for simpler task sets and generate optimal solutions w.r.t. the state space representation for a broader range of problems than prior methods.

- Untethered Soft Millirobot with Magnetic Actuation

    Author: Bhattacharjee, Anuruddha | Southern Methodist University
    Author: Rogowski, Louis | Southern Methodist University
    Author: Zhang, Xiao | Southern Methodist University
    Author: Kim, MinJun | Southern Methodist University
 
    keyword: Task Planning; Soft Robot Materials and Design; Cellular and Modular Robots

    Abstract : This paper presents scalable designs and fabrication, actuation, and manipulation techniques for soft millirobots under uniform magnetic field control. The millirobots were fabricated through an economic and robust moulding technique using polydimethylsiloxane (PDMS), acrylonitrile butadiene styrene (ABS) filaments, and 3D printed polylactic acid (PLA) rings. The soft millirobots were simple hollow rod-like structures with different configurations of embedded permanent magnets inside of their soft-body or at their ends. The soft-robots were actuated using six different motion modes including: pivot walking, rolling, tumbling, side-tapping, wiggling, and wavy-motion under an external uniform magnetic field control system. The velocities of the millirobots under different motion modes were analyzed under varying magnetic flux densities (<i><b>B</b></i>). Moreover, deformation of the soft-robotic body in response to the magnetic field strength was measured and a deflection curve showing bending angle (<i>&#934;</i>) was produced. Soft millirobots were navigated through a maze using a combination of the available motion modes. Different arrangements of the embedded permanent magnets enabled individual soft millirobots to respond heterogeneously under the same magnetic field inputs towards performing assembly and disassembly operation as modular subunits. Overall, this soft millirobot platform shows enormous potential for minimally invasive <i>in vivo</i> applications.

## Brain-Machine Interfaces
- Accelerated Robot Learning Via Human Brain Signals

    Author: Akinola, Iretiayo | Columbia University
    Author: Wang, Zizhao | University of Michigan-Ann Arbor
    Author: Shi, Jack | Columbia University
    Author: He, Xiaomin | Columbia University
    Author: Lapborisuth, Pawan | Columbia University
    Author: Xu, Jingxi | Columbia University
    Author: Watkins-Valls, David | Columbia University
    Author: Sajda, Paul | Columbia University
    Author: Allen, Peter | Columbia University
 
    keyword: Brain-Machine Interface; Learning and Adaptive Systems; Cognitive Human-Robot Interaction

    Abstract :  In reinforcement learning (RL), sparse rewards are a natural way to specify the task to be learned. However, most RL algorithms struggle to learn in this setting since the learning signal is mostly zeros. In contrast, humans are good at assessing and predicting the future consequences of actions and can serve as good reward/policy shapers to accelerate the robot learning process. Previous works have shown that the human brain generates an error-related signal, measurable using electroencephelography (EEG), when the human perceives the task being done erroneously. In this work, we propose a method that uses evaluative feedback obtained from human brain signals measured via scalp EEG to accelerate RL for robotic agents in sparse reward settings. As the robot learns the task, the EEG of a human observer watching the robot attempts is recorded and decoded into noisy error feedback signal. From this feedback, we use supervised learning to obtain a policy that subsequently augments the behavior policy and guides exploration in the early stages of RL. This bootstraps the RL learning process to enable learning from sparse reward. Using a simple robotic navigation task as a test bed, we show that our method achieves a stable obstacle-avoidance policy with high success rate, outperforming learning from sparse rewards only that struggles to achieve obstacle avoidance behavior or fails to advance to the goal.

- Muscle and Brain Activations in Cylindrical Rotary Controller Manipulation with Index Finger and Thumb

    Author: Okatani, Rio | DOSHISHA University
    Author: Tsumugiwa, Toru | Doshisha University
    Author: Yokogawa, Ryuichi | Doshisha University
    Author: Narusue, Mitsuhiro | Mazda Motor Corporation
    Author: Nishimura, Hiroto | Mazda Corporation
    Author: Takeda, Yuusaku | Mazda Motor Corporation
    Author: Hara, Toshihiro | Mazda Motor Corporation
 
    keyword: Brain-Machine Interface; Human Factors and Human-in-the-Loop; Cognitive Human-Robot Interaction

    Abstract : This study aim to confirm the effect of viscosity characteristics differences on the rotational manipulation of a cylindrical rotary controller with the index finger and thumb through a quantitative analysis and evaluation of muscle and brain activations. The target motion was a rotary manipulation with the index finger and thumb of a cylindrical rotary controller with a 50 mm diameter. The rotary motion of the controller produces a click sensation at every 12 degrees in the rotation. The experimental conditions were three conditions with different viscosity characteristics related to the rotary motion of the controller. The subjects were six right-handed healthy males with a mean age of 21.7 (S. D.: 1.03) years. We analyzed the brain activity from a near�infrared spectroscopy measurement system, the muscles activity using a surface myoelectric potential measurement device, the force data at the index finger and thumb tip using two independent six-axis force/torque sensors, and the position data using a 3D position measurement device. The experimental results showed that there was no significant difference in the questionnaire survey, muscle activity, and grasping force, respectively; however, a significant difference in brain activity was observed with increased controller viscosity. Therefore, it became clear that there was a change in the brain activity when rotating the cylindrical rotary controller with the viscosity characteristics related to the rotary motion.

- Real-Time Robot Reach-To-Grasp Movements Control Via EOG and EMG Signals Decoding

    Author: Specht, Bernhard | TUM
    Author: Tayeb, Zied | Technical University of Munich
    Author: Dean-Leon, Emmanuel | Technischen Universitaet Muenchen
    Author: Soroushmojdehi, Rahil | IIT
    Author: Cheng, Gordon | Technical University of Munich
 
    keyword: Brain-Machine Interface; Cognitive Human-Robot Interaction; Rehabilitation Robotics

    Abstract : In this paper, we propose a real-time human-robot interface (HRI) system, where Electrooculography (EOG) and Electromyography (EMG) signals were decoded to perform reach-to-grasp movements. For that, five different eye movements (up, down, left, right and rest) were classified in real-time and translated into commands to steer an industrial robot (UR- 10) to one of the four approximate target directions. Thereafter, EMG signals were decoded to perform the grasping task using an attached gripper to the UR-10 robot arm. The proposed system was tested offline on three different healthy subjects, and mean validation accuracy of 93.62% and 99.50% were obtained across the three subjects for EOG and EMG decoding, respectively. Furthermore, the system was successfully tested in real-time with one subject, and mean online accuracy of 91.66% and 100% were achieved for EOG and EMG decoding, respectively. Our results obtained by combining real- time decoding of EOG and EMG signals for robot control show overall the potential of this approach to develop powerful and less complex HRI systems. Overall, this work provides proof- of-concept for successful real-time control of robot arms using EMG and EOG signals, paving the way for the development of more dexterous and human-controlled assistive devices.

- Simultaneous Estimations of Joint Angle and Torque in Interactions with Environments Using EMG

    Author: Kim, Dongwon | University of Michigan
    Author: Koh, Kyung | University of Maryland
    Author: Oppizzi, Giovanni | University of Maryland
    Author: Baghi, Raziyeh | University of Maryland, Baltimore
    Author: Lo, Li-Chuan | University of Maryland at Baltimore
    Author: Zhang, Chunyang | University of Maryland at Baltimore
    Author: Zhang, Li-Qun | Rehabilitation Institute of Chicago/Northwestern University
 
    keyword: Brain-Machine Interface; Wearable Robots; Rehabilitation Robotics

    Abstract : We develop a decoding technique that estimates both the position and torque of a joint of the limb in interaction with an environment based on activities of the agonist-antagonist pair of muscles using electromyography in real time. The long short-term memory (LSTM) network is employed as the core processor of the proposed technique that is capable of learning time series of a long-time span with varying time lags. A validation that is conducted on the wrist joint shows that the decoding approach provides an agreement of greater than 95% in kinetics (i.e. torque) estimation and an agreement of greater than 85% in kinematics (i.e. angle) estimation, between the actual and estimated variables, during interactions with an environment. Also, it is revealed that the proposed decoding method inherits the strengths of the LSTM network in terms of the capability of learning EMG signals and the corresponding responses with time dependency.

- High-Density Electromyography Based Control of Robotic Devices: On the Execution of Dexterous Manipulation Tasks

    Author: Dwivedi, Anany | University of Auckland
    Author: Lara, Jaime | The University of Auckland
    Author: Cheng, Leo K. | University of Auckland
    Author: Paskaranandavadivel, Niranchan | University of Auckland
    Author: Liarokapis, Minas | The University of Auckland
 
    keyword: Brain-Machine Interface; Neurorobotics

    Abstract : Electromyography (EMG) based interfaces have been used in various robotics studies ranging from teleoperation and telemanipulation applications to the EMG based control of prosthetic, assistive, or robotic rehabilitation devices. But most of these studies have focused on the decoding of user's motion or on the control of the robotic devices in the execution of simple tasks (e.g., grasping tasks). In this work, we present a learning scheme that employs High Density Electromyography (HD-EMG) sensors to decode a set of dexterous, in-hand manipulation motions (in the object space) based on the myoelectric activations of human forearm and hand muscles. To do that, the subjects were asked to perform roll, pitch, and yaw motions manipulating two different cubes. The first cube was designed to have a center of mass coinciding with the geometric center of the cube, while for the second cube the center of mass was shifted 14 mm to the right (off-centered design). Regarding the acquisition of the myoelectric data, custom HD-EMG electrode arrays were designed and fabricated. Using these arrays, a total of 89 EMG signals were extracted. The object motion decoding was formulated as a regression problem using the Random Forests (RF) technique and the muscle importances were studied using the inherent feature variables importance calculation procedure of the RF. The muscle importance results show that different subjects use different strategies to execute the same motions on same object whe

- The Role of the Control Framework for Continuous Teleoperation of a Brain�Machine Interface-Driven Mobile Robot (I)

    Author: Tonin, Luca | University of Padova
    Author: Bauer, Felix Christian | ETH Zurich, aiCTX AG
    Author: Mill�n, Jos' del R. | EPFL
 
    keyword: Neurorobotics; Brain-Machine Interface; Telerobotics and Teleoperation

    Abstract : Despite the growing interest in brain-machine interface (BMI) driven neuroprostheses, the optimization of the control framework and the translation of the BMI output into a suitable control signal are often neglected. In this study, we propose a novel approach based on dynamical systems that was explicitly designed to take into account the nature of the BMI output. We hypothesize that such a control framework would allow users to continuously drive a mobile robot and it would enhance the navigation performance. 13 healthy users evaluated the system by using a 2-class motor imagery BMI to drive the robot to 5 targets in two experimental conditions: with a discrete control strategy, traditionally exploited in the BMI field, and with the novel continuous control framework developed herein. Experimental results showed that the new approach: i) allowed users to continuously drive the mobile robot via BMI; ii) led to significant improvements in the navigation performance; iii) promoted a better coupling between user and robot. These results highlight the importance of designing a suitable control framework to improve the performance and the reliability of BMI driven neurorobotic devices.

## Tendon/Wire Mechanism
- Asynchronous and Decoupled Control of the Position and the Stiffness of a Spatial RCM Tensegrity Mechanism for Needle Manipulation

    Author: Jurado Realpe, Jr | Université De Montpellier
    Author: Aiche, Guillaume | Université De Montpellier
    Author: Abdelaziz, Salih | LIRMM, University of Montpellier 2
    Author: Poignet, Philippe | LIRMM University of Montpellier CNRS
 
    keyword: Tendon/Wire Mechanism; Motion Control; Compliance and Impedance Control

    Abstract : This paper introduces a 2-DOF spatial remote center of motion (RCM) tensegrity mechanism, based on a double parallelogram system, dedicated for percutaneous needle insertion. The originality of this mechanism is its ability to be reconfigured and its capacity to perform a decoupled modulation of its stiffness in an asynchronous way. To do so, an analytical stiffness model of the robot is established, and a control methodology is proposed. A prototype of the robot is developed and assessed experimentally. The position tracking is evaluated using a 6-DOF magnetic tracker sensor showing a root mean square error less than 0.8� in both directions of the needle guide.

- Redundancy Resolution Integrated Model Predictive Control of CDPRs: Concept, Implementation and Experiments

    Author: Cavalcanti Santos, Joao | University of Montpellier, LIRMM
    Author: Chemori, Ahmed | Cnrs / Lirmm
    Author: Gouttefarde, Marc | CNRS
 
    keyword: Tendon/Wire Mechanism; Parallel Robots; Motion Control of Manipulators

    Abstract : This paper introduces a Model Predictive Control (MPC) strategy for fully-constrained Cable-Driven Parallel Robots. The main advantage of the proposed scheme lies in its ability to explicitly handle cable tension limits. Indeed, the cable tension distribution is performed as an integral part of the main control architecture. This characteristic significantly improves the safety of the system. Experimental results demonstrate this advantage addressing a typical pick-and-place task with two different scenarios: nominal cable tension limits and reduced maximum tension. Satisfactory tracking errors were obtained in the first scenario. In the second scenario, the desired trajectory escapes from the workspace defined by the new set of tension limits. The proposed MPC scheme is able to minimize the tracking errors without violating the tension limits. Satisfying results were also obtained regarding robustness against uncertainties on the payload mass.

- Mechanics for Tendon Actuated Multisection Continuum Arms

    Author: Gonthina, Phanideep | Clemson University
    Author: Wooten, Michael | Clemson University
    Author: Godage, Isuru S. | Depaul University
    Author: Walker, Ian | Clemson University
 
    keyword: Tendon/Wire Mechanism; Compliant Joint/Mechanism; Biologically-Inspired Robots

    Abstract : Tendon actuated multisection continuum arms have high potential for inspection applications in highly constrained spaces. They generate motion by axial and bending deformations. However, because of the high mechanical coupling between continuum sections, variable length-based kinematic models produce poor results. A new mechanics model for tendon actuated multisection continuum arms is proposed in this paper. The model combines the continuum arm curve parameter kinematics and concentric tube kinematics to correctly account for the large axial and bending deformations observed in the robot. Also, the model is computationally efficient and utilizes tendon tensions as the joint space variables thus eliminating the actuator length related problems such as slack and backlash. A recursive generalization of the model is also presented. Despite the high coupling between continuum sections, numerical results show that the model can be used for generating correct forward and inverse kinematic results. The model is then tested on a thin and long multisection continuum arm. The results show that the model can be used to successfully model the deformation.

- Trajectory Optimization for a Six-DOF Cable-Suspended Parallel Robot with Dynamic Motions Beyond the Static Workspace

    Author: Xiang, Sheng | Harbin Institute of Technology
    Author: Gao, Haibo | Harbin Institute of Technology
    Author: Liu, Zhen | Harbin Institute of Technology
    Author: Gosselin, Clement | Université Laval
 
    keyword: Tendon/Wire Mechanism; Motion Control; Dynamics

    Abstract : This paper presents a trajectory optimization formulation for planning dynamic trajectories of a six-degree-of-freedom (six-DOF) cable-suspended parallel robot (CSPR) that extend beyond the static workspace. The optimization is guided by low-dimensional dynamic models to overcome the local minima and accelerate the exploration of the narrow feasible state space. The dynamic similarity between the six-DOF CSPR and the three-DOF point-mass CSPR is discussed with the analyses of their feasible force polyhedra. Finally, the transition trajectories of a three-DOF CSPR are used as the initial guess of the translational part of the six-DOF motion. With the proposed approach, highly dynamic motions for a six-DOF CSPR are efficiently generated with multiple oscillations. The feasibility is demonstrated by point-to-point and periodic trajectories in the physics simulation.

- Design of Tensegrity-Based Manipulators: Comparison of Two Approaches to Respect a Remote Center of Motion Constraint

    Author: Begey, J�r�my | University of Strasbourg
    Author: Vedrines, Marc | ICube - INSA De Strasbourg
    Author: Renaud, Pierre | ICube AVR
 
    keyword: Tendon/Wire Mechanism; Mechanism Design; Parallel Robots

    Abstract : Tensegrity mechanisms can offer key features such as compliance and deployability for high compactness. The absence of systematic design methods has however strongly limited the development of tensegrity mechanisms for manipulation up to now. In this paper, we consider how tensegrity mechanisms can be used to respect a Remote Center of Motion (RCM) constraint. Mechanisms of high compactness, respecting RCM constraint and offering compliance can indeed be of great interest in a challenging environment such as the medical context. Two architectures are elaborated, using cable- and bar-actuated Snelson crosses. Their analysis is performed, proofs of concept are built and experimentally evaluated, and their relative interest is discussed. This work brings at the same time initial results on design of tensegrity mechanisms for manipulation in a medical environment, and first guidelines to perform tensegrity mechanism synthesis.

- Accurate Dynamic Modeling of Twisted String Actuators Accounting for String Compliance and Friction

    Author: Nedelchev, Simeon | Innopolis University
    Author: Gaponov, Igor | Innopolis University
    Author: Ryu, Jee-Hwan | Korea Advanced Institute of Science and Technology
 
    keyword: Tendon/Wire Mechanism; Dynamics

    Abstract : This paper proposes a more accurate dynamic model of twisted string actuators (TSAs) that accounts for both elastic deformation of strings and frictional forces, which have not been considered by any mathematical models to date. The proposed model allows more accurate estimation of the required motor torque in both low-speed (statics) and highspeed (up to 2 Hz) motion. Consideration of both joint-space and task-space frictional forces enables us to better model the hysteresis in torque behavior, which was not possible by stateof-the-art models that only considered joint-space friction. In addition, the inclusion of elastic deformation of the strings during twisting in both longitudinal and radial (transverse) directions allows the proposed model to estimate the required torque with higher accuracy, especially in statics. This paper presents both theoretical derivation of the underlying dynamic equations and their experimental evaluation on a practical setup. The analysis of the experimental data has shown that the relative error between theoretical and practical curves never exceeded 7% for the range of tested motion frequencies between 0.1 and 2 Hz. The proposed dynamic model can be used for accurate model-based control of the TSA-based systems and for efficient TSA motor selection.

## Agricultural Automation
- An Intelligent Spraying System with Deep Learning-Based Semantic Segmentation of Fruit Trees in Orchards

    Author: Kim, Jeongeun | Chonnam National University
    Author: Seol, Jaehwi | Chonnam National University
    Author: Lee, SukWoo | Chonnam National University
    Author: Hong, Se-Woon | Chonnam National University
    Author: Son, Hyoung Il | Chonnam National University
 
    keyword: Agricultural Automation; Robotics in Agriculture and Forestry; Deep Learning in Robotics and Automation

    Abstract : This study proposes an intelligent spraying system with semantic segmentation of fruit trees in a pear orchard. A fruit tree detection system was developed using the SegNet model, a semantic segmentation structure. The system is trained with images categorized into five distinct classes. The learned deep learning model performed with an accuracy of 83.79%. Further, we fusion depth data from an RGB-D camera to prevent the tree in the background from being detected. To operate the nozzles, each image captured from the camera is separated lengthwise into quarters and mapped to the nozzles. Then, the nozzle was opened when the area of fruit trees in each zone exceeded 20%. Two types of field experiments were performed in a pear orchard to verify the effectiveness of our system. From the results obtained, we can confirm the satisfactory performance of our deep learning-based intelligent spraying system. It is expected that the introduction of this system to actual farms will significantly reduce the amount of pesticide used and will make the work environment safer for farmers.

- An Efficient Planning and Control Framework for Pruning Fruit Trees

    Author: You, Alexander | Oregon State University
    Author: Sukkar, Fouad | University of Technology Sydney
    Author: Fitch, Robert | University of Technology Sydney
    Author: Karkee, Manoj | Washington State University
    Author: Davidson, Joseph | Oregon State University
 
    keyword: Agricultural Automation; Manipulation Planning; Planning, Scheduling and Coordination

    Abstract : Dormant pruning is a major cost component of fresh market tree fruit production, nearly equal in scale to harvesting the fruit. However, relatively little focus has been given to the problem of pruning trees autonomously. In this paper, we introduce a robotic system consisting of an industrial manipulator, an eye-in-hand RGB-D camera configuration, and a custom pneumatic cutter. The system is capable of planning and executing a sequence of cuts while making minimal assumptions about the environment. We leverage a novel planning framework designed for high-throughput operation which builds upon previous work to reduce motion planning time and sequence cut points intelligently. In end-to-end experiments with a set of ten different branch configurations, the system achieved a high success rate in plan execution and a 1.5x speedup in throughput versus a baseline planner, representing a significant step towards the goal of practical implementation of robotic pruning.

- Context Dependant Iterative Parameter Optimisation for Robust Robot Navigation

    Author: Binch, Adam | Saga Robotics UK
    Author: Das, Gautham | University of Lincoln
    Author: Pulido Fentanes, Jaime | Saga Robotics
    Author: Hanheide, Marc | University of Lincoln
 
    keyword: Optimization and Optimal Control; Robotics in Agriculture and Forestry; Autonomous Vehicle Navigation

    Abstract : Progress in autonomous mobile robotics has seen significant advances in the development of many algorithms for motion control and path planning. However, robust performance from these algorithms can often only be expected if the parameters controlling them are tuned specifically for the respective robot model, and optimised for specific scenarios in the environment the robot is working in. Such parameter tuning can, depending on the underlying algorithm, amount to a substantial combinatorial challenge, often rendering extensive manual tuning of these parameters intractable. In this paper, we present a framework that permits the use of different navigation actions with different parameters depending on the spatial context of the navigation task. We consider the respective navigation algorithms themselves mostly as a "black box", and find suitable parameters by means of an iterative optimisation, improving for performance metrics in simulated environments. We present a genetic algorithm incorporated into the framework and empirically show that the resulting parameter sets lead to substantial performance improvements in both simulated and real-world environments.

- Combining Domain Adaptation and Spatial Consistency for Unseen Fruits Counting: A Quasi-Unsupervised Approach

    Author: Bellocchio, Enrico | University of Perugia
    Author: Costante, Gabriele | University of Perugia
    Author: Cascianelli, Silvia | University of Perugia
    Author: Fravolini, Mario | University of Perugia
    Author: Valigi, Paolo | Universita' Di Perugia
 
    keyword: Agricultural Automation; Robotics in Agriculture and Forestry; Visual Learning

    Abstract : Autonomous robotic platforms can be effectively used to perform automatic fruits yield estimation. To this aim, robots need data-driven models that process image streams and count, even approximately, the number of fruits in an orchard. However, training such models following a supervised paradigm is expensive and unpractical. Extending pre-trained models to perform yield estimation for a completely new type of fruit is even more challenging, but interesting since this situation is typical in practice. In this work, we combine a State-of-the-Art weakly-supervised fruit counting model with an unsupervised style transfer method for addressing the task above. In this sense, our proposed approach is quasi-unsupervised. In particular, we use a Cycle-Generative Adversarial Network (C-GAN) to perform unsupervised domain adaptation and train it alongside with a Presence-Absence Classifier (PAC) that discriminates images containing fruits or not. The PAC produces the weak-supervision signal for the counting network, that can then be used on the target orchard directly. Experiments on datasets collected in four different orchards show that the proposed approach is more accurate than the supervised baseline methods.

- A Navigation Architecture for Ackermann Vehicles in Precision Farming

    Author: Carpio, Renzo Fabrizio | Roma Tre University
    Author: Potena, Ciro | Sapienza University of Rome
    Author: Maiolini, Jacopo | University of Roma 3
    Author: Ulivi, Giovanni | Université Di Roma Tre
    Author: Bono Rossello, Nicolas | ULB-SAAS
    Author: Garone, Emanuele | Université Libre De Bruxelles
    Author: Gasparri, Andrea | Université Degli Studi Roma Tre
 
    keyword: Agricultural Automation; Robotics in Agriculture and Forestry; Motion Control

    Abstract : In this work, inspired by the needs of the European H2020 Project PANTHEON, we propose a full navigation stack purposely designed for the autonomous navigation of Ackermann steering vehicles in precision farming settings. The proposed stack is composed of a local planner and a pose regulation controller, both implemented in ROS. The local planner generates, in real-time, optimal trajectories described by a sequence of successive poses. The planning problem is formulated as a real-time cost-function minimization problem over a finite time horizon where the Ackermann kinematics and the presence of obstacles are encoded as constraints. The control law ensures the convergence toward each of these poses. To do so, in this paper we propose a novel non-smooth control law designed to ensure the solvability of the pose regulation problem for the Ackermann vehicle. Theoretical characterization of the convergence property of the proposed pose regulation controller is provided. Numerical simulations along with real-world experiments are provided to corroborate the effectiveness of the proposed navigation strategy.

- MinneApple: A Benchmark Dataset for Apple Detection and Segmentation

    Author: H�ni, Nicolai | University of Minnesota
    Author: Roy, Pravakar | University of Minnesota
    Author: Isler, Volkan | University of Minnesota
 
    keyword: Agricultural Automation; Robotics in Agriculture and Forestry; Object Detection, Segmentation and Categorization

    Abstract : In this work, we present a new dataset to advance the state-of-the-art in fruit detection, segmentation, and counting in orchard environments. While there has been significant recent interest in solving these problems, the lack of a unified dataset has made it difficult to compare results. We hope to enable direct comparisons by providing a large variety of high-resolution images acquired in orchards, together with human annotations of the fruit on trees. The fruits are labeled using polygonal masks for each object instance to aid in precise object detection, localization, and segmentation. Additionally, we provide data for patch-based counting of clustered fruits. Our dataset contains over 41, 000 annotated object instances in 1000 images. We present a detailed overview of the dataset together with baseline performance analysis for bounding box detection, segmentation, and fruit counting as well as representative results for yield estimation. We make this dataset publicly available and host a CodaLab challenge to encourage comparison of results on a common dataset. To download the data and learn more about MinneApple please see the project website: http://rsn.cs.umn.edu/index.php/MinneApple. Up to date information is available online.

## Underactuated Robots
- Extending Riemmanian Motion Policies to a Class of Underactuated Wheeled-Inverted-Pendulum Robots

    Author: Wingo, Bruce | Georgia Institute of Technology
    Author: Cheng, Ching-an | Georgia Institute of Technology
    Author: Murtaza, Muhammad Ali | Georgia Institute of Technology
    Author: Zafar, Munzir | Georgia Institute of Technology
    Author: Hutchinson, Seth | Georgia Institute of Technology
 
    keyword: Underactuated Robots; Motion and Path Planning; Manipulation Planning

    Abstract : Riemannian Motion Policies (RMPs) have recently been introduced as a way to specify motion policies for robot tasks in terms of a set of second order differential equations defined directly in the task space. RMP-based approaches have the advantage of being significantly more general than traditional operational space approaches; for example, when using RMPs, generalized task inertia can be fully state-dependent (rather than merely configuration dependent), leading to more effective motions that naturally incorporate the task dynamics, as well as task constraints such as collision avoidance. Until now, RMPs have been applied only to fully actuated systems, i.e., systems for which each degree of freedom (DoF) can be directly actuated by a control input. In this paper, we present a method that generalizes the RMP formalism to a class of underacutated systems whose dynamics are amenable to a particular class of decomposition such that the original underactuated dynamics can be effectively controlled by a fully actuated subsystem. We show the efficacy of the approach by constructing a suitable decomposition for a Wheeled Inverted Pendulum (WIP) humanoid robot, and applying our method to derive motion policies for combined locomotion and manipulation tasks. Simulation results are presented for a 7-DoF system with one degree of underactuation.

- Augmenting Self-Stability: Height Control of a Bernoulli Ball Via Bang-Bang Control

    Author: Howison, Toby | University of Cambridge
    Author: Giardina, Fabio | Harvard University
    Author: Iida, Fumiya | University of Cambridge
 
    keyword: Underactuated Robots; Motion Control; Dynamics

    Abstract : Mechanical self-stability is often useful for controlling systems in uncertain and unstructured environments because it can regulate processes without explicit state observation or feedback computation. However, the performance of such systems is often not optimised, which begs the question how their dynamics can be naturally augmented by a control law to improve performance metrics. We propose a minimalistic approach to controlling mechanically self-stabilising systems by utilising model-based, feedforward bang-bang control at a global level and self-stabilising dynamics at a local level. We demonstrate the approach in the height control problem of a sphere hovering in a vertical air jet�the so-called Bernoulli Ball. After developing a model to study the system and theoretically proving global asymptotic stability, we present the augmented controller and show how to enhance performance measures and plan behaviour. Our physical experiments show that the proposed control approach has a reduced time-to-target compared to the uncontrolled system without loss of stability (ranging from a 2.4 to 4.4 fold improvement) and that we can plan sequences of target positions at will.

- Singularity-Free Inverse Dynamics for Underactuated Systems with a Rotating Mass

    Author: Tafrishi, Seyed Amir | Kyushu University
    Author: Svinin, Mikhail | Ritsumeikan University
    Author: Yamamoto, Motoji | Kyushu University
 
    keyword: Underactuated Robots; Dynamics; Nonholonomic Mechanisms and Systems

    Abstract : Motion control of underactuated systems through the inverse dynamics contains configuration singularities. These limitations in configuration space mainly stem from the inertial coupling that passive joints/bodies create. In this study, we present a model that is free from singularity while the trajectory of the rotating mass has a small-amplitude sine wave around its circle. First, we derive the modified non-linear dynamics for a rolling system. Also, the singularity regions for this underactuated system is demonstrated. Then, the wave parameters are designed under certain conditions to remove the coupling singularities. We obtain these conditions from the positive definiteness of the inertia matrix in the inverse dynamics. Finally, the simulation results are confirmed by using a prescribed Beta function on the specified states of the rolling carrier. Because our algebraic method is integrated into the non-linear dynamics, the proposed solution has a great potential to be extended to the Lagrangian mechanics with multiple degrees-of-freedom.

- Coordinated Particle Relocation Using Finite Static Friction with Boundary Walls

    Author: Schmidt, Arne | TU Braunschweig
    Author: Montano, Victor | University of Houston
    Author: Becker, Aaron | University of Houston
    Author: Fekete, S�ndor | Technische Universitét Braunschweig
 
    keyword: Underactuated Robots; Path Planning for Multiple Mobile Robots or Agents; Manipulation Planning

    Abstract : We present theoretical and practical methods for achieving <i>arbitrary</i> reconfiguration of a set of objects, based on the use of external forces, such as a magnetic field or gravity: Upon actuation, each object is pushed in the same direction until it collides with an obstruction. This concept can be used for a wide range of applications in which particles do not have their own energy supply. <p>A crucial challenge for achieving any desired target configuration is breaking global symmetry in a controlled fashion. Previous work made use of specifically placed barriers; however, introducing precisely located obstacles into the workspace is impractical for many scenarios. In this paper, we present a different, less intrusive method: making use of the interplay between static friction with a boundary and the external force to achieve <i>arbitrary reconfiguration</i>. Our key contributions are a precise <i>theoretical</i> characterization of the critical coefficient of friction that is sufficient for rearranging two particles in triangles, convex polygons, and regular polygons; a method for reconfiguring multiple particles in rectangular workspaces, and deriving <i>practical</i> algorithms for these rearrangements. Hardware experiments show the efficacy of these procedures, demonstrating the usefulness of this novel approach.

- Robust Capture of Unknown Objects with a Highly Under-Actuated Gripper

    Author: Glick, Paul | UCSD Bioinspired Robotics and Design Lab
    Author: Van Crey, Nikko | University of Michigan Ann Arbor
    Author: Tolley, Michael T. | University of California, San Diego
    Author: Ruffatto III, Donald | NASA Jet Propulsion Lab
 
    keyword: Underactuated Robots; Grippers and Other End-Effectors; Tendon/Wire Mechanism

    Abstract : Capturing large objects of unknown shape and orientation remains a challenge for most robotic grippers. In this letter, we present a highly under-actuated gripper well suited for this task. Prior work shows that the stability of an under-actuated linkage depends on the configuration of the links and that grippers with many links are unlikely to be stable in arbitrary configurations. We unlock the potential of highly under-actuated grippers by implementing two methods of stabilization, allowing operation on unknown surfaces. We show highly under-actuated linkages successfully grasp in many configurations and without strict stability. The gripper, capable of holding over 30 N and conforming tightly to a set of test geometries, consists of two cable-driven linkages that are each 65 cm long. Furthermore, we show this type of gripper is well suited for tasks with space and mass constraints such as satellite servicing, and outfit the gripper with a gecko-inspired adhesive to improve performance.	

- TWISTER Hand: Underactuated Robotic Gripper Inspired by Origami Twisted Tower (I)
 
    Author: Lee, Kiju | Texas A&amp;M University
    Author: Wang, Yanzhou | Johns Hopkins University
    Author: Zheng, Chuanqi | Case Western Reserve University
 
    keyword: Underactuated Robots; Grippers and Other End-Effectors; Soft Robot Applications

    Abstract : This article presents a new cable-driven underactuated robotic gripper, called TWISTER Hand. It is designed for adaptable grasping of objects in different shapes, weights, sizes, and textures. Each finger of the gripper is made of a compliant and continuum mechanism inspired by an origami design. This design is converted into a computer-aided design (CAD) model and 3-D printed using flexible and rigid polymer composite materials. Two CAD modeling methods for this design are compared in terms of structural stiffness and durability in the printed outcomes. For each design, two soft materials are used for preliminary evaluation of the material effect in these properties. The best combination of the model and material is selected to fabricate the three fingers of the robotic gripper. Each finger has a single cable routed along the structure. All three cables are tied and actuated simultaneously using a single servo motor to generate closing and opening motions in the gripper. TWISTER Hand's adaptable grasping capability is tested using 36 different objects. The robot's grasping performance under object pose uncertainties is also experimentally tested and analyzed. This compact fully integrated gripper can be attached to a robotic arm for various manipulative tasks.

## Applications
- Robust Autonomous Navigation of Unmanned Aerial Vehicles (UAVs) for Warehouses' Inventory Applications

    Author: Kwon, Woong | Samsung Electronics Co., Ltd
    Author: Park, Junho | Samsung Electronics
    Author: Lee, Minsu | Samsung Electronics
    Author: Her, Jongbeom | Samsung Electronics
    Author: Kim, Sang-Hyeon | Samsung Electronics
    Author: Seo, Ja-Won | Samsung Electronics
 
    keyword: Aerial Systems: Applications; Aerial Systems: Perception and Autonomy

    Abstract : The inventory inspection using autonomous UAVs is beneficial in terms of cost, time and safety of human workers. However, in typical warehouses, it is very challenging for the autonomous UAVs to do inventory task motions safely because aisles are narrow and long, and the illumination is poor. Prior autonomous UAVs are not suitable for such environments, since they suffer from either localization methods prone to disturbance, drift and outliers; or expensive sensors. We present a low-cost sensing system with an Extended Kalman Filter(EKF)-based multi-sensor fusion framework to achieve practical autonomous navigation of UAVs in warehouse environments. To overcome the inherent drift, outliers, and disturbance problems of na�ve UAV localization methods, we suggest 1) exploiting component test of Mahalanobis norm to reject outliers efficiently, 2) introducing pseudo-covariance to incorporate a visual SLAM algorithm, and 3) recognizing floor lanes to get absolute information - as robust data fusion methods. Exemplar results are provided to demonstrate the effectiveness of the methods. The proposed system has been successfully implemented for diverse cyclic inventory inspection tasks in a materials warehouse.

- SUMMIT: A Simulator for Urban Driving in Massive Mixed Traffic

    Author: Cai, Panpan | National University of Singapore
    Author: Lee, Yiyuan | National University of Singapore
    Author: Luo, Yuanfu | School of Computing, National University of Singapore
    Author: Hsu, David | National University of Singapore
 
    keyword: Simulation and Animation; Autonomous Vehicle Navigation; Deep Learning in Robotics and Automation

    Abstract : Autonomous driving in an unregulated urban crowd is an outstanding challenge, especially, in the presence of many aggressive, high-speed traffic participants. This paper presents SUMMIT, a high-fidelity simulator that facilitates the development and testing of crowd-driving algorithms. By leveraging the open-source OpenStreetMap map database and a heterogeneous multi-agent motion prediction model developed in our earlier work, SUMMIT simulates dense, unregulated urban traffic for heterogeneous agents at any worldwide locations that OpenStreetMap supports. SUMMIT is built as an extension of CARLA and inherits from it the physics and visual realism for autonomous driving simulation. SUMMIT supports a wide range of applications, including perception, vehicle control and planning, and end-to-end learning. We provide a context-aware planner together with benchmark scenarios and show that SUMMIT generates complex, realistic traffic behaviors in challenging crowd-driving settings.

- A Model-Based Reinforcement Learning and Correction Framework for Process Control of Robotic Wire Arc Additive Manufacturing

    Author: Dharmawan, Audelia Gumarus | Singapore University of Technology and Design
    Author: Xiong, Yi | Singapore University of Technology and Design
    Author: Foong, Shaohui | Singapore University of Technology and Design
    Author: Soh, Gim Song | Singapore University of Technology and Design
 
    keyword: Additive Manufacturing; Intelligent and Flexible Manufacturing; Industrial Robots

    Abstract : Robotic Wire Arc Additive Manufacturing (WAAM) utilizes a robot arm as a motion system to build 3D metallic objects by depositing weld beads one above the other in a layer by layer fashion. A key part of this approach is the process study and control of Multi-Layer Multi-Bead (MLMB) deposition, which is very sensitive to process parameters and prone to error stacking. Despite its importance, it has been receiving less attention than its single bead counterpart in literature, probably due to the higher experimental overhead and complexity of modeling. To address these challenges, this paper proposes an integrated learning-correction framework, adapted from Model-Based Reinforcement Learning, to iteratively learn the direct effect of process parameters on MLMB print while simultaneously correct for any inter-layer geometric digression such that the final output is still satisfactory. The advantage is that this learning architecture can be used in conjunction with actual parts printing (hence, in-situ study), thus minimizing the required training time and material wastage. The proposed learning framework is implemented on an actual robotic WAAM system and experimentally evaluated.

- Toward Optimal FDM Toolpath Planning with Monte Carlo Tree Search

    Author: Yoo, Chanyeol | University of Technology Sydney
    Author: Lensgraf, Samuel | Dartmouth College
    Author: Fitch, Robert | University of Technology Sydney
    Author: Clemon, Lee | University of Technology Sydnet
    Author: Mettu, Ramgopal | Tulane University
 
    keyword: Additive Manufacturing; Intelligent and Flexible Manufacturing; Motion and Path Planning

    Abstract : The most widely used methods for toolpath planning in 3D printing slice the input model into successive 2D layers to construct the toolpath. Unfortunately the methods can incur a substantial amount of wasted motion (i.e., the extruder is moving while not printing). In recent years we have introduced a new paradigm that characterizes the space of feasible toolpaths using a dependency graph on the input model, along with several algorithms that optimize objective functions (wasted motion or print time). A natural question that arises is, under what circumstances can we efficiently compute an optimal toolpath? In this paper, we give an algorithm for computing fused deposition modeling (FDM) toolpaths that utilizes Monte Carlo Tree Search (MCTS), a powerful general-purpose method for navigating large search spaces that is guaranteed to converge to the optimal solution. Under reasonable assumptions on printer geometry that allow us to compress the dependency graph, our MCTS-based algorithm converges to find the optimal toolpath. We validate our algorithm on a dataset of 75 models and examine the performance on MCTS against our previous best local search-based algorithm in terms of toolpath quality. We show that a relatively short time budget for MCTS yields results on par with local search, while a larger time budget yields a 15% improvement in quality over local search. Additionally, we examine the properties of the models and MCTS executions that lead to better or worse results.

- Optimizing Performance in Automation through Modular Robots

    Author: Liu, Stefan Boson | Technical University of Munich
    Author: Althoff, Matthias | Technische Universitét M�nchen
 
    keyword: Cellular and Modular Robots; Industrial Robots

    Abstract : Flexible manufacturing and automation require robots that can be adapted to changing tasks. We propose to use modular robots that are customized from given modules for a specific task. This work presents an algorithm for proposing a module composition that is optimal with respect to performance metrics such as cycle time and energy efficiency, while considering kinematic, dynamic, and obstacle constraints. Tasks are defined as trajectories in Cartesian space, as a list of poses for the robot to reach as fast as possible, or as dexterity in a desired workspace. In a simulated comparison with commercially available industrial robots, we demonstrate the superiority of our approach in randomly generated tasks with respect to the chosen performance metrics. We use our modular robot proModular.1 for the comparison.

- Towards Practical Multi-Object Manipulation Using Relational Reinforcement Learning

    Author: Li, Richard | UC Berkeley
    Author: Jabri, Allan | UC Berkeley
    Author: Agrawal, Pulkit | MIT
    Author: Darrell, Trevor | UC Berkeley
 
    keyword: Learning and Adaptive Systems

    Abstract : Learning robotic manipulation tasks using rein- forcement learning with sparse rewards is currently impractical due to the outrageous data requirements. Many practical tasks require manipulation of multiple objects, and the complexity of such tasks increases with the number of objects. Learning from a curriculum of increasingly complex tasks appears to be a natural solution, but unfortunately, does not work for many scenarios. We hypothesize that the inability of the state- of-the-art algorithms to effectively utilize a task curriculum stems from the absence of inductive biases for transferring knowledge from simpler to complex tasks. We show that graph-based relational architectures overcome this limitation and enable learning of complex tasks when provided with a simple curriculum of tasks with increasing numbers of objects. We demonstrate the utility of our framework on a simulated block stacking task. Starting from scratch, our agent learns to stack six blocks into a tower. Despite using step-wise sparse rewards, our method is orders of magnitude more data- efficient and outperforms the existing state-of-the-art method that utilizes human demonstrations. Furthermore, the learned policy exhibits zero-shot generalization, successfully stacking blocks into taller towers and previously unseen configurations such as pyramids, without any further training.

- SwarmMesh: A Distributed Data Structure for Cooperative Multi-Robot Applications

    Author: Majcherczyk, Nathalie | Worcester Polytechnic Institute
    Author: Pinciroli, Carlo | Worcester Polytechnic Institute
 
    keyword: Networked Robots; Distributed Robot Systems; Swarms

    Abstract : We present an approach to the distributed storage of data across a swarm of mobile robots that forms a shared global memory. We assume that external storage infrastructure is absent, and that each robot is capable of devoting a quota of memory and bandwidth to distributed storage. Our approach is motivated by the insight that in many applications data is collected at the periphery of a swarm topology, but the periphery also happens to be the most dangerous location for storing data, especially in exploration missions. Our approach is designed to promote data storage in the locations in the swarm that best suit a specific feature of interest in the data, while accounting for the constantly changing topology due to individual motion. We analyze two possible features of interest: the data type and the data item position in the environment. We assess the performance of our approach in a large set of simulated experiments. The evaluation shows that our approach is capable of storing quantities of data that exceed the memory of individual robots, while maintaining near-perfect data retention in high-load conditions.

## Robust and Sensor-Based Control
- Avalanche Victim Search Via Robust Observers

    Author: Mimmo, Nicola | University of Bologna
    Author: Bernard, Pauline | MINES ParisTech, Université PSL
    Author: Marconi, Lorenzo | University of Bologna
 
    keyword: Sensor-based Control; Search and Rescue Robots

    Abstract : This paper introduces a new approach for victim localization in avalanches that will be exploited by UAVs using the ARVA sensor. We show that the nominal ARVA measurement can be linearly related to a quantity that is sufficient to reconstruct the victim position. We explicitly deal with a robust scenario in which the measurement is actually perturbed by a noise that grows with the distance to the victim and we propose an adaptive control scheme made of a least-square identifier and a trajectory generator whose role is both to guarantee the persistence of excitation for the identifier and to steer the ARVA receiver towards the victim. We show that the system succeeds in localizing the victim in a domain where the ARVA output is sufficiently informative and illustrate its performance in simulation. This new approach could significantly reduce the searching time by providing an exploitable estimate before having reached the victim. The work is framed within the EU project AirBorne whose goals is to develop at TRL8 a drone for quick localization of victims in avalanche scenarios.

- Reactive Control and Metric-Topological Planning for Exploration

    Author: Ohradzansky, Michael | University of Colorado Boulder
    Author: Mills, Andrew | University of Colorado, Boulder
    Author: Rush, Eugene | University of Colorado Boulder
    Author: Riley, Danny | University of Colorado Boulder
    Author: Frew, Eric W. | University of Colorado
    Author: Humbert, James Sean | University of Colorado Boulder
 
    keyword: Sensor-based Control; Motion and Path Planning; Biologically-Inspired Robots

    Abstract : Autonomous navigation in unknown environments with the intent of exploring all traversable areas is a significant challenge for robotic platforms. In this paper, a simple yet reliable method for exploring unknown environments is presented based on bio-inspired reactive control and metric-topological planning. The reactive control algorithm is modeled after the spatial decomposition of wide and small-field patterns of optic flow in the insect visuomotor system. Centering behaviour and small obstacle detection and avoidance are achieved through wide- field integration and Fourier residual analysis of instantaneous measured nearness respectively. A topological graph is estimated using image processing techniques on a continuous occupancy grid image. Node paths are rapidly generated to navigate to the nearest unexplored edge in the graph. It is shown through rigorous field-testing that the proposed control and planning method is robust, reliable, and computationally efficient.

- Information Theoretic Active Exploration in Signed Distance Fields

    Author: Saulnier, Kelsey | University of Pennsylvania
    Author: Atanasov, Nikolay | University of California, San Diego
    Author: Pappas, George J. | University of Pennsylvania
    Author: Kumar, Vijay | University of Pennsylvania, School of Engineering and Applied Sc
 
    keyword: Sensor-based Control; Autonomous Agents; Reactive and Sensor-Based Planning

    Abstract : This paper focuses on exploration and occupancy mapping of unknown environments using a mobile robot. While a truncated signed distance field (TSDF) is a popular, efficient, and highly accurate representation of occupancy, few works have considered optimizing robot sensing trajectories for autonomous TSDF mapping. We propose an efficient approach for maintaining TSDF uncertainty and predicting its evolution from potential future sensor measurements without actually receiving them. Efficient uncertainty prediction is critical for long-horizon optimization of potential sensing trajectories. We develop a deterministic tree-search algorithm that evaluates the information gain between the TSDF distribution and potential observations along sequences of robot motion primitives. Efficient planning is achieved by branch-and-bound pruning of uninformative sensing trajectories. The effectiveness of our active TSDF mapping approach is evaluated in several simulated environments with complex visibility constraints.

- Adaptive Integral Inverse Kinematics Control for Lightweight Compliant Manipulators

    Author: Rodr�guez de Cos, Carlos | Universidad De Sevilla
    Author: Acosta, Jose Angel | University of Seville
    Author: Ollero, Anibal | University of Seville
 
    keyword: Robust/Adaptive Control of Robotic Systems; Compliance and Impedance Control; Aerial Systems: Mechanics and Control

    Abstract : In this paper, an adaptive to unknown stiffness algorithm for controlling low-cost lightweight compliant manipulators is presented. The proposed strategy is based on the well-known transpose inverse kinematics approach, that has been enhanced with an integral action and an update law for the unknown stiffness of the compliant links, making it valid for soft materials. Moreover, the algorithm is proven to guarantee global task-space regulation of the end-effector. This approach has been implemented on a very low-cost robotic manipulator setup (comprised of 4 actuated and 3 flexible links) equipped with a simple Arduino board running at 27Hz. Notwithstanding, the strategy is capable of achieving a first-order-like response when undisturbed, and recover from overshoots provided by unforeseen impacts, smoothly returning to its nominal behaviour. Moreover, the adaptive capabilities are also used to perform contact tasks, achieving zero steady-state error. The tracking performance and disturbance rejection capabilities are demonstrated with both theoretical and experimental results.

- Bayesian Learning-Based Adaptive Control for Safety Critical Systems

    Author: Fan, David D | Georgia Institute of Technology
    Author: Nguyen, Jennifer | West Virginia University
    Author: Thakker, Rohan | Nasa's Jet Propulsion Laboratory, Caltech
    Author: Alatur, Nikhilesh Athresh | ETH Zurich
    Author: Agha-mohammadi, Ali-akbar | NASA-JPL, Caltech
    Author: Theodorou, Evangelos | Georgia Institute of Technology
 
    keyword: Robust/Adaptive Control of Systems; Robot Safety; Probability and Statistical Methods

    Abstract : Deep learning has enjoyed much recent success, and applying state-of-the-art model learning methods to controls is an exciting prospect. However, there is a strong reluctance to use these methods on safety-critical systems, which have constraints on safety, stability, and real-time performance. We propose a framework which satisfies these constraints while allowing the use of deep neural networks for learning model uncertainties. Central to our method is the use of Bayesian model learning, which provides an avenue for maintaining appropriate degrees of caution in the face of the unknown. In the proposed approach, we develop an adaptive control framework leveraging the theory of stochastic CLFs (Control Lyapunov Functions) and stochastic CBFs (Control Barrier Functions) along with tractable Bayesian model learning via Gaussian Processes or Bayesian neural networks. Under reasonable assumptions, we guarantee stability and safety while adapting to unknown dynamics with probability 1. We demonstrate this architecture for high-speed terrestrial mobility targeting potential applications in safety-critical high-speed Mars rover missions.

- A Novel Adaptive Controller for Robot Manipulators Based on Active Inference

    Author: Pezzato, Corrado | Delft University of Technology
    Author: Ferrari, Riccardo M.G. | Delft University of Technology
    Author: Hern�ndez, Carlos | Delft University of Technology
 
    keyword: Robust/Adaptive Control of Robotic Systems; Industrial Robots; Biologically-Inspired Robots

    Abstract : More adaptive controllers for robot manipulators are needed, which can deal with large model uncertainties. This paper presents a novel active inference controller (AIC) as an adaptive control scheme for industrial robots. This scheme is easily scalable to high degrees-of-freedom, and it maintains high performance even in the presence of large unmodeled dynamics. The proposed method is based on active inference, a promising neuroscientific theory of the brain, which describes a biologically plausible algorithm for perception and action. In this work, we formulate active inference from a control perspective, deriving a model-free control law which is less sensitive to unmodeled dynamics. The performance and the adaptive properties of the algorithm are compared to a state-of-the-art model reference adaptive controller (MRAC) in an experimental setup with a real 7-DOF robot arm. The results showed that the AIC outperformed the MRAC in terms of adaptability, providing a more general control law. This confirmed the relevance of active inference for robot control.

## Object Detection, Segmentation and Categorization

- Stillleben: Realistic Scene Synthesis for Deep Learning in Robotics

    Author: Schwarz, Max | University Bonn
    Author: Behnke, Sven | University of Bonn
 
    keyword: Deep Learning in Robotics and Automation; Object Detection, Segmentation and Categorization; Semantic Scene Understanding

    Abstract : Training data is the key ingredient for deep learning approaches, but difficult to obtain for the specialized domains often encountered in robotics. We describe a synthesis pipeline capable of producing training data for cluttered scene perception tasks such as semantic segmentation, object detection, and correspondence or pose estimation. Our approach arranges object meshes in physically realistic, dense scenes using physics simulation. The arranged scenes are rendered using high-quality rasterization with randomized appearance and material parameters. Noise and other transformations introduced by the camera sensors are simulated. Our pipeline can be run online during training of a deep neural network, yielding applications in life-long learning and in iterative render-and-compare approaches. We demonstrate the usability by learning semantic segmentation on the challenging YCB-Video dataset without actually using any training frames, where our method achieves performance comparable to a conventionally trained model. Additionally, we show successful application in a real-world regrasping system.

- From Planes to Corners: Multi-Purpose Primitive Detection in Unorganized 3D Point Clouds

    Author: Sommer, Christiane | Technical University of Munich
    Author: Sun, Yumin | Technical University of Munich
    Author: Guibas, Leonidas | Stanford University
    Author: Cremers, Daniel | Technical University of Munich
    Author: Birdal, Tolga | Technical University of Munich
 
    keyword: Object Detection, Segmentation and Categorization; Range Sensing; Computational Geometry

    Abstract : We propose a new method for segmentation-free joint estimation of orthogonal planes, their intersection lines, relationship graph and corners lying at the intersection of three orthogonal planes. Such unified scene exploration under orthogonality allows for multitudes of applications such as semantic plane detection or local and global scan alignment, which in turn can aid robot localization or grasping tasks. Our two-stage pipeline involves a rough yet joint estimation of orthogonal planes followed by a subsequent joint refinement of plane parameters respecting their orthogonality relations. We form a graph of these primitives, paving the way to the extraction of further reliable features: lines and corners. Our experiments demonstrate the validity of our approach in numerous scenarios from wall detection to 6D tracking, both on synthetic and real data.

- Addressing the Sim2Real Gap in Robotic 3D Object Classification

    Author: Weibel, Jean-Baptiste | TU Wien
    Author: Patten, Timothy | TU Wien
    Author: Vincze, Markus | Vienna University of Technology
 
    keyword: Object Detection, Segmentation and Categorization; Deep Learning in Robotics and Automation; RGB-D Perception

    Abstract : Object classification with 3D data is an essential component of any scene understanding method. It has gained significant interest in a variety of communities, most notably in robotics and computer graphics. While the advent of deep learning has progressed the field of 3D object classification, most work using this data type are solely evaluated on CAD model datasets. Consequently, current work does not address the discrepancies existing between real and artificial data. In this work, we examine this gap in a robotic context by specifically addressing the problem of classification when transferring from artificial CAD models to real reconstructed objects. This is performed by training on ModelNet (CAD models) and evaluating on ScanNet (reconstructed objects). We show that standard methods do not perform well in this task. We thus introduce a method that carefully samples object parts that are reproducible under various transformations and hence robust. Using graph convolution to classify the composed graph of parts, our method significantly improves upon the baseline.

- A Generative Approach towards Improved Robotic Detection of Marine Litter

    Author: Hong, Jungseok | University of Minnesota
    Author: Fulton, Michael | University of Minnesota
    Author: Sattar, Junaed | University of Minnesota
 
    keyword: Object Detection, Segmentation and Categorization; Deep Learning in Robotics and Automation; Marine Robotics

    Abstract : This paper presents an approach to address data scarcity problems in underwater image datasets for visual detection of marine debris. The proposed approach relies on a two-stage variational autoencoder (VAE) and a binary classifier to evaluate the generated imagery for quality and realism. From the images generated by the two-stage VAE, the binary classifier selects "good quality" images and augments the given dataset with them. Lastly, a multi-class classifier is used to evaluate the impact of the augmentation process by measuring the accuracy of an object detector trained on combinations of real and generated trash images. Our results show that the classifier trained with the augmented data outperforms the one trained only with the real data. This approach will not only be valid for the underwater trash classification problem presented in this paper, but it will also be useful for any data-dependent task for which collecting more images is challenging or infeasible.

- Learning to Optimally Segment Point Clouds

    Author: Hu, Peiyun | Carnegie Mellon University
    Author: Held, David | Carnegie Mellon University
    Author: Ramanan, Deva | Carnegie Mellon University
 
    keyword: Deep Learning in Robotics and Automation; Object Detection, Segmentation and Categorization; Autonomous Vehicle Navigation

    Abstract : We focus on the problem of class-agnostic instance segmentation of LiDAR point clouds. We propose an approach that combines graph-theoretic search with data-driven learning: it searches over a set of candidate segmentations and returns one where individual segments score well according to a data-driven point-based model of "objectness". We prove that if we score a segmentation by the worst objectness among its individual segments, there is an efficient algorithm that finds the optimal worst-case segmentation among an exponentially large number of candidate segmentations. We also present an efficient algorithm for the average-case. For evaluation, we repurpose KITTI 3D detection as a segmentation benchmark and empirically demonstrate that our algorithms significantly outperform past bottom-up segmentation approaches and top-down object-based algorithms on segmenting point clouds.

- CNN Based Road User Detection Using the 3D Radar Cube

    Author: Palffy, Andras | Delft University of Technology
    Author: Dong, Jiaao | Daimler Greater China Ltd
    Author: Kooij, Julian | TU Delft
    Author: Gavrila, Dariu | Delft University of Technology
 
    keyword: Object Detection, Segmentation and Categorization; Sensor Fusion; Deep Learning in Robotics and Automation

    Abstract : This paper presents a novel radar based, single-frame, multi-class detection method for moving road users (pedestrian, cyclist, car), which utilizes low-level radar cube data. The method provides class information both on the radar target- and object-level. Radar targets are classified individually after extending the target features with a cropped block of the 3D radar cube around their positions, thereby capturing the motion of moving parts in the local speed distribution. A Convolutional Neural Network (CNN) is proposed for this classification step. Afterwards, object proposals are generated with a clustering step, which not only considers the radar targets' positions and speeds, but their calculated class scores as well. In experiments on a real-life dataset we demonstrate that our method outperforms the state-of-the-art methods both target and object-wise by reaching an average of 0.70 (baseline: 0.68) target-wise and 0.56 (baseline: 0.48) object-wise<p>F1 score. Furthermore, we examine the importance of the used features in an ablation study.

- 

- PST900: RGB-Thermal Calibration, Dataset and Segmentation Network

    Author: Skandan, Shreyas | University of Pennsylvania
    Author: Rodrigues, Neil | University of Pennsylvania
    Author: Zhou, Alex | University of Pennsylvania
    Author: Miller, Ian | University of Pennsylvania
    Author: Kumar, Vijay | University of Pennsylvania
    Author: Taylor, Camillo Jose | University of Pennsylvania
 
    keyword: Object Detection, Segmentation and Categorization; Sensor Fusion; Deep Learning in Robotics and Automation

    Abstract : In this work we propose long wave infrared (LWIR) imagery as a viable supporting modality for semantic segmentation using learning-based techniques. We first address the problem of RGB-thermal camera calibration by proposing a passive calibration target and procedure that is both portable and easy to use. Second, we present PST900, a dataset of 894 synchronized and calibrated RGB and Thermal image pairs with per pixel human annotations across four distinct classes from the DARPA Subterranean Challenge. Lastly, we propose a CNN architecture for fast semantic segmentation that combines both RGB and Thermal imagery in a way that leverages RGB imagery independently. We compare our method against the state-of-the-art and show that our method outperforms them in our dataset.

- Instance Segmentation of LiDAR Point Clouds

    Author: Zhang, Feihu | University of Oxford
    Author: Guan, Chenye | Baidu
    Author: Fang, Jin | Baidu
    Author: Bai, Song | University of Oxford
    Author: Yang, Ruigang | University of Kentucky
    Author: Torr, Philip | University of Oxford
    Author: Prisacariu, Victor | University of Oxford
 
    keyword: Object Detection, Segmentation and Categorization; Deep Learning in Robotics and Automation; Computer Vision for Transportation

    Abstract : We propose a robust baseline method for instance segmentation which are specially designed for large-scale outdoor LiDAR point clouds. Our method includes a novel dense feature encoding technique, allowing the localization and segmentation of small, far-away objects, a simple but effective solution for single-shot instance prediction and effective strategies for handling severe class imbalances. Since there is no public dataset for the study of LiDAR instance segmentation, we also build a new publicly available LiDAR point cloud dataset to include both precise 3D bounding box and point-wise labels for instance segmentation, while still being about 3~20 times as large as other existing LiDAR datasets. The dataset and the source code will be published along with the paper.

- Generation of Object Candidates through Simply Looking Around

    Author: Patar, Do&#287;an | Bogazici University
    Author: Bozma, H. Isil | Bogazici University
 
    keyword: Object Detection, Segmentation and Categorization; Visual Tracking; Sensor-based Control

    Abstract : In this paper, we consider the generation of generic object candidates by a mobile robot that is endowed with a pan-tilt monocular camera. This is an important problem because these candidates serve as basis for the robot to categorize and/or recognize the objects in its surroundings. The previously proposed methods either do not have a means of enabling the robot to look around through moving its camera or do not take advantage of the temporal coherence of the video data. We present a novel approach that enables the robot to achieve both of these capabilities simultaneously. In this approach, the robot's camera movements are governed by a family of controllers whose constructions depend on the set of object candidates that have been hitherto generated, but not directly looked at. In parallel, the robot discovers the object candidates through tracking segments and determining spatio-temporally coherent ones. The advantage of the proposed approach is that while the robot can explore its surroundings by simply looking around prior to more sophisticated exploration behavior involving possibly bodily locomotion the generated object candidates turn out to be consolidated across the visual stream in comparison to single-shot methods. This is demonstrated in extensive experimental results with a robot operating indoors varying in clutter as well as outdoors.

- Dilated Point Convolutions: On the Receptive Field Size of Point Convolutions on 3D Point Clouds

    Author: Engelmann, Francis | RWTH Aachen University
    Author: Kontogianni, Theodora | University of Aachen
    Author: Leibe, Bastian | RWTH Aachen University
 
    keyword: Object Detection, Segmentation and Categorization; Semantic Scene Understanding; Deep Learning in Robotics and Automation

    Abstract : In this work, we propose Dilated Point Convolutions (DPC). In a thorough ablation study, we show that the receptive field size is directly related to the performance of 3D point cloud processing tasks, including semantic segmentation and object classification. Point convolutions are widely used to efficiently process 3D data representations such as point clouds or graphs. However, we observe that the receptive field size of recent point convolutional networks is inherently limited. Our dilated point convolutions alleviate this issue, they significantly increase the receptive field size of point convolutions. Importantly, our dilation mechanism can easily be integrated into most existing point convolutional networks. To evaluate the resulting network architectures, we visualize the receptive field and report competitive scores on popular point cloud benchmarks.

- A Water-Obstacle Separation and Refinement Network for Unmanned Surface Vehicles

    Author: Bovcon, Borja | Faculty of Computer and Information Science, University of Ljubl
    Author: Kristan, Matej | University of Ljubljana
 
    keyword: Object Detection, Segmentation and Categorization; Computer Vision for Transportation; Visual-Based Navigation

    Abstract : Obstacle detection by semantic segmentation shows a great promise for autonomous navigation in unmanned surface vehicles (USV). However, existing methods suffer from poor estimation of the water edge in the presence of visual ambiguities, poor detection of small obstacles and high false-positive rate on water reflections and wakes. We propose a new deep encoder-decoder architecture, a water-obstacle separation and refinement network (WaSR), to address these issues. Detection and water edge accuracy are improved by a novel decoder that gradually fuses inertial information from IMU with the visual features from the encoder. In addition, a novel loss function is designed to increase the separation between water and obstacle features early on in the network. Subsequently, the capacity of the remaining layers in the decoder is better utilised, leading to a significant reduction in false positives and increased true positives. Experimental results show that WaSR outperforms the current state-of-the-art by a large margin, yielding a 14% increase in F-measure over the second-best method.

- Dynamic Anchor Selection for Improving Object Localization

    Author: Shyam, Pranjay | Korea Advanced Institute of Science and Technology
    Author: Yoon, Kuk-Jin | KAIST
    Author: Kim, Kyung-Soo | KAIST(Korea Advanced Institute of Science and Technology)
 
    keyword: Object Detection, Segmentation and Categorization

    Abstract : Anchor boxes acting as potential object detection candidates allow single-stage detectors to achieve realtime performance, at the cost of localization accuracy when compared to state of the art two-stage detectors. Therefore, correct selection of the scale and aspect ratio associated with an anchor box is crucial for detector performance. In this work, we propose a novel architecture (DANet) for improving the localization performance of single-stage object detectors, while maintaining real-time inference. The proposed network achieves this by predicting (1) the combination of aspect ratios and scales per feature map based on object density and (2) localization confidence per anchor box. We evaluate the proposed network using the benchmark dataset. On the MS COCO dataset, DANet achieves 30.9% AP at 51.8 fps using ResNet-18 and 45.3% AP at 7.4 fps using ResNeXt-101. The code and models will be available at https://github.com/PS06/AnchorNet.

- 3D Object Detection and Tracking Based on Streaming Data

    Author: Guo, Xusen | Sun Yet-Sen University
    Author: Gu, Jianfeng | Sun Yat-Sen University
    Author: Guo, Silu | SunYat-senUniversity
    Author: Xu, Zixiao | Sun Yat-Sen University
    Author: Yang, Chengzhang | Sun Yat-Sen University
    Author: Liu, Shanghua | Sysu
    Author: Cheng, Long | Sun Yat-Sen University
    Author: Huang, Kai | Sun Yat-Sen University
 
    keyword: Object Detection, Segmentation and Categorization; Visual Tracking; Sensor Fusion

    Abstract : Recent approaches for 3D object detection have&#12288;made tremendous progresses due to the development of deep&#12288;learning. However, previous researches are mostly based on&#12288;individual frames, leading to limited exploitation of&#12288;information between frames. In this paper, we attempt to leverage&#12288;the temporal information in streaming data and explore 3D&#12288;streaming based object detection as well as tracking. Toward&#12288;this goal, we set up a dual-way network for 3D object detection&#12288;based on keyframes, and then propagate predictions to non-key&#12288;frames through a motion based interpolation algorithm guided&#12288;by temporal information. Our framework is not only shown&#12288;to have significant improvements on object detection compared&#12288;with frame-by-frame paradigm, but also proven to produce&#12288;competitive results on KITTI Object Tracking Benchmark, with&#12288;76.68% in MOTA and 81.65% in MOTP respectively.

- Object-Centric Stereo Matching for 3D Object Detection

    Author: Pon, Alexander | University of Toronto
    Author: Ku, Jason | University of Toronto
    Author: Li, Chengyao | University of Toronto
    Author: Waslander, Steven Lake | University of Toronto
 
    keyword: Object Detection, Segmentation and Categorization; Autonomous Vehicle Navigation

    Abstract : Safe autonomous driving requires reliable 3D object detection-determining the 6 DoF pose and dimensions of objects of interest. Using stereo cameras to solve this task is a cost-effective alternative to the widely used LiDAR sensor. The current state-of-the-art for stereo 3D object detection takes the existing PSMNet stereo matching network, with no modifications, and converts the estimated disparities into a 3D point cloud, and feeds this point cloud into a LiDAR-based 3D object detector. The issue with existing stereo matching networks is that they are designed for disparity estimation, not 3D object detection; the shape and accuracy of object point clouds are not the focus. Stereo matching networks commonly suffer from inaccurate depth estimates at object boundaries, which we define as streaking, because background and foreground points are jointly estimated. Existing networks also penalize disparity instead of the estimated position of object point clouds in their loss functions. We propose a novel 2D box association and object-centric stereo matching method that only estimates the disparities of the objects of interest to address these two issues. With the open-sourced 3D object detector AVOD, we achieve state-of-the-art results on the KITTI 3D and BEV benchmarks.

- The Relative Confusion Matrix, a Tool to Assess Classifiablility in Large Scale Picking Applications

    Author: Balasch, Alexander | TGW Logistics Group
    Author: Beinhofer, Maximilian | TGW Logistics Group
    Author: Zauner, Gerald | Upper Austria University of Applied Sciences, School of Engineer
 
    keyword: Object Detection, Segmentation and Categorization; Logistics; Perception for Grasping and Manipulation

    Abstract : For bin picking robots in real logistics installations, the certainty of picking the correct product out of a mixed-product bin is essential. This paper proposes an approach for the robot to efficiently decide whether it can robustly distinguish the product to pick from the others in the bin. If not, the pick has to be routed not to the robot workstation but to a manual picking station. For this, we introduce a modified version of the confusion matrix, which we call the relative confusion matrix. We show how this matrix can be used to make the required decision, taking into account that all other products in the warehouse can be logically ruled out as they are not contained in the bin. Considering only this sub-set of products would require a re-computation of the standard confusion matrix. With the relative confusion matrix, no such re-computation is needed, which makes our approach more efficient. We show the usefulness of our approach in extensive experiments with a real bin picking robot, on simulated data, and on a publicly available image dataset.

- Pose-Guided Auto-Encoder and Feature-Based Refinement for 6-DoF Object Pose Regression

    Author: Li, Zhigang | Tsinghua University
    Author: Ji, Xiangyang | Tsinghua University
 
    keyword: Object Detection, Segmentation and Categorization; Computer Vision for Other Robotic Applications; Perception for Grasping and Manipulation

    Abstract : Accurately estimating the 6-DoF object pose from a single RGB image is a challenging task in computer vision. Though pose regression approaches have achieved great progress, the performance is still limited. In this work, we propose Pose-guided Auto-Encoder (PAE), which can distill better pose-related features from the image by utilizing a suitable pose representation, 3D Location Field (3DLF), to guide the encoding process. The features from PAE show strong robustness to pose-irrelevant factors. Compared with traditional auto-encoder, PAE can not only improve the pose estimation performance but also handle the ambiguity viewpoints problem. Further, we propose Feature-based Pose Refiner (FPR), which refines the pose from the extracted features without rendering. Combining PAE with FPR, our approach achieved state-of-the-art performance on the widely used LINEMOD dataset. Our approach not only outperforms the direct regression-based approaches with a large margin but also thrillingly surpasses current state-of-the-art indirect PnP-based approach.

- PrimiTect: Fast Continuous Hough Voting for Primitive Detection

    Author: Sommer, Christiane | Technical University of Munich
    Author: Sun, Yumin | Technical University of Munich
    Author: Bylow, Erik | Technical University of Munich
    Author: Cremers, Daniel | Technical University of Munich
 
    keyword: Object Detection, Segmentation and Categorization; Semantic Scene Understanding; Range Sensing

    Abstract : This paper tackles the problem of data     Abstraction in the context of 3D point sets. Our method classifies points into different geometric primitives, such as planes and cones, leading to a compact representation of the data. Being based on a semi-global Hough voting scheme, the method does not need initialization and is robust, accurate and efficient. We use a local, low-dimensional parameterization of primitives to determine type, shape and pose of object that a point belongs to. This makes our algorithm suitable to run on devices with low computational power, as often required in robotics applications. The evaluation shows that our method outperforms state-of-the-art methods both in terms of accuracy and robustness.

- FarSee-Net: Real-Time Semantic Segmentation by Efficient Multi-Scale Context Aggregation and Feature Space Super-Resolution

    Author: Zhang, Zhanpeng | SenseTime Group Limited
    Author: Zhang, Kaipeng | The University of Tokyo
 
    keyword: Object Detection, Segmentation and Categorization; Deep Learning in Robotics and Automation; Computer Vision for Transportation

    Abstract : Real-time semantic segmentation is desirable in many robotic applications with limited computation resources. One challenge of semantic segmentation is to deal with the object scale variations and leverage the context. How to perform multi-scale context aggregation within limited computation budget is important. In this paper, firstly, we introduce a novel and efficient module called Cascaded Factorized Atrous Spatial Pyramid Pooling (CF-ASPP). It is a lightweight cascaded structure for Convolutional Neural Networks (CNNs) to efficiently leverage context information. On the other hand, for runtime efficiency, state-of-the-art methods will quickly decrease the spatial size of the inputs or feature maps in the early network stages. The final high-resolution result is usually obtained by non-parametric up-sampling operation (e.g. bilinear interpolation). Differently, we rethink this pipeline and treat it as a super-resolution process. We use optimized superresolution operation in the up-sampling step and improve the accuracy, especially in sub-sampled input image scenario for real-time applications. By fusing the above two improvements, our methods provide better latency-accuracy trade-off than the other state-of-the-art methods. In particular, we achieve 68.4% mIoU at 84 fps on the Cityscapes test set with a single Nivida Titan X (Maxwell) GPU card. The proposed module can be plugged into any feature extraction CNN and benefits from the CNN structure development.

## Aerial Systems: Perception and Autonomy
- Pose-Estimate-Based Target Tracking for Human-Guided Remote Sensor Mounting with a UAV

    Author: McArthur, Daniel | Purdue University
    Author: An, Ze | Purdue University
    Author: Cappelleri, David | Purdue University
 
    keyword: Aerial Systems: Applications; Visual-Based Navigation

    Abstract : In this paper, we present a method for pose estimate-based target tracking (PBTT) that enables the performance of autonomous aerial manipulation operations in unstructured environments using fully on-board computation for both UAV localization and target tracking. The PBTT method does not depend on extracting traditional visual features (e.g. using SIFT, SURF, ORB, etc.) on or near the target. Instead, the algorithm combines input from an RGB-D camera and the UAV's position estimator (which utilizes a downward-facing optical flow camera for horizontal localization) to track a target point selected by a human operator. The effectiveness of the PBTT method is evaluated through several autonomous flight tests performed with the Interacting-Boomcopter (I-BC) UAV platform in unstructured environments and in the presence of light wind disturbances.

- Aerial Single-View Depth Completion with Image-Guided Uncertainty Estimation

    Author: Teixeira, Lucas | ETH Zurich
    Author: Oswald, Martin R. | ETH Zurich
    Author: Pollefeys, Marc | ETH Zurich
    Author: Chli, Margarita | ETH Zurich
 
    keyword: Aerial Systems: Perception and Autonomy; Deep Learning in Robotics and Automation

    Abstract : On the pursuit of autonomous flying robots, the scientific community has been developing onboard real-time algorithms for localisation and mapping. Despite recent progress, the available solutions still lack accuracy and robustness in many aspects. While mapping for autonomous cars had a substantive boost using learning techniques to enhance LIDAR measurements using image-based depth completion, the viewpoint variations experienced by aerial vehicles are still posing challenges for learning-based mapping approaches. In this paper, we propose a depth completion and uncertainty estimation approach that better handles the challenges of aerial platforms, such as viewpoint and depth variations, and limited computing resources. The core of our method is a novel compact network that performs both depth completion and confidence estimation using an image-guided approach. Real-time performance onboard a GPU suitable for small robots is achieved by sharing deep features between both tasks. Experiments demonstrate that our network outperforms the state-of-the-art in depth completion and uncertainty estimation for single-view methods on mobile GPUs. We further present a new aerial depth completion dataset that exhibits challenging depth completion scenarios and an open-source, visual-inertial UAV simulator for photo-realistic data generation. Our results show that our network trained on this dataset can be deployed on real-world aerial public datasets without tuning or style transfer.

- EVDodgeNet: Deep Dynamic Obstacle Dodging with Event Cameras

    Author: J Sanket, Nitin | University of Maryland, College Park
    Author: Parameshwara, Chethan | University of Maryland, College Park
    Author: Singh, Chahat | University of Maryland, College Park
    Author: Kuruttukulam, Ashwin Varghese | University of Maryland
    Author: Fermuller, Cornelia | University of Maryland
    Author: Scaramuzza, Davide | University of Zurich
    Author: Aloimonos, Yiannis | University of Maryland
 
    keyword: Aerial Systems: Perception and Autonomy; Deep Learning in Robotics and Automation; Visual-Based Navigation

    Abstract : Dynamic obstacle avoidance on quadrotors requires low latency. A class of sensors that are particularly suitable for such scenarios are event cameras. In this paper, we present a deep learning based solution for dodging multiple dynamic obstacles on a quadrotor with a single event camera and on-board computation. Our approach uses a series of shallow neural networks for estimating both the ego-motion and the motion of independently moving objects. The networks are trained in simulation and directly transfer to the real world without any fine-tuning or retraining. <p>We successfully evaluate and demonstrate the proposed approach in many real-world experiments with obstacles of different shapes and sizes, achieving an overall success rate of 70% including objects of unknown shape and a low light testing scenario. To our knowledge, this is the first deep learning - based solution to the problem of dynamic obstacle avoidance using event cameras on a quadrotor. Finally, we also extend our work to the pursuit task by merely reversing the control policy, proving that our navigation stack can cater to different scenarios.

- Direct Visual-Inertial Ego-Motion Estimation Via Iterated Extended Kalman Filter

    Author: Zhong, Shangkun | City University of Hong Kong
    Author: Chirarattananon, Pakpong | City University of Hong Kong
 
    keyword: Visual-Based Navigation; Aerial Systems: Perception and Autonomy; Range Sensing

    Abstract : This paper proposes a reactive navigation strategy for recovering the altitude, translational velocity and orientation of Micro Aerial Vehicles. The main contribution lies in the direct and tight fusion of Inertial Measurement Unit (IMU) measurements with monocular feedback under an assumption of a single planar scene. An Iterated Extended Kalman Filter (IEKF) scheme is employed. The state prediction makes use of IMU readings while the state update relies directly on photometric feedback as measurements. Unlike feature-based methods, the photometric difference for the innovation term renders an inherent and robust data association process in a single step. The proposed approach is validated using real-world datasets. The results show that the proposed method offers better robustness, accuracy, and efficiency than a feature-based approach. Further investigation suggests that the accuracy of the flight velocity estimates from the proposed approach is comparable to those of two state-of-the-art Visual Inertial Systems (VINS) while the proposed framework is &#8776;15-30 times faster thanks to the omission of reconstruction and mapping.

- A Robust UAV System for Operations in a Constrained Environment

    Author: Petrlik, Matej | Czech Technical University in Prague, Faculty of Electrical Engi
    Author: Baca, Tomas | Czech Technical Univerzity in Prague
    Author: Hert, Daniel | Czech Technical University in Prague
    Author: Vrba, Matous | Faculty of Electrical Engineering, Czech Technical University In
    Author: Krajn�k, Tom� | Czech Technical University
    Author: Saska, Martin | Czech Technical University in Prague
 
    keyword: Aerial Systems: Perception and Autonomy; Search and Rescue Robots; Robotics in Hazardous Fields

    Abstract : In this letter we present an autonomous system intended for aerial monitoring, inspection and assistance in Search and Rescue (SAR) operations within a constrained workspace. The proposed system is designed for deployment in demanding real-world environments with extremely narrow passages only slightly wider than the aerial platform, and with limited visibility due to the absence of illumination and the presence of dust. The focus is on precise localization in an unknown environment, high robustness, safety and fast deployment without any need to install an external infrastructure such as an external computer and localization system. These are the main requirements of the targeted SAR scenarios. The performance of the proposed system was successfully evaluated in the Tunnel Circuit of the DARPA Subterranean Challenge, where the UAV cooperated with ground robots to precisely localize artifacts in a coal mine tunnel system. The challenge was unique due to the intention of the organizers to emulate the unpredictable conditions of a real SAR operation, in which there is no prior knowledge of the obstacles that will be encountered.

- On Training Datasets for Machine Learning-Based Visual Relative Localization of Micro-Scale UAVs

    Author: Walter, Viktor | Czech Technical University
    Author: Vrba, Matous | Faculty of Electrical Engineering, Czech Technical University In
    Author: Saska, Martin | Czech Technical University in Prague
 
    keyword: Aerial Systems: Perception and Autonomy; Multi-Robot Systems; Deep Learning in Robotics and Automation

    Abstract : By leveraging our relative Micro-scale Unmanned Aerial Vehicle localization sensor UVDAR, we generated an automatically annotated dataset MIDGARD, which the community is invited to use for training and testing their machine learning systems for the detection and localization of Micro-scale Unmanned Aerial Vehicles (MAVs) by other MAVs. Furthermore, we provide our system as a mechanism for rapidly generating custom annotated datasets specifically tailored for the needs of a given application. The recent literature is rich in applications of machine learning methods in automation and robotics. One particular subset of these methods is visual object detection and localization, using means such as Convolutional Neural Networks, which nowadays enable objects to be detected and classified with previously inconceivable precision and reliability. Most of these applications, however, rely on a carefully crafted training dataset of annotated camera footage. These must contain the objects of interest in environments similar to those where the detector is expected to operate. Notably, the positions of the objects must be provided in annotations. For non-laboratory settings, the construction of such datasets requires many man-hours of manual annotation, which is especially the case for use onboard Micro-scale Unmanned Aerial Vehicles. In this paper, we are providing for the community a practical alternative to that kind of approach.

- Fast Frontier-Based Information-Driven Autonomous Exploration with an MAV

    Author: Dai, Anna | ETH Zurich
    Author: Papatheodorou, Sotiris | Imperial College London
    Author: Funk, Nils | Imperial College London
    Author: Tzoumanikas, Dimos | Imperial College London
    Author: Leutenegger, Stefan | Imperial College London
 
    keyword: Aerial Systems: Perception and Autonomy; Visual-Based Navigation

    Abstract : Exploration and collision-free navigation through an unknown environment is a fundamental task for autonomous robots. In this paper, a novel exploration strategy for Micro Aerial Vehicles (MAVs) is presented. The goal of the exploration strategy is the reduction of map entropy regarding occupancy probabilities, which is reflected in a utility function to be maximised. We achieve fast and efficient exploration performance with tight integration between our octree-based occupancy mapping approach, frontier extraction, and motion planning--as a hybrid between frontier-based and sampling-based exploration methods. The computationally expensive frontier clustering employed in classic frontier-based exploration is avoided by exploiting the implicit grouping of frontier voxels in the underlying octree map representation. Candidate next-views are sampled from the map frontiers and are evaluated using a utility function combining map entropy and travel time, where the former is computed efficiently using sparse raycasting. These optimisations along with the targeted exploration of frontier-based methods result in a fast and computationally efficient exploration planner. The proposed method is evaluated using both simulated and real-world experiments, demonstrating clear advantages over state-of-the-art approaches.

- Dynamic Landing of an Autonomous Quadrotor on a Moving Platform in Turbulent Wind Conditions

    Author: Paris, Aleix | Massachusetts Institute of Technology
    Author: Lopez, Brett Thomas | Massachusetts Institute of Technology
    Author: How, Jonathan Patrick | Massachusetts Institute of Technology
 
    keyword: Aerial Systems: Perception and Autonomy; Aerial Systems: Mechanics and Control

    Abstract : Autonomous landing on a moving platform presents unique challenges for multirotor vehicles, including the need to accurately localize the platform, fast trajectory planning, and precise/robust control. Previous works studied this problem but most lack explicit consideration of the wind disturbance, which typically leads to slow descents onto the platform. This work presents a fully autonomous vision-based system that addresses these limitations by tightly coupling the localization, planning, and control, thereby enabling fast and accurate landing on a moving platform. The platform's position, orientation, and velocity are estimated by an extended Kalman filter using simulated GPS measurements when the quadrotor-platform distance is large, and by a visual fiducial system when the platform is nearby. The landing trajectory is computed online using receding horizon control and is followed by a boundary layer sliding controller that provides tracking performance guarantees in the presence of unknown, but bounded, disturbances. To improve the performance, the characteristics of the turbulent conditions are accounted for in the controller. The landing trajectory is fast, direct, and does not require hovering over the platform, as is typical of most state-of-the-art approaches. Simulations and hardware experiments are presented to validate the robustness of the approach.

- Cross-Drone Binocular Coordination for Ground Moving Target Tracking in Occlusion-Rich Scenarios

    Author: Chang, Yuan | National University of Defense Technology
    Author: Zhou, Han | National University of Defense Technology
    Author: Wang, Xiangke | National University of Defense Technology
    Author: Shen, Lincheng | National University of Defense Technology
    Author: Hu, Tianjiang | Sun Yat-Sen University
 
    keyword: Aerial Systems: Perception and Autonomy; Multi-Robot Systems; Visual Tracking

    Abstract : How to work effectively under occlusion-rich environments remains a challenge for airborne vision-based ground target tracking, due to the natural limitation of monocular vision. Given this, a novel cross-drone binocular coordination approach, inspired by the efficient coordination of human eyes, is proposed and developed. The idea, derived from neural models of the human visual system, is to utilize distributed target measurements to overcome occlusion effects. Eventually, a binocular coordination controller is developed. It enables two distributed pan-tilt cameras to execute synergistic movements similar to human eyes. The proposed approach is able to work based on binocular or monocular vision, and hence it is practically appropriate for various environments. Both testbed experiments and field experiments are conducted for performance evaluation. Testbed experiments highlight its advantages over independent tracking in terms of accuracy while being robust to a partial perception ratio of up to 43%. Field experiments with a pair of drones further demonstrate its effectiveness in the real-world scenarios.

- Direct NMPC for Post-Stall Motion Planning with Fixed-Wing UAVs

    Author: Basescu, Max | Johns Hopkins University Applied Physics Lab
    Author: Moore, Joseph | Johns Hopkins University Applied Physics Lab
 
    keyword: Aerial Systems: Perception and Autonomy; Aerial Systems: Mechanics and Control; Optimization and Optimal Control

    Abstract : Fixed-wing unmanned aerial vehicles (UAVs) offer significant performance advantages over rotary-wing UAVs in terms of speed, endurance, and efficiency. However, these vehicles have traditionally been severely limited with regards to maneuverability. In this paper, we present a nonlinear control approach for enabling aerobatic fixed-wing UAVs to maneuver in constrained spaces. Our approach utilizes full-state direct trajectory optimization and a minimalistic, but representative, nonlinear aircraft model to plan aggressive fixed-wing trajectories in real-time at 5 Hz across high angles-of-attack. Randomized motion planning is used to avoid local minima and local-linear feedback is used to compensate for model inaccuracies between updates. We demonstrate our method in hardware and show that both local-linear feedback and re-planning are necessary for successful navigation of a complex environment in the presence of model uncertainty.

-  IMU-Based Inertia Estimation for a Quadrotor Using Newton-Euler Dynamics

    Author: Svacha, James | University of Pennsylvania
    Author: Paulos, James | University of Pennsylvania
    Author: Loianno, Giuseppe | New York University
    Author: Kumar, Vijay | University of Pennsylvania


- A Flight Envelope Determination and Protection System for Fixed-Wing UAVs

    Author: Zogopoulos-Papaliakos, Georgios | National Technical University of Athens
    Author: Kyriakopoulos, Kostas | National Technical Univ. of Athens
 
    keyword: Aerial Systems: Perception and Autonomy; Motion Control; Optimization and Optimal Control

    Abstract : In this work we present a novel, approximate, efficient algorithm for determining the Trim Flight Envelope of a fixed-wing UAV, based on a generic, nonlinear numerical model. The resulting Flight Envelope is expressed as a convex intersection of half-spaces. Subsequently, a Model Predictive Controller (MPC) is designed which takes into account the Flight Envelope constraints, to avoid Loss-of-Control. The overall system is shown to operate in real-time in a simulation environment.

- AU-AIR: A Multi-Modal Unmanned Aerial Vehicle Dataset for Low Altitude Traffic Surveillance

    Author: Bozcan, &#304;lker | Middle East Technical University
    Author: Kayacan, Erdal | Aarhus University
 
    keyword: Aerial Systems: Perception and Autonomy; Object Detection, Segmentation and Categorization; Aerial Systems: Applications

    Abstract : Unmanned aerial vehicles (UAVs) with mounted cameras have the advantage of capturing aerial (bird-view) images. The availability of aerial visual data and the recent advances in object detection algorithms led the computer vision community to focus on object detection tasks on aerial images. As a result of this, several aerial datasets have been introduced, including visual data with object annotations. UAVs are used solely as flying-cameras in these datasets, discarding different data types regarding the flight (e.g., time, location, internal sensors). In this work, we propose a multi-purpose aerial dataset (AU-AIR) that has multi-modal sensor data (i.e., visual, time, location, altitude, IMU, velocity) collected in real-world outdoor environments. The AU-AIR dataset includes meta-data for extracted frames (i.e., bounding box annotations for trafficrelated object category) from recorded RGB videos. Moreover, we emphasize the differences between natural and aerial images in the context of object detection task. For this end, we train and test mobile object detectors (including YOLOv3- Tiny and MobileNetv2-SSDLite) on the AU-AIR dataset, which are applicable for real-time object detection using on-board computers with UAVs. Since our dataset has diversity in recorded data types, it contributes to filling the gap between computer vision and robotics. The dataset is available at https://bozcani.github.io/auairdataset.

- Design and Autonomous Stabilization of a Ballistically Launched Multirotor

    Author: Bouman, Amanda | Caltech
    Author: Nadan, Paul | Olin College
    Author: Anderson, Matthew | Jet Propulsion Laboratory
    Author: Pastor, Daniel | Caltech
    Author: Izraelevitz, Jacob | NASA Jet Propulsion Laboratory
    Author: Burdick, Joel | California Institute of Technology
    Author: Kennedy, Brett | Jet Propulsion Laboratory
 
    keyword: Aerial Systems: Perception and Autonomy; Aerial Systems: Applications

    Abstract : Aircraft that can launch ballistically and convert to autonomous, free-flying drones have applications in many areas such as emergency response, defense, and space exploration, where they can gather critical situational data using onboard sensors. This paper presents a ballistically-launched, autonomously-stabilizing multirotor prototype (SQUID - Streamlined Quick Unfolding Investigation Drone) with an onboard sensor suite, autonomy pipeline, and passive aerodynamic stability. We demonstrate autonomous transition from passive to vision-based, active stabilization, confirming the multirotor's ability to autonomously stabilize after a ballistic launch in a GPS-denied environment.

- Asynchronous Event-Based Clustering and Tracking for Intrusion Monitoring in UAS

    Author: Rodriguez-Gomez, Juan Pablo | University of Seville
    Author: G�mez Egu�luz, Augusto | University of Seville
    Author: Martinez-de-Dios, Jose Ramiro | University of Seville
    Author: Ollero, Anibal | University of Seville
 
    keyword: Aerial Systems: Perception and Autonomy; Aerial Systems: Applications; Computer Vision for Other Robotic Applications

    Abstract : Automatic surveillance and monitoring using Unmanned Aerial Systems (UAS) require the development of perception systems that robustly work under different illumination conditions. Event cameras are neuromorphic sensors that capture the illumination changes in the scene with very low latency and high dynamic range. Although recent advances in event-based vision have explored the use of event cameras onboard UAS, most techniques group events in frames and, therefore, do not fully exploit the sequential and asynchronous nature of the event stream. This paper proposes a fully asynchronous scheme for intruder monitoring using UAS. It employs efficient event clustering and feature tracking modules and includes a sampling mechanism to cope with the computational cost of event-by-event processing adapting to on-board hardware computational constraints. The proposed scheme was tested on a real multirotor in challenging scenarios showing significant accuracy and robustness to lighting conditions.

- SHIFT: Selective Heading Image for Translation, an Onboard Monocular Optical Flow Estimator for Fast Constantly Rotating UAVs

    Author: Ng, Matthew | Singapore University of Technology and Design
    Author: Tang, Emmanuel | Singapore University of Technology &amp; Design
    Author: Soh, Gim Song | Singapore University of Technology and Design
    Author: Foong, Shaohui | Singapore University of Technology and Design
 
    keyword: Aerial Systems: Perception and Autonomy; Aerial Systems: Applications; Computer Vision for Other Robotic Applications

    Abstract : Pose estimation is of paramount importance for flight control as well as localization and navigation of Unmanned Aerial Vehicles (UAVs) to enable autonomous operations. In environments without GPS, such estimation can only be determined using onboard sensors; optical flow using a monocular camera is a popular approach. Monocopters are a class of nature inspired UAVs known as free rotors where their design and flight dynamics are inspired by the falling samara seed. With a constantly rotating body frame, free rotors introduces some unique challenges for visual perception required during optical flow sensing. This paper addresses these problems with the introduction of SHIFT (Selective Heading Image for Translation) that selects optimal images for determining translation with optical flow. It achieves this by decoupling rotation vectors about the optical axis from translation vectors in a flow field through the separate tracking of orientation and position using an Unscented Kalman Filter with phase correlation in the log-polar and spatial domain. The experiments show that SHIFT's estimation in orientation is stable even under sinusoidal excitation with a median absolute percentage errors of less than 1%. It is able to track position and orientation of a UAV accurately.

- Flydar: Magnetometer-Based High Angular Rate Estimation During Gyro Saturation for SLAM

    Author: Tan, Chee How | Singapore University of Technology &amp; Design
    Author: Sufiyan, Danial | Singapore University of Technology &amp; Design
    Author: Tang, Emmanuel | Singapore University of Technology &amp; Design
    Author: Khaw, Jien-Yi | Singapore University of Technology &amp; Design
    Author: Soh, Gim Song | Singapore University of Technology and Design
    Author: Foong, Shaohui | Singapore University of Technology and Design
 
    keyword: Aerial Systems: Perception and Autonomy; Range Sensing; Sensor Fusion

    Abstract : In this paper, the high angular rate estimation for simultaneous localisation and mapping (SLAM) of a Flying Li-DAR (Flydar) is presented. The proposed EKF-based algorithm exploits the sinusoidal magnetometer measurement generated by the continuously rotating airframe for estimation of the robot hovering angular velocity. Significantly, the proposed method does not rely on additional sensors other than existing IMU sensors already being used for flight stabilization. The gyro measurement and the gyro bias are incorporated as a control input and a filter state respectively to enable estimation even under gyro saturation. Additionally, this work proposes leveraging on the inherently rotating locomotion to generate a planar lidar scan using only a single-point laser for possible lightweight autonomy. The proposed estimation method was experimentally evaluated on a ground rotating rig up to twice the gyro saturation limit with an effective rms error of 0.0045Hz; and on the proposed aerial platform - Flydar - hovering beyond the saturation limit with a rms error of 0.0056Hz. Lastly, the proposed method for SLAM using the rotating dynamics of Flydar was demonstrated with a localisation accuracy of 0.11m.

- Nonlinear MPC with Motor Failure Identification and Recovery for Safe and Aggressive Multicopter Flight

    Author: Tzoumanikas, Dimos | Imperial College London
    Author: Yan, Qingyue | Imperial College London
    Author: Leutenegger, Stefan | Imperial College London
 
    keyword: Aerial Systems: Perception and Autonomy

    Abstract : Safe and precise reference tracking is a crucial characteristic of Micro Aerial Vehicles (MAVs) that have to operate under the influence of external disturbances in cluttered environments. In this paper, we present a Model Predictive Controller (MPC) that exploits the fully physics based non-linear dynamics of the system. We furthermore show how the control inputs can be transformed into feasible actuator commands. In order to guarantee safe operation despite potential loss of a motor under which we show our system keeps operating safely, we developed an ac{EKF} based motor failure identification algorithm. We verify the effectiveness of the developed pipeline in flight experiments with and without motor failures.

## Autonomous Vehicle Navigation

- Autonomous Navigation in Inclement Weather Based on a Localizing Ground Penetrating Radar

    Author: Ort, Teddy | Massachusetts Institute of Technology
    Author: Gilitschenski, Igor | Massachusetts Institute of Technology
    Author: Rus, Daniela | MIT
 
    keyword: Autonomous Vehicle Navigation; Wheeled Robots; Intelligent Transportation Systems

    Abstract : Most autonomous driving solutions require some method of localization within their environment. The GPS has not been widely adopted for autonomous driving because it is neither sufficiently precise, nor robust. Instead, state-of-the art autonomous driving systems use onboard sensors such as cameras or LiDAR to localize the robot precisely in a previously recorded map. However, these solutions are sensitive to ambient lighting conditions such as darkness and inclement weather. Additionally the maps can become outdated in a rapidly changing environment and require continuous updating. While LiDAR systems don't require visible light, they are sensitive to weather such as fog, or snow, which can interfere with localization. In this paper, we utilize a Ground Penetrating Radar (GPR) sensor to obtain precise vehicle localization. By mapping and localizing using features beneath the ground, we obtain features that are both stable over time, and maintain their appearance during changing ambient weather and lighting conditions. We incorporate this solution into a full-scale autonomous vehicle and evaluate the performance on over 17 km of testing data in a variety of challenging weather conditions. We find that this novel sensing modality is capable of providing precise localization for autonomous navigation without using cameras or LiDAR sensors.

- Robot Navigation in Crowds by Graph Convolutional Networks with Attention Learned from Human Gaze

    Author: Chen, Yuying | Hong Kong University of Science and Technology
    Author: Liu, Congcong | Hong Kong University of Science and Technology
    Author: Shi, Bertram Emil | Hong Kong University of Science and Technology
    Author: Liu, Ming | Hong Kong University of Science and Technology
 
    keyword: Autonomous Vehicle Navigation; Social Human-Robot Interaction; Deep Learning in Robotics and Automation

    Abstract : Safe and efficient crowd navigation for mobile robot is a crucial yet challenging task. Previous work has shown the power of deep reinforcement learning frameworks to train efficient policies. However, their performance deteriorates when the crowd size grows. We suggest that this can be addressed by enabling the network to identify and pay attention to the humans in the crowd that are most critical to navigation. We propose a novel network utilizing a graph representation to learn the policy. We first train a graph convolutional network based on human gaze data that accurately predicts human attention to different agents in the crowd as they perform a navigation task based on a top down view of the environment. We incorporate the learned attention into a graph-based reinforcement learning architecture. The proposed attention mechanism enables the assignment of meaningful weightings to the neighbors of the robot, and has the additional benefit of interpretability. Experiments on real-world dense pedestrian datasets with various crowd sizes demonstrate that our model outperforms state-of-art methods, increasing the task completion rate by 18.4% and decreasing navigation time by 16.4%.

- Wall Deadlock Evasion Control Based on Rotation Radius Adjustment

    Author: Kojima, Shotaro | Tohoku University
    Author: Ohno, Kazunori | Tohoku University
    Author: Suzuki, Takahiro | Tohoku University
    Author: Okada, Yoshito | Tohoku University
    Author: Westfechtel, Thomas | Tohoku University
    Author: Tadokoro, Satoshi | Tohoku University
 
    keyword: Autonomous Vehicle Navigation; Motion Control; Dynamics

    Abstract : This paper describes a wall deadlock evasion method for tracked vehicles. Wall deadlock is a phenomenon where the robot cannot rotate to the commanded direction when it collides with a wall, because the motion is restricted by the wall. The key idea behind solving this problem involves an adjustment of the rotation radius to generate sufficient rotational moment. There are several approaches to generate a rotational moment; however, no previous solution has been established to address this problem by adjusting the rotation radius based on the dynamics of wall deadlock. In this paper, the     Authors propose a new wall deadlock evasion method based on the sufficient rotation radius estimation. Experimental results show that the robot can generate rotational motion that satisfies conditions expected by the model. The wall deadlock evasion method is implemented and shows improved performance in terms of reproducibility of motion compared with the different approach proposed in our previous work. Wall deadlock evasion provides more choices of motion such as being as close to the obstacles as possible and ensures that the robot can continue locomotion after such motion. By handling wall deadlock, the robots can utilize surrounding walls for motion in situations such as relative positioning or driving in fixed lanes.

- Socially-Aware Reactive Obstacle Avoidance Strategy Based on Limit Cycle

    Author: Boldrer, Manuel | University of Trento
    Author: Andreetto, Marco | University of Trento
    Author: Divan, Stefano | University of Trento
    Author: Palopoli, Luigi | University of Trento
    Author: Fontanelli, Daniele | University of Trento
 
    keyword: Autonomous Vehicle Navigation; Collision Avoidance; Sensor-based Control

    Abstract :  The paper proposes a combination of ideas to support navigation for a<p> mobile robot across dynamic environments, cluttered with obstacles and populated by human beings. The combination of the classical potential field methods and limit cycle based approach with an innovative shape for the limit cycles, generates paths which are reasonably short, smooth and comfortable to follow (which can be very important for assistive robots), and it respects the safety and psychological comfort of the by-standers by staying clear of their private space.

- Multi-Head Attention for Multi-Modal Joint Vehicle Motion Forecasting

    Author: Mercat, Jean | 1991
    Author: Gilles, Thomas | Polytechnique
    Author: El Zoghby, Nicole | RENAULT
    Author: Sandou, Guillaume | SUPELEC
    Author: Dominique, Beauvois | Sup�lec
    Author: Guillermo, Pita Gil | Renault
 
    keyword: Intelligent Transportation Systems; Deep Learning in Robotics and Automation; Motion and Path Planning

    Abstract : This paper presents a novel vehicle motion forecasting method based on multi-head attention. It produces joint forecasts for all vehicles on a road scene as sequences of multi-modal probability density functions of their positions. Its architecture uses multi-head attention to account for complete interactions between all vehicles, and long short-term memory layers for encoding and forecasting. It relies solely on vehicle position tracks, does not need maneuver definitions, and does not represent the scene with a spatial grid. This allows it to be more versatile than similar model while combining many forecasting capabilities, namely joint forecast with interactions, uncertainty estimation, and multi-modality. The resulting prediction likelihood outperforms state-of-the-art models on the same dataset.

- Temporal Information Integration for Video Semantic Segmentation

    Author: Guarino, Guillaume | INSA Strasbourg
    Author: Chateau, Thierry | Clermont Auvergne University
    Author: Teuliere, Celine | Institut Pascal, Clermont Auvergne University
    Author: Antoine, Violaine | Clermont Auvergne University, LIMOS
 
    keyword: Autonomous Vehicle Navigation; Semantic Scene Understanding

    Abstract : We present a temporal Bayesian filter for semantic segmentation of a video sequence. Each pixel is a random variable following a discrete probabilistic distribution function representing possible semantic classes (eg. road, pedestrian, traffic sign,... for autonomous driving applications). Bayesian filtering consists in two main steps: 1) a prediction model and 2) an observation model (likelihood). We propose to use a data-driven prediction function derived from a dense optical flow between images t and t+1 achieved by a deep neural network. Moreover, the observation function uses a semantic segmentation network. The resulting approach is evaluated on the public dataset Cityscapes. We show that using the temporal filtering increases the accuracy of the semantic segmentation.

- Map-Predictive Motion Planning in Unknown Environments

    Author: Elhafsi, Amine | Stanford University
    Author: Ivanovic, Boris | Stanford University
    Author: Janson, Lucas | Harvard University
    Author: Pavone, Marco | Stanford University
 
    keyword: Autonomous Vehicle Navigation; Motion and Path Planning; Deep Learning in Robotics and Automation

    Abstract : Algorithms for motion planning in unknown environments are generally limited in their ability to reason about the structure of the unobserved environment. As such, current methods generally navigate unknown environments by relying on heuristic methods to choose intermediate objectives along frontiers. We present a unified method that combines map prediction and motion planning for safe, time-efficient autonomous navigation of unknown environments by dynamically-constrained robots. We propose a data-driven method for predicting the map of the unobserved environment, using the robot's observations of its surroundings as context. These map predictions are then used to plan trajectories from the robot's position to the goal without requiring frontier selection. We applied this map-predictive motion planning strategy to randomly generated winding hallway environments, yielding substantial improvement in trajectory duration over a naive frontier pursuit method. We also experimentally demonstrate similar performance to methods using more sophisticated frontier selection heuristics while significantly reducing computation time.

- Using Multiple Short Hops for Multicopter Navigation with Only Inertial Sensors

    Author: Wu, Xiangyu | University of California, Berkeley
    Author: Mueller, Mark Wilfried | University of California, Berkeley
 
    keyword: Autonomous Vehicle Navigation; Aerial Systems: Applications; Localization

    Abstract : In certain challenging environments, such as inside buildings on fire, the main sensors (e.g. cameras, LiDARs and GPS systems) used for multicopter localization can become unavailable. Direct integration of the inertial navigation sensors (the accelerometer and rate gyroscope), is however unaffected by external disturbances, but the rapid error accumulation quickly makes a naive application of such a strategy feasible only for very short durations. In this work we propose a motion strategy for reducing the inertial navigation state estimation error of multicopters. The proposed strategy breaks a long duration flight into multiple short duration hops between which the vehicle remains stationary on the ground. When the vehicle is stationary, zero-velocity pseudo-measurements are introduced to an extended Kalman Filter to reduce the state estimation error. We perform experiments for closed-loop control of a multicopter for evaluation. The mean absolute position estimation error was 3.4% over a total flight distance of 5m in the experiments. The results showed a 80% reduction compared to the standard inertial navigation method without using this strategy. In addition, an additional experiment with total flight distance of 10m is conducted to demonstrate the ability of this method to navigate a multicopter in real-world environment. The final trajectory tracking error was 3% of the total flight distance.

- An Efficient and Continuous Approach to Information-Theoretic Exploration

    Author: Henderson, Theia | Massachusetts Institute of Technology
    Author: Sze, Vivienne | Massachusetts Institute of Technology
    Author: Karaman, Sertac | Massachusetts Institute of Technology
 
    keyword: Autonomous Vehicle Navigation; Motion and Path Planning; Search and Rescue Robots

    Abstract : Exploration of unknown environments is embedded and essential in many robotics applications. Traditional algorithms, that decide where to explore by computing the expected information gain of an incomplete map from future sensor measurements, are limited to very powerful computational platforms. In this paper, we describe a novel approach for computing this expected information gain efficiently, as principally derived via mutual information. The key idea behind the proposed approach is a continuous occupancy map framework and the recursive structure it reveals. This structure makes it possible to compute the expected information gain of sensor measurements across an entire map much faster than computing each measurements' expected gain independently. Specifically, for an occupancy map composed of |M| cells and a range sensor that emits |T| measurement beams, the algorithm (titled FCMI) computes the information gain corresponding to measurements made at each cell in O(|T||M|) steps. To the best of our knowledge, this complexity bound is better than all existing methods for computing information gain. In our experiments, we observe that this novel, continuous approach is two orders of magnitude faster than the state-of-the-art FSMI algorithm.

- A Feature-Based Underwater Path Planning Approach Using Multiple Perspective Prior Maps

    Author: Cagara, Daniel | Queensland University of Technology
    Author: Dunbabin, Matthew | Queensland University of Technology
    Author: Rigby, Paul | Australian Institute of Marine Science
 
    keyword: Autonomous Vehicle Navigation; Visual-Based Navigation; Marine Robotics

    Abstract : This paper presents a path planning methodology which enables Autonomous Underwater Vehicles (AUVs) to navigate in shallow complex environments such as coral reefs. The approach leverages prior information from an aerial photographic survey, and derived bathymetric information of the corresponding area. From these prior maps, a set of features is obtained which define an expected arrangement of objects and bathymetry likely to be perceived by the AUV when underwater. A navigation graph is then constructed by predicting the arrangement of features visible from a set of test points within the prior, which allows the calculation of the shortest paths from any pair of start and destination points. A maximum likelihood function is defined which allows the AUV to match its observations to the navigation graph as it undertakes its mission. To improve robustness, the history of observed features are retained to facilitate possible recovery from non-detectable or misclassified objects. The approach is evaluated using a photo-realistic simulated environment, and results illustrate the merits of the approach even when only a relatively small number of features can be identified from the prior map.

- Automatic LiDAR-Camera Calibration of Extrinsic Parameters Using a Spherical Target

    Author: T�th, Tekla | E�tv's Lor�nd University
    Author: Pusztai, Zolt�n | E�tv's Lorand University
    Author: Hajder, Levente | E�tv's Lor�nd University
 
    keyword: Autonomous Vehicle Navigation; Object Detection, Segmentation and Categorization; Sensor Fusion

    Abstract : This paper investigates a novel calibration process of devices with different modalities, which is a critical step of computer vision applications. We propose a fully automatic extrinsic calibration of a LiDAR-camera system. Our approach applies sphere as their surfaces and contours can be accurately detected on point clouds and camera images, respectively. Experiments on synthetic and real data exhibits that our automatic algorithm is fast and robust and it yields accurate camera and LiDAR extrinsic parameters.

## Mapping
- A Unified Framework for Piecewise Semantic Reconstruction in Dynamic Scenes Via Exploiting Superpixel Relations

    Author: Di, Yan | Tsinghua University
    Author: Morimitsu, Henrique | Tsinghua University
    Author: Lou, ZhiQiang | Tsinghua University
    Author: Ji, Xiangyang | Tsinghua University
 
    keyword: Mapping; SLAM; Localization

    Abstract : This paper presents a novel framework for dense piecewise semantic reconstruction in dynamic scenes containing complex background and moving objects via exploiting superpixel relations. We utilize two kinds of superpixel relations: motion relations and spatial relations, each having three subcategories: coplanar, hinge and crack. Spatial relations provide constraints on the spatial locations of neighboring superpixels and thus can be used to reconstruct dynamic scenes. However, spatial relations can not be estimated directly with epipolar geometry due to moving objects in dynamic scenes. We synthesize the results of semantic instance segmentation and motion relations to estimate spatial relations. Given consecutive frames, we mainly develop our method in five main stages: preprocessing, motion estimation, superpixel relation analysis, reconstruction and refinement. Extensive experiments on various datasets demonstrate that our method outperforms competitors in reconstruction quality. Furthermore, our method presents a feasible way to incorporate semantic information in Structure-from-Motion (SFM) based reconstruction pipelines.

- Keyframe-Based Dense Mapping with the Graph of View-Dependent Local Maps

    Author: Belter, Dominik | Poznan University of Technology
    Author: Zieli&#324;ski, Krzysztof | Institute of Control, Robotics and Information Engineering, Pozn
 
    keyword: Mapping; Range Sensing; RGB-D Perception

    Abstract : In this article, we propose a new keyframe-based mapping system. The proposed method updates local Normal Distribution Transform maps (NDT) using data from an RGB-D sensor. The cells of the NDT are stored in 2D view-dependent structures to better utilize the properties and uncertainty model of RGB-D cameras. This method naturally represents an object closer to the camera origin with higher precision. The local maps are stored in the pose graph which allows correcting global map after loop closure detection. We also propose a procedure that allows merging and filtering local maps to obtain a global map of the environment. Finally, we compare our method with Octomap and NDT-OM and provide example applications of the proposed mapping method.

- Informative Path Planning for Active Mapping under Localization Uncertainty

    Author: Popovic, Marija | Imperial College London
    Author: Vidal-Calleja, Teresa A. | University of Technology Sydney
    Author: Chung, Jen Jen | Eidgen�ssische Technische Hochschule Zurich
    Author: Nieto, Juan | ETH Zurich
    Author: Siegwart, Roland | ETH Zurich
 
    keyword: Mapping; Planning, Scheduling and Coordination; Motion and Path Planning

    Abstract : Information gathering algorithms play a key role in unlocking the potential of robots for efficient data collection in a wide range of applications. However, most existing strategies neglect the fundamental problem of the robot pose uncertainty, which is an implicit requirement for creating robust, high-quality maps. To address this issue, we introduce an informative planning framework for active mapping that explicitly accounts for the pose uncertainty in both the mapping and planning tasks. Our strategy exploits a Gaussian Process (GP) model to capture a target environmental field given the uncertainty on its inputs. For planning, we formulate a new utility function that couples the localization and field mapping objectives in GP-based mapping scenarios in a principled way, without relying on manually-tuned parameters. Extensive simulations show that our approach outperforms existing strategies, reducing mean pose uncertainty and map error. We present a proof of concept in an indoor temperature mapping scenario.

- Ensemble of Sparse Gaussian Process Experts for Implicit Surface Mapping with Streaming Data

    Author: Stork, Johannes A. | Orebro University
    Author: Stoyanov, Todor | Örebro University
 
    keyword: Mapping; Range Sensing; Learning and Adaptive Systems

    Abstract : Creating maps is an essential task in robotics and provides the basis for effective planning and navigation. In this paper, we learn a compact and continuous implicit surface map of an environment from a stream of range data with known poses.For this, we create and incrementally adjust an ensemble of approximate Gaussian process (GP) experts which are each responsible for a different part of the map. Instead of inserting all arriving data into the GP models, we greedily trade-off between model complexity and prediction error. Our algorithm therefore uses less resources on areas with few geometric features and more where the environment is rich in variety. We evaluate our approach on synthetic and real-world data sets and analyze sensitivity to parameters and measurement noise. The results show that we can learn compact and accurate implicit surface models under different conditions, with a performance comparable to or better than that of exact GP regression with subsampled data.

- Robust Method for Removing Dynamic Objects from Point Clouds

    Author: Pagad, Shishir | Nio
    Author: Agarwal, Divya | NIO Automotive, Purdue University
    Author: Kasturi Rangan, Sathya Narayanan | NIO
    Author: Kim, Hyungjin | NIO USA Inc
    Author: Yalla, Ganesh | Capella Space
 
    keyword: Mapping; SLAM; Object Detection, Segmentation and Categorization

    Abstract : 3D point cloud maps are an accumulation of laser scans obtained at different positions and times. Since laser scans represent a snapshot of the surrounding at the time of capture, they often contain moving objects which may not be observed at all times. Dynamic objects in point cloud maps decrease the quality of maps and affect localization accuracy, hence it is important to remove the dynamic objects from 3D point cloud maps. In this paper, we present a robust method to remove dynamic objects from 3D point cloud maps. Given a registered set of 3D point clouds, we build an occupancy map in which the voxels represent the occupancy state of the volume of space over an extended time period. After building the occupancy map, we use it as a filter to remove dynamic points in lidar scans before adding the points to the map. Furthermore, we accelerate the process of building occupancy maps using object detection and a novel voxel traversal method. Once the occupancy map is built, dynamic object removal can run in real-time. Our approach works well on wide urban roads with stopped or moving traffic and the occupancy maps get better with the inclusion of more lidar scans from the same scene.

- Skeleton-Based Conditionally Independent Gaussian Process Implicit Surfaces for Fusion in Sparse to Dense 3D Reconstruction

    Author: Wu, Lan | University of Technology Sydney
    Author: Falque, Raphael | University of Technology Sydney
    Author: Perez-Puchalt, Victor | EPFL
    Author: Liu, Liyang | University of Technology Sydney
    Author: Pietroni, Nico | University of Technology Sydney
    Author: Vidal-Calleja, Teresa A. | University of Technology Sydney
 
    keyword: Mapping; RGB-D Perception

    Abstract : 3D object reconstructions obtained from 2D or 3D cameras are typically noisy. Probabilistic algorithms are suitable for information fusion and can deal with noise robustly. Consequently, these algorithms can be useful for accurate surface reconstruction. This paper presents an approach to estimate a probabilistic representation of the implicit surface of 3D objects. One of the contributions of the paper is the pipeline for generating an accurate reconstruction, given a set of sparse points that are close to the surface and a dense noisy point cloud. A novel submapping method following the topology of the object is proposed to generate conditional independent Gaussian Process Implicit Surfaces. This allows inference and fusion mechanisms to be performed in parallel followed by information propagation through the submaps. Large datasets can efficiently be processed by the proposed pipeline producing not only a surface but also the uncertainty information of the reconstruction. We evaluate the performance of our algorithm using simulated and real datasets.

- Motion Estimation in Occupancy Grid Maps in Stationary Settings Using Recurrent Neural Networks

    Author: Schreiber, Marcel | Ulm University
    Author: Belagiannis, Vasileios | Universitét Ulm
    Author: Glaeser, Claudius | Robert Bosch GmbH
    Author: Dietmayer, Klaus | University of Ulm
 
    keyword: Mapping; Intelligent Transportation Systems; Deep Learning in Robotics and Automation

    Abstract : In this work, we tackle the problem of modeling the vehicle environment as dynamic occupancy grid map in complex urban scenarios using recurrent neural networks. Dynamic occupancy grid maps represent the scene in a bird's eye view, where each grid cell contains the occupancy probability and the two dimensional velocity. As input data, our approach relies on measurement grid maps, which contain occupancy probabilities, generated with lidar measurements. Given this configuration, we propose a recurrent neural network architecture to predict a dynamic occupancy grid map, i.e. filtered occupancy and velocity of each cell, by using a sequence of measurement grid maps. Our network architecture contains convolutional long-short term memories in order to sequentially process the input, makes use of spatial context, and captures motion. In the evaluation, we quantify improvements in estimating the velocity of braking and turning vehicles compared to the state-of-the-art. Additionally, we demonstrate that our approach provides more consistent velocity estimates for dynamic objects, as well as, less erroneous velocity estimates in static area.

- A Divide and Conquer Method for 3D Registration of Inhomogeneous, Partially Overlapping Scans with Fourier Mellin SOFT (FMS)

    Author: Buelow, Heiko | Jacobs University
    Author: Mueller, Christian Atanas | Jacobs University
    Author: Gomez Chavez, Arturo | Jacobs University Bremen GGmbH
    Author: Buda, Frederike | Jacobs University
    Author: Birk, Andreas | Jacobs University
 
    keyword: Mapping; Big Data in Robotics and Automation

    Abstract : High-end laser range-finders provide accurate 3D data over long ranges. But their scans are inhomogeneous, i.e., the environment is non-uniformly sampled, as there is denser data in the near range than in the far range. Furthermore, the generation of a scan is time-consuming. Thus, it is desirable to cover an area by as few scans as possible, i.e., scanning is more time-efficient if the overlap between scans is as small as possible. However, these factors pose significant challenges for state-of-the-art registration algorithms. In this work, we present a divide-and-conquer method that uses an efficient strategy to check for possible registrations between partitions of two scans. As underlying registration method, Fourier-Mellin-SOFT (FMS) is used. FMS is quite robust against partial overlaps but its performance is significantly boosted by the presented partitioning method. As concrete use case, results from the digitization of a WWII submarine bunker as a large-scale cultural heritage site are presented.

- Estimating Motion Uncertainty with Bayesian ICP

    Author: Afzal Maken, Fahira | The University of Sydney
    Author: Ramos, Fabio | University of Sydney, NVIDIA
    Author: Ott, Lionel | University of Sydney
 
    keyword: Mapping

    Abstract : Estimating the uncertainty associated with the pose transformation between two 3D point clouds is critical for autonomous navigation, grasping, and data fusion. Iterative closest point (ICP) is widely used to estimate the transformation between point cloud pairs by iteratively performing data association and motion estimation. Despite its success and popularity, ICP is effectively a deterministic algorithm, and attempts to formulate it in a probabilistic manner generally do not model all sources of uncertainty, such as data association errors and sensor noise. This leads to overconfident transformation estimates, potentially compromising the robustness of the system. In this paper we propose a novel method to estimate pose uncertainty in ICP with a Markov Chain Monte Carlo (MCMC) algorithm. Our method combines recent developments in optimization such as stochastic gradient Langevin dynamics (SGLD) and scalable Bayesian sampling to infer a full posterior distribution of the pose transformation given two point clouds and a prior distribution. We call this method Bayesian ICP. Experiments using 3D Kinect data shows that our method is capable of estimating pose uncertainty accurately, taking into account data association uncertainty as reflected by the shape of the objects.

- Actively Mapping Industrial Structures with Information Gain-Based Planning on a Quadruped Robot

    Author: Wang, Yiduo | University of Oxford
    Author: Ramezani, Milad | University of Oxford
    Author: Fallon, Maurice | University of Oxford
 
    keyword: Mapping; Legged Robots; Motion and Path Planning

    Abstract : In this paper, we develop an online active mapping system to enable a quadruped robot to autonomously survey large physical structures. We describe the perception, planning and control modules needed to scan and reconstruct an object of interest, without requiring a prior model. The system builds a voxel representation of the object, and iteratively determines the Next-Best-View (NBV) to extend the representation, according to both the reconstruction itself and to avoid collisions with the environment. By computing the expected information gain of a set of candidate scan locations sampled on the as-sensed terrain map, as well as the cost of reaching these candidates, the robot decides the NBV for further exploration. The robot plans an optimal path towards the NBV, avoiding obstacles and un-traversable terrain. Experimental results on both simulated and real-world environments show the capability and efficiency of our system. Finally we present a full system demonstration on the real robot, the ANYbotics ANYmal, autonomously reconstructing a building facade and an industrial structure.

- Efficient Covisibility-Based Image Matching for Large-Scale SfM

    Author: Ye, Zhichao | Zhejiang University
    Author: Zhang, Guofeng | Zhejiang University
    Author: Bao, Hujun | Zhejiang University
 
    keyword: Mapping; Visual Tracking

    Abstract : Obtaining accurate and sufficient feature matches is crucial for robust large-scale Structure-from-Motion. For unordered image collections, a traditional feature matching method with geometric verification requires a huge cost to find sufficient feature matches. Although several methods have been proposed to speed up this stage, none of them makes full use of existing matches. In this paper, we propose a novel efficient image matching method by using the transitivity of region covisibility. The overlapping image pairs can be efficiently found in an iterative matching strategy even only with few inlier feauture matches. The experimental results on unordered image datasets demonstrate that the proposed method is three times faster than the state-of-the-art and the matching result is high-quality enough for robust SfM.

- Probabilistic TSDF Fusion Using Bayesian Deep Learning for Dense 3D Reconstruction with a Single RGB Camera

    Author: Kim, Hanjun | Seoul National University
    Author: Lee, Beom-Hee | Seoul National University
 
    keyword: Mapping; Visual Learning; SLAM

    Abstract : In this paper, we address a 3D reconstruction problem using depth prediction from a single RGB image. Thanks to the recent advances in deep learning, depth prediction shows high performance. However, due to the gap between training environment and test environment, 3D reconstruction can be vulnerable to uncertainty of depth prediction. To consider uncertainty of depth prediction for robust 3D reconstruction, we adopt Bayesian deep learning framework. Conventional Bayesian deep learning requires a large amount of time and GPU memory to perform Monte Carlo sampling. To address this problem, we propose a lightweight Bayesian neural network consisting of U-net structure and summation-based skip connections, which is performed in real-time. Estimated uncertainty is utilized in probabilistic TSDF fusion for dense 3D reconstruction by maximizing the posterior of TSDF value per voxel. As a result, global TSDF robust to erroneous depth values can be obtained and then dense 3D reconstruction from the global TSDF is achievable more accurately. To evaluate the performance of depth prediction and 3D reconstruction using our method, we utilized two official datasets and demonstrated the outperformance of the proposed method over other conventional methods.

- A Volumetric Albedo Framework for 3D Imaging Sonar Reconstruction

    Author: Westman, Eric | Carnegie Mellon University
    Author: Gkioulekas, Ioannis | Carnegie Mellon University
    Author: Kaess, Michael | Carnegie Mellon University
 
    keyword: Mapping; Marine Robotics; Field Robots

    Abstract : In this work, we present a novel framework for object-level 3D underwater reconstruction using imaging sonar sensors. We demonstrate that imaging sonar reconstruction is analogous to the problem of confocal non-line-of-sight (NLOS) reconstruction. Drawing upon this connection, we formulate the problem as one of solving for volumetric albedo, wherein the scene of interest is modeled as a directionless albedo field. After discretization, reconstruction reduces to a convex linear optimization problem, which we can augment with a variety of priors and regularization terms. We show how to solve the resulting regularized problems using the alternating direction method of multipliers (ADMM) algorithm. We demonstrate the effectiveness of the proposed approach in simulation and on real-world datasets collected in a controlled, test tank environment with several different sonar elevation apertures.

- Map Management Approach for SLAM in Large-Scale Indoor and Outdoor Areas

    Author: Ehlers, Simon F. G. | Leibniz University Hannover
    Author: Stuede, Marvin | Leibniz University Hannover, Institute of Mechatronic Systems
    Author: Nuelle, Kathrin | Leibniz Universitét Hannover
    Author: Ortmaier, Tobias | Leibniz University Hanover
 
    keyword: Mapping; SLAM; Field Robots

    Abstract : This work presents a semantic map management approach for various environments by triggering multiple maps with different simultaneous localization and mapping (SLAM) configurations. A modular map structure allows to add, modify or delete maps without influencing other maps of different areas. The hierarchy level of our algorithm is above the utilized SLAM method. Evaluating laser scan data (e.g. the detection of passing a doorway) triggers a new map, automatically choosing the appropriate SLAM configuration from a manually predefined list. Single independent maps are connected by link-points, which are located in an overlapping zone of both maps, enabling global navigation over several maps. Loop-closures between maps are detected by an appearance-based method, using feature matching and iterative closest point (ICP) registration between point clouds. Based on the arrangement of maps and link-points, a topological graph is extracted for navigation purpose and tracking the global robot's position over several maps. Our approach is evaluated by mapping a university campus with multiple indoor and outdoor areas and     Abstracting a metrical-topological graph. It is compared to a single map running with different SLAM configurations. Our approach enhances the overall map quality compared to the single map approaches by automatically choosing predefined SLAM configurations for different environmental setups.

- A Hierarchical Framework for Collaborative Probabilistic Semantic Mapping

    Author: Yue, Yufeng | Nanyang Technological University
    Author: Zhao, Chunyang | Nanyang Technological University
    Author: Li, Ruilin | Nanyang Technological University
    Author: Yang, Chule | Nanyang Technological University
    Author: Zhang, Jun | Nanyang Technological University
    Author: Wen, Mingxing | Nanyang Technological University
    Author: Wang, Yuanzhe | Nanyang Technological University
    Author: Wang, Danwei | Nanyang Technological University
 
    keyword: Mapping; Semantic Scene Understanding; Cooperating Robots

    Abstract : Performing collaborative semantic mapping is a critical challenge for cooperative robots to maintain a comprehensive contextual understanding of the surroundings. Most of the existing work either focus on single robot semantic mapping or collaborative geometry mapping. In this paper, a novel hierarchical collaborative probabilistic semantic mapping framework is proposed, where the problem is formulated in a distributed setting. The key novelty of this work is the mathematical modeling of the overall collaborative semantic mapping problem and the derivation of its probability decomposition. In the single robot level, the semantic point cloud is obtained based on heterogeneous sensor fusion model and is used to generate local semantic maps. Since the voxel correspondence is unknown in collaborative robots level, an Expectation-Maximization approach is proposed to estimate the hidden data association, where Bayesian rule is applied to perform semantic and occupancy probability update.	The experimental results show the high quality global semantic map, demonstrating the accuracy and utility of 3D semantic map fusion algorithm in real missions.

- Autonomous Navigation in Unknown Environments Using Sparse Kernel-Based Occupancy Mapping

    Author: Duong, Thai | University of California, San Diego
    Author: Das, Nikhil | UCSD
    Author: Yip, Michael C. | University of California, San Diego
    Author: Atanasov, Nikolay | University of California, San Diego
 
    keyword: Mapping; Autonomous Vehicle Navigation; Collision Avoidance

    Abstract : This paper focuses on real-time occupancy mapping and collision checking onboard an autonomous robot navigating in an unknown environment. We propose a new map representation, in which occupied and free space are separated by the decision boundary of a kernel perceptron classifier. We develop an online training algorithm that maintains a very sparse set of support vectors to represent obstacle boundaries in configuration space. We also derive conditions that allow complete (without sampling) collision-checking for piecewise-linear and piecewise-polynomial robot trajectories. We demonstrate the effectiveness of our mapping and collision checking algorithms for autonomous navigation of an Ackermann-drive robot in unknown environments.

- Hybrid Topological and 3D Dense Mapping through Autonomous Exploration for Large Indoor Environments

    Author: Gomez, Clara | University Carlos III of Madrid
    Author: Fehr, Marius | ETH Zurich
    Author: Millane, Alexander James | ETH Zurich
    Author: Hernandez Silva, Alejandra Carolina | University Carlos III of Madrid
    Author: Nieto, Juan | ETH Zurich
    Author: Barber, Ramon | Universidad Carlos III of Madrid
    Author: Siegwart, Roland | ETH Zurich
 
    keyword: Mapping; Motion and Path Planning; Autonomous Agents

    Abstract : Robots require a detailed understanding of the 3D structure of the environment for autonomous navigation and path planning. A popular approach is to represent the environment using metric, dense 3D maps such as 3D occupancy grids. However, in large environments the computational power required for most state-of-the-art 3D dense mapping systems is compromising precision and real-time capability. In this work, we propose a novel mapping method that is able to build and maintain 3D dense representations for large indoor environments using standard CPUs. Topological global representations and 3D dense submaps are maintained as hybrid global map. Submaps are generated for every new visited place. A place (room) is identified as an isolated part of the environment connected to other parts through transit areas (doors). This semantic partitioning of the environment allows for a more efficient mapping and path-planning. We also propose a method for autonomous exploration that directly builds the hybrid representation in real time. We validate the real-time performance of our hybrid system on simulated and real environments regarding mapping and path-planning. The improvement in execution time and memory requirements upholds the contribution of the proposed work.

- Resolving Marker Pose Ambiguity by Robust Rotation Averaging with Clique Constraints

    Author: Ch'ng, Shin-Fang | The University of Adelaide
    Author: Sogi, Naoya | University of Tsukuba
    Author: Purkait, Pulak | The University of Adelaide
    Author: Chin, Tat-Jun | The University of Adelaide
    Author: Fukui, Kazuhiro | Tsukuba University
 
    keyword: Mapping; Localization; SLAM

    Abstract : Planar markers are useful in robotics and computer vision for mapping and localisation. Given a detected marker in an image, a frequent task is to estimate the 6DOF pose of the marker relative to the camera, which is an instance of planar pose estimation (PPE). Although there are mature techniques, PPE suffers from a fundamental ambiguity problem, in that there can be more than one plausible pose solutions for a PPE instance. Especially when localisation of the marker corners is noisy, it is often difficult to disambiguate the pose solutions based on reprojection error alone. Previous methods choose between the possible solutions using a heuristic criterion, or simply ignore ambiguous markers.<p>We propose to resolve the ambiguities by examining the consistencies of a set of markers across multiple views. Our specific contributions include a novel rotation averaging formulation that incorporates long-range dependencies between possible marker orientation solutions that arise from PPE ambiguities. We analyse the combinatorial complexity of the problem, and develop a novel lifted algorithm to effectively resolve marker pose ambiguities, without discarding any marker observations. Results on real and synthetic data show that our method is able to handle highly ambiguous inputs, and provides more accurate and/or complete marker-based mapping and localisation.



## Computer Vision for Other Robotic Applications

- Real-Time Semantic Stereo Matching

    Author: Dovesi, Pier | KTH, Univrses
    Author: Poggi, Matteo | University of Bologna
    Author: Andraghetti, Lorenzo | Univrses
    Author: Mart� i Rabad�n, Miquel | KTH Royal University of Technology, Univrses AB
    Author: Kjellstrom, Hedvig | KTH
    Author: Pieropan, Alessandro | KTH
    Author: Mattoccia, Stefano | University of Bologna
 
    keyword: Computer Vision for Transportation; Computer Vision for Other Robotic Applications; Computer Vision for Automation

    Abstract : Scene understanding is paramount in robotics, self-navigation, augmented reality, and many other fields. To fully accomplish this task, an autonomous agent has to infer the 3D structure of the sensed scene (to know where it looks at) and its content (to know what it sees). To tackle the two tasks, deep neural networks trained to infer semantic segmentation and depth from stereo images are often the preferred choices. Specifically, Semantic Stereo Matching can be tackled by either standalone models trained for the two tasks independently or joint end-to-end architectures. Nonetheless, as proposed so far, both solutions are inefficient because requiring two forward passes in the former case or due to the complexity of a single network in the latter, although jointly tackling both tasks is usually beneficial in terms of accuracy. In this paper, we propose a single compact and lightweight architecture for real-time semantic stereo matching. Our framework relies on coarse-to-fine estimations in a multi-stage fashion, allowing: i) very fast inference even on embedded devices, with marginal drops in accuracy, compared to state-of-the-art networks, ii) trade accuracy for speed, according to the specific application requirements. Experimental results on high-end GPUs as well as on an embedded Jetson TX2 confirm the superiority of semantic stereo matching compared to standalone tasks and highlight the versatility of our framework on any hardware and for any application.

- Multi-Task Learning for Single Image Depth Estimation and Segmentation Based on Unsupervised Network

    Author: Lu, Yawen | Rochester Institute of Technology
    Author: Sarkis, Michel | Qualcomm Technologies Inc
    Author: Lu, Guoyu | Rochester Institute of Technology
 
    keyword: Computer Vision for Transportation; Visual-Based Navigation; Autonomous Vehicle Navigation

    Abstract : Deep neural networks have significantly enhanced the performance of various computer vision tasks, including single image depth estimation and image segmentation. However, most existing approaches handle them in supervised manners and require a large number of ground truth labels that consume extensive human efforts and are not always available in real scenarios. In this paper, we propose a novel framework to estimate disparity maps and segment images simultaneously by jointly training an encoder-decoder-based interactive convolutional neural network (CNN) for single image depth estimation and a multiple class CNN for image segmentation. Learning the neural network for one task can be beneficial from simultaneously learning from another one under a multi-task learning framework. We show that our proposed model can learn per-pixel depth regression and segmentation from just a single image input. Extensive experiments on available public datasets, including KITTI, Cityscapes urban, and PASCAL-VOC demonstrate the effectiveness of our model compared with other state-of-the-art methods for both tasks.

- Learning Transformable and Plannable Se(3) Features for Scene Imitation of a Mobile Service Robot

    Author: Park, J. hyeon | Seoul National University
    Author: Kim, Jigang | Seoul National University
    Author: Jang, YoungSeok | Seoul National University
    Author: Jang, Inkyu | Seoul National University
    Author: Kim, H. Jin | Seoul National University
 
    keyword: Computer Vision for Other Robotic Applications; Deep Learning in Robotics and Automation; Learning from Demonstration

    Abstract : Deep neural networks facilitate visuosensory inputs for robotic systems. However, the features encoded in a network without specific constraints have little physical meaning. In this research, we add constraints on the network so that the trained features are forced to represent the actual twist coordinates of interactive objects in a scene. The trained coordinates describe 6d-pose of the objects, and SE(3) transformation is applied to change the coordinate system. This algorithm is developed for a mobile service robot that imitates an object-oriented task by watching human demonstrations. As the robot has mobility, the video demonstrations are collected from the different view points. Our feature trajectories of twist coordinates are synthesized in the global coordinate after SE(3) transformation is applied according to robot localization. Then, the trajectories are trained as probabilistic model and imitated by the robot with geometric dynamics of se(3). Our main contribution is to develop a trainable robot with visually demonstrated human performances. Additionally, our algorithmic contribution is to design a scene interpretation network where se(3) constraints are incorporated to estimate 6d-pose of objects.

- Multimodal Multispectral Imaging System for Small UAVs

    Author: Haavardsholm, Trym Vegard | Norwegian Defence Research Establishment (FFI)
    Author: Skauli, Torbj�rn | Forsvarets Forskningsinstitutt (FFI)
    Author: Stahl, Annette | Norwegian University of Science and Technology (NTNU)
 
    keyword: Computer Vision for Other Robotic Applications; Mapping; Surveillance Systems

    Abstract : Multispectral imaging is an attractive sensing modality for small unmanned aerial vehicles (UAVs) in numerous applications. The most compact spectral camera architecture is based on spectral filters in the focal plane. Vehicle movement can be used to scan the scene using multiple bandpass filters arranged perpendicular to the flight direction. With known camera trajectory and scene structure, it is possible to assemble a spectral image in software.<p>In this paper, we demonstrate the feasibility of a novel concept for low-cost wide area multispectral imaging with integrated spectral consistency testing. Six bandpass filters are arranged in a periodically repeating pattern.</p><p>Since different bands are recorded at different times and in different viewing directions, there is a risk of obtaining spectral artifacts in the image. We exploit the repeated sampling of bands to enable spectral consistency testing, which leads to significantly improved spectral integrity. In addition, an unfiltered region permits conventional 2D video imaging that can be used for image-based navigation and 3D reconstruction.</p><p>The proposed multimodal imaging system was tested on a UAV in a realistic experiment. The results demonstrate that spectral reconstruction and consistency testing can be performed by image processing alone, based on visual simultaneous localization and mapping (VSLAM).

- Unseen Salient Object Discovery for Monocular Robot Vision

    Author: Chan, Darren | University of California, San Diego
    Author: Riek, Laurel D. | University of California San Diego
 
    keyword: Computer Vision for Other Robotic Applications; Object Detection, Segmentation and Categorization

    Abstract : A key challenge in robotics is the capability to perceive unseen objects, which can improve a robot's ability to learn from and adapt to its surroundings. One approach is to employ unsupervised, salient object discovery methods, which have shown promise in the computer vision literature. However, most state-of-the-art methods are unsuitable for robotics because they are limited to processing whole video segments before discovering objects, which can constrain real-time perception. To address these gaps, we introduce Unsupervised Foraging of Objects (UFO), a novel, unsupervised, salient object discovery method designed for monocular robot vision. We designed UFO with a parallel discover-prediction paradigm, permitting it to discover arbitrary, salient objects on a frame-by-frame basis, which can help robots to engage in scalable object learning. We compared UFO to the two fastest and most accurate methods for unsupervised salient object discovery (Fast Segmentation and Saliency-Aware Geodesic), and show that UFO 6.5 times faster, achieving state-of-the-art precision, recall, and accuracy. Furthermore our evaluation suggests that UFO is robust to real-world perception challenges encountered by robots, including moving cameras and moving objects, motion blur, and occlusion. It is our goal that this work will be used with other robot perception methods, to design robots that can learn novel object concepts, leading to improved autonomy.

- CorsNet: 3D Point Cloud Registration by Deep Neural Network

    Author: Kurobe, Akiyoshi | Keio University
    Author: Sekikawa, Yusuke | Denso IT Laboratory
    Author: Ishikawa, Kohta | Denso IT Laboratory, Inc
    Author: Saito, Hideo | Keio University
 
    keyword: Computer Vision for Other Robotic Applications; Deep Learning in Robotics and Automation; Perception for Grasping and Manipulation

    Abstract : Point cloud registration is a key problem for robotics and computer vision communities. This represents estimating a rigid transform which aligns one point cloud to another. Iterative closest point (ICP) is a well-known classical method for this problem. ICP generally achieves high alignment only when the source and template point cloud are mostly pre-aligned. If each point cloud is far away or contains a repeating structure, the registration often fails because of being fallen into a local minimum. Recently, inspired by PointNet, several deep learning-based methods have been developed. PointNetLK is a representative approach, which directly optimizes the distance of aggregated features using gradient method by Jacobian. In this paper, we propose CorsNet: Point Cloud Registration based on Deep Learning. Since CorsNet concatenates the local features with the global features and regresses correspondences between point clouds, not directly pose or aggregated features, more useful information is integrated than the conventional approaches. For comparison, we developed the simplest baseline approach (DirectNet) which directly regresses the pose between point clouds. Through our experiments, we show that CorsNet achieves higher accuracy than not only the classic ICP method but also the recently proposed learning-based proposal PointNetLK and DirectNet, including on seen and unseen categories.

- Anticipating the Start of User Interaction for Service Robot in the Wild

    Author: Ito, Koichiro | Hitcahi, Ltd
    Author: Kong, Quan | Hitachi, Ltd
    Author: Horiguchi, Shota | Hitachi, Ltd
    Author: Sumiyoshi, Takashi | Hitachi, Ltd., Reseach &amp; Development Group
    Author: Nagamatsu, Kenji | Hitachi, Ltd
 
    keyword: Computer Vision for Other Robotic Applications; Service Robots; Deep Learning in Robotics and Automation

    Abstract : A service robot is expected to provide proactive service for visitors who require its help. In contrast to passive service, e.g., providing service only after being spoken to, proactive service initiates an interaction at an early stage, e.g., talking to potential visitors who need the robot's help in advance. This paper addresses how to anticipate the start of user interaction. We propose an approach using only a single RGB camera that anticipates whether a visitor will come to the robot for interaction or just pass it by. In the proposed approach, we (i) utilize the visitor's pose information from captured images incorporating facial information, (ii) train a CNN-LSTM--based model in an end-to-end manner with an exponential loss for early anticipation, and (iii) during the training, the network branch for facial keypoints acquired as the part of the human pose information is taught to mimic the branch trained with the face image from a specialized face detector with a human verification. By virtue of (iii), at the inference, we can run our model in an embedded system processing only the pose information without an additional face detector and typical accuracy drop. We evaluated the proposed approach on our collected real world data with a real service robot and publicly available JPL interaction dataset and found that it achieved accurate anticipation performance.

- Spin Detection in Robotic Table Tennis

    Author: Tebbe, Jonas | University of Tübingen
    Author: Klamt, Lukas | University of Tübingen
    Author: Gao, Yapeng | University of Tuebingen
    Author: Zell, Andreas | University of Tübingen
 
    keyword: Computer Vision for Other Robotic Applications; Object Detection, Segmentation and Categorization; Deep Learning in Robotics and Automation

    Abstract : In table tennis, the rotation (spin) of the ball plays a crucial role. A table tennis match will feature a variety of strokes. Each generates different amounts and types of spin. To develop a robot that can compete with a human player, the robot needs to detect spin, so it can plan an appropriate return stroke. In this paper we compare three methods to estimate spin. The first two approaches use a high-speed camera that captures the ball in flight at a frame rate of 380 Hz. This camera allows the movement of the circular brand logo printed on the ball to be seen. The first approach uses background difference to determine the position of the logo. In a second alternative, we train a CNN to predict the orientation of the logo. The third method evaluates the trajectory of the ball and derives the rotation from the effect of the Magnus force. This method gives the highest accuracy and is used for a demonstration. Our robot successfully copes with different spin types in a real table tennis rally against a human opponent.

- Look, Listen, and Act: Towards Audio-Visual Embodied Navigation

    Author: Gan, Chuang | IBM
    Author: Zhang, Yiwei | Tsinghua University
    Author: Wu, Jiajun | Stanford University
    Author: Gong, Boqing | Tencent AI Lab, Seattle
    Author: Tenenbaum, Joshua | Massachusetts Institute of Technology
 
    keyword: Computer Vision for Other Robotic Applications

    Abstract : A crucial ability of mobile intelligent agents is to integrate the evidence from multiple sensory inputs in an environment and to make a sequence of actions to reach their goals. In this paper, we attempt to approach the problem of Audio-Visual Embodied Navigation, the task of planning the shortest path from a random starting location in a scene to the sound source in an indoor environment, given only raw egocentric visual and audio sensory data. To accomplish this task, the agent is required to learn from various modalities, i.e., relating the audio signal to the visual environment. Here we describe an approach to audio-visual embodied navigation that takes advantage of both visual and audio pieces of evidence. Our solution is based on three key ideas: a visual perception mapper module that constructs its spatial memory of the environment, a sound perception module that infers the relative location of the sound source from the agent, and a dynamic path planner that plans a sequence of actions based on the audio-visual observations and the spatial memory of the environment to navigate toward the goal. Experimental results on a newly collected Visual-Audio-Room dataset using the simulated multi-modal environment demonstrate the effectiveness of our approach over several competitive baselines.

- Autonomous Tool Construction with Gated Graph Neural Network

    Author: Yang, Chenjie | Xi'an Jiaotong University
    Author: Lan, Xuguang | Xi'an Jiaotong University
    Author: Zhang, Hanbo | Xi'an Jiaotong University
    Author: Zheng, Nanning | Xi'an Jiaotong University
 
    keyword: Computer Vision for Other Robotic Applications; Semantic Scene Understanding; Perception for Grasping and Manipulation

    Abstract : Autonomous tool construction is a significant but challenging task in robotics. This task can be interpreted as when given a reference tool, selecting some available candidate parts to reconstruct it. Most of the existing works perform tool construction in the form of action part and grasp part, which is only a specific construction pattern and limits its application to some extent. In general scenarios, a tool can be constructed in various patterns with different part pairs. Therefore, whether a part pair is most suitable for constructing the tool depends not only on itself, but on other parts in the same scene. To solve this problem, we construct a Gated Graph Neural Network (GGNN) to model the relations between all part pairs, so that we can select the candidate parts in consideration of the global information. Afterwards, we embed the constructed GGNN into a RCNN-like structure to finally accomplish tool construction. The whole model will be named Tool Construction Graph RCNN (TC-GRCNN). In addition, we develop a mechanism that can generate large-scale training and testing data in simulation environments, by which we can save the time of data collection and annotation. Finally, the proposed model is deployed on the physical robot. The experiment results show that TC-GRCNN can perform well in the general scenarios of tool construction.

- Training-Set Distillation for Real-Time UAV Object Tracking

    Author: Li, Fan | Tongji University
    Author: Fu, Changhong | Tongji University
    Author: Lin, Fuling | Tongji University
    Author: Li, Yiming | Tongji University
    Author: Lu, Peng | The Hong Kong Polytechnic University
 
    keyword: Computer Vision for Other Robotic Applications; Visual Learning; Aerial Systems: Applications

    Abstract : Correlation filter (CF) has recently exhibited promising performance in visual object tracking for unmanned aerial vehicle (UAV). Such online learning method heavily depends on the quality of the training-set, yet complicated aerial scenarios like occlusion or out of view can reduce its reliability. In this work, a novel time slot-based distillation approach is proposed to efficiently and effectively optimize the training-set's quality on the fly. A cooperative energy minimization function is established to score the historical samples adaptively. To accelerate the scoring process, frames with high confident tracking results are employed as the keyframes to divide the tracking process into multiple time slots. After the establishment of a new slot, the weighted fusion of the previous samples generates one key-sample, in order to reduce the number of samples to be scored. Besides, when the current time slot exceeds the maximum frame number, which can be scored, the sample with the lowest score will be discarded. Consequently, the training-set can be efficiently and reliably distilled. Comprehensive tests on two well-known UAV benchmarks prove the effectiveness of our method with real-time speed on single CPU.

- CNN-Based Simultaneous Dehazing and Depth Estimation

    Author: Lee, Byeong-Uk | KAIST
    Author: Lee, Kyunghyun | KAIST
    Author: Oh, Jean | Carnegie Mellon University
    Author: Kweon, In So | KAIST
 
    keyword: Computer Vision for Other Robotic Applications; AI-Based Methods; Visual Learning

    Abstract : It is difficult for both cameras and depth sensors to obtain reliable information in hazy scenes. Therefore, image dehazing is still one of the most challenging problems to solve in computer vision and robotics. With the development of convolutional neural networks (CNNs), lots of dehazing and depth estimation algorithms using CNNs have emerged. However, very few of those try to solve these two problems at the same time. Focusing on the fact that traditional haze modeling contains depth information in its formula, we propose a CNN-based simultaneous dehazing and depth estimation network. Our network aims to estimate both a dehazed image and a fully scaled depth map from a single hazy RGB input with end-to-end training. The network contains a single dense encoder and four separate decoders; each of them shares the encoded image representation while performing individual tasks. We suggest a novel depth-transmission consistency loss in the training scheme to fully utilize the correlation between the depth information and transmission map. To demonstrate the robustness and effectiveness of our algorithm, we performed various ablation studies and compared our results to those of state-of-the-art algorithms in dehazing and single image depth estimation, both qualitatively and quantitatively. Furthermore, we show the generality of our network by applying it to some real-world examples.

- IF-Net: An Illumination-Invariant Feature Network

    Author: Chen, Po-Heng | National Chiao-Tung University
    Author: Luo, Zhao Xu | National Chiao Tung University
    Author: Huang, Tsu-Kuan | National Chiao Tung University
    Author: Yang, Chun | National Chiao-Tung University
    Author: Chen, Kuan-Wen | National Chiao Tung University
 
    keyword: Computer Vision for Other Robotic Applications; Visual Learning; AI-Based Methods

    Abstract : Feature descriptor matching is a critical step is many computer vision applications such as image stitching, image retrieval and visual localization. However, it is often affected by many practical factors which will degrade its performance. Among these factors, illumination variations are the most influential one, and especially no previous descriptor learning works focus on dealing with this problem. In this paper, we propose IF-Net, aimed to generate a robust and generic descriptor under crucial illumination changes conditions. We find out not only the kind of training data important but also the order it is presented. To this end, we investigate several dataset scheduling methods and propose a separation training scheme to improve the matching accuracy. Further, we propose a ROI loss and hard-positive mining strategy along with the training scheme, which can strengthen the ability of generated descriptor dealing with large illumination change conditions. We evaluate our approach on public patch matching benchmark and achieve the best results compared with several state-of-the-arts methods. To show the practicality, we further evaluate IF-Net on the task of visual localization under large illumination changes scenes, and achieves the best localization accuracy.

- Deep-Learning Assisted High-Resolution Binocular Stereo Depth Reconstruction

    Author: Hu, Yaoyu | Carnegie Mellon University
    Author: Zhen, Weikun | Carnegie Mellon University
    Author: Scherer, Sebastian | Carnegie Mellon University
 
    keyword: Computer Vision for Other Robotic Applications; Deep Learning in Robotics and Automation; Aerial Systems: Applications

    Abstract : This work presents dense stereo reconstruction using high-resolution images for infrastructure inspections. The state-of-the-art stereo reconstruction methods, both learning and non-learning ones, consume too much computational resource on high-resolution data. Recent learning-based methods achieve top ranks on most benchmarks. However, they suffer from the generalization issue due to lack of task-specific training data. We propose to use a less resource demanding non-learning method, guided by a learning-based model, to handle high-resolution images and achieve accurate stereo reconstruction. The deep-learning model produces an initial disparity prediction with uncertainty for each pixel of the down-sampled stereo image pair. The uncertainty serves as a self-measurement of its generalization ability and the per-pixel searching range around the initially predicted disparity. The downstream process performs a modified version of the Semi-Global Block Matching method with the up-sampled per-pixel searching range. The proposed deep-learning assisted method is evaluated on the Middlebury dataset and high-resolution stereo images collected by our customized binocular stereo camera. The combination of learning and non-learning methods achieves better performance on 12 out of 15 cases of the Middlebury dataset. In our infrastructure inspection experiments, the average 3D reconstruction error is less than 0.004m.

- Least-Squares Optimal Relative Planar Motion for Vehicle-Mounted Cameras

    Author: Hajder, Levente | E�tv's Lor�nd University
    Author: Barath, Daniel | MTA SZTAKI; Visual Recognition Group in CTU Prague
 
    keyword: Computer Vision for Other Robotic Applications; Visual-Based Navigation

    Abstract : A new closed-form solver is proposed minimizing the algebraic error optimally, in the least squares sense, to estimate the relative planar motion of two calibrated cameras. The main objective is to solve the over-determined case, i.e., when a larger-than-minimal sample of point correspondences is given - thus, estimating the motion from at least three correspondences. The algorithm requires the camera movement to be constrained to a plane, e.g. mounted to a vehicle, and the image plane to be orthogonal to the ground. The solver obtains the motion parameters as the roots of a 6-th degree polynomial. It is validated both in synthetic experiments and on publicly available real-world datasets that using the proposed solver leads to results superior to the state-of-the-art in terms of geometric accuracy with no noticeable deterioration in the processing time.

- Relative Planar Motion for Vehicle-Mounted Cameras from a Single Affine Correspondence

    Author: Hajder, Levente | E�tv's Lor�nd University
    Author: Barath, Daniel | MTA SZTAKI; Visual Recognition Group in CTU Prague
 
    keyword: Computer Vision for Other Robotic Applications; Visual-Based Navigation

    Abstract : Two solvers are proposed for estimating the extrinsic camera parameters from a single affine correspondence assuming general planar motion. In this case, the camera movement is constrained to a plane and the image plane is orthogonal to the ground. The algorithms do not assume other constraints, e.g. the non-holonomic one, to hold. A new minimal solver is proposed for the semi-calibrated case, i.e. the camera parameters are known except a common focal length. Another method is proposed for the fully calibrated case. Due to requiring a single correspondence, robust estimation, e.g. histogram voting, leads to a fast and accurate procedure. The proposed methods are tested in our synthetic environment and on publicly available real datasets consisting of videos through tens of kilometers. They are superior to the state-of-the-art both in terms of accuracy and processing time.

- Moving Object Detection for Visual Odometry in a Dynamic Environment Based on Occlusion Accumulation

    Author: Kim, Haram | Seoul National University
    Author: Kim, Pyojin | Simon Fraser University
    Author: Kim, H. Jin | Seoul National University
 
    keyword: Computer Vision for Other Robotic Applications; Visual-Based Navigation; Object Detection, Segmentation and Categorization

    Abstract : Detection of moving objects is an essential capability in dealing with dynamic environments. Most moving object detection algorithms have been designed for color images without depth. For robotic navigation where real-time RGB-D data is often readily available, utilization of the depth information would be beneficial for obstacle recognition. Here, we propose a simple moving object detection algorithm that uses RGB-D images. The proposed algorithm does not require estimating a background model. Instead, it uses an occlusion model which enables us to estimate the camera pose on a background confused with moving objects that dominate the scene. The proposed algorithm allows to separate the moving object detection and visual odometry (VO) so that an arbitrary robust VO method can be employed in a dynamic situation with a combination of moving object detection, whereas other VO algorithms for a dynamic environment are inseparable. In this paper, we use dense visual odometry (DVO) as a VO method with a bi-square regression weight. Experimental results show the segmentation accuracy and the performance improvement of DVO in the situations. We validate our algorithm in public datasets and our dataset which also publicly accessible.

- A Low-Rank Matrix Approximation Approach to Multiway Matching with Applications in Multi-Sensory Data Association

    Author: Leonardos, Spyridon | University of Pennsylvania
    Author: Zhou, Xiaowei | Zhejiang University
    Author: Daniilidis, Kostas | University of Pennsylvania
 
    keyword: Computer Vision for Other Robotic Applications

    Abstract : Consider the case of multiple visual sensors perceiving the same scene from different viewpoints. In order to achieve consistent visual perception, the problem of data association, in this case establishing correspondences between observed features, must be first solved. In this work, we consider multiway matching which is a specific instance of multi-sensory data association. Multiway matching refers to the problem of establishing correspondences among a set of images from noisy pairwise correspondences, typically by exploiting cycle-consistency.<p>We propose a novel optimization-based formulation of multiway matching problem as a	nonconvex low-rank matrix approximation problem. We propose two novel algorithms for numerically solving the problem at hand. The first one	is an algorithm based on the Alternating Direction Method of Multipliers (ADMM). The second one is a Riemannian trust-region method on	the multinomial manifold, the manifold of strictly positive stochastic matrices, equipped with the Fisher information metric. Experimental results demonstrate that the proposed methods have the state of the art performance in multiway matching while reducing the computational complexity compared to the state of the art.




## Humanoid and Bipedal Locomotion


- LQR-Assisted Whole-Body Control of a Wheeled Bipedal Robot with Kinematic Loops

    Author: Klemm, Victor | ETH Zurich
    Author: Morra, Alessandro | ETH Zurich
    Author: Gulich, Lionel | ETH Zurich
    Author: Mannhart, Dominik | ETH Zurich
    Author: Rohr, David | ETH Zurich
    Author: Kamel, Mina | Autonomous Systems Lab, ETH Zurich
    Author: de Viragh, Yvain | ETH Zurich
    Author: Siegwart, Roland | ETH Zurich
 
    keyword: Legged Robots; Wheeled Robots; Parallel Robots

    Abstract : We present a hierarchical whole-body controller leveraging the full rigid body dynamics of the wheeled bipedal robot Ascento. We derive closed-form expressions for the dynamics of its kinematic loops in a way that readily generalizes to more complex systems. The rolling constraint is incorporated using a compact analytic solution based on rotation matrices. The non-minimum phase balancing dynamics are accounted for by including a linear-quadratic regulator as a motion task. Robustness when driving curves is increased by regulating the lean angle as a function of the zero-moment point. The proposed controller is computationally lightweight and significantly extends the rough-terrain capabilities and robustness of the system, as we demonstrate in several experiments.

- Leveraging the Template and Anchor Framework for Safe, Online Robotic Gait Design

    Author: Liu, Jinsun | University of Michigan, Ann Arbor
    Author: Zhao, Pengcheng | University of Michigan
    Author: Gan, Zhenyu | University of Michigan
    Author: Johnson-Roberson, Matthew | University of Michigan
    Author: Vasudevan, Ram | University of Michigan
 
    keyword: Humanoid and Bipedal Locomotion; Robot Safety; Underactuated Robots

    Abstract : Online control design using a high-fidelity, full-order model for a bipedal robot can be challenging due to the size of the state space of the model. A commonly adopted solution to overcome this challenge is to approximate the full-order model (anchor) with a simplified, reduced-order model (template), while performing control synthesis. Unfortunately it is challenging to make formal guarantees about the safety of an anchor model using a controller designed in an online fashion using a template model. To address this problem, this paper proposes a method to generate safety-preserving controllers for anchor models by performing reachability analysis on template models while bounding the modeling error. This paper describes how this reachable set can be incorporated into a Model Predictive Control framework to select controllers that result in safe walking on the anchor model in an online fashion. The method is illustrated on a 5-link RABBIT model, and is shown to allow the robot to walk safely while utilizing controllers designed in an online fashion.

- Unified Push Recovery Fundamentals: Inspiration from Human Study

    Author: McGreavy, Christopher | University of Edinburgh
    Author: Yuan, Kai | University of Edinburgh
    Author: Gordon, Daniel F. N. | University of Edinburgh
    Author: Tan, Kang | The University of Glasgow
    Author: Wolfslag, Wouter | University of Edinburgh
    Author: Vijayakumar, Sethu | University of Edinburgh
    Author: Li, Zhibin | University of Edinburgh
 
    keyword: Humanoid and Bipedal Locomotion; Legged Robots; Motion Control

    Abstract : Currently for balance recovery, humans outperform humanoid robots which use hand-designed controllers in terms of the diverse actions. This study aims to close this gap by finding core control principles that are shared across ankle, hip, toe and stepping strategies by formulating experiments to test human balance recoveries and define criteria to quantify the strategy in use. To reveal fundamental principles of balance strategies, our study shows that a minimum jerk controller can accurately replicate comparable human behaviour at the Centre of Mass level. Therefore, we formulate a general Model-Predictive Control (MPC) framework to produce recovery motions in any system, including legged machines, where the framework parameters are tuned for time-optimal performance in robotic systems.

- Nonholonomic Virtual Constraint Design for Variable-Incline Bipedal Robotic Walking

    Author: Horn, Jonathan | University of Texas at Dallas
    Author: Mohammadi, Alireza | University of Michigan, Dearborn
    Author: Akbari Hamed, Kaveh | Virginia Tech
    Author: Gregg, Robert D. | University of Michigan
 
    keyword: Legged Robots; Underactuated Robots; Motion Control

    Abstract : This paper presents a method of designing relative-degree-two nonholonomic virtual constraints (NHVCs) that allow for stable bipedal robotic walking across variable terrain slopes. relative-degree-two NHVCs are virtual constraints that encode velocity-dependent walking gaits via momenta conjugate to the unactuated degrees of freedom for the robot. We recently introduced a systematic method of designing NHVCs, based on the hybrid zero dynamics (HZD) control framework, to achieve hybrid invariant flat ground walking without the use of dynamic reset variables. This work addresses the problem of walking over variable-inclined terrain disturbances. We propose a methodology for designing NHVCs, via an optimization problem, in order to achieve stable walking across variable terrain slopes. The end result is a single controller capable of walking over variable-inclined surfaces, that is also robust to inclines not considered in the optimization design problem, and uncertainties in the inertial parameters of the model.

- MPC for Humanoid Gait Generation: Stability and Feasibility (I)

    Author: Scianca, Nicola | Sapienza University of Rome
    Author: De Simone, Daniele | Sapienza University of Rome
    Author: Lanari, Leonardo | Sapienza University of Rome
    Author: Oriolo, Giuseppe | Sapienza University of Rome
 
    keyword: Humanoid and Bipedal Locomotion; Humanoid Robots

    Abstract : In this article, we present an intrinsically stable Model Predictive Control (IS-MPC) framework for humanoid gait generation that incorporates a stability constraint in the formulation. The method uses as prediction model a dynamically extended Linear Inverted Pendulum with Zero Moment Point (ZMP) velocities as control inputs, producing in real time a gait (including footsteps with timing) that realizes omnidirectional motion commands coming from an external source. The stability constraint links future ZMP velocities to the current state so as to guarantee that the generated Center of Mass (CoM) trajectory is bounded with respect to the ZMP trajectory. Being the MPC control horizon finite, only part of the future ZMP velocities are decision variables; the remaining part, called tail, must be either conjectured or anticipated using preview information on the reference motion. Several options for the tail are discussed, each corresponding to a specific terminal constraint. A feasibility analysis of the generic MPC iteration is developed and used to obtain sufficient conditions for recursive feasibility. Finally, we prove that recursive feasibility guarantees stability of the CoM/ZMP dynamics. Simulation and experimental results on NAO and HRP-4 are presented to highlight the performance of IS-MPC.

- A Robust Walking Controller Based on Online Optimization of Ankle, Hip, and Stepping Strategies (I)
 
    Author: Jeong, Hyobin | KAIST
    Author: Lee, Inho | IHMC
    Author: Oh, Jaesung | KAIST
    Author: Lee, Kang Kyu | KAIST Hubolab
    Author: Oh, Jun Ho | Korea Advanced Inst. of Sci. and Tech
 
    keyword: Humanoid and Bipedal Locomotion; Humanoid Robots; Legged Robots

    Abstract : In this paper, we propose a biped walking controller that optimized three push recovery strategies: the ankle, hip, and stepping strategies. We suggested formulations that related the effects of each strategy to the stability of walking based on the linear inverted pendulum with flywheel model.With these relations, we could set up an optimization problem that integrates all the strategies, including step time change. These strategies are not applied hierarchically, but applied according to each weighting factor. Various combinations of weighting factors can be used to determine how the robot should respond to an external push. The optimization problem derived here includes many nonlinear components, but it has been linearized though some assumptions and it can be applied to a robot in real time. Our method is designed to be robust to modeling errors or weak perturbations, by exploiting the advantages of the foot. Hence, it is very practical to apply this algorithm to a real robot. The effectiveness of the walking controller has been verified through     Abstracted model simulation, full dynamics simulation, and a practical robot experiments.


- Passive Dynamic Balancing and Walking in Actuated Environments

    Author: Reher, Jenna | California Institute of Technology
    Author: Csomay-Shanklin, Noel | California Institute of Technology
    Author: Christensen, David | Stanford University
    Author: Bristow, Robert | Walt Disney Imagineering
    Author: Ames, Aaron | California Institute of Technology
    Author: Smoot, Lanny | Walt Disney Imagineering R&amp;D
 
    keyword: Passive Walking; Underactuated Robots; Humanoid and Bipedal Locomotion

    Abstract : The control of passive dynamic systems remains a challenging problem in the field of robotics, and insights from their study can inform everything from dynamic behaviors on actuated robots to robotic assistive devices. In this work, we explore the use of flat actuated environments for realizing passive dynamic balancing and locomotion. Specifically, we utilize a novel omnidirectional actuated floor to dynamically stabilize two robotic systems. We begin with an inverted pendulum to demonstrate the ability to control a passive system through an active environment. We then consider a passive bipedal robot wherein dynamically stable periodic walking gaits are generated through an optimization that leverages the actuated floor. The end result is the ability to demonstrate passive dynamic walking experimentally through the use of actuated environments.

- Biped Stabilization by Linear Feedback of the Variable-Height Inverted Pendulum Model

    Author: Caron, Stephane | ANYbotics AG
 
    keyword: Humanoid and Bipedal Locomotion

    Abstract : The variable-height inverted pendulum (VHIP) model enables a new balancing strategy by height variations of the center of mass, in addition to the well-known ankle strategy. We propose a biped stabilizer based on linear feedback of the VHIP that is simple to implement, coincides with the state-of-the-art for small perturbations and is able to recover from larger perturbations thanks to this new strategy. This solution is based on "best-effort" pole placement of a 4D divergent component of motion for the VHIP under input feasibility and state viability constraints. We complement it with a suitable whole-body admittance control law and test the resulting stabilizer on the HRP-4 humanoid robot.

- Stability Criteria of Balanced and Steppable Unbalanced States for Full-Body Systems with Implications in Robotic and Human Gait

    Author: Peng, William | New York University
    Author: Mummolo, Carlotta | New York University
    Author: Kim, Joo H. | New York University
 
    keyword: Legged Robots; Humanoid and Bipedal Locomotion; Passive Walking

    Abstract : Biped walking involves a series of transitions between single support (SS) and double support (DS) contact configurations that can include both balanced and unbalanced states. The new concept of steppability is introduced to partition the set of unbalanced states into steppable states and falling (unsteppable) states based on the ability of a biped system to respond to forward velocity perturbations by stepping. In this work, a complete system-specific analysis of the stepping process including full-order nonlinear system dynamics is presented for the DARwIn-OP humanoid robot and a human subject in the sagittal plane with respect to both balance stability and steppability. The balance stability and steppability of each system are analyzed by numerical construction of its balance stability boundaries (BSB) for the initial SS and final DS contact configuration and the steppable unbalanced state boundary (SUB). These results are presented with center of mass (COM) trajectories obtained from walking experiments to benchmark robot controller performance and analyze the variation of balance stability and steppability with COM and swing foot position along the progression of a step cycle. For each system, DS BSBs were obtained with both constrained and unconstrained arms in order to demonstrate the ability of this approach to incorporate the effects of angular momentum and system-specific characteristics such as actuation torque, velocity, and angle limits.

- Material Handling by Humanoid Robot While Pushing Carts Using a Walking Pattern Based on Capture Point

    Author: Chagas Vaz, Jean M. | University of Nevada Las Vegas
    Author: Oh, Paul Y. | University of Nevada, Las Vegas (UNLV)
 
    keyword: Humanoid and Bipedal Locomotion; Legged Robots; Humanoid Robots

    Abstract : This paper presents a study that evaluates the effects on the walking pattern of a full-sized humanoid robot as it pushes different carts. Furthermore, it discuss a modified Zero Moment Point (ZMP) pattern based on a capture point method, and a friction compensation method for the arms. Humanoid researchers have demonstrated that robots can perform a wide range of tasks including handling tools, climbing ladders, and patrolling rough terrain. However, when it comes to handling objects while walking, humanoids are relatively limited; it becomes more apparent when humanoids have to push a cart. Many challenges become evident under such circumstances; for example, the walking pattern will be severely affected by the external force opposed by the cart. Therefore, an appropriate walking pattern dynamic model and arm compliance are needed to mitigate external forces. This becomes crucial in order to ensure the robot's self-balance and minimize external disturbances.

- Interconnection and Damping Assignment Passivity-Based Control for Gait Generation in Underactuated Compass-Like Robots

    Author: Arpenti, Pierluigi | CREATE Consortium
    Author: Ruggiero, Fabio | Université Di Napoli Federico II
    Author: Lippiello, Vincenzo | University of Naples FEDERICO II
 
    keyword: Passive Walking; Legged Robots

    Abstract : A compass-like biped robot can go down a gentle slope without the need of actuation through a proper choice of its dynamic parameter and starting from a suitable initial condition. Addition of control actions is requested to generate additional gaits and robustify the existing one. This paper designs an interconnection and damping assignment passivity- based control, rooted within the port-Hamiltonian framework, to generate further gaits with respect to state-of-the-art method- ologies, enlarge the basin of attraction of existing gaits, and further robustify the system against controller discretization and parametric uncertainties. The performance of the proposed algorithm is validated through numerical simulations and comparison with existing passivity-based techniques.

-  Safety-Critical Control of a Cassie Bipedal Robot Riding Hovershoes for Vision-Based Obstacle Avoidance

    Author: Zhang, Bike | University of California, Berkeley
    Author: Sreenath, Koushil | University of California, Berkeley


- A Methodology for the Incorporation of Arbitrarily-Shaped Feet in Passive Bipedal Walking Dynamics

    Author: Smyrli, Aikaterini | National Technical University of Athens
    Author: Papadopoulos, Evangelos | National Technical University of Athens
 
    keyword: Humanoid and Bipedal Locomotion; Passive Walking; Dynamics

    Abstract : A methodology for implementing arbitrary foot shapes in the passive walking dynamics of biped robots is developed. The dynamic model of a walking robot is defined in a way that allows shape-dependent foot kinetics to contribute to the robot's dynamics, for all convex foot shapes regardless of the exact foot geometry: for the developed method, only the set of points describing the foot profile curve is needed. The method is mathematically derived and then showcased with an application. The open-source pose estimation system OpenPose is used to determine the foot profile that enables the rigid-foot passive robot to reproduce the ankle trajectory of the actively powered, multi-DOF human foot complex. The passive gait of the biped robot walking on the specified foot shape is simulated and analyzed, and a stable walking cycle is found and evaluated. The proposed model enables the study of the effects of foot shape on the walking dynamics of biped robots, eliminating the necessity of solely using simple, and analytically defined geometric shapes as the walking robots' feet. The method can be used for foot shape optimization towards achieving any desired walking pattern in walking robots.

- Experimental Analysis of Structural Vibration Problems of a Biped Walking Robot

    Author: Berninger, Tobias Franz Christian | TU Munich
    Author: Sygulla, Felix | Technical University of Munich
    Author: Fuderer, Sebastian | Technical University of Munich
    Author: Rixen, Daniel | Technische Universitét M�nchen
 
    keyword: Humanoid and Bipedal Locomotion; Legged Robots; Calibration and Identification

    Abstract : Over the past decade we have been able to vastly improve the control algorithms of our biped walking robot Lola. Further enhancements, however, are limited by vibration problems caused by the dynamics of Lola's mechanical structure. In this work, we present small examples how structural dynamics limit our control design for walking control as well as low level position control of the joints. We also provide a procedure to identify weaknesses in the structural design of our biped using Experimental Modal Analysis. Using this method, we could successfully identify the structural modes of the system. Furthermore, we were able to use a closed-loop identification method to show a connection between the control loop resonances and the structural resonances of our robot.

- Dynamic Coupling As an Indicator of Gait Robustness for Underactuated Biped Robots

    Author: Fevre, Martin | University of Notre Dame
    Author: Schmiedeler, James | University of Notre Dame
 
    keyword: Legged Robots

    Abstract : This paper employs velocity decomposition of underactuated mechanical systems to determine the degree of dynamic coupling in the gaits of a two-link biped model. The degree of coupling between controlled and uncontrolled directions quantifies the control     Authority the system has over its unactuated degree of freedom. This paper shows that the amount of coupling is directly correlated to gait robustness, as seen through the size of the gait's region of attraction. The analytical measure of coupling is applied in the context of trajectory optimization to generate two-link gaits that maximize or minimize coupling. Simulation studies show that gaits maximizing coupling exhibit significantly superior robustness, as measured by 1) stochastic performance on uneven terrain, 2) ability to maintain desired walking speed under non-vanishing disturbances, 3) size of the region of attraction, and 4) robustness to model uncertainties.

- ZMP Constraint Restriction for Robust Gait Generation in Humanoids

    Author: Smaldone, Filippo Maria | Sapienza University of Rome
    Author: Scianca, Nicola | Sapienza University of Rome
    Author: Modugno, Valerio | Sapienza Université Di Roma
    Author: Lanari, Leonardo | Sapienza University of Rome
    Author: Oriolo, Giuseppe | Sapienza University of Rome
 
    keyword: Humanoid and Bipedal Locomotion; Humanoid Robots; Robust/Adaptive Control of Robotic Systems

    Abstract : We present an extension of our previously proposed IS-MPC method for humanoid gait generation aimed at obtaining robust performance in the presence of disturbances. The considered disturbance signals vary in a range of known amplitude around a mid-range value that can change at each sampling time, but whose current value is assumed to be available. The method consists in modifying the stability constraint that is at the core of IS-MPC by incorporating the current mid-range disturbance, and performing an appropriate restriction of the ZMP constraint in the control horizon on the basis of the range amplitude of the disturbance. We derive explicit conditions for recursive feasibility and internal stability of the IS-MPC method with constraint modification. Finally, we illustrate its superior performance with respect to the nominal version by performing dynamic simulations on the NAO robot.

- Hybrid Zero Dynamics Inspired Feedback Control Policy Design for 3D Bipedal Locomotion Using Reinforcement Learning

    Author: Castillo, Guillermo | The Ohio State University
    Author: Weng, Bowen | The Ohio State University
    Author: Zhang, Wei | Southern University of Science and Technology
    Author: Hereid, Ayonga | Ohio State University
 
    keyword: Legged Robots; Deep Learning in Robotics and Automation

    Abstract : This paper presents a novel model-free reinforcement learning (RL) framework to design feedback control policies for 3D bipedal walking. Existing RL algorithms are often trained in an end-to-end manner or rely on prior knowledge of some reference joint trajectories. Different from these studies, we propose a novel policy structure that appropriately incorporates physical insights gained from the hybrid nature of the walking dynamics and the well-established hybrid zero dynamics approach for 3D bipedal walking. As a result, the overall RL framework has several key advantages, including lightweight network structure, short training time, and less dependence on prior knowledge. We demonstrate the effectiveness of the proposed method on Cassie, a challenging 3D bipedal robot. The proposed solution produces stable limit walking cycles that can track various walking speed in different directions. Surprisingly, without specifically trained with disturbances to achieve robustness, it also performs robustly against various adversarial forces applied to the torso towards both the forward and the backward directions.

- Optimal Reduced-Order Modeling of Bipedal Locomotion

    Author: Chen, Yu-Ming | University of Pennsylvania
    Author: Posa, Michael | University of Pennsylvania
 
    keyword: Humanoid and Bipedal Locomotion; Legged Robots; Model Learning for Control

    Abstract : State-of-the-art approaches to legged locomotion are widely dependent on the use of models like the linear inverted pendulum (LIP) and the spring-loaded inverted pendulum (SLIP), popular because their simplicity enables a wide array of tools for planning, control, and analysis. However, they inevitably limit the ability to execute complex tasks or agile maneuvers. In this work, we aim to automatically synthesize models that remain low-dimensional but retain the capabilities of the high-dimensional system. For example, if one were to restore a small degree of complexity to LIP, SLIP, or a similar model, our approach discovers the form of that additional complexity which optimizes performance. In this paper, we define a class of reduced-order models and provide an algorithm for optimization within this class. To demonstrate our method, we optimize models for walking at a range of speeds and ground inclines, for both a five-link model and the Cassie bipedal robot.

## Motion Control
- Anti-Jackknife Control of Tractor-Trailer Vehicles Via Intrinsically Stable MPC

    Author: Beglini, Manuel | DIAG, Sapienza University of Rome
    Author: Lanari, Leonardo | Sapienza University of Rome
    Author: Oriolo, Giuseppe | Sapienza University of Rome
 
    keyword: Motion Control; Nonholonomic Mechanisms and Systems; Autonomous Vehicle Navigation

    Abstract : It is common knowledge that tractor-trailer vehicles are affected by jackknifing, a phenomenon that consists in the divergence of the trailer hitch angle and ultimately causes the vehicle to fold up. For the case of backwards motion, in which jackknifing can also occur at low speeds, we present a control method that drives the vehicle along a reference Cartesian trajectory while avoiding the divergence of the hitch angle. In particular, a feedback control law is obtained by combining two actions: a tracking term, computed using input-output linearization, and a corrective term, generated via IS-MPC, an intrinsically stable MPC scheme which is effective for stable inversion of nonminimum-phase systems. The proposed method has been verified in simulation and experimentally validated on a purposely built prototype.

- On Sensing-Aware Model Predictive Path-Following Control for a Reversing General 2-Trailer with a Car-Like Tractor

    Author: Ljungqvist, Oskar | Link�ping University, ISY, Automatic Control
    Author: Axehill, Daniel | Link�ping University
    Author: Pettersson, Henrik | Scania CV
 
    keyword: Motion Control; Optimization and Optimal Control; Wheeled Robots

    Abstract : The design of reliable path-following controllers is a key ingredient for successful deployment of self-driving vehicles. This controller-design problem is especially challenging for a general 2-trailer with a car-like tractor due to the vehicle's structurally unstable joint-angle kinematics in backward motion and the car-like tractor's curvature limitations which can cause the vehicle segments to fold and enter a jackknife state. Furthermore, optical sensors with a limited field of view have been proposed to solve the joint-angle estimation problem online, which introduce additional restrictions on which vehicle states that can be reliably estimated. To incorporate these restrictions at the level of control, a model predictive path-following controller is proposed. By taking the vehicle's physical and sensing limitations into account, it is shown in real-world experiments that the performance of the proposed path-following controller in terms of suppressing disturbances and recovering from non-trivial initial states is significantly improved compared to a previously proposed solution where the constraints have been neglected.

- Offline Practising and Runtime Training Framework for Autonomous Motion Control of Snake Robots

    Author: Cheng, Long | Sun Yat-Sen University
    Author: Huang, Jianping | Sun Yat-Sen University
    Author: Liu, Linlin | Sun Yat-Sen University
    Author: Jian, Zhiyong | Sun Yat-Sen University
    Author: Huang, Yuhong | National University of Defense Technology
    Author: Huang, Kai | Sun Yat-Sen University
 
    keyword: Motion Control; Robust/Adaptive Control of Robotic Systems; Biologically-Inspired Robots

    Abstract : This paper proposes an offline and runtime combined framework for the autonomous motion of snake robots. With the dynamic feedback of its state during runtime, the robot utilizes the linear regression to update its control parameters for better performance and thus adaptively reacts to the environment. To reduce interference from infeasible samples and improve efficiency, the data set for runtime training is chosen from one in several clusters categorized from samples collected in offline practice. Moreover, only the most sensitive control parameter is updated at one iteration for better robustness and efficiency. The effectiveness and efficiency of our approach are evaluated by a set of case studies of pole climbing. Experimental results demonstrate that with the proposed framework, the snake robot can adapt its locomotion gait to poles with different unknown diameters.

- Control of a Differentially Driven Nonholonomic Robot Subject to a Restricted Wheels Rotation

    Author: Pazderski, Dariusz | Poznan University of Technology
    Author: Kozlowski, Krzysztof R. | Poznan University of Technology
 
    keyword: Motion Control; Wheeled Robots; Nonholonomic Mechanisms and Systems

    Abstract : The paper deals with non-standard motion tasks specified for a two-wheeled nonholonomic robot. It is assumed that wheels cannot fully rotate which reduces a set of feasible movements significantly. In spite of these constraints, it is expected that position of the robot can be changed without violating nonholonomic constraints. Such a possibility comes from small time local controllability (STLC) of the kinematics described on four-dimensional configuration manifold.<p>In order to solve these specific tasks a feedback taking advantage of the transverse function approach is designed. Consequently, the system can be virtually released from nonholonomic constraints. The transverse function also defines a virtual geometry constraint which makes it possible to limit wheels rotation. </p><p>Properties of the designed controller are illustrated by results of numerical simulations in various motion task scenarios.

- Inferring Task-Space Central Pattern Generator Parameters for Closed-Loop Control of Underactuated Robots

    Author: Kent, Nathan | University of Rochester
    Author: Bhirangi, Raunaq Mahesh | Carnegie Mellon University
    Author: Travers, Matthew | Carnegie Mellon University
    Author: Howard, Thomas | University of Rochester
 
    keyword: Motion Control; Underactuated Robots; Model Learning for Control

    Abstract : The complexity associated with the control of highly-articulated legged robots scales quickly as the number of joints increases. Traditional approaches to the control of these robots are often impractical for many real-time applications. This work thus presents a novel sampling-based planning approach for highly-articulated robots that utilizes a probabilistic graphical model (PGM) to infer in real-time how to optimally modify goal-driven, locomotive behaviors for use in closed-loop control. Locomotive behaviors are quantified in terms of the parameters associated with a network of neural oscillators, or rather a central pattern generator (CPG). For the first time, we show that the PGM can be used to optimally modulate different behaviors in real-time (i.e., to select of optimal choice of parameter values across the CPG model) in response to changes both in the local environment and in the desired control signal. The PGM is trained offline using a library of optimal behaviors that are generated using a gradient-free optimization framework.

- Magnetically Actuated Simple Millirobots for Complex Navigation and Modular Assembly

    Author: Al Khatib, Ehab | Southern Methodist University
    Author: Bhattacharjee, Anuruddha | Southern Methodist University
    Author: Razzaghi, Pouria | Southern Methodist University
    Author: Rogowski, Louis | Southern Methodist University
    Author: Kim, MinJun | Southern Methodist University
    Author: Hurmuzlu, Yildirim | Southern Methodist University
 
    keyword: Motion Control; Task Planning; Additive Manufacturing

    Abstract : Magnetic millirobots can be controlled remotely by external magnetic fields, making them promising candidates for biomedical and engineering applications. This paper presents a low-cost millirobot that has simple in design, easy to fabricate, highly scalable, and can be used as modular sub-units within complex structures for large-scale manipulation. The rectangular-shaped millirobot was made by 3D printing by using polylactic acid (PLA) filaments. Two cylindrical permanent magnets are embedded in each end. Individual millirobots are highly agile and capable of performing a variety of locomotive tasks such as pivot walking, tapping, and tumbling. A comparative study is presented to demonstrate the advantages and disadvantages of each locomotion mode. However, among these modes of locomotion, pivot walking at millimeter length scale is demonstrated for the first time in this paper, and our experimental data shows that this is the fastest and the most stable. Further, we demonstrate that the millirobot could be deployed through an esophagus-like bent tube and a maze-like path with combined motion modes. Later, to extend the functionality of our millirobots, we present two systems utilizing multiple millirobots combined together: a stag beetle and a carbot. Using a powerful electromagnetic coil system, we conduct extensive experiments to establish feasibility and practical utility of the magnetically actuated millirobot.

## Dexterous Manipulation
- MagicHand: Context-Aware Dexterous Grasping Using an Anthropomorphic Robotic Hand

    Author: Li, Hui | Wichita State University
    Author: Tan, Jindong | University of Tennessee, Knoxville
    Author: He, Hongsheng | Wichita State University
 
    keyword: Dexterous Manipulation; Recognition; Grasping

    Abstract : Understanding of characteristics of objects such as fragility, rigidity, texture and dimensions facilitates and innovates robotic grasping. In this paper, we propose a context-aware anthropomorphic robotic hand (MagicHand) grasping system which is able to gather various information about its target object and generate grasping strategies based on the perceived information. In this work, NIR spectra of target objects are perceived to recognize materials on a molecular level and RGB-D images are collected to estimate dimensions of the objects. We selected six most used grasping poses and our system is able to decide the most suitable grasp type and grasp size based on the characteristics of an object. Through multiple experiments, the performance of the MagicHand system is demonstrated.

- Strategy for Roller Chain Assembly with Parallel Jaw Gripper

    Author: Tatemura, Keiki | Wakayama University
    Author: Dobashi, Hiroki | Wakayama University
 
    keyword: Dexterous Manipulation; Grippers and Other End-Effectors; Manufacturing, Maintenance and Supply Chains

    Abstract : For realizing a versatile, &#64258;exible robotic assembly system in manufacturing, robots need to handle not only rigid parts but also parts with &#64258;exible characteristics such as belts, cables, roller chains, and so on. This paper presents a strategy for assembling a roller chain to a set of sprockets with a conventional parallel jaw gripper, utilizing the property of the roller chain. Targeting the roller chain assembly of a belt drive unit designed for the World Robot Summit 2018, the validity and the utility of the proposed strategy are experimentally veri&#64257;ed.

- Distal Hyperextension Is Handy: High Range of Motion in Cluttered Environments

    Author: Ruotolo, Wilson | Stanford University
    Author: Thomasson, Rachel | University of California, Berkeley
    Author: Herrera, Joel | Stanford
    Author: Gruebele, Alexander | Stanford University
    Author: Cutkosky, Mark | Stanford University
 
    keyword: Dexterous Manipulation; Grippers and Other End-Effectors; Multifingered Hands

    Abstract : As robots branch out from the manufacturing sector into the home, there is a pressing need for new technology that can operate in cluttered and unstructured human environments. Loading and unloading a dishwasher serves as a difficult representative challenge for in-home robots, and a new robotic end-effector has been developed for this type of task. The actuation of the fingers is integrated with a bending degree of freedom that is nearly coincident with the proximal joints of the fingers, an arrangement that greatly increases the kinematic workspace in constrained environments. In addition, the distal joints of the fingers are capable of hyperextension (bending backwards), allowing them to pinch a wider range of surface curvatures and angles securely. A third feature of the hand is a palm that combines a granular jamming substrate with suction cups to adhere to wet and slippery objects of varying curvatures. Integration of these features into a single prototype allows the hand to grasp and manipulate dirty dishes reliably and with low gripping forces, as demonstrated in object acquisition and manipulation with less than 10N of applied force.

- Learning Pre-Grasp Manipulation for Objects in Un-Graspable Poses

    Author: Sun, Zhaole | Tsinghua University, the University of Edinburgh, Intel Lab Chin
    Author: Yuan, Kai | University of Edinburgh
    Author: Hu, Wenbin | University of Edinburgh
    Author: Yang, Chuanyu | University of Edinburgh
    Author: Li, Zhibin | University of Edinburgh
 
    keyword: Dexterous Manipulation; Dual Arm Manipulation; Grasping

    Abstract : In robotic grasping, objects are often occluded in ungraspable configurations such that no feasible grasp pose can be found, e.g. large flat boxes on the table that can only be grasped once lifted. Inspired by human bimanual manipulation, e.g. one hand to lift up things and the other to grasp, we address this type of problems by introducing pregrasp manipulation -- push and lift actions. We propose a model-free Deep Reinforcement Learning framework to train feedback control policies that utilize visual information and proprioceptive states of the robot to autonomously discover robust pregrasp manipulation. The robot arm learns to push the object first towards a support surface and then lift up one side of the object, creating an object-table clearance for possible grasping solutions. Furthermore, we show the robustness of the proposed learning framework in training pregrasp policies that can be directly transferred to a real robot. Lastly, we evaluate the effectiveness and generalization ability of the learned policy in real-world experiments, and demonstrate pregrasp manipulation of objects with various sizes, shapes, weights, and surface friction.

- Object-Level Impedance Control for Dexterous In-Hand Manipulation

    Author: Pfanne, Martin | DLR German Aerospace Center
    Author: Chalon, Maxime | German Aerospace Center (DLR)
    Author: Stulp, Freek | DLR - Deutsches Zentrum F�r Luft Und Raumfahrt E.V
    Author: Ritter, Helge Joachim | Bielefeld University
    Author: Albu-Sch�ffer, Alin | DLR - German Aerospace Center
 
    keyword: Dexterous Manipulation; Grasping; Compliance and Impedance Control

    Abstract : This work presents a novel object-level control framework for the dexterous in-hand manipulation of objects with torque-controlled robotic hands. The proposed impedance-based controller realizes the compliant 6-DOF control of a grasped object. Enabled by the in-hand localization, the slippage of contacts is avoided by actively maintaining the desired grasp configuration. The internal forces on the object are determined by solving a quadratic optimization problem, which explicitly considers friction constraints on the contacts and allows to gradually shift the load between fingers. The proposed framework is capable of dealing with dynamic changes in the grasp configuration, which makes it applicable for the control of the object during grasp acquisition or the reconfiguration of fingers (i.e. finger gaiting). A nullspace controller avoids joint limits and singularities. Experiments with the DLR robot David demonstrate the efficiency and performance of the controller in various grasping scenarios.

- Picking Thin Objects by Tilt-And-Pivot Manipulation and Its Application to Bin Picking

    Author: Tong, Zhekai | The Hong Kong University of Science and Technology
    Author: He, Tierui | The Hong Kong University of Science and Technology
    Author: Kim, Chung Hee | The Hong Kong University of Science and Technology
    Author: Ng, Yu Hin | The Hong Kong University of Science and Technology
    Author: Xu, Qianyi | The Hong Kong University of Science and Technology
    Author: Seo, Jungwon | The Hong Kong University of Science and Technology
 
    keyword: Dexterous Manipulation; Grasping; Grippers and Other End-Effectors

    Abstract : This paper introduces the technique of tilt-and-pivot manipulation, a new method for picking thin, rigid objects lying on a flat surface through robotic dexterous in-hand manipulation. During the manipulation process, the gripper is controlled to reorient about the contact with the object such that its finger can get in the space between the object and the supporting surface, which is formed by tilting up the object, with no relative sliding motion at the contact. As a result, a pinch grasp can be obtained on the faces of the thin object with ease. We discuss issues regarding the kinematics and planning of tilt-and-pivot, effector shape design, and the overall practicality of the manipulation technique, which is general enough to be applicable to any rigid convex polygonal objects. We also present a set of experiments in a range of bin picking scenarios.

- In-Hand Manipulation of Objects with Unknown Shapes

    Author: Cruciani, Silvia | KTH Royal Institute of Technology
    Author: Yin, Hang | KTH
    Author: Kragic, Danica | KTH
 
    keyword: Dexterous Manipulation; Perception for Grasping and Manipulation

    Abstract : This work addresses the problem of changing grasp configurations on objects with an unknown shape through in-hand manipulation. Our approach leverages shape priors, learned as deep generative models, to infer novel object shapes from partial visual sensing. The Dexterous Manipulation Graph method is extended to build incrementally and account for object shape uncertainty when planning a sequence of manipulation actions. We show that our approach successfully solves in-hand manipulation tasks with unknown objects, and demonstrate the validity of these solutions with robot experiments.

- Learning Hierarchical Control for Robust In-Hand Manipulation

    Author: Li, Tingguang | The Chinese University of Hong Kong
    Author: Srinivasan, Krishnan | Stanford University
    Author: Meng, Max Q.-H. | The Chinese University of Hong Kong
    Author: Yuan, Wenzhen | Carnegie Mellon University
    Author: Bohg, Jeannette | Stanford University
 
    keyword: Dexterous Manipulation; Deep Learning in Robotics and Automation; Motion Control of Manipulators

    Abstract : Robotic in-hand manipulation has been a long-standing challenge due to the complexity of modeling hand and object in contact and of coordinating finger motion for complex manipulation sequences. To address these challenges, the majority of prior work has either focused on model-based, low-level controllers or on model-free deep reinforcement learning that each have their own limitations. We propose a hierarchical method that relies on traditional, model-based controllers on the low-level and learned policies on the mid-level. The low-level controllers can robustly execute different manipulation primitives (reposing, sliding, flipping). The mid-level policy orchestrates these primitives. We extensively evaluate our approach in simulation with a 3-fingered hand that controls three degrees of freedom of elongated objects. We show that our approach can move objects between almost all the possible poses in the workspace while keeping them firmly grasped. We also show that our approach is robust to inaccuracies in the object models and to observation noise. Finally, we show how our approach generalizes to objects of other shapes.

- Tactile Dexterity: Manipulation Primitives with Tactile Feedback

    Author: Hogan, Francois | Massachusetts Institute of Technology
    Author: Ballester, Jose | Massachusetts Institute of Technology
    Author: Dong, Siyuan | MIT
    Author: Rodriguez, Alberto | Massachusetts Institute of Technology
 
    keyword: Dexterous Manipulation; Force and Tactile Sensing; Dual Arm Manipulation

    Abstract : This paper develops closed-loop tactile controllers for dexterous robotic manipulation with a dual-palm robotic system. Tactile dexterity is an approach to dexterous manipulation that plans for robot/object interactions that render interpretable tactile information for control. We divide the role of tactile control into two goals: 1) control the contact state between the end-effector and the object (contact/no-contact, stick/slip) by regulating the stability of planned contact configurations and monitoring undesired slip events; and 2) control the object state by tactile-based tracking and iterative replanning of the object and robot trajectories.<p>Key to this formulation is the decomposition of manipulation plans into sequences of manipulation primitives with simple mechanics and efficient planners. We consider the scenario of manipulating an object from an initial pose to a target pose on a flat surface while correcting for external perturbations and uncertainty in the initial pose of the object. We experimentally validate the approach with an ABB YuMi dual-arm robot and demonstrate the ability of the tactile controller to react to external perturbations.

- Design of a Roller-Based Dexterous Hand for Object Grasping and Within-Hand Manipulation

    Author: Yuan, Shenli | Stanford University
    Author: Epps, Austin | Dexterity Systems
    Author: Nowak, Jerome | Stanford University
    Author: Salisbury, Kenneth | Stanford University
 
    keyword: Dexterous Manipulation; Grasping; Grippers and Other End-Effectors

    Abstract : This paper describes the development of a novel non-anthropomorphic robot hand with the ability to manipulate objects by means of articulated, actively driven rollers located at the fingertips. An analysis is conducted and systems of equations for two-finger and three-finger manipulation of a sphere are formulated to demonstrate full six degree of freedom nonholonomic spatial motion capability. A prototype version of the hand was constructed and used to grasp and manipulate a variety of objects. Tests conducted with the prototype confirmed the validity of the mathematical analysis. Unlike conventional approaches to within-hand manipulation using legacy robotic hands, the continuous rotation capability of our rolling fingertips allows for unbounded rotation of a grasped object without the need for finger gaiting.

- High-Resolution Optical Fiber Shape Sensing of Continuum Robots: A Comparative Study

    Author: Monet, Fr�d�ric | Polytechnique Montreal
    Author: Sefati, Shahriar | Johns Hopkins University
    Author: Lorre, Pierre | Polytechnique Montreal
    Author: Poiffaut, Arthur | Polytechnique Montreal
    Author: Kadoury, Samuel | Polytechnique Montr�al
    Author: Armand, Mehran | Johns Hopkins University Applied Physics Laboratory
    Author: Iordachita, Ioan Iulian | Johns Hopkins University
    Author: Kashyap, Raman | Polytechnique Montreal
 
    keyword: Dexterous Manipulation; Medical Robots and Systems

    Abstract : Flexible medical instruments, such as Continuum Dexterous Manipulators (CDM), constitute an important class of tools for minimally invasive surgery. Fiber Bragg grating (FBG) sensors have demonstrated great potential in shape sensing and consequently tip position estimation of CDMs. However, due to the limited number of sensing locations, these sensors can only accurately recover basic shapes, and become unreliable in the presence of obstacles or many inflection points such as s-bends. Optical Frequency Domain Reflectometry (OFDR), on the other hand, can achieve much higher spatial resolution, and can therefore accurately reconstruct more complex shapes. Additionally, Random Optical Gratings by Ultraviolet laser Exposure (ROGUEs) can be written in the fibers to increase signal to noise ratio of the sensors. In this comparison study, the tip position error is used as a metric to compare both FBG and OFDR shape reconstructions for a CDM developed for orthopedic surgeries, using a pair of stereo cameras as ground truth. The tip position error for the OFDR (and FBG) technique was found to be 0.32 (0.83) mm in free-bending environment, 0.41 (0.80) mm when interacting with obstacles, and 0.45 (2.27) mm in s-bending. Moreover, the maximum tip position error remains sub-mm for the OFDR reconstruction, while it reaches 3.40 mm for FBG reconstruction. These results propose a cost-effective, robust and more accurate alternative to FBG sensors for reconstructing complex CDM shapes.

- Local Trajectory Stabilization for Dexterous Manipulation Via Piecewise Affine Approximations

    Author: Han, Weiqiao | Massachusetts Institute of Technology
    Author: Tedrake, Russ | Massachusetts Institute of Technology
 
    keyword: Dexterous Manipulation; Motion and Path Planning; Motion Control of Manipulators

    Abstract : We propose a model-based approach to design feedback policies for dexterous robotic manipulation. The manipulation problem is formulated as reaching the target region from an initial state for some non-smooth nonlinear system. First, we use trajectory optimization to find a feasible trajectory. Next, we characterize the local multi-contact dynamics around the trajectory as a piecewise affine system, and build a funnel around the linearization of the nominal trajectory using polytopes. We prove that the feedback controller at the vicinity of the linearization is guaranteed to drive the nonlinear system to the target region. During online execution, we solve linear programs to track the system trajectory. We validate the algorithm on hardware, showing that even under large external disturbances, the controller is able to accomplish the task.

## Computer Vision for Automation and Manufacturing
- Monocular Direct Sparse Localization in a Prior 3D Surfel Map

    Author: Ye, Haoyang | The Hong Kong University of Science and Technology
    Author: Huang, Huaiyang | The Hong Kong University of Science and Technology
    Author: Liu, Ming | Hong Kong University of Science and Technology
 
    keyword: Computer Vision for Automation; Localization; Visual Tracking

    Abstract : In this paper, we introduce an approach to tracking the pose of a monocular camera in a prior surfel map. By rendering vertex and normal maps from the prior surfel map, the global planar information for the sparse tracked points in the image frame is obtained. The tracked points with and without the global planar information involve both global and local constraints of frames to the system. Our approach formulates all constraints in the form of direct photometric errors within a local window of the frames. The final optimization utilizes these constraints to provide the accurate estimation of global 6-DoF camera poses with the absolute scale. The extensive simulation and real-world experiments demonstrate that our monocular method can provide accurate camera localization results under various conditions.

- LINS: A Lidar-Inertial State Estimator for Robust and Efficient Navigation

    Author: Qin, Chao | Shenzhen Yiqing Inovation Co., Ltd
    Author: Ye, Haoyang | The Hong Kong University of Science and Technology
    Author: Pranata, Christian Edwin | Robotics and Multiperception Lab HKUST
    Author: Han, Jun | University of Notre Dame
    Author: Zhang, Shuyang | Shenzhen Yiqing Inovation Co., Ltd
    Author: Liu, Ming | Hong Kong University of Science and Technology
 
    keyword: Computer Vision for Automation; Calibration and Identification

    Abstract : We present LINS, a lightweight lidar-inertial state estimator, for real-time ego-motion estimation. The proposed method enables robust and efficient navigation for ground vehicles in challenging environments, such as feature-less scenes, via fusing a 6-axis IMU and a 3D lidar in a tightly-coupled scheme. An iterated error-state Kalman filter (ESKF) is designed to correct the estimated state recursively by generating new feature correspondences in each iteration, and to keep the system computationally tractable. Moreover, we use a robocentric formulation that represents the state in a moving local frame in order to prevent filter divergence in a long run. To validate robustness and generalizability, extensive experiments are performed in various scenarios. Experimental results indicate that LINS offers comparable performance with the state-of-the-art lidar-inertial odometry in terms of stability and accuracy and has order-of-magnitude improvement in speed.

- Automated Eye-In-Hand Robot-3D Scanner Calibration for Low Stitching Errors

    Author: Madhusudanan, Harikrishnan | University of Toronto
    Author: Liu, Xingjian | University of Toronto
    Author: Chen, Wenyuan | University of Toronto
    Author: Li, Dahai | University of Toronto
    Author: Du, Linghao | University of Toronto
    Author: Li, Jianfeng | University of Toronto
    Author: Ge, Ji | University of Toronto
    Author: Sun, Yu | University of Toronto
 
    keyword: Computer Vision for Manufacturing; Factory Automation; Industrial Robots

    Abstract : A 3D measurement system consisting of a 3D scanner and an industrial robot (eye-in-hand) is commonly used to scan large object under test (OUT) from multiple field-of-views (FOVs) for complete measurement. A data stitching process is required to align multiple FOVs into a single coordinate system. Marker-free stitching assisted by robot's accurate positioning becomes increasingly attractive since it bypasses the cumbersome traditional fiducial marker-based method. Most existing methods directly use initial Denavit-Hartenberg (DH) parameters and hand-eye calibration to calculate the transformations between multiple FOVs. Since accuracy of DH parameters deteriorates over time, such methods suffer from high stitching errors (e.g., 0.2 mm) in long-term routine industrial use. This paper reports a new robot-scanner calibration approach to realize such measurement with low data stitching errors. During long-term continuous measurement, the robot periodically moves towards a 2D standard calibration board to optimize kinematic model's parameters to maintain a low stitching error. This capability is enabled by several techniques including virtual arm-based robot-scanner kinematic model, trajectory-based robot-world transformation calculation, nonlinear optimization. Experimental results demonstrated a low data stitching error (&lt; 0.1 mm) similar to the cumbersome marker-based method and a lower system downtime (&lt; 60 seconds vs. 10-15 minutes by traditional DH and hand-eye calibration).

- Monocular Visual Odometry Using Learned Repeatability and Description

    Author: Huang, Huaiyang | The Hong Kong University of Science and Technology
    Author: Ye, Haoyang | The Hong Kong University of Science and Technology
    Author: Sun, Yuxiang | Hong Kong University of Science and Technology
    Author: Liu, Ming | Hong Kong University of Science and Technology
 
    keyword: Computer Vision for Automation; SLAM; Mapping

    Abstract : Robustness and accuracy for monocular visual odometry (VO) under challenging environments are widely concerned. In this paper, we present a monocular VO system leveraging learned repeatability and description. In a hybrid scheme, the camera pose is initially tracked on the predicted repeatability maps in a direct manner and then refined with the patch-wise 3D-2D association. The local feature parameterization and the adapted mapping module further boost different functionalities in the system. Extensive evaluations on challenging public datasets are performed. The competitive performance on camera pose estimation demonstrates the effectiveness of our method. Additional studies on the local reconstruction accuracy and running time exhibit that our system is capable of maintaining a robust and lightweight backend.

- Interaction Graphs for Object Importance Estimation in On-Road Driving Videos

    Author: Zhang, Zehua | Indiana University Bloomington
    Author: Tawari, Ashish | Honda Research Institute
    Author: Martin, Sujitha | Honda Research Institute
    Author: Crandall, David | Indiana University
 
    keyword: Computer Vision for Automation; Deep Learning in Robotics and Automation; Visual Learning

    Abstract : A vehicle driving along the road is surrounded by many objects, but only a small subset of them influence the driver's decisions and actions. Learning to estimate the importance of each object on the driver's real-time decision-making may help better understand human driving behavior and lead to more reliable autonomous driving systems. Solving this problem requires models that understand the interactions between the ego-vehicle and the surrounding objects. However, interactions among other objects in the scene can potentially also be very helpful, e.g., a pedestrian beginning to cross the road between the ego-vehicle and the car in front will make the car in front less important. We propose a novel framework for object importance estimation using an interaction graph, in which the features of each object node are updated by interacting with others through graph convolution. Experiments show that our model outperforms state-of-the-art baselines with much less input and pre-processing.

- A Robotics Inspection System for Detecting Defects on Semi-Specular Painted Automotive Surfaces

    Author: Akhtar, Sohail | University of Guelph
    Author: Tandiya, Adarsh | University of Guelph
    Author: Moussa, Medhat | Guelph
    Author: Tarry, Cole | University of Guelph
 
    keyword: Computer Vision for Manufacturing; Industrial Robots

    Abstract : This paper describes the design and implementation of a real-time robotics system for semi-specular/painted surface defect detection. The system can be used on moving parts, tolerate varying lighting conditions, and can accommodate small inherent vibrations of the inspected surface that is common in manufacturing operations. Topographical information of the inspected surface is first obtained by the analysis of reflections of a known pattern from this surface. Spectral analysis is then applied to identify defects through novelty detection. Finally, a defect tracking mechanism eliminates spurious defects. The proposed system operates continuously at 90 fps. The paper presents field testing results that show the system can be used as a consistent and cost-effective way of quality control.

## Visual Servoing
- Active Deformation through Visual Servoing of Soft Objects

    Author: Lagneau, Romain | INSA Rennes
    Author: Krupa, Alexandre | INRIA Rennes - Bretagne Atlantique
    Author: Marchal, Maud | INSA/INRIA
 
    keyword: Visual Servoing

    Abstract : In this paper, we propose the ADVISEd (Active Deformation through VIsual SErvoing) method, a novel model-free deformation servoing method able to deform a soft object towards a desired shape. ADVISEd relies on an online estimation of the deformation Jacobian that relates the motion of the robot end-effector to the deformation behavior of the object. The estimation is based on a weighted least-squares minimization with a sliding window. The robustness of the method to observation noise is ensured using an eigenvalue-based confidence criterion. The ADVISEd method is validated through comparisons with a model-based and a model-free state-of-the-art methods. Two experimental setups are proposed to compare the methods, one to perform a marker-based active shaping task and one to perform several marker-less active shaping and shape preservation tasks. Experiments showed that our approach can interactively control the deformations of an object in different tasks while ensuring better robustness to external perturbations than the state-of-the-art methods.

- Visual Geometric Skill Inference by Watching Human Demonstration

    Author: Jin, Jun | University of Alberta
    Author: Petrich, Laura | University of Alberta
    Author: Zhang, Zichen | University of Alberta, Canada
    Author: Dehghan, Masood | University of Alberta
    Author: Jagersand, Martin | University of Alberta
 
    keyword: Visual Servoing; Visual Learning; Learning from Demonstration

    Abstract : We study the problem of learning manipulation skills from human demonstration video by inferring the association relationships between geometric features. Motivation for this work stems from the observation that humans perform eye-hand coordination tasks by using geometric primitives to define a task while a geometric control error drives the task through execution. We propose a graph based kernel regression method to directly infer the underlying association constraints from human demonstration video using Incremental Maximum Entropy Inverse Reinforcement Learning (InMaxEnt IRL). The learned skill inference provides human readable task definition and outputs control errors that can be directly plugged into traditional controllers. Our method removes the need for tedious feature selection and robust feature trackers required in traditional approaches (e.g. feature-based visual servoing). Experiments show our method infers correct geometric associations even with only one human demonstration video and can generalize well under variance.

- Direct Visual Servoing in the Frequency Domain

    Author: Marchand, Eric | Univ Rennes, Inria, CNRS, IRISA
 
    keyword: Visual Servoing

    Abstract : In this paper, we propose an original approach to extend direct visual servoing to the frequency domain. Whereas most of visual servoing approaches relied on the geometric features, recent works have highlighted the importance of taking into account the photometric information of the entire images. This leads to direct visual servoing (DVS) approaches. In this paper we propose no longer to consider the image itself in the spatial domain but its transformation in the frequency domain. The idea is to consider the Discrete Cosine Transform (DCT) which allows to represent the image in the frequency domain in terms of a sum of cosine functions that oscillate at various frequencies. This leads to a new set of coordinates in a new precomputed orthogonal basis, the coefficients of the DCT. We propose to use these coefficients as the visual features that are then consider in a visual servoing control law. We then exhibit the analytical formulation of the interaction matrix related to these coefficients. Experimental results validate our approach.

- DFVS: Deep Flow Guided Scene Agnostic Image Based Visual Servoing

    Author: Y V S, Harish | International Institute of Information Technology Hyderabad
    Author: Pandya, Harit | IIIT Hyderabad
    Author: Gaud, Ayush | International Institute of Information Technology Hyderabad
    Author: Terupally, Shreya | International Institute of Information Technology, Hyderabad
    Author: Narasimhan, Sai Shankar | IIIT Hyderabad
    Author: Krishna, Madhava | IIIT Hyderabad
 
    keyword: Visual Servoing

    Abstract : Existing deep learning based visual servoing approaches regress the relative camera pose between a pair of images. Therefore, they require a huge amount of training data and sometimes fine-tuning for adaptation to a novel scene. Furthermore, current approaches do not consider underlying geometry of the scene and rely on direct estimation of camera pose. Thus, inaccuracies in prediction of the camera pose, especially for distant goals, lead to a degradation in the servoing performance. In this paper, we propose a two-fold solution:(i)We consider optical flow as our visual features, which are predicted using a deep neural network.(ii)These flow features are then systematically integrated with depth estimates provided by another neural network using interaction matrix.We further present an extensive benchmark in a photo-realistic 3D simulation across diverse scenes to study the convergence and generalisation of visual servoing approaches. We show convergence for over 3m and 40 degrees while maintaining precise positioning of under 2cm and 1 degree on our challenging benchmark where the existing approaches that are unable to converge for majority of scenarios for over 1.5m and 20 degrees. Furthermore,we also evaluate our approach for a real scenario on an aerial robot. Our approach generalizes to novel scenarios producing precise and robust servoing performance for 6 degrees of freedom positioning tasks with even large camera transformations without any retraining or fine-tuning.

- Photometric Path Planning for Vision-Based Navigation

    Author: Rodriguez Martinez, Eder Alejandro | MIS Laboratory, University of Picardie Jules Verne
    Author: Caron, Guillaume | Université De Picardie Jules Verne
    Author: Pegard, Claude | Université De Picardie Jules Verne
    Author: Lara, David | Instituto Tecnologico Superior De Misantla
 
    keyword: Visual Servoing; Visual-Based Navigation

    Abstract : We present a vision-based navigation system that uses a visual memory to navigate. Such memory corresponds to a topological map of key images created from moving a virtual camera over a model of the real scene. The advantage of our approach is that it provides a useful insight into the navigability of a visual path without relying on a traditional learning stage. During the navigation stage, the robot is controlled by sequentially comparing the images stored in the memory with the images acquired by the onboard camera. The evaluation is conducted on a robotic arm equipped with a camera and the model of the environment corresponds to a top view image of an urban scene.

- A Memory of Motion for Visual Predictive Control Tasks

    Author: Paolillo, Antonio | Idiap Research Institute
    Author: Lembono, Teguh Santoso | Idiap Research Institute
    Author: Calinon, Sylvain | Idiap Research Institute
 
    keyword: Visual Servoing; Learning and Adaptive Systems

    Abstract : This paper addresses the problem of efficiently achieving visual predictive control tasks. To this end, a memory of motion, containing a set of trajectories built off-line, is used for leveraging precomputation and dealing with difficult visual tasks. Standard regression techniques, such as k-nearest neighbors and Gaussian process regression, are used to query the memory and provide on-line a warm-start and a way point to the control optimization process. The proposed technique allows the control scheme to achieve high performance and, at the same time, keep the computational time limited. Simulation and experimental results, carried out with a 7-axis manipulator, show the effectiveness of the approach.

## Soft Robot Materials and Design

- Designing Ferromagnetic Soft Robots (FerroSoRo) with Level-Set-Based Multiphysics Topology Optimization

    Author: Tian, Jiawei | The State University of New York at Stony Brook
    Author: Zhao, Xuanhe | MIT
    Author: Gu, Xianfeng | Stony Brook University
    Author: Chen, Shikui | State University of New York at Stony Brook
 
    keyword: Soft Robot Materials and Design; Dynamics

    Abstract : Soft active materials can generate flexible locomotion and change configurations through large deformations when subjected to an external environmental stimulus. They can be engineered to design �soft machines' such as soft robots, compliant actuators, flexible electronics, or bionic medical devices. By embedding ferromagnetic particles into soft elastomer matrix, the ferromagnetic soft matter can generate flexible movement and shift morphology in response to the external magnetic field. By taking advantage of this physical property, soft active structures undergoing desired motions can be generated by tailoring the layouts of the ferromagnetic soft elastomers. Structural topology optimization has emerged as an attractive tool to achieve innovative structures by optimizing the material layout within a design domain, and it can be utilized to architect ferromagnetic soft active structures. In this paper, the level-set-based topology optimization method is employed to design ferromagnetic soft robots (FerroSoRo). The objective function comprises a sub-objective function for the kinematics requirement and a sub-objective function for minimum compliance. Shape sensitivity analysis is derived using the material time derivative and adjoint variable method. Three examples, including a gripper, an actuator, and a flytrap structure, are studied to demonstrate the effectiveness of the proposed framework.

- Exoskeleton-Covered Soft Finger with Vision-Based Proprioception and Tactile Sensing

    Author: She, Yu | Massachusetts Institute of Technology
    Author: Liu, Sandra Q. | Massachusetts Institute of Technology
    Author: Yu, Peiyu | Tsinghua University
    Author: Adelson, Edward | MIT
 
    keyword: Soft Robot Materials and Design; Modeling, Control, and Learning for Soft Robots; Soft Robot Applications

    Abstract : Soft robots offer significant advantages in adapt-ability, safety, and dexterity compared to conventional rigid-body robots. However, it is challenging to equip soft robots with accurate proprioception and exteroception due to their high flexibility and elasticity. In this work, we describe the development of a vision-based proprioceptive and tactile sensor for soft robots called GelFlex. More specifically, we develop a novel exoskeleton-covered soft finger with embedded cameras and deep learning methods that enable high-resolution proprioceptive sensing and rich tactile sensing. To do so, we design features along the axial direction of the gripper, which enable high-resolution proprioceptive sensing, and incorporate a reflective ink coating on the surface of the gripper to enable rich tactile sensing. We design a highly underactuated exoskeleton with a tendon-driven mechanism to actuate the gripper. We then train neural networks for proprioception and shape classification using data from the embedded sensors. Finally, we perform a bar stock classification task, which requires both shape and tactile information. The accuracy for proprioception while grasping objects was within an accumulative positional and angle error of 2 mm and 5.5&#9702;. These proposed techniques offer soft robots the high-level ability to simultaneously perceive their proprioceptive state and peripheral environment, providing potential solutions for soft robots to solve everyday manipulation tasks.

- Tuning the Energy Landscape of Soft Robots for Fast and Strong Motion

    Author: Sun, Jiefeng | Colorado State University
    Author: Tighe, Brandon | Colorado State University
    Author: Zhao, Jianguo | Colorado State University
 
    keyword: Soft Robot Materials and Design; Soft Robot Applications; Compliant Joint/Mechanism

    Abstract : Soft robots demonstrate great potential compared with traditional rigid robots owing to their inherently soft body structures. Although researchers have made tremendous progress in recent years, existing soft robots are in general plagued by a main issue: slow speeds and small forces. In this work, we aim to address this issue by actively designing the energy landscape of the soft body: the total strain energy with respect to the robot's deformation. With such a strategy, a soft robot's dynamics can be tuned to have fast and strong motion. We introduce the general design principle using a soft module with two stable states that can rapidly switch from one state to the other under external forces. We characterize the required triggering (switching) force with respect to design parameters (e.g., the initial shape of the module). We then apply the soft bistable module to develop fast and strong soft robots, whose triggering forces are generated by a soft actuator -- twisted-and-coiled actuator (TCA). We demonstrate a soft gripper that can hold weights more than 8 times its own weight, and a soft jumping robot that can jump more than 5 times its body height. We envision our strategies will overcome the weakness of soft robots to unleash their potential for diverse applications.

- REBOund: Untethered Origami Jumping Robot with Controllable Jump Height

    Author: Carlson, Jaimie | University of Pennsylvania
    Author: Friedman, Jason | University of Pennsylvania
    Author: Kim, Christopher Yoon Jae | University of Pennsylvania
    Author: Sung, Cynthia | University of Pennsylvania
 
    keyword: Soft Robot Materials and Design; Modeling, Control, and Learning for Soft Robots; Soft Robot Applications

    Abstract : Origami robots are well-suited for jumping maneuvers because of their light weight and ability to incorporate actuation and control strategies directly into the robot body. However, existing origami robots often model fold patterns as rigidly foldable and fail to take advantage of the deformation in an origami sheet for potential energy storage. In this paper, we consider a parametric origami tessellation, the Reconfigurable Expanding Bistable Origami (REBO) pattern, which leverages face deformations to act as a nonlinear spring. We present a spring-based pseudo-rigid-body model for the REBO that calculates its energy when compressed to a given displacement and compare that model to experimental measurements taken on a mechanical testing system. This stored potential energy, when released quickly, can cause the pattern to jump. Using our model and experimental data, we design and fabricate a jumping robot, REBOund, that uses the spring-like REBO pattern as its body. Four lightweight servo motors with custom release mechanisms allow for quick compression and release of the origami pattern, allowing the fold pattern to jump over its own height even when carrying 5~times its own weight in electronics and power. We further demonstrate that small geometric changes to the pattern allow us to control the jump height without changing the actuation or control mechanism.

- Concentric Precurved Bellows: New Bending Actuators for Soft Robots

    Author: Childs, Jake | University of Tennessee, Knoxville
    Author: Rucker, Caleb | University of Tennessee
 
    keyword: Soft Robot Materials and Design; Modeling, Control, and Learning for Soft Robots

    Abstract : We present a new mechanical bending actuator for soft and continuum robots based on a pair of concentric precurved bellows. Each bellows is rotated axially at its base, allowing independent control of the curvature and bending plane of the concentric bellows pair. Rotation of precurved nested tubes is a well-known principle by which needle-sized concentric-tube robots operate, but the concept has never been scaled up to large diameters due to the trade-offs of increased actuation forces, decreased range of motion, strain limits, and torsional windup. In this letter, we show that using bellows structures instead of tubes allows two important breakthroughs: (1) actuation by rotation of precurved concentric elements can be achieved at much larger scales, and (2) torsional lag and instability are virtually eliminated due to the high ratio of torsional rigidity to flexural rigidity endowed by the bellows geometry. We discuss the development of two types of 3D printed concentric precurved bellows prototypes (revolute and helical), perform model parameter identification, and experimentally verify a torsionless mechanics model for the actuated shape which accounts for direction-dependent rigidities.

- Design of Deployable Soft Robots through Plastic Deformation of Kirigami Structures

    Author: Sedal, Audrey | University of Michigan
    Author: H. Memar, Amirhossein | Facebook Reality Labs
    Author: Liu, Tianshu | Facebook Reality Labs
    Author: Menguc, Yigit | Facebook Reality Labs
    Author: Corson, Nick | Oculus Research
 
    keyword: Soft Robot Materials and Design

    Abstract : Kirigami-patterned mechanisms are an emergent class of deployable structure that are easy to fabricate and offer the potential to be integrated into deployable robots. In this paper, we propose a design methodology for robotic kirigami structures that takes into consideration the deformation, loading, and stiffness of the structure under typical use cases. We show how loading-deformation behavior of a kirigami structure can be mechanically programmed by imposing plastic deformation. We develop a model for plasticity in the stretching of a kirigami structure. We show the creation of kirigami structures that have an increased elastic region, and specified stiffness, in their deployed states. We demonstrate the benefits of such a plastically-deformed structure by integrating it into a soft deployable crawling robot: the kirigami structure matches the stiffness of the soft actuator such that the deployed, coupled behavior serves to mechanically program the gait step size.

- Self-Excited Vibration Valve That Induces Traveling Waves in Pneumatic Soft Mobile Robots

    Author: Tsukagoshi, Hideyuki | Tokyo Institute of Technology
    Author: Miyaki, Yuji | Tokyo Institute of Technology
 
    keyword: Soft Sensors and Actuators

    Abstract : This paper presents a soft compact valve inducing self-excited vibration aiming at simplification of piping, power saving and downsizing the total system for pneumatic soft mobile robots generating traveling waves. The presented device, composed of flat tubes, resistant part, permanent magnet and holder, can induce the self-excited vibration from constant supplied pressure, enabling to switch the inner pressure of different chambers periodically. In this paper, we propose a new structure of the self-excited vibration valve, capable of switching more than three different chambers in order, which can detect the set pressure inside the chamber. Moreover, the developed valve is mounted on a flexible sheet-type mobile unit that is propelled by a traveling wave, and the verification of its effectiveness is discussed through the experimental results.

- A 1mm-Thick Miniatured Mobile Soft Robot with Mechanosensation and Multimodal Locomotion

    Author: Liu, Zemin | BeiHang University
    Author: Liu, Jiaqi | Beihang University
    Author: Wang, He | Beihang University
    Author: Yu, Xiao | Johns Hopkins University
    Author: Yang, Kang | Beihang University
    Author: Liu, Wenbo | Beihang University
    Author: Nie, Shilin | Beihang University
    Author: Sun, Wenguang | Beihang University
    Author: Xie, Zhexin | Beihang University
    Author: Chen, Bohan | Buaa
    Author: Liang, Shuzhang | Beihang University
    Author: Yingchun, Guan | Beihang University
    Author: Wen, Li | Beihang University
 
    keyword: Soft Robot Materials and Design; Micro/Nano Robots; Marine Robotics

    Abstract : The miniature soft robots have many promising applications, including micro-manipulations, endoscopy, and microsurgery, etc. Nevertheless, it remains challenging to fabricate a miniatured robot device that is thin, flexible, and can perform multimodal locomotor mobility with sensory capacity. In this study, we propose a miniatured, multi-layer (two shape memory polymer layers, a flexible copper heater, a silk particle enhanced actuator layer, and a sensory layer) four-limb soft robot (0.45-gram, 35mm-long, 12mm-wide) with a total thickness of 1mm. A precise flip-assembling technique is utilized to integrate multiple functional layers (fabricated by soft lithography, laser micromachining technologies). The actuator layer's elastic modulus increased ~100% by mixing with 20% silk particles by weight, which enhanced the mechanical properties of the miniature soft robot. We demonstrate that the soft robot can perform underwater crawling and jumping-gliding locomotion. The sensing data depicts the robot's multiple bending configurations after the sensory data been processed by the microprocessor mounted on the robot torso. The miniatured soft robot can also be reshaped to a soft miniatured gripper. The proposed miniatured soft robots can be helpful for studying soft organisms' body locomotion as well as medical applications in the future.

- Anisotropic Soft Robots Based on 3D Printed Meso-Structured Materials: Design, Modeling by Homogenization and Simulation

    Author: Vanneste, F�lix | INRIA
    Author: Goury, Olivier | Inria - Lille Nord Europe
    Author: Martínez, Jon's | INRIA
    Author: Lefebvre, Sylvain | Inria
    Author: Delingette, Herve | INRIA
    Author: Duriez, Christian | INRIA
 
    keyword: Soft Robot Materials and Design; Additive Manufacturing

    Abstract : In this paper, we propose to use new 3D-printed meso-structured materials to build soft robots and we present a modeling pipeline for design assistance and control. These meta-materials can be programmed before printing to target specific mechanical properties, in particular heterogeneous stiffness and anisotropic behaviour. Without changing the external shape, we show that using such meta-material can lead to a dramatic change in the kinematics of the robot. This highlights the importance of modeling. Therefore, to help the design and to control soft robots made of these meso-structured materials, we present a modeling method based on numerical homogenization and Finite Element Method (FEM) that captures the anisotropic deformations. The method is tested on a 3 axis parallel soft robot initially made of silicone. We demonstrate the change in kinematics when the robot is built with meso-structured materials and compare its behavior with modeling results.

- 3D-Printed Electroactive Hydraulic Valves for Use in Soft Robotic Applications

    Author: Bira, Nicholas | Oregon State University
    Author: Menguc, Yigit | Oregon State University
    Author: Davidson, Joseph | Oregon State University
 
    keyword: Modeling, Control, and Learning for Soft Robots; Soft Robot Applications; Hydraulic/Pneumatic Actuators

    Abstract : Soft robotics promises developments in the research areas of safety, bio-mimicry, manipulation, human-robot interaction, and alternative locomotion techniques. The research presented here is directed towards developing an improved, low-cost, and open-source method for soft robotic control using electrorheological fluids in compact, 3D-printed electroactive hydraulic valves. We construct high-pressure electrorheological valves and deformable actuators using only commercially available materials and accessible fabrication methods. The printed valves were characterized with industrial-grade electrorheological fluid (RheOil 3.0), but the design is generalizable to other electrorheological fluids. Valve performance was shown to be an improvement over comparable work with demonstrated higher yield pressures at lower voltages (up to 230 kPa), larger flow rates (up to 15 ml/min) and lower response times (1 to 3 seconds, depending on design). The resulting valve and actuator systems enable future novel applications of electrorheological fluid-based control and hydraulics in soft robotics and other disciplines.

- Design and Workspace Characterisation of Malleable Robots

    Author: Clark, Angus Benedict | Imperial College London
    Author: Rojas, Nicolas | Imperial College London
 
    keyword: Soft Robot Materials and Design; Flexible Robots; Mechanism Design

    Abstract : For the majority of tasks performed by traditional serial robot arms, such as bin picking or pick and place, only two or three degrees of freedom (DOF) are required for motion; however, by augmenting the number of degrees of freedom, further dexterity of robot arms for multiple tasks can be achieved. Instead of increasing the number of joints of a robot to improve flexibility and adaptation, which increases control complexity, weight, and cost of the overall system, malleable robots utilise a variable stiffness link between joints allowing the relative positioning of the revolute pairs at each end of the link to vary, thus enabling a low DOF serial robot to adapt across tasks by varying its workspace. In this paper, we present the design and prototyping of a 2-DOF malleable robot, calculate the general equation of its workspace using a parameterisation based on distance geometry-suitable for robot arms of variable topology, and characterise the workspace categories that the end effector of the robot can trace via reconfiguration. Through the design and construction of the malleable robot we explore design considerations, and demonstrate the viability of the overall concept. By using motion tracking on the physical robot, we show examples of the infinite number of workspaces that the introduced 2-DOF malleable robot can achieve.

- A Tri-Stable Soft Robotic Finger Capable of Pinch and Wrap Grasps

    Author: Nguyen, Aaron Khoa | University of California, Santa Barbara
    Author: Russell, Alexander | University of California, Santa Barbara
    Author: Vuong, Vu | University of California, Santa Barbara
    Author: Naclerio, Nicholas | University of California, Santa Barbara
    Author: Huang, Heming | UCSB
    Author: Chui, Kenny | University of California, Santa Barbara
    Author: Hawkes, Elliot Wright | University of California, Santa Barbara
 
    keyword: Soft Robot Materials and Design; Soft Robot Applications; Modeling, Control, and Learning for Soft Robots

    Abstract : Soft robotic pneumatic grippers have been shown to be versatile, robust to impacts, and safe for use on delicate objects. One type, fluidic elastomer grippers, are characterized by fingers with an inextensible gripping surface backed by extensible pneumatic chambers; when inflated, this mismatch in extensibility results in the finger curling. However, one drawback of these simple fingers is that they have one pre-programmed grasp, usually a simple constant-curvature wrap. While well-suited for finger-sized round objects, they do not grasp flat or small objects well. Here, we present an adaptable tri-stable soft robotic finger that can form either a pinch or wrap grasp based on the shape of the grasped object. We enable this by incorporating two bi-stable springs into the inextensible layer. The three stable positions are: i) open (unpressurized), ii) pinch (with only the proximal section bending), and iii) wrap (with the entire finger bending). We present a simple model of the behavior of our finger and experimental results verifying the model. Further, we apply forces and moments to grasped objects, and show that the tri-stable finger increases the grasping performance when compared to a control gripper with equal gripping force. Our work presents a novel design modification that is unobtrusive, simple, and passive. Our introduction of inexpensive programmable hardware advances the versatility and adaptability of soft grippers.

- A Dexterous Tip-Extending Robot with Variable-Length Shape-Locking

    Author: Wang, Sicheng | University of California, Santa Barbara
    Author: Zhang, Ruotong | Xi'an Jiaotong University
    Author: Haggerty, David Arthur | UC Santa Barbara
    Author: Naclerio, Nicholas | University of California, Santa Barbara
    Author: Hawkes, Elliot Wright | University of California, Santa Barbara
 
    keyword: Soft Robot Materials and Design; Soft Robot Applications; Flexible Robots

    Abstract : Soft, tip-extending "vine" robots offer a uniqueability for inspection	and manipulation in highly	constrainedenvironments. It is desirable that the distal end of the robotcan be manipulated freely, while	the body remains stationary.However, in previous vine robots, either the shape of the bodywas fixed after growth with no ability to manipulate the distalend, or the whole body moved together with the tip. Here, wepresent a concept for shape-locking that enables a vine robotto move only its distal end, while the rest of the body is lockedin place. This is	achieved using two inextensible, pressurized,tip-extending,	chambers that "grow" along the sides of therobot body, preserving curvature in the	section where	theyhave been deployed. The length of the locked and free sectionscan be varied by	 controlling the extension and retractionof	these chambers. We present models describing the shape-locking mechanism and workspace	of the robot	in both freeand constrained environments. We experimentaly validate thesemodel and show an increased dexterous workspace compared toprevious vine robots, as well as decreased contact forces of theproximal end with the environment. Our shape-locking concept allows improved	performance for vine robots, advancing the field of soft robotics for inspection and manipulation in highly constrained environments.

- Compliant Electromagnetic Actuator Architecture for Soft Robotics

    Author: Kohls, Noah | Georgia Institute of Technology
    Author: Dias, Beatriz | Georgia Institute of Technology
    Author: Mensah, Yaw | University of Tennessee - Knoxville
    Author: Ruddy, Bryan P. | University of Auckland
    Author: Mazumdar, Yi | Georgia Institute of Technology
 
    keyword: Soft Robot Materials and Design; Flexible Robots; Soft Sensors and Actuators

    Abstract : Soft materials and compliant actuation concepts have generated new design and control approaches in areas from robotics to wearable devices. Despite the potential of soft robotic systems, most designs currently use hard pumps, valves, and electromagnetic actuators. In this work, we take a step towards fully soft robots by developing a new compliant electromagnetic actuator architecture using gallium-indium liquid metal conductors, as well as compliant permanent magnetic and compliant iron composites. Properties of the new materials are first characterized and then co-fabricated to create an exemplary biologically-inspired soft actuator with pulsing or grasping motions, similar to Xenia soft corals. As current is applied to the liquid metal coil, the compliant permanent magnetic tips on passive silicone arms are attracted or repelled. The dynamics of the robotic actuator are characterized using stochastic system identification techniques and then operated at the resonant frequency of 7 Hz to generate high-stroke (&gt; 6 mm) motions.

- Dynamically Reconfigurable Discrete Distributed Stiffness for Inflated Beam Robots

    Author: Do, Brian | Stanford University
    Author: Banashek, Valory | Stanford University
    Author: Okamura, Allison M. | Stanford University
 
    keyword: Soft Robot Materials and Design; Mechanism Design; Compliant Joint/Mechanism

    Abstract : Inflated continuum robots are promising for a variety of navigation tasks, but controlling their motion with a small number of actuators is challenging. These inflated beam robots tend to buckle under compressive loads, producing extremely tight local curvature at difficult-to-control buckle point locations. In this paper, we present an inflated beam robot that uses distributed stiffness changing sections enabled by positive pressure layer jamming to control or prevent buckling. Passive valves are actuated by an electromagnet carried by an electromechanical device that travels inside the main inflated beam robot body. The valves themselves require no external connections or wiring, allowing the distributed stiffness control to be scaled to long beam lengths. Multiple layer jamming elements are stiffened simultaneously to achieve global stiffening, allowing the robot to support greater cantilevered loads and longer unsupported lengths. Local stiffening, achieved by leaving certain layer jamming elements unstiffened, allows the robot to produce ``virtual joints" that dynamically change the robot kinematics. Implementing these stiffening strategies is compatible with growth through tip eversion and tendon-steering, and enables a number of new capabilities for inflated beam robots and tip-everting robots.

- Retraction of Soft Growing Robots without Buckling

    Author: Coad, Margaret M. | Stanford University
    Author: Thomasson, Rachel | University of California, Berkeley
    Author: Blumenschein, Laura | Stanford University
    Author: Usevitch, Nathan | Stanford
    Author: Hawkes, Elliot Wright | University of California, Santa Barbara
    Author: Okamura, Allison M. | Stanford University
 
    keyword: Soft Robot Materials and Design; Modeling, Control, and Learning for Soft Robots

    Abstract : Tip-extending soft robots that "grow" via pneumatic eversion of their body material have demonstrated applications in exploration of cluttered environments. During growth, the motion and force of the robot tip can be controlled in three degrees of freedom using actuators that direct the tip in combination with extension. However, when reversal of the growth process is attempted by retracting the internal body material from the base, the robot body often responds by buckling rather than inversion of its body material, which makes control of tip motion and force impossible. We present and validate a model to predict when buckling occurs instead of inversion during retraction, and we present and evaluate an electromechanical device that can be added to a tip- extending soft robot to prevent buckling during retraction and enable control of all three degrees of freedom of tip actuation during inversion. Using our retraction device, we demonstrate completion of three previously impossible tasks: exploring different branches of a forking path, reversing growth while applying minimal force on the environment, and bringing back environment samples to the base.

## Rehabilitation Robotics

- Motion Intensity Extraction Scheme for Simultaneous Recognition of Wrist/Hand Motions

    Author: Kim, Minjae | KIST
    Author: Chung, Wan Kyun | POSTECH
    Author: Kim, Keehoon | POSTECH, Pohang University of Science and Technology
 
    keyword: Rehabilitation Robotics; Recognition

    Abstract : Surface electromyography contains muscular information representing gestures and corresponding forces. However, conventional sEMG-based motion recognition methods, such as pattern classification and regression, have intrinsic limitations due to the complex characteristics of sEMG signals. In this paper, motion intensity, a highly selective sEMG feature proportional to the level of muscle contraction, is proposed. The motion intensity feature allows proportional and simultaneous recognition of multiple degrees of freedom. The proposed method was demonstrated in terms of simultaneous recognition of wrist/hand motions. The result shows that the proposed method can successfully decompose sEMG signals into highly selective signals to target motions. In future works, the proposed method will be adapted for more subjects and to sEMG applications for practical evaluation considering various grasping motions.

- Simultaneous Online Motion Discrimination and Evaluation of Whole-Body Exercise by Synergy Probes for Home Rehabilitation

    Author: Moreira Ramos, Felipe | Tohoku University
    Author: Hayashibe, Mitsuhiro | Tohoku University
 
    keyword: Rehabilitation Robotics; Human Detection and Tracking; Neurorobotics

    Abstract : The development of algorithms for motion discrimination in home rehabilitation sessions poses numerous challenges. Recent studies have used the concept of synergies to discriminate a set of movements. However, the discrimination depends on the correlation of the reconstructed movement with the online data, and the training data requires well-defined movements. In this paper, we introduced the concept of a synergy probe, which makes a direct comparison between synergies and online data. The system represents synergies and movements in the same space and monitors their behavior. The results indicated that conventional methods are influenced by the segmentation of training data, and even though the reconstructed movement is similar to the ground-truth, it does not provide sufficient information to evaluate the data in real time. The synergy probes were used to discriminate and evaluate the performance of natural whole-body exercises without segmentation or previous determination of movements. An analysis of the results also demonstrated the possibility to identify the strategies used by the subjects for movement. Such information aids in gaining a better insight and can prove beneficial in home rehabilitation.

- IART: Learning from Demonstration for Assisted Robotic Therapy Using LSTM

    Author: Pareek, Shrey | University of Illinois at Urbana Champaign
    Author: Kesavadas, Thenkurussi | University of Illinois at Urbana-Champaign
 
    keyword: Rehabilitation Robotics; Learning from Demonstration; AI-Based Methods

    Abstract : In this paper, we present an intelligent Assistant for Robotic Therapy (iART), that provides robotic assistance during 3D trajectory tracking tasks. We propose a novel LSTM-based robot learning from demonstration (LfD) paradigm to mimic a therapist's assistance behavior. iART presents a trajectory agnostic LfD routine that can generalize learned behavior from a single trajectory to any 3D shape. Once the therapist's behavior has been learned, iART enables the patient to modify this behavior as per their preference. The system requires only a single demonstration of 2 minutes and exhibits a mean accuracy of 91.41% in predicting, and hence mimicking a therapist's assistance behavior. The system delivers stable assistance in realtime and successfully reproduces different types of assistance behaviors.

- Validation of a Forward Kinematics Based Controller for a Mobile Tethered Pelvic Assist Device to Augment Pelvic Forces During Walking

    Author: Stramel, Danielle | Columbia University in the City of New York
    Author: Agrawal, Sunil | Columbia University
 
    keyword: Physically Assistive Devices; Rehabilitation Robotics; Human-Centered Robotics

    Abstract : For those with irregular gait, re-calibration of motor control strategies and retraining of coordination are key goals. Thoughtful external forces or resistances during repetitive tasks can reprogram motor control patterns and strategies. Prior work in our lab has utilized this theory to improve gait in various patient groups using the Tethered Pelvic Assist Device (TPAD), a treadmill-based robotic trainer. In this paper, we propose a new, portable extension of the TPAD, which relies on an open-loop, forward kinematics based controller to remove the restriction of walking in the laboratory on a treadmill, and therefore accommodates overground ambulation. To evaluate the effects of this new control scheme and the effects of the users holding the mobile TPAD frame, a dataset of walking in four conditions was collected from eight healthy individuals. When applying a constant pelvic loading force of 10% body weight, the mean ground reaction force increased by 8.2�7.7% when the individual holds the walker frame and 11.1 - 7.8% when no hand contact is made. The mobile TPAD was shown to still induce a targeted loading on individuals during treadmill walking. The validation of this mobile device's controller and characterization of holding the frame allow overground studies to be conducted, and now opens the door to new training paradigms for overground gait training.

- Temporal Muscle Synergy Features Estimate Effects of Short-Term Rehabilitation in Sit-To-Stand of Post-Stroke Patients

    Author: Yang, Ningjia | The University of Tokyo
    Author: An, Qi | The University of Tokyo
    Author: Kogami, Hiroki | The University of Tokyo
    Author: Yamakawa, Hiroshi | The University of Tokyo
    Author: Tamura, Yusuke | The University of Tokyo
    Author: Takahashi, Kouji | Morinomiya Hospital
    Author: Kinomoto, Makoto | Morinomiya Hospital
    Author: Yamasaki, Hiroshi | BSI-TOYOTA Collaboration Center in the Nagoya Science Park Resea
    Author: Itkonen, Matti | RIKEN
    Author: Alnajjar, Fady | United Arab Emirates University,
    Author: Shimoda, Shingo | RIKEN
    Author: Hattori, Noriaki | Morinomiya Hospital
    Author: Fujii, Takanori | Morinomiya Hospital
    Author: Otomune, Hironori | Takanorifujii19@yahoo.co.jp
    Author: Miyai, Ichiro | Morinomiya Hospital
    Author: Yamashita, Atsushi | The University of Tokyo
    Author: Asama, Hajime | The University of Tokyo
 
    keyword: Rehabilitation Robotics; Physically Assistive Devices

    Abstract : Sit-to-stand (STS) motion is an important daily activity and many post-stroke patients have difficulty in performing the STS motion. Post-stroke patients who can perform STS independently, still utilize four muscle synergies (synchronized muscle activation) as seen in healthy people. In addition, temporal muscle synergy features can reflect motor impairment of post-stroke patients. However, it has been unclear whether post-stroke patients improve their STS movements in short-term rehabilitation and which muscle synergy features can estimate this improvement. Here, we demonstrate that temporal features of muscle synergies which contribute to body extension and balance maintenance can estimate the effect of short-term rehabilitation based on machine learning methods. By analyzing muscle synergies of post-stroke patients (n=33) before and with the intervention of physical therapists, we found that about half of the patients who were severely impaired, improved activation timing of muscle synergy to raise the hip with the intervention. Additionally, we identified the temporal features that can estimate whether severely impaired post-stroke patients improve. We conclude that temporal features of muscle synergies can estimate the motor recovery in short-term rehabilitation of post-stroke patients. This finding may lead to new rehabilitation strategies for post-stroke patients that focus on improving activation timing of different muscle synergies.

- Model Learning for Control of a Paralyzed Human Arm with Functional Electrical Stimulation

    Author: Wolf, Derek | Cleveland State University
    Author: Hall, Zinnia | University of Connecticut
    Author: Schearer, Eric | Cleveland State University
 
    keyword: Rehabilitation Robotics; Model Learning for Control; Physically Assistive Devices

    Abstract : Functional electrical stimulation (FES) is a promising technique for restoring reaching ability to individuals with tetraplegia. To this point, the complexities of goal-directed reaching motions and the shoulder-arm complex have prevented the realization of this potential in full-arm 3D reaching tasks. We trained a Gaussian process regression model to form the basis of a feedforward-feedback control structure capable of achieving reaching motions with a paralyzed upper limb. Over a series of 95 reaches of at least 10 cm in length, the controller achieved an average accuracy (measured by the Euclidean distance of the wrist to the final target position) of 3.8 cm and an average error along the path of 3.5 cm. This controller is the first demonstration of an accurate, complete-arm, FES-driven 3D reaching controller to be implemented with an individual with tetraplegia.

- Patient-Specific, Voice-Controlled, Robotic FLEXotendon Glove-II System for Spinal Cord Injury

    Author: Tran, Phillip | Georgia Institute of Technology
    Author: Jeong, Seokhwan | Georgia Institute of Technology
    Author: Wolf, Steven | Emory University School of Medicine
    Author: Desai, Jaydev P. | Georgia Institute of Technology
 
    keyword: Rehabilitation Robotics; Medical Robots and Systems; Soft Robot Applications

    Abstract : Reduced hand function in spinal cord injury (SCI) patients is commonly associated with a lower quality of life and limits the autonomy of the patient because he/she cannot perform most tasks independently. Robotic rehabilitation exoskeletons have been introduced as a method for assisting in hand function restoration. In this work, we propose a voice-controlled, tendon-actuated soft exoskeleton for improving hand function rehabilitation. The exoskeleton is constructed from soft materials to conform to the user's hand for improved fit and flexibility. A partially biomimetic tendon routing strategy independently actuates the index finger, middle finger, and thumb for a total of 4 degrees-of-freedom of the overall system. Nitinol wires are used for passive finger extension and screw-guided twisted tendon actuators are used for active finger flexion to create a compact, lightweight actuation mechanism. A continuous voice control strategy is implemented to provide a hands-free control interface and a simplified user interface experience while retaining distinct user intention. The exoskeleton was evaluated in a case study with a spinal cord injury patient. The patient used the exoskeleton and completed range-of-motion measurement as well as hand function tests, including the Box and Block Test and Jebsen-Taylor Hand Function Test.

- Integration of Self-Sealing Suction Cups on the FLEXotendon Glove-II Robotic Exoskeleton System

    Author: Jeong, Seokhwan | Georgia Institute of Technology
    Author: Tran, Phillip | Georgia Institute of Technology
    Author: Desai, Jaydev P. | Georgia Institute of Technology
 
    keyword: Rehabilitation Robotics; Medical Robots and Systems; Soft Robot Applications

    Abstract : This paper presents a hand exoskeleton using self-sealing suction cup modules to assist and simplify various grasping tasks. Robotic hands, grippers, and hand rehabilitation exoskeletons require complex motion planning and control algorithms to manipulate various objects, which increases system complexity. The proposed hand exoskeleton integrated with self-sealing suction cup modules provides simplified grasping with the assistance of suction. The suction cup has a self-sealing mechanism with a passive opening valve and it reduces vacuum consumption and pump noise. The gimbal mechanism allows the suction cup to have a wide range of contact angles, which increases adaptability of grasping of the exoskeleton. The fabrication process of the device is introduced with the suction cup design and material selection. The vacuum canister and solenoid valve that comprise the proposed pneumatic circuit provide a continuous vacuum supply source without continuous operation of a vacuum pump and autonomous suction/release motion, respectively. The performance of the hand exoskeleton was demonstrated with various grasping tasks and it provided stable grasping and pick-and-place task without complex finger manipulation. The proposed hand exoskeleton has the potential to simplify the grasping process and allow patients with hand dysfunction to expand their versatility of grasping tasks.

- A Novel End-Effector Robot System Enabling to Monitor Upper-Extremity Posture During Robot-Aided Reaching Movements

    Author: Hwang, Yeji | DGIST
    Author: Lee, Seongpung | DGIST
    Author: Hong, Jaesung | DGIST
    Author: Kim, Jonghyun | Sungkyunkwan University
 
    keyword: Rehabilitation Robotics; Sensor Fusion; Human Detection and Tracking

    Abstract : End-effector type robots have been popularly applied to robot-aided therapy for rehabilitation purpose. However, those robots have a key drawback for the purpose: lack of the user's posture (joint angle) information. This paper proposes a novel end-effector rehabilitation robot system that contains a contactless motion sensor to monitor upper- extremity posture during robot-aided reaching exercise. The sensor allows the posture estimation without complicated procedures but has an inaccuracy problem such as occlusion and an unreliable segment length. Therefore, we developed a posture monitoring method, which is an analytical method without training procedure, based on the combined use of the information obtained from the sensor and the robot. Eight healthy subjects participated in the experiment with planar reaching exercise for validation. The results of joint angle estimation, high correlation coefficient (0.95 - 0.03) and small errors (3.55 - 0.70 deg), show that the proposed system can provide affordable upper-extremity posture estimation.

- Optimal Design of a Novel 3-DOF Orientational Parallel Mechanism for Pelvic Assistance on a Wheelchair: An Approach Based on Kinematic Geometry and Screw Theory

    Author: Ophaswongse, Chawin | Columbia University
    Author: Agrawal, Sunil | Columbia University
 
    keyword: Physically Assistive Devices; Parallel Robots; Mechanism Design

    Abstract : Pelvis mobility is essential to the daily seated activities of wheelchair users, however it is not yet fully addressed in the field of active wearable devices. This paper presents a novel design and optimization methodology of an in-parallel actuated robotic brace for assisting the human pelvis during seated maneuvers on wheelchair. This design uses human data captured by cameras in conjunction with the knowledge of kinematic geometry and screw theory. The mechanism has full rotational three degrees-of-freedom (DOFs) and also accommodates coupled translation of the human pelvic segment. This type of motion was realized by employing three kinematic limbs that impose non-intersecting zero-pitch constraint wrenches on the platform. Our multi-objective optimization (MOO) routine consists of two stages: (I) platform constraint synthesis, where the geometric parameters of the limb constraints were determined to minimize the pelvis-platform errors of trajectories and instantaneous screw axes (ISAs); and (II) limb structural synthesis, where limb types and dimensions, workspace, transmission performances, singularities, and actuated joint displacements were considered. The optimized mechanism has an asymmetrical [RRR]U-2[RR]S architecture. This mechanism can also be integrated into our previously developed Wheelchair Robot for Active Postural Support (WRAPS).

- Using Human Ratings for Feedback Control: A Supervised Learning Approach with Application to Rehabilitation Robotics (I)

    Author: Menner, Marcel | ETH Zurich
    Author: Neuner, Lukas | ETH Zurich
    Author: Lunenburger, Lars | Hocoma AG
    Author: Zeilinger, Melanie N. | ETH Zurich
 
    keyword: Rehabilitation Robotics; Learning and Adaptive Systems

    Abstract : This paper presents a method for tailoring a parametric controller based on human ratings. The method leverages supervised learning concepts in order to train a reward model from data. It is applied to a gait rehabilitation robot with the goal of teaching the robot how to walk patients physiologically. In this context, the reward model judges the physiology of the gait cycle (instead of therapists) using sensor measurements provided by the robot and the automatic feedback controller chooses the input settings of the robot to maximize the reward. The key advantage of the proposed method is that only a few input adaptations are necessary to achieve a physiological gait cycle. Experiments with non-disabled subjects show that the proposed method permits the incorporation of human expertise into a control law and to automatically walk patients physiologically.

- Compliant Humanoids Moving Toward Rehabilitation Applications: Transparent Integration of Real-Time Control, Whole-Body Motion Generation, and Virtual Reality (I)

    Author: Mohammadi, Pouya | Braunschweig University of Technology
    Author: Mingo, Enrico | Istituto Italiano Di Tecnologia
    Author: Dehio, Niels | Karlsruhe Institute of Technology
    Author: Malekzadeh, Milad S. | Technical University of Btraunschweig, IRP
    Author: Giese, Martin | University Clinic Tübingen
    Author: Tsagarakis, Nikos | Istituto Italiano Di Tecnologia
    Author: Steil, Jochen J. | Technische Universitét Braunschweig
 
    keyword: Rehabilitation Robotics; Software, Middleware and Programming Environments; Humanoid Robots

    Abstract : Humanoids fascinate through their anthropomorphic appearance, high dexterity and the potential to work in human-tailored environment and to interact with humans in novel applications. In our research, we promote two real-world applications in physiotherapeutic juggling and assisted walking using two compliant humanoids COMAN and COMAN+. We focus on rehabilitation, which as a result of changing demographics becomes an increasingly crucial application field. But alike most humanoid experiments, the realization of these scenarios is challenging due to the fact that the hardware is brittle, software is complex and control remains highly demanding. In this article, we describe an integrative and transparent control architecture that alleviates this complexity by strictly adhering in design and implementation to a component-based approach. It promotes flexibility and reusability and allows transparent switching between different humanoid robots, between simulation and real world, between control paradigms. It also orchestrates the integration of real-time and non-real-time components, including a Virtual Reality framework, towards rich user interaction.

- Data-Driven Reinforcement Learning for Walking Assistance Control of a Lower Limb Exoskeleton with Hemiplegic Patients

    Author: Peng, Zhinan | Unversity of Electronic Science and Tehcnology of China
    Author: Luo, Rui | Unversity of Electronic Science and Tehcnology of China
    Author: Huang, Rui | University of Electronic Science and Technology of China
    Author: Hu, Jiangping | University of Electronic Science and Technology of China
    Author: Shi, Kecheng | The School of Automation Engineering, University of Electronic S
    Author: Cheng, Hong | University of Electronic Science and Technology
    Author: Ghosh, Bijoy | Texas Tech University
 
    keyword: Rehabilitation Robotics; Robust/Adaptive Control of Robotic Systems; Optimization and Optimal Control

    Abstract : Lower limb exoskeleton (LLE) has gained considerable interests in both strength augmentation, rehabilitation and walking assistance scenarios. In walking assistance of hemiplegic patients, the LLE should have the ability to control the affected leg to track the unaffected leg's motion naturally. A critical issue in this scenario is that the exoskeleton system needs to deal with unpredictable disturbance from the patient, which lead the controller of exoskeleton system should have the ability to adapt different patients. This paper presents a novel Data-Driven Reinforcement Learning (DDRL) control strategy for adapting different hemiplegic patients with unpredictable disturbances. In the proposed DDRL strategy, the interaction between two lower limbs of LLE and the legs of hemiplegic patient are modeled as a leader-follower multi-agent system framework. The walking assistance control problem is transformed into a optimal control problem. Then, a policy iteration (PI) algorithm is proposed to obtain optimal controller. In order to achieve online adaptation control for different patients, based on PI algorithm, an Actor-Critic Neural Network (ACNN) technology of the reinforcement learning (RL) is employed in the proposed DDRL strategy. We conduct experiments both on a simulation environment and a real LLE system with healthy subjects. The experimental results demonstrate that the proposed control strategy have strong robustness against disturbances and ability to adapt to differ

- On the Effects of Visual Anticipation of Floor Compliance Changes on Human Gait: Towards Model-Based Robot-Assisted Rehabilitation

    Author: Michael, Drolet | Arizona State University
    Author: Qui�ones Yumbla, Emiliano | Arizona State University
    Author: Hobbs, Bradley | Arizona State University
    Author: Artemiadis, Panagiotis | University of Delaware
 
    keyword: Rehabilitation Robotics

    Abstract : The role of various types of robot assistance in post-stroke gait rehabilitation has gained much attention in recent years. Naturally, this results in the need to study how the different robot-assisted interventions affect the various underlying sensorimotor mechanisms involved in rehabilitation. To answer this important question, this paper combines a virtual reality experience with a unique robotic rehabilitation device, the Variable Stiffness Treadmill (VST), as a way of understanding interactions across different sensorimotor mechanisms involved in gait. The VST changes the walking surface stiffness in order to simulate real-world compliant surfaces while seamlessly interacting with a virtual environment. Through the manipulated visual and proprioceptive feedback, this paper focuses on the muscle activation patterns before, during, and after surface changes that are both visually informed and uninformed. The results show that there are predictable and repeatable muscle activation patterns both before and after surface stiffness changes, and these patterns are affected by the perceived visual and proprioceptive feedback. The interaction of feedback mechanisms and their effect on evoked muscular activation can be used in future robot-assisted gait therapies, where the intended muscle responses are informed by deterministic models and are tailored to a specific patient's needs.

- A Visual Positioning System for Indoor Blind Navigation

    Author: Zhang, He | Virginia Commonwealth University
    Author: Ye, Cang | Virginia Commonwealth University
 
    keyword: Rehabilitation Robotics; SLAM; Visual-Based Navigation

    Abstract : This paper presents a visual positioning system (VPS) for real-time pose estimation of a robotic navigation aid (RNA) for assistive navigation. The core of the VPS is a new method called depth-enhanced visual-inertial odometry (DVIO) that uses an RGB-D camera and an inertial measurement unit (IMU) to estimate the RNA pose. The DVIO method extracts the geometric feature (the floor plane) from the camera's depth data and integrates its measurement residuals with that of the visual features and the inertial data in a graph optimization framework for pose estimation. A new measure based on the Sampson error is introduced to describe the measurement residuals of the near-range visual features with a known depth and that of the far-range visual features whose depths are unknown. The measure allows for the incorporation of both types of visual features into graph optimization. The use of the geometric feature and the Sampson error improves pose estimation accuracy and precision. The DVIO method is paired with a particle filter localization (PFL) method to locate the RNA in a 2D floor plan and the information is used to guide a visually impaired person. The PFL reduces the RNA's position and heading error by aligning the camera's depth data with the floor plan map. Together, the DVIO and the PFL allow for accurate pose estimation for wayfinding and 3D mapping for obstacle avoidance. Experimental results demonstrate the usefulness of the RNA in assistive navigation in indoor spaces.

- An Outsole-Embedded Optoelectronic Sensor to Measure Shear Ground Reaction Forces During Locomotion

    Author: Duong, Ton | Stevens Institute of Technology
    Author: Whittaker, David R. | U.S. Navy Bureau of Medicine and Surgery (BUMED)
    Author: Zanotto, Damiano | Stevens Institute of Technology
 
    keyword: Rehabilitation Robotics; Prosthetics and Exoskeletons; Wearable Robots

    Abstract : Online estimation of 3D ground reaction forces (GRFs) is becoming increasingly important for closed-loop control of lower-extremity robotic exoskeletons. Through inverse dynamics and optimization models, 3D GRFs can be used to estimate net joint torques and approximate muscle forces. Although instrumented footwear to measure vertical GRFs in out-of-the-lab environments is available, accurately measuring shear GRFs with foot-mounted sensors still remains a challenging task. In this paper, a new outsole-embedded optoelectronic sensor configuration that is able to measure biaxial shear GRFs is proposed. Compared with traditional strain-gauge based solutions, optoelectronic sensors allow for a more affordable design. To mitigate the risk of altering the wearer's natural gait, the proposed solution does not involve external modifications to the footwear structure. A preliminary validation of the outsole-embedded sensor was conducted against validated laboratory equipment. The test involved two sessions of treadmill walking at different speeds. Experimental results suggest that the proposed design may be a promising solution for measuring shear GRFs in unconstrained environments.

- Bump�em: An Open-Source, Bump-Emulation System for Studying Human Balance and Gait

    Author: Tan, Guan Rong | Stanford University
    Author: Raitor, Michael | Stanford University
    Author: Collins, Steven H. | Stanford University
 
    keyword: Rehabilitation Robotics; Legged Robots; Force Control

    Abstract : Fall-related injury is a significant health problem on a global scale and is expected to grow with the aging population. Laboratory-based perturbation systems have the capability of simulating various modes of fall-inducing perturbations in a repeatable way. These systems enable fundamental research on human gait and balance and facilitate the development of devices to assist human balance. We present a robotic, rope-driven system capable of rendering bumps and force-fields at a person's pelvis in any direction in the transverse plane with forces up to 200 N, and a 90% rise time of as little as 44 ms, which is faster than a human's ability to sense and respond to the force. These capabilities enable experiments that require stabilizing or destabilizing subjects as they stand or walk on a treadmill. To facilitate use by researchers from all backgrounds, we designed both a configuration with simpler open-loop force control, and another with higher-performance, closed-loop force control. Both configurations are modular, and the open-loop system is made entirely from 3D-printed and catalog components. The design files and assembly instructions for both are freely available in an online repository.

- A Hybrid, Soft Exoskeleton Glove Equipped with a Telescopic Extra Thumb and Abduction Capabilities

    Author: Gerez, Lucas | The University of Auckland
    Author: Dwivedi, Anany | University of Auckland
    Author: Liarokapis, Minas | The University of Auckland
 
    keyword: Prosthetics and Exoskeletons; Rehabilitation Robotics

    Abstract : Over the last years, hand exoskeletons have become a popular and efficient technical solution for assisting people that suffer from neurological and musculoskeletal diseases and enhance the capabilities of healthy individuals. These devices can vary from rigid and complex structures to soft, lightweight, wearable gloves. Despite the significant progress in the field, most existing solutions do not provide the same dexterity as the healthy human hand. In this paper, we focus on the development of a hybrid (tendon-driven and pneumatic), lightweight, affordable, wearable exoskeleton glove equipped with abduction/adduction capabilities and a pneumatic telescopic extra thumb that increases grasp stability. The efficiency of the proposed device is experimentally validated through three different types of experiments: i) abduction/adduction tests, ii) force exertion experiments that capture the maximum forces that can be applied by the proposed device, and iii) grasp quality assessment experiments that focus on the effect of the inflatable thumb on enhancing grasp stability. The hybrid assistive glove considerably improves the grasping capabilities of the user, being able to exert the forces required to assist people in the execution of activities of daily living.

## Physical Human-Robot Interaction

- Transient Behavior and Predictability in Manipulating Complex Objects

    Author: Nayeem, Rashida | Northeastern University
    Author: Bazzi, Salah | Northeastern University
    Author: Hogan, Neville | Massachusetts Institute of Technology
    Author: Sternad, Dagmar | Northeastern University
 
    keyword: Physical Human-Robot Interaction; Biologically-Inspired Robots; Dexterous Manipulation

    Abstract :  Relatively little work in human and robot control has examined the control of complex objects with intrinsic dynamics, such as carrying a cup of coffee, a task that presents little problems for humans. This study examined how humans move a �cup-of-coffee� with a view to identify principles that may be useful for robot control. The specific focus was on how humans choose initial conditions to safely reach a steady state. We hypothesized that subjects choose initial conditions that minimized the transient duration to reach the steady state faster as it presented more predictable dynamics. In the experiment the cup of coffee was reduced to a 2-D cup with a sliding ball inside which was simulated in a virtual environment. Human subjects interacted with this virtual object via a robotic manipulandum that provided haptic feedback. Participants moved the cup between two targets without losing the ball; they were instructed to explore different initial conditions before initiating the continuous interaction. Results showed that subjects converged to a small set of initial conditions that decreased their transient durations and achieved a predictable steady state faster. Simulations with a simple feedforward controller and inverse dynamics calculations confirmed that these initial conditions indeed led to shorter transients and less complex interaction forces. These results may inform robot control of complex objects where the effects of initial conditions need further investigation.

- A Variable-Fractional Order Admittance Controller for PHRI

    Author: Sirintuna, Doganay | Koc University, College of Engineering, Turkey
    Author: Aydin, Yusuf | Koc University
    Author: Caldiran, Ozan | Koc University
    Author: Tokatli, Ozan | UKAEA
    Author: Patoglu, Volkan | Sabanci University
    Author: Basdogan, Cagatay | Koc University
 
    keyword: Physical Human-Robot Interaction; Cooperating Robots; Human-Centered Automation

    Abstract : In today's automation driven manufacturing environments, emerging technologies like cobots (collaborative robots) and augmented reality interfaces can help integrating humans into the production workflow to benefit from their adaptability and cognitive skills. In such settings, humans are expected to work with robots side by side and physically interact with them. However, the trade-off between stability and transparency is a core challenge in the presence of physical human robot interaction (pHRI). While stability is of utmost importance for safety, transparency is required for fully exploiting the precision and ability of robots in handling labor intensive tasks. In this work, we propose a new variable admittance controller based on fractional order control to handle this trade-off more effectively. We compared the performance of fractional order variable admittance controller with a classical admittance controller with fixed parameters as a baseline and an integer order variable admittance controller during a realistic drilling task. Our comparisons indicate that the proposed controller led to a more transparent interaction compared to the other controllers without sacrificing the stability. We also demonstrate a use case for an augmented reality (AR) headset which can augment human sensory capabilities for reaching a certain drilling depth otherwise not possible without changing the role of the robot as the decision maker.

- Assistive Gym: A Physics Simulation Framework for Assistive Robotics

    Author: Erickson, Zackory | Georgia Institute of Technology
    Author: Gangaram, Vamsee | Georgia Institute of Technology
    Author: Kapusta, Ariel | Georgia Institute of Technology
    Author: Liu, Karen | Georgia Tech
    Author: Kemp, Charlie | Georgia Institute of Technology
 
    keyword: Physical Human-Robot Interaction; Simulation and Animation; Physically Assistive Devices

    Abstract : Autonomous robots have the potential to serve as versatile caregivers that improve quality of life for millions of people worldwide. Yet, conducting research in this area presents numerous challenges, including the risks of physical interaction between people and robots. Physics simulations have been used to optimize and train robots for physical assistance, but have typically focused on a single task. In this paper, we present Assistive Gym, an open source physics simulation framework for assistive robots that models multiple tasks. It includes six simulated environments in which a robotic manipulator can attempt to assist a person with activities of daily living (ADLs): itch scratching, drinking, feeding, body manipulation, dressing, and bathing. Assistive Gym models a person's physical capabilities and preferences for assistance, which are used to provide a reward function. We present baseline policies trained using reinforcement learning for four different commercial robots in the six environments. We demonstrate that modeling human motion results in better assistance and we compare the performance of different robots. Overall, we show that Assistive Gym is a promising tool for assistive robotics research.

- Learning Whole-Body Human-Robot Haptic Interaction in Social Contexts

    Author: Campbell, Joseph | Arizona State University
    Author: Yamane, Katsu | Honda
 
    keyword: Physical Human-Robot Interaction; Learning from Demonstration; Social Human-Robot Interaction

    Abstract : This paper presents a learning-from-demonstration (LfD) framework for teaching human-robot social interactions that involve whole-body haptic interaction, i.e. direct human-robot contact over the full robot body. The performance of existing LfD frameworks suffers in such interactions due to the high dimensionality and spatiotemporal sparsity of the demonstration data. We show that by leveraging this sparsity, we can reduce the data dimensionality without incurring a significant accuracy penalty, and introduce three strategies for doing so. By combining these techniques with an LfD framework for learning multimodal human-robot interactions, we can model the spatiotemporal relationship between the tactile and kinesthetic information during whole-body haptic interactions. Using a teleoperated bimanual robot equipped with 61 force sensors, we experimentally demonstrate that a model trained with 121 sample hugs from 4 participants generalizes well to unseen inputs and human partners.

- Human Preferences in Using Damping to Manage Singularities During Physical Human-Robot Collaboration

    Author: Carmichael, Marc | Centre for Autonomous Systems
    Author: Khonasty, Richardo | Centre for Autonomous Systems
    Author: Aldini, Stefano | University of Technology Sydney
    Author: Liu, Dikai | University of Technology, Sydney
 
    keyword: Physical Human-Robot Interaction; Human Factors and Human-in-the-Loop; Human-Centered Automation

    Abstract : When a robot manipulator approaches a kinematic singular configuration, control strategies need to be employed to ensure safe and robust operation. If this manipulator is being controlled by a human through physical human-robot collaboration, the choice of strategy for handling singularities can have a significant effect on the feelings and impressions of the user. To date the preferences of humans during physical human-robot collaboration regarding strategies for managing kinematic singularities have yet to be thoroughly explored.<p>This work presents an empirical study of a damping-based strategy for handling singularities with regard to the preferences of the human operator. Two different parameters, damping rate and damping asymmetry, are tested using a double-blind A/B pairwise comparison testing protocol. Participants included two cohorts made up of the general public (n=51) and people working within a robotic research centre (n=18). In total 105 individual trials were performed. Results indicate a preference for a faster, asymmetric damping behavior that slows motions towards singularities whilst allowing for faster motions away.

- MOCA-MAN: A MObile and Reconfigurable Collaborative Robot Assistant for Conjoined huMAN-Robot Actions

    Author: Kim, Wansoo | Istituto Italiano Di Tecnologia
    Author: Balatti, Pietro | Istituto Italiano Di Tecnologia
    Author: Lamon, Edoardo | Istituto Italiano Di Tecnologia
    Author: Ajoudani, Arash | Istituto Italiano Di Tecnologia
 
    keyword: Physical Human-Robot Interaction; Human-Centered Robotics; Physically Assistive Devices

    Abstract : The objective of this paper is to create a new collaborative robotic system that subsumes the advantages of mobile manipulators and supernumerary limbs. By exploiting the reconfiguration potential of a MObile Collaborative robot Assistant (MOCA), we create a collaborative robot that can function autonomously, in close proximity to humans, or be physically coupled to the human counterpart as a supernumerary body (MOCA-MAN). Through an admittance interface and a hand gesture recognition system, the controller can give higher priority to the mobile base (e.g., for long distance co-carrying tasks) or the arm movements (e.g., for manipulating tools), when performing conjoined actions. The resulting system has a high potential not only to reduce waste associated with the equipment waiting and setup times, but also to mitigate the human effort when performing heavy or prolonged manipulation tasks. The performance of the proposed system, i.e., MOCA-MAN, is evaluated by multiple subjects in two different use-case scenarios, which require large mobility or close-proximity manipulation.

- Variable Damping Control of a Robotic Arm to Improve Trade-Off between Agility and Stability and Reduce User Effort

    Author: Bitz, Tanner | Arizona State University
    Author: Zahedi, Fatemeh | Arizona State University
    Author: Lee, Hyunglae | Arizona State University
 
    keyword: Physical Human-Robot Interaction; Physically Assistive Devices; Human Performance Augmentation

    Abstract : This paper presents a variable damping controller to improve the trade-off between agility and stability in physical human-robot interaction (pHRI), while reducing user effort. Variable robotic damping, defined as a dual-sided logistic function, was determined in real time throughout a range of negative to positive values based on the user's intent of movement. To evaluate the effectiveness of the proposed controller, we performed a set of human experiments with subjects interacting with the end-effector of a 7 degree-of-freedom robot. Twelve subjects completed target reaching tasks under three robotic damping conditions: fixed positive, fixed negative, and variable damping. On average, the variable damping controller significantly shortened the rise time by 22.4% compared to the fixed positive damping. It is also important to note that the rise time in the variable damping condition was as fast as that in the fixed negative damping condition. The variable damping controller significantly decreased the percentage overshoot by 49.6% and shortened the settling time by 29.0% compared to the fixed negative damping. Both the maximum and mean root-mean-squared (RMS) interaction forces were significantly lower in the variable damping condition than the other two fixed damping conditions, i.e., the variable damping controller reduced user effort. The maximum and mean RMS interaction forces were at least 17.3% and 20.3% lower than any of the fixed damping conditions, respectively.

- Robustness in Human Manipulation of Dynamically Complex Objects through Control Contraction Metrics

    Author: Bazzi, Salah | Northeastern University
    Author: Sternad, Dagmar | Northeastern University
 
    keyword: Physical Human-Robot Interaction; Biologically-Inspired Robots; Dexterous Manipulation

    Abstract : Control and manipulation of objects with underactuated dynamics remains a challenge for robots.Due to their typically nonlinear dynamics, it is computationally taxing to implement model-based planning and control techniques. Yet humans can skillfully manipulate such objects, seemingly with ease. More insight into human control strategies may inform how to enhance control strategies in robots. This study examined human control of objects that exhibit complex - underactuated and nonlinear - dynamics. We hypothesized that humans seek to make their trajectories exponentially stable to achieve robustness in the face of external perturbations. A stable trajectory is also robust to the high levels of noise in the human neuromotor system. Motivated by the task of carrying a cup of coffee, a virtual implementation of transporting a cart-pendulum system was developed. Subjects interacted with the virtual system via a robotic manipulandum that provided a haptic and visual interface. Human subjects were instructed to transport this simplified system to a target position as fast as possible without �spilling coffee,� while accommodating different visible perturbations that could be anticipated. To test the hypothesis of exponential convergence, tools fromthe framework of control contraction metrics were leveraged to analyze human trajectories. Results showed that with practice the trajectories indeed became exponentially stable, selectively around the perturbation.

- Cooperative Human-Robot Grasping with Extended Contact Patches

    Author: Marullo, Sara | University of Siena
    Author: Pozzi, Maria | University of Siena
    Author: Prattichizzo, Domenico | University of Siena
    Author: Malvezzi, Monica | University of Siena
 
    keyword: Physical Human-Robot Interaction; Contact Modeling; Grasping

    Abstract : Grasping large and heavy objects with a robot assistant is one of the most interesting scenarios in physical Human-Robot Interaction. Many solutions have been proposed in the last 40 years, focusing not only on human safety, but also on comfort and ergonomics. When carrying objects with large planar surfaces, classical contact models developed in robotic grasping cannot be used. This is why we conceived a contact model explicitly considering the contact area properties and thus suitable to deal with grasps requiring large contact patches from the robot side. Together with the model, this work proposes a decentralized control strategy to implement cooperative object handling between humans and robots. Experimental results showed that the proposed method performs better than a simpler one, which does not account for contact patch properties. The control strategy is decentralized and needs minimal exteroceptive sensing (force/torque sensor at the robot wrist), so the proposed approach can easily be generalized to human-robot teams composed of more than two agents.

- The InSight Crutches: Analyzing the Role of Arm Support During Robot-Assisted Leg Movements (I)

    Author: Haufe, Florian Leander | ETH Zurich
    Author: Haji Hassani, Roushanak | University of Basel
    Author: Riener, Robert | ETH Zurich
    Author: Wolf, Peter | ETH Zurich, Institute of Robotics and Intelligent Systems
 
    keyword: Physical Human-Robot Interaction; Rehabilitation Robotics; Prosthetics and Exoskeletons

    Abstract : To complement the assistance of a wearable robot, users with a leg weakness often rely on balance and body-weight support through their arms and passive walking aids. A precise quantification of this arm support is crucial to better understand the real-world robot dynamics, the human-robot interaction, and the human user performance. In this article, we present a novel measurement system, the InSight Crutches, that allows such a quantification, and evaluate the crutches' functionality in three exemplary movement scenarios with different wearable robots and users with spinal cord injury.

- Cognitive and Motor Compliance in Intentional Human-Robot Interaction

    Author: Chame, Hendry | Okinawa Institute of Science and Technology Graduate University
    Author: Tani, Jun | Okinawa Institute of Science and Technology
 
    keyword: Neurorobotics; Physical Human-Robot Interaction; Humanoid Robots

    Abstract : Embodiment and subjective experience in human-robot interaction are important aspects to consider when studying both natural cognition and adaptive robotics to human environments. Although several researches have focused on nonverbal communication and collaboration, the study of autonomous physical interaction has obtained less attention. From the perspective of neurorobotics, we investigate the relation between intentionality, motor compliance, cognitive compliance, and behavior emergence. We propose a variational model inspired by the principles of predictive coding and active inference to study intentionality and cognitive compliance, and an intermittent control concept for motor deliberation and compliance based on torque feed-back. Our experiments with the humanoid Torobo portrait interesting perspectives for the bio-inspired study of developmental and social processes.

- Controlling an Upper-Limb Exoskeleton by EMG Signal While Carrying Unknown Load

    Author: Treussart, Benjamin | Cea-List, Diasi, Lri
    Author: Geffard, Franck | Atomic Energy Commissariat (CEA)
    Author: Vignais, Nicolas | Univ. Paris-Sud
    Author: Marin, Fr�d�ric | UTC
 
    keyword: Physical Human-Robot Interaction; Physically Assistive Devices; Prosthetics and Exoskeletons

    Abstract : Implementing an intuitive control law for an upper-limb exoskeleton dedicated to force augmentation is a challenging issue in the field of human-robot collaboration. The aim of this study is to design an innovative approach to assist carrying an unknown load. The method is based on user's intentions estimated through a wireless EMG armband allowing movement direction and intensity estimation along 1 Degree of Freedom. This control law aimed to behave like a gravity compensation except that the mass of the load does not need to be known. The proposed approach is tested by 10 participants on a lifting task with a single Degree of Freedom upper-limb exoskeleton. Participants perform it in three different conditions : without assistance, with an exact gravity compensation and with the proposed method based on EMG armband (Myo Armband). The evaluation of the efficiency of the assistance is based on EMG signals captured on seven muscles (objective indicator) and a questionnaire (subjective indicator). Results shows a statically significant reduction of mean activity of the biceps, erector spinae and deltoid by 20+/-14%, 18+/-12% and 25+/-16% respectively while comparing the proposed method with no assistance. In addition, similar muscle activities are found both in the proposed method and the traditional gravity compensation. Subjective evaluation shows better precision, efficiency and responsiveness of the proposed method compared to the traditional one.

- Learning Grasping Points for Garment Manipulation in Robot-Assisted Dressing

    Author: Zhang, Fan | Imperial College London
    Author: Demiris, Yiannis | Imperial College London
 
    keyword: Physical Human-Robot Interaction; Perception for Grasping and Manipulation; Human-Centered Robotics

    Abstract : Assistive robots have the potential to provide tremendous support for disabled and elderly people in their daily dressing activities. Recent studies on robot-assisted dressing usually simplify the setup of the initial robot configuration by manually attaching the garments on the robot end-effector and positioning them close to the user's arm. A fundamental challenge in automating such a process for robots is computing suitable grasping points on garments that facilitate robotic manipulation. In this paper, we address this problem by introducing a supervised deep neural network to locate a pre-defined grasping point on the garment, using depth images for their invariance to color and texture. To reduce the amount of real data required, which is costly to collect, we leverage the power of simulation to produce large amounts of labeled data. The network is jointly trained with synthetic datasets of depth images and a limited amount of real data. We introduce a robot-assisted dressing system that combines the grasping point prediction method, with a grasping and manipulation strategy which takes grasping orientation computation and robot-garment collision avoidance into account. The experimental results demonstrate that our method is capable of yielding accurate grasping point estimations. The proposed dressing system enables the Baxter robot to autonomously grasp a hospital gown hung on a rail, bring it close to the user and successfully dress the upper-body.

- TACTO-Selector: Enhanced Hierarchical Fusion of PBVS with Reactive Skin Control for Physical Human-Robot Interaction

    Author: Huezo Martin, Ana Elvira | Technische Universitét M�nchen
    Author: Dean-Leon, Emmanuel | Technischen Universitaet Muenchen
    Author: Cheng, Gordon | Technical University of Munich
 
    keyword: Physical Human-Robot Interaction; Collision Avoidance; Force and Tactile Sensing

    Abstract : In a physical Human-Robot Interaction for industrial scenarios is paramount to guarantee the safety of the user while keeping the robot's performance. Hierarchical task approaches are not sufficient since they tend to sacrifice the low priority tasks in order to guarantee the consistency of the main task. To handle this problem, we enhance the standard hierarchical fusion by introducing a novel interactive task-reconfiguring approach (TACTO-Selector) that uses the information of the tactile interaction to adapt the dimension of the tasks, therefore guaranteeing the execution of the safety task while performing the other task as good as possible. In this work, we hierarchically combine a 6 DOF Position-Based Visual Servoing (PBVS) task with a reactive skin control. This approach was evaluated on a 6 DOF industrial robot showing an improvement of 36.37% on average in tracking error reduction compared with the standard approach.

- Towards an Intelligent Collaborative Robotic System for Mixed Case Palletizing

    Author: Lamon, Edoardo | Istituto Italiano Di Tecnologia
    Author: Leonori, Mattia | Istituto Italiano Di Tecnologia
    Author: Kim, Wansoo | Istituto Italiano Di Tecnologia
    Author: Ajoudani, Arash | Istituto Italiano Di Tecnologia
 
    keyword: Physical Human-Robot Interaction; Logistics; Mobile Manipulation

    Abstract : In this paper, a novel human-robot collaborative framework for mixed case palletizing is presented. The frame- work addresses several challenges associated with the detection and localisation of boxes and pallets through visual perception algorithms, high-level optimisation of the collaborative effort through effective role-allocation principles, and maximisation of packing density. A graphical user interface (GUI) is additionally developed to ensure an intuitive allocation of roles and the optimal placement of the boxes on target pallets. The framework is evaluated in two conditions where humans operate with and without the support of a Mobile COllaborative robotic Assistant (MOCA). The results show that the optimised placement can improve up to the 20% with respect to a manual execution of the same task, and reveal the high potential of MOCA in increasing the performance of collaborative palletizing tasks.

- Treadmill Based Three Tether Parallel Robot for Evaluating Auditory Warnings While Running

    Author: Luttmer, Nathaniel | University of Utah
    Author: Truong, Takara | University of Utah
    Author: Boynton, Alicia | University of Utah, School of Biological Sciences
    Author: Carrier, David | University of Utah
    Author: Minor, Mark | University of Utah
 
    keyword: Physical Human-Robot Interaction; Tendon/Wire Mechanism; Human Detection and Tracking

    Abstract : We design and test a 3 DoF parallel cable system capable of applying precise and accurate impulses to walking and running subjects for the University of Utah's Treadport Active Wind Tunnel (TPAWT). Using Nexus VICON motion capture and gait algorithms, perturbations can be applied at different points in the subject's gait. The use of a PID force controller allow the system to create omnidirectional perturbations with walking and running subjects while having the capability to vary amplitude and direction of perturbations. Analysis is presented of the workspace of the large treadmill to test whether the workspace available to activate these perturbations is safe. This paper reports the efficacy of the system and evaluates how warning a runner before impact may affect their displacement. Participants experienced 48 perturbations while running applied with a random combination of a front/back/left/right impact at either toe-off or mid-stance with or without warning. A two sample T-test reveals that warning a runner before impact significantly reduced the magnitude they were displaced for both toe-off (t(46) = 4.98 p&lt;.001) and mid-stance (t(46) = 3.44, p = .001).

- Evaluation of Human-Robot Object Co-Manipulation under Robot Impedance Control

    Author: Mujica, Martin | INP-ENI of Tarbes
    Author: Benoussaad, Mourad | INP-ENI of Tarbes
    Author: Fourquet, Jean-Yves | ENIT
 
    keyword: Physical Human-Robot Interaction; Compliance and Impedance Control; Force Control

    Abstract : The human-robot collaboration is a promising and challenging field of robotics research. One of the main collaboration tasks is the object co-manipulation where the human and robot are in a continuous physical interaction and forces exerted must be handled. This involves some issues known in robotics as physical Human-Robot Interaction (pHRI), where human safety and interaction comfort are required. Moreover, a definition of interaction quality metrics would be relevant. In the current work, the assessment of Human-Robot object co-manipulation task was explored through the proposed metrics of interaction quality, based on human forces throughout the movement. This analysis is based on co-manipulation of objects with different dynamical properties (weight and inertia), with and without including these properties knowledge in the robot control law. Here, the human is a leader of task and the robot the follower without any information of the human trajectory and movement profile. For the robot control law, a well-known impedance control was applied on a 7-dof Kuka LBR iiwa 14 R820 robot. Results show that the consideration of object dynamical properties in the robot control law is crucial for a good and more comfortable interaction. Besides, human efforts are more significant with a higher no-considered weight, whereas it remains stable when these weights were considered.

## Telerobotics and Teleoperation
- Adaptive     Authority Allocation in Shared Control of Robots Using Bayesian Filters

    Author: Balachandran, Ribin | DLR
    Author: Mishra, Hrishik | German Aerospace Center (DLR)
    Author: Cappelli, Matteo | German Aerospace Center (DLR)
    Author: Weber, Bernhard | German Aerospace Center
    Author: Secchi, Cristian | Univ. of Modena &amp; Reggio Emilia
    Author: Ott, Christian | German Aerospace Center (DLR)
    Author: Albu-Sch�ffer, Alin | DLR - German Aerospace Center
 
    keyword: Telerobotics and Teleoperation; Haptics and Haptic Interfaces; Sensor-based Control

    Abstract : In the present paper, we propose a novel system-driven adaptive shared control framework in which the autonomous system allocates the     Authority among the human operator and itself.     Authority allocation is based on a metric derived from a Bayesian filter, which is being adapted online according to real measurements. In this way, time-varying measurement noise characteristics are incorporated. We present the stability proof for the proposed shared control architecture with adaptive     Authority allocation, which includes time delay in the communication channel between the operator and the robot. Furthermore, the proposed method is validated through experiments and a user-study evaluation. the obtained results indicate significant improvements in task execution compared with pure teleoperation.

- Tactile Telerobots for Dull, Dirty, Dangerous, and Inaccessible Tasks

    Author: Fishel, Jeremy | Tangible Research
    Author: Oliver, Toni | Shadow Robot Company
    Author: Eichermueller, Michael | HaptX, Inc
    Author: Barbieri, Giuseppe | Shadow Robot Company
    Author: Fowler, Ethan | Shadow Robot Company
    Author: Hartikainen, Toivo | Shadow Robot Company
    Author: Moss, Luke | Shadow Robot Company
    Author: Walker, Rich | Shadow Robot Company
 
    keyword: Telerobotics and Teleoperation; Dexterous Manipulation; Haptics and Haptic Interfaces

    Abstract : The sense of touch, which is essential for human dexterity, is virtually absent from today's robotic hands. In this work we present progress in creating a highly-dexterous bimanual tactile telerobot, and evaluate its performance compared to bare hands. The system, consisting of anthropomorphic robot hands, biomimetic tactile sensors, and advanced haptic gloves enables a human operator to intuitively control and feel what the robotic hands are touching. Through carefully tuned tactile and kinematic mapping it was possible to intuitively perform dexterous operations, including pick and place tasks and even in-hand manipulation, a challenge for most autonomous robotic hands. Performance of the system was evaluated in standard measures of human and robotic dexterity such as the Box and Block test and other YCB benchmarks. This first-generation telerobot was found to have promising performance with the pilot able to do the same tasks in the telerobot between 1/4th to 1/12th the speed of their bare hands depending on the task complexity.

- A Teleoperation Framework for Mobile Robots Based on Shared Control

    Author: Luo, Jing | South China University of Technology
    Author: Lin, Zhidong | South China University of Technology
    Author: Li, Yanan | University of Sussex
    Author: Yang, Chenguang | University of the West of England
 
    keyword: Telerobotics and Teleoperation; Haptics and Haptic Interfaces; Cognitive Human-Robot Interaction

    Abstract : Mobile robots can complete a task in cooperation with a human partner. In this paper, a hybrid shared control method for a mobile robot with omnidirectional wheels is proposed. A human partner utilizes a six degrees of freedom haptic device and electromyography (EMG) signals sensor to control the mobile robot. A hybrid shared control approach based on EMG and artificial potential field is exploited to avoid obstacles according to the repulsive force and attractive force and to enhance the human perception of the remote environment based on force feedback of the mobile platform. This shared control method enables the human partner to tele-control the mobile robot's motion and achieve obstacles avoidance synchronously. Compared with conventional shared control methods, this proposed one provides a force feedback based on muscle activation and drives the human partners to update their control intention with predictability. Experimental results demonstrate the enhanced performance of the mobile robots in comparison with the methods in the literatures.

- A Novel Orientability Index and the Kinematic Design of the RemoT-ARM: A Haptic Master with Large and Dexterous Workspace

    Author: Li, Gaofeng | Italy Institute of Technology (IIT)
    Author: Del Bianco, Edoardo | Istituto Italiano Di Tecnologia
    Author: Caponetto, Fernando | Istituto Italiano Di Tecnologia
    Author: Katsageorgiou, Vasiliki-Maria | Humanoids and Human Centered Mechatronics, Istituto Italiano Di
    Author: Tsagarakis, Nikos | Istituto Italiano Di Tecnologia
    Author: Sarakoglou, Ioannis | Fondazione Istituto Italiano Di Tecnologia
 
    keyword: Telerobotics and Teleoperation; Haptics and Haptic Interfaces; Kinematics

    Abstract : Orientability is an important performance index to evaluate the dexterity of haptic master devices. Currently, most of the existing haptic master devices have limited workspace and limited dexterity. In this paper, we present the RemoT-ARM, a 6 Degree-of-Freedom (DOF) haptic master device that can provide larger and more dexterous workspace for operators. To evaluate its reachability of orientations, we propose a novel orientability index. Furthermore, a relative orientability index is proposed to characterize the matching degree of the workspace of a given manipulator to its target workspace. The volume, the manipulability and the condition number are also introduced as performance indices to evaluate the size and the isotropy of the workspace. According to these performance indices, all possible configurations for the RemoT-ARM have been taken into consideration, analyzed, and compared to finalize its optimal configuration.

- Enhancing the Transparency by Onomatopoeia for Passivity-Based Time-Delayed Teleoperation

    Author: Zhu, Yaonan | Nagoya University
    Author: Aoyama, Tadayoshi | Nagoya University
    Author: Hasegawa, Yasuhisa | Nagoya University
 
    keyword: Telerobotics and Teleoperation; Haptics and Haptic Interfaces; Virtual Reality and Interfaces

    Abstract : Robotic teleoperation with force feedback has been studied extensively since it was first developed in the 1940s. Time delay is a common problem of bilateral teleoperation systems. Although many efforts on optimizing the control architectures have been made, there is always a trade-off between transparency and stability for bilateral systems, and the perfect transparency and stability can only be achieved simultaneously in ideal situations. In this paper, we propose a novel approach to compensate for the degraded transparency while using the conventional passivity-based approach to maintain system stability under time-delay. The proposed approach is based on visual feedback and enhances the transparency by displaying different kinds of onomatopoeia according to contact force detected on the slave side. The basic performance is evaluated by conducting a stiffness classification task under constant round trip time delays (0 ms, 500 ms and 1000 ms). The preliminary results indicate that the subjects have higher accuracy for classifying the stiffness of a remote object by using onomatopoeia enhanced force feedback compared with the conventional passivity-based position-force feedback.

- RAVEN-S: Design and Simulation of a Robot for Teleoperated Microgravity Rodent Dissection under Time Delay
 
    Author: Lewis, Andrew | University of Washington
    Author: Drajeske, David | Applied Dexterity
    Author: Raiti, John | University of Washington
    Author: Berens, Angelique | University of Washington
    Author: Rosen, Jacob | &#8203;University of California, Los Angeles
    Author: Hannaford, Blake | University of Washington
 
    keyword: Telerobotics and Teleoperation; Space Robotics and Automation; Mechanism Design

    Abstract : The International Space Station (ISS) serves as a research lab for a wide variety of experiments including some that study the biological effects of microgravity and spaceflight using the Rodent Habitat and Microgravity Science Glovebox (MSG). Astronauts train for onboard dissections of rodents following basic training. An alternative approach for conducting these experiments is teleoperation of a robot located on the ISS from earth by a scientist who is proficient in rodent dissection. This pilot study addresses (1) the effects of extreme time delay on skill degradation during Fundamentals of Laparoscopic Surgery (FLS) tasks and rodent dissections using RAVEN II; (2) derivation and testing of rudimentary interaction force estimation; (3) elicitation of design requirements for an onboard dissection robot, RAVEN-S; and (4) simulation of the RAVEN-S prototype design with dissection data. The results indicate that the tasks' completion times increased by a factor of up to 9 for a 3 s time delay while performing manipulation and cutting tasks (FLS model) and by a factor of up to 3 for a 0.75 s time delay during mouse dissection tasks (animal model). Average robot forces/torques of 14N/0.1Nm (peak 90N/0.75Nm) were measured along with average linear/angular velocities of 0.02m/s / 4rad/s (peak 0.1m/s / 40rad/s) during dissection. A triangular configuration of three arms with respect to the operation site showed the best configuration given the MSG geometry and the dissection tasks.

- Closing the Force Loop to Enhance Transparency in Time-Delayed Teleoperation

    Author: Balachandran, Ribin | DLR
    Author: Ryu, Jee-Hwan | Korea Advanced Institute of Science and Technology
    Author: Jorda, Mikael | Stanford University
    Author: Ott, Christian | German Aerospace Center (DLR)
    Author: Albu-Sch�ffer, Alin | DLR - German Aerospace Center
 
    keyword: Telerobotics and Teleoperation; Force Control; Force and Tactile Sensing

    Abstract : In the present paper, we first adopt explicit force control from general robotics and embed it into teleoperation systems to enhance the transparency by reducing the effect of the perceived inertia to the human operator and simultaneously improve contact perception. To ensure stability of the proposed teleoperation system considering time-delays, we propose a sequential design procedure based on time domain passivity approach. Experimental results of master-slave teleoperation system, based on KUKA light-weight-robots, for different values of delays are presented. Comparative analysis is conducted considering two existing approaches, namely 2-channel and 4-channel architecture based bilateral controllers, and its results clearly indicate significant improvement in force transparency owing to the proposed method. The proposed system is finally validated considering a real industrial assembly scenario.

- Evaluation of an Exoskeleton-Based Bimanual Teleoperation Architecture with Independently Passivated Slave Devices

    Author: Sant'Anna), Francesco Porcini (Scuola | PERCRO Laboratory, TeCIP Institute, Sant�Anna School of Advanced
    Author: Chiaradia, Domenico | Scuola Superiore Sant'Anna, TeCIP Institute, PERCRO Laboratory,
    Author: Marcheschi, Simone | PERCRO - Scuola Superiore S.Anna
    Author: Solazzi, Massimiliano | Scuola Superiore Sant'Anna, TeCIP Institute
    Author: Frisoli, Antonio | TeCIP Institute, Scuola Superiore Sant'Anna
 
    keyword: Telerobotics and Teleoperation; Physical Human-Robot Interaction; Wearable Robots

    Abstract : Search and rescue robotics is becoming a relevant topic in the last years. In this context, the possibility to drive a remote robot with an exoskeleton is a promising strategy to enhance dexterity, reduce operator effort and save time. However, the use of haptic feedback (bilateral teleoperation) may lead to instability in the presence of communication delay and more complex is the case of bimanual teleoperation where the two arms can exchange energy. In this work, we present a bimanual teleoperation system based on an exoskeletal master, where multi-degrees of freedom and kinematically different devices are involved. In the implemented architecture the two slaves are managed in parallel and independently passivated using the Time Domain Passivity Approach extended for multi-DoFs devices. To investigate the stability of the architecture we designed two tasks highly related to real disaster scenarios: the first one was useful to verify the system behavior in case of small movements and constrained configurations, whereas the second experiment was designed to involve larger contact forces and movements. Moreover, we compared the effect of both delay and low control loop frequency on the stability of the system when TDPA was applied. From the results, it was evident that the overall system exhibited a stable behavior with the use of the TDPA, even passivating the two slaves independently, under simulated time delay and in presence of a low control loop frequency.

- Hand-Worn Haptic Interface for Drone Teleoperation

    Author: Macchini, Matteo | EPFL
    Author: Havy, Thomas&nbsp;Clint&nbsp;Patrick | EPFL
    Author: Weber, Antoine | EPFL
    Author: Schiano, Fabrizio | Ecole Polytechnique Federale De Lausanne, EPFL
    Author: Floreano, Dario | Ecole Polytechnique Federal, Lausanne
 
    keyword: Telerobotics and Teleoperation; Haptics and Haptic Interfaces; Human Performance Augmentation

    Abstract : Drone teleoperation is usually accomplished using remote radio controllers, devices that can be hard to master for inexperienced users. Moreover, the limited amount of information fed back to the user about the robot's state, often limited to vision, can represent a bottleneck for operation in several conditions. In this work, we present a wearable interface for drone teleoperation and its evaluation through a user study. The two main features of the proposed system are a data glove to allow the user to control the drone trajectory by hand motion and a haptic system used to augment their awareness of the environment surrounding the robot. This interface can be employed for the operation of robotic systems in line of sight (LOS) by inexperienced operators and allows them to safely perform tasks common in inspection and search-and-rescue missions such as approaching walls and crossing narrow passages with limited visibility conditions. In addition to the design and implementation of the wearable interface, we performed a systematic study to assess the effectiveness of the system through three user studies (n = 36) to evaluate the users' learning path and their ability to perform tasks with limited visibility. We validated our ideas in both a simulated and a real-world environment. Our results demonstrate that the proposed system can improve teleoperation performance in different cases compared to standard remote controllers, making it a viable alternative to standard Human-Rob

- Toward Human-Like Teleoperated Robot Motion: Performance and Perception of a Choreography-Inspired Method in Static and Dynamic Tasks for Rapid Pose Selection of Articulated Robots

    Author: Bushman, Allison | University of Illinois
    Author: Asselmeier, Maxwell | University of Illinois at Urbana-Champaign
    Author: Won, Justin | University of Illinois
    Author: LaViers, Amy | University of Illinois at Urbana-Champaign
 
    keyword: Telerobotics and Teleoperation; Performance Evaluation and Benchmarking

    Abstract : In some applications, operators may want to create fluid, human-like motion on a remotely-operated robot, for example, a device used for remote telepresence. This paper examines two methods of controlling the pose of a Baxter robot via an Xbox One controller. The first method is a joint-by-joint (JBJ) method in which one joint of each limb is specified in sequence. The second method of control, named Robot Choreography Center (RCC), utilizes choreographic     Abstractions in order to simultaneously move multiple joints of the limb of the robot in a predictable manner. Thirty-eight users were asked to perform four tasks with each method. Success rate and duration of successfully completed tasks were used to analyze the performances of the participants. Analysis of the preferences of the users found that the joint-by-joint (JBJ) method was considered to be more precise, easier to use, safer, and more articulate, while the choreography-inspired (RCC) method of control was perceived as faster, more fluid, and more expressive. Moreover, performance data found that while both methods of control were over 80% successful for the two static tasks, the RCC method was an average of 11.85% more successful for the two more difficult, dynamic tasks. Future work will leverage this framework to investigate ideas of fluidity, expressivity, and human-likeness in robotic motion through online user studies with larger participant pools.

- Helping Robots Learn: A Human-Robot Master-Apprentice Model Using Demonstrations Via Virtual Reality Teleoperation

    Author: DelPreto, Joseph | Massachusetts Institute of Technology
    Author: Lipton, Jeffrey | University of Washington
    Author: Sanneman, Lindsay | Massachusetts Institute of Technology
    Author: Fay, Aidan | MIT CSAIL
    Author: Fourie, Christopher K | Massachusetts Institute of Technology (MIT)
    Author: Choi, Changhyun | University of Minnesota, Twin Cities
    Author: Rus, Daniela | MIT
 
    keyword: Telerobotics and Teleoperation; Learning from Demonstration; Human Factors and Human-in-the-Loop

    Abstract : As artificial intelligence becomes an increasingly prevalent method of enhancing robotic capabilities, it is important to consider effective ways to train these learning pipelines and to leverage human expertise. Working towards these goals, a master-apprentice model is presented and is evaluated during a grasping task for effectiveness and human perception. The apprenticeship model augments self-supervised learning with learning by demonstration, efficiently using the human's time and expertise while facilitating future scalability to supervision of multiple robots; the human provides demonstrations via virtual reality when the robot cannot complete the task autonomously. Experimental results indicate that the robot learns a grasping task with the apprenticeship model faster than with a solely self-supervised approach and with fewer human interventions than a solely demonstration-based approach; 100% grasping success is obtained after 150 grasps with 19 demonstrations. Preliminary user studies evaluating workload, usability, and effectiveness of the system yield promising results for system scalability and deployability. They also suggest a tendency for users to overestimate the robot's skill and to generalize its capabilities, especially as learning improves.

- A Framework for Interactive Virtual Fixture Generation for Shared Teleoperation in Unstructured Environments

    Author: Pruks, Vitalii | KAIST
    Author: Ryu, Jee-Hwan | Korea Advanced Institute of Science and Technology
 
    keyword: Telerobotics and Teleoperation; Haptics and Haptic Interfaces; Virtual Reality and Interfaces

    Abstract :  Virtual fixtures (VFs) improve human operator performance in teleoperation scenarios. However, the generation of VFs is challenging, especially in unstructured environments. In this work, we introduce a framework for the interactive generation of VF. The method is based on the observation that a human can easily understand just by looking at the remote environment which VF could help in task execution. We propose a user interface that detects features on camera images and permits interactive selection of the features. We demonstrate how the feature selection can be used for designing VF, providing 6-DOF haptic feedback. In order to make the proposed framework more generally applicable to a wider variety of applications, we formalize the process of virtual fixture generation (VFG) into the specification of features, geometric primitives, and constraints. The framework can be extended further by the introduction of additional components. Through the human subject study, we demonstrate the proposed framework is intuitive, easy to use while effective, especially for performing hard contact tasks.

- Whole-Body Bilateral Teleoperation of a Redundant Aerial Manipulator

    Author: Coelho, Andre | German Aerospace Center (DLR)
    Author: Singh, Harsimran | DLR German Aerospace Center
    Author: Kondak, Konstantin | German Aerospace Center
    Author: Ott, Christian | German Aerospace Center (DLR)
 
    keyword: Telerobotics and Teleoperation; Aerial Systems: Mechanics and Control; Haptics and Haptic Interfaces

    Abstract : Attaching a robotic manipulator to a flying base allows for significant improvements in the reachability and versatility of manipulation tasks. In order to explore such systems while taking advantage of human capabilities in terms of perception and cognition, bilateral teleoperation arises as a reasonable solution. However, since most telemanipulation tasks require visual feedback in addition to the haptic one, real-time (task-dependent) positioning of a video camera, which is usually attached to the flying base, becomes an additional objective to be fulfilled. Since the flying base is part of the kinematic structure of the robot, if proper care is not taken, moving the video camera could undesirably disturb the end-effector motion. For that reason, the necessity of controlling the base position in the null space of the manipulation task arises. In order to provide the operator with meaningful information about the limits of the allowed motions in the null space, this paper presents a novel haptic concept called Null-Space Wall. In addition, a framework to allow stable bilateral teleoperation of both tasks is presented. Numerical simulation data confirm that the proposed framework is able to keep the system passive while allowing the operator to perform time-delayed telemanipulation and command the base to a task-dependent optimal pose.

- Shared Autonomous Interface for Reducing Physical Effort in Robot Teleoperation Via Human Motion Mapping

    Author: Lin, Tsung-Chi | Worcester Polytechnic Institute
    Author: Unni Krishnan, Achyuthan | Worcester Polytechnic Institute
    Author: Li, Zhi | Worcester Polytechnic Institute
 
    keyword: Telerobotics and Teleoperation; Human Factors and Human-in-the-Loop; Medical Robots and Systems

    Abstract : Motion mapping is an intuitive method of teleoperation with a low learning curve. Our previous study investigates the physical fatigue caused by teleoperating a robot to perform general-purpose assistive tasks and this fatigue affects the operator's performance. The results from that study indicate that physical fatigue happens more in the tasks which involve more precise manipulation and steady posture maintenance. In this paper, we investigate how teleoperation assistance in terms of shared autonomy can reduce the physical workload in robot teleoperation via motion mapping. Specifically, we conduct a user study to compare the muscle effort in teleoperating a mobile humanoid robot to (1) reach and grasp an individual object and (2) collect objects in a cluttered workspace with and without an autonomous grasping function that can be triggered manually by the teleoperator. We also compare the participants' task performance, subjective user experience, and change in attitude towards the usage of teleoperation assistance in the future based on their experience using the assistance function. Our results show that: (1) teleoperation assistance like autonomous grasping can effectively reduce the physical effort, task completion time and number of errors; (2) based on their experience performing the tasks with and without assistance, the teleoperators reported that they would prefer to use automated functions for future teleoperation interfaces.

- DexPilot: Vision-Based Teleoperation of Dexterous Robotic Hand-Arm System

    Author: Handa, Ankur | IIIT Hyderabad
    Author: Van Wyk, Karl | NVIDIA
    Author: Yang, Wei | NVIDIA
    Author: Liang, Jacky | Carnegie Mellon University
    Author: Chao, Yu-Wei | Univeristy of Michigan
    Author: Wan, Qian | Harvard University
    Author: Birchfield, Stan | NVIDIA
    Author: Ratliff, Nathan | Lula Robotics Inc
    Author: Fox, Dieter | University of Washington
 
    keyword: Telerobotics and Teleoperation; Learning from Demonstration; Grasping

    Abstract : Teleoperation relays natural human motion to control robotic systems that are relatively free of sophisticated reasoning skills, intuition, and creativity. However, tele-operation solutions for high degree-of-actuation (DoA), multi-fingered robots are generally cost-prohibitive, while low-cost offerings usually offer reduced degrees of control. Herein, a low-cost, RGB-D based teleoperation system was developed that allows for complete control over the full 23 DoA robotic system by merely observing the bare human hand. The system was used to solve a variety of manipulation tasks that go beyond simple pick-and-place operations accompanied by a thorough assessment of system performance. The videos of the experiments can be found at https://sites.google.com/view/dex-pilot.

- Distributed Winner-Take-All Teleoperation of a Multi-Robot System

    Author: Yang, Yuan | University of Victoria
    Author: Constantinescu, Daniela | University of Victoria
    Author: Shi, Yang | University of Victoria
 
    keyword: Telerobotics and Teleoperation; Multi-Robot Systems; Networked Robots

    Abstract : In a distributed multi-master-multi-slave teleoperation system, the human users may compete against each other for the control of the team of slave robots. To win the competition, one operator would send the largest command to the slave group. For the sake of team cohesion, the slave group should follow the command of the winning operator and ignore the commands of the other users. To enable (i) the slave team to identify the winning operator, and (ii) each slave to determine whether to admit or discard the command it receives from its operator, this paper proposes a dynamic decision-making protocol that distinguishes the decision variable of the slave commanded by the winner from the decision variables of all other slave robots. The protocol only requires the slaves to exchange and evaluate their decision variables locally. Lyapunov stability analysis proves the theoretical convergence of the proposed decision-making algorithm. An experimental distributed winner-take-all teleoperation in a 3-masters-11-slaves teleoperation testbed validates its practical efficacy.

- Enhanced Teleoperation Using Autocomplete

    Author: Kassem Zein, Mohammad | American University of Beirut (AUB)
    Author: Sidaoui, Abbas | American University of Beirut
    Author: Asmar, Daniel | American University of Beirut
    Author: Elhajj, Imad | American University of Beirut
 
    keyword: Telerobotics and Teleoperation; Human Performance Augmentation

    Abstract : Controlling and manning robots from a remote location is difficult because of the limitations one faces in perception and available degrees of actuation. Although humans can become skilled teleoperators, the amount of training time required to acquire such skills is typically very high. In this paper, we propose a novel solution (named Autocomplete) to aid novice teleoperators in manning robots adroitly. At the input side, Autocomplete relies on machine learning to detect and categorize human inputs as one from a group of motion primitives. Once a desired motion is recognized, at the actuation side an automated command replaces the human input in performing the desired action. So far, Autocomplete can recognize and synthesize lines, arcs, full circles, 3-D helices, and sine trajectories. Autocomplete was tested in simulation on the teleoperation of an unmanned aerial vehicle, and results demonstrate the advantages of the proposed solution versus manual steering.

## Collision Avoidance
- Collision-Free Navigation of Human-Centered Robots Via Markov Games

    Author: Ye, Guo | Northwestern University
    Author: Lin, Qinjie | Northwestern University
    Author: Juang, Tzung-Han | Northwestern University
    Author: Liu, Han | Northwestern University
 
    keyword: Collision Avoidance; Path Planning for Multiple Mobile Robots or Agents; Deep Learning in Robotics and Automation

    Abstract : We exploit Markov games as a framework for collision-free navigation of human-centered robots. Unlike the classical methods which formulate robot navigation as a single-agent Markov decision process with a static environment, our framework of Markov games adopts a multi-agent formulation with one primary agent representing the robot and the remaining auxiliary agents form a dynamic or even competing environment. Such a framework allows us to develop a path-following type adversarial training strategy to learn a robust decentralized collision avoidance policy. Through thorough experiments on both simulated and real-world mobile robots, we show that the learnt policy outperforms the state-of-the-art algorithms in both sample complexity and runtime robustness.

- DenseCAvoid: Real-Time Navigation in Dense Crowds Using Anticipatory Behaviors

    Author: Sathyamoorthy, Adarsh Jagan | University of Maryland
    Author: Liang, Jing | University of Maryland
    Author: Patel, Utsav | University of Maryland
    Author: Guan, Tianrui | University of Maryland
    Author: Chandra, Rohan | University of Maryland
    Author: Manocha, Dinesh | University of Maryland
 
    keyword: Collision Avoidance; Motion and Path Planning

    Abstract : We present DenseCAvoid, a novel algorithm for navigating a robot through dense crowds and avoiding collisions by anticipating pedestrian behaviors. Our formulation uses visual sensors and a pedestrian trajectory prediction algorithm to track pedestrians in a set of input frames and compute bounding boxes that extrapolate to the pedestrian positions in a future time. Our hybrid approach combines this trajectory prediction with a Deep Reinforcement Learning-based collision avoidance method to train a policy to generate smoother, safer, and more robust trajectories during run-time. We train our policy in realistic 3-D simulations of static and dynamic scenarios with multiple pedestrians. In practice, our hybrid approach generalizes well to unseen, real-world scenarios and can navigate a robot through dense crowds (~1-2 humans per square meter) in indoor scenarios, including narrow corridors and lobbies. As compared to cases where prediction was not used, we observe that our method reduces the occurrence of the robot freezing in a crowd by up to 48%, and performs comparably with respect to trajectory lengths and mean arrival times to goal.

- DEEPCRASHTEST: Turning Dashcam Videos into Virtual Crash Tests for Automated Driving Systems

    Author: Bashetty, Sai Krishna | ASU
    Author: Ben Amor, Heni | Arizona State University
    Author: Fainekos, Georgios | Arizona State University
 
    keyword: Collision Avoidance; Deep Learning in Robotics and Automation; Object Detection, Segmentation and Categorization

    Abstract : The goal of this paper is to generate simulations with real-world collision scenarios for training and testing autonomous vehicles. We use numerous dashcam crash videos uploaded on the internet to extract valuable collision data and recreate the crash scenarios in a simulator. We tackle the problem of extracting 3D vehicle trajectories from videos recorded by an unknown and uncalibrated monocular camera source using a modular approach. A working architecture and demonstration videos along with the open-source implementation are provided with the paper.

- Observer-Extended Direct Method for Collision Monitoring in Robot Manipulators Using Proprioception and IMU Sensing

    Author: Baradaran Birjandi, Seyed Ali | Technical University of Munich
    Author: Kuehn, Johannes | Technical University of Munich
    Author: Haddadin, Sami | Technical University of Munich
 
    keyword: Collision Avoidance; Sensor Fusion; Robot Safety

    Abstract : In this paper a novel method for accurate and high-bandwidth real-time monitoring of robot collisions is presented. To the     Authors' knowledge this is the first time the so called direct method, which is mathematically the simplest and theoretically the ideal one, has been realized at practically relevant levels. For this, joint velocity and acceleration of serial chain robots are initially estimated using observer techniques that fuse joint position, Cartesian acceleration and angular velocity measurements. Consequently, this algorithm, which also extends our previous work in velocity and acceleration estimation, together with the available robot dynamics model are utilized to algebraically monitor external forces applied to the robot. Specifically, the proposed sensor fusion setup increases estimation bandwidth and decreases detection uncertainties compared to existing methods. Moreover, since neither inversion of large matrices nor their derivatives are required, our approach also shows increased numerical stability. Finally, the developed algorithm is evaluated based on a realistic simulation with the consideration of all parasitic effects and experimentally with a 7-DoF flexible joint robot.

- DCAD: Decentralized Collision Avoidance with Dynamics Constraints for Agile Quadrotor Swarms

    Author: Arul, Senthil Hariharan | University of Maryland, College Park
    Author: Manocha, Dinesh | University of Maryland
 
    keyword: Collision Avoidance; Path Planning for Multiple Mobile Robots or Agents; Simulation and Animation

    Abstract : We present DCAD, a novel, decentralized collision avoidance algorithm for navigating a swarm of quadrotors in dense environments populated with static and dynamic obstacles. Our algorithm relies on the concept of Optimal Reciprocal Collision Avoidance (ORCA) and utilizes a flatness-based Model Predictive Control (MPC) to generate local collision-free trajectories for each quadrotor. We feedforward linearize the non-linear dynamics of the quadrotor and subsequently use this linearized model in our MPC framework. Our approach tends to compute safe trajectories that avoid quadrotors from entering each other's downwash regions during close proximity maneuvers. In addition, we account for the uncertainty in the position and velocity sensor data using Kalman filter. We evaluate the performance of our algorithm with other state-of-the-art decentralized methods and demonstrate its superior performance in terms of smoothness of generated trajectories and lower probability of collision during high-velocity maneuvers.

- Forward Kinematics Kernel for Improved Proxy Collision Checking

    Author: Das, Nikhil | UCSD
    Author: Yip, Michael C. | University of California, San Diego
 
    keyword: Collision Avoidance; Kinematics; Motion and Path Planning

    Abstract : Kernel functions may be used in robotics for comparing different poses of a robot, such as in collision checking, inverse kinematics, and motion planning. These comparisons provide distance metrics often based on joint space measurements and are performed hundreds or thousands of times a second, continuously for changing environments. We introduce a new kernel function based on forward kinematics (FK) to compare robot manipulator configurations. We integrate our new FK kernel into our proxy collision checker, Fastron, that previously showed significant speed improvements to collision checking and motion planning. With the new FK kernel, we realize a two-fold speedup in proxy collision check speed, 8 times less memory, and a boost in classification accuracy from 74% to over 95% for a 7 degrees-of-freedom robot arm compared to the previously-used radial basis function kernel. Compared to state-of-the-art geometric collision checkers, with the FK kernel, collision checks are now 9 times faster. To show the broadness of the approach, we apply Fastron FK in OMPL across a wide variety of motion planners, showing unanimously faster robot planning.

- Local Obstacle-Skirting Path Planning for a Fast Bi-Steerable Rover Using B�ziers Curves

    Author: Fnadi, Mohamed | ISIR - Sorbonne University
    Author: Du, Wenqian | Sorbonne University, ISIR, Paris 6
    Author: Gomes da Silva, Rafael | ENSTA Paris
    Author: Plumet, Frederic | UPMC
    Author: Ben Amar, Faiz | Université Pierre Et Marie Curie, Paris 6
 
    keyword: Collision Avoidance; Dynamics; Field Robots

    Abstract :  This paper focuses on local path planning for obstacle avoidance tasks dedicated to double steering off-road mobile robots. This technique calculates a new local path for the vehicle using a set of cubic B�zier curves once the safety distance is not respected; otherwise, the vehicle follows the global reference path which is defined off-line. Two basic steps are used to determine this new path. Firstly, some significant points that should belong to the planned path are extracted on-line according to the obstacle's sizes and the current state of the vehicle, these points are adopted as waypoints. Secondly, on-line cubic B�zier curves are computed to create a smooth path for these points such that the safety and lateral stability of the vehicle are ensured (i.e., preventing huge curvatures and wide-variation in steering angles). This path will be used as a reference to be performed by the vehicle using a constrained model predictive control. The validation of our navigation strategy is performed via numerical simulations and experiments using a real off-road mobile robot.

- Collision Avoidance with Proximity Servoing for Redundant Serial Robot Manipulators

    Author: Ding, Yitao | Chemnitz University of Technology
    Author: Thomas, Ulrike | Chemnitz University of Technology
 
    keyword: Collision Avoidance; Reactive and Sensor-Based Planning; Motion Control of Manipulators

    Abstract : Collision avoidance is a key technology towards safe human-robot interaction, especially on-line and fast-reacting motions are required. Skins with proximity sensors mounted on the robot's outer shell provide an interesting approach to occlusion-free and low-latency perception. However, collision avoidance algorithms which make extensive use of these properties for fast-reacting motions have not yet been fully investigated. We present an improved collision avoidance algorithm for proximity sensing skins by formulating a quadratic optimization problem with inequality constraints to compute instantaneous optimal joint velocities. Compared to common repulsive force methods, our algorithm confines the approach velocity to obstacles and keeps motions pointing away from obstacles unrestricted. Since with repulsive motions the robot only moves in one direction, opposite to obstacles, our approach has better exploitation of the redundancy space to maintain the task motion and gets stuck less likely in local minima. Furthermore, our method incorporates an active behaviour for avoiding obstacles and evaluates all potentially colliding obstacles for the whole arm, rather than just the single nearest obstacle. We demonstrate the effectiveness of our method with simulations and on real robot manipulators in comparison with commonly used repulsive force methods and our prior proposed approach.

- Predicting Obstacle Footprints from 2D Occupancy Maps by Learning from Physical Interactions

    Author: Kollmitz, Marina | University of Freiburg
    Author: B�scher, Daniel | Albert-Ludwigs-Universitét Freiburg
    Author: Burgard, Wolfram | Toyota Research Institute
 
    keyword: Collision Avoidance; Deep Learning in Robotics and Automation; Learning and Adaptive Systems

    Abstract : Horizontally scanning 2D laser rangefinders are a popular approach for indoor robot localization because of the high accuracy of the sensors and the compactness of the required 2D maps. As the scanners in this configuration only provide information about one slice of the environment, the measurements typically do not capture the full extent of a large variety of obstacles, including chairs or tables. Accordingly, obstacle avoidance based on laser scanners mounted in such a fashion is likely to fail. In this paper, we propose a learning-based approach to predict collisions in 2D occupancy maps. Our approach is based on a convolutional neural network which is trained on a 2D occupancy map and collision events recorded with a bumper while the robot is navigating in its environment. As the network operates on local structures only, it can generalize to new environments. In addition, the robot can collect and integrate new collision examples after an initial training phase. Extensive experiments carried out in simulation and a realistic real-world environment confirm that our approach allows robots to learn from collision events to avoid collisions in the future.

- Path Planning in Dynamic Environments Using Generative RNNs and Monte Carlo Tree Search

    Author: Eiffert, Stuart | The University of Sydney: The Australian Centre for Field Roboti
    Author: Kong, He | University of Sydney
    Author: Pirmarzdashti, Navid | The University of Sydney: The Australian Centre for Field Roboti
    Author: Sukkarieh, Salah | The University of Sydney: The Australian Centre for Field Roboti
 
    keyword: Collision Avoidance; Autonomous Vehicle Navigation

    Abstract : State of the art methods for robotic path planning in dynamic environments, such as crowds or traffic, rely on hand crafted motion models for agents. These models often do not reflect interactions of agents in real world scenarios. To overcome this limitation, this paper proposes an integrated path planning framework using generative Recurrent Neural Networks within a Monte Carlo Tree Search (MCTS). This approach uses a learnt model of social response to predict crowd dynamics during planning across the action space. This extends our recent work using generative RNNs to learn the relationship between planned robotic actions and the likely response of a crowd. We show that the proposed framework can considerably improve motion prediction accuracy during interactions, allowing more effective path planning. The performance of our method is compared in simulation with existing methods for collision avoidance in a crowd of pedestrians, demonstrating the ability to control future states of nearby individuals. We also conduct preliminary real world tests to validate the effectiveness of our method.

- Safety-Critical Rapid Aerial Exploration of Unknown Environments

    Author: Singletary, Andrew | California Institute of Technology
    Author: Gurriet, Thomas | California Institute of Technology
    Author: Nilsson, Petter | California Institute of Technology
    Author: Ames, Aaron | California Institute of Technology
 
    keyword: Collision Avoidance; Aerial Systems: Perception and Autonomy; Robot Safety

    Abstract : This paper details a novel approach to collision avoidance for aerial vehicles that enables high-speed flight in uncertain environments. This framework is applied at the controller level and provides safety regardless of the planner that is used. The method is shown to be robust to state uncertainty and disturbances, and is computed entirely online utilizing the full nonlinear system dynamics. The effectiveness of this method is shown in a high-fidelity simulation of a quadrotor with onboard sensors rapidly and safely exploring a cave environment utilizing a simple planner.

- Reactive Navigation under Non-Parametric Uncertainty through Hilbert Space Embedding of Probabilistic Velocity Obstacles

    Author: Poonganam, SriSai Naga Jyotish | IIIT Hyderabad
    Author: Gopalakrishnan, Bharath | IIIT HYDERABAD
    Author: Avula, Venkata Seetharama Sai Bhargav Kumar | International Institute of Information Technology, Hyderabad
    Author: Singh, Arun Kumar | Tampere University of Technology, Finland
    Author: Krishna, Madhava | IIIT Hyderabad
    Author: Manocha, Dinesh | University of Maryland
 
    keyword: Collision Avoidance

    Abstract : The probabilistic velocity obstacle (PVO) extends the concept of velocity obstacle (VO) to work in uncertain dynamic environments. In this paper, we show how a robust model predictive control (MPC) with PVO constraints under non-parametric uncertainty can be made computationally tractable. At the core of our formulation is a novel yet simple interpretation of our robust MPC as a problem of matching the distribution of PVO with a certain desired distribution. To this end, we propose two methods. Our first baseline method is based on approximating the distribution of PVO with a Gaussian Mixture Model (GMM) and subsequently performing distribution matching using Kullback Leibler (KL) divergence metric. Our second formulation is based on the possibility of representing arbitrary distributions as functions in Reproducing Kernel Hilbert Space (RKHS). We use this foundation to interpret our robust MPC as a problem of minimizing the distance between the desired distribution and the distribution of the PVO in the RKHS. Both the RKHS and GMM based formulation can work with any uncertainty distribution and thus allowing us to relax the prevalent Gaussian assumption in the existing works. We validate our formulation by taking an example of 2D navigation of quadrotors with a realistic noise model for perception and ego-motion uncertainty.

- Contact-Based Bounding Volume Hierarchy for Assembly Tasks

    Author: Shellshear, Evan | FCC
    Author: Li, Yi | Fraunhofer-Chalmers Research Centre
    Author: Bohlin, Robert | Fraunhofer-Chalmers Research Centre
    Author: Carlson, Johan | Fraunhofer-Chalmers Research Centre
 
    keyword: Collision Avoidance; Motion and Path Planning; Assembly

    Abstract : Path planning of an object which is allowed to be in contact with other objects during assembly process is a significant challenge due to the variety of permitted or forbidden collisions between the distinct parts of the objects to be assembled. In order to put objects together in real-life scenarios, parts of assembled objects may be required to flex, whereas other parts may have to fit exactly. Consequently, existing collision checking and distance computation algorithms have to be modified to enable path planning of objects that can be in contact during the assembly process. In this paper, we analyze an improved broad phase proximity query algorithm to enable such contact-based assembly tasks we call CHAT (Contact-based Hierarchy for Assembly Tasks). We demonstrate that, compared to existing approaches, our proposed method is more than an order of magnitude faster for collision queries and up to three times faster for distance queries when the two objects contain a large number of parts (with some parts containing thousands or tens of thousands of triangles). Due to the nature of the algorithm, we expect the performance improvements to increase as the number of parts in an object becomes larger.

- Construction of Bounding Volume Hierarchies for Triangle Meshes with Mixed Face Sizes

    Author: Li, Yi | Fraunhofer-Chalmers Research Centre
    Author: Shellshear, Evan | FCC
    Author: Bohlin, Robert | Fraunhofer-Chalmers Research Centre
    Author: Carlson, Johan | Fraunhofer-Chalmers Research Centre
 
    keyword: Collision Avoidance; Motion and Path Planning; Assembly

    Abstract : We consider the problem of creating tighter-fitting bounding volumes (more specifically rectangular swept spheres) when constructing bounding volume hierarchies (BVHs) for complex 3D geometries given in the form of unstructured triangle meshes/soups with the aim of speeding up our IPS Path Planner for rigid bodies, where the triangles often have very different sizes. Currently, the underlying collision and distance computation module (IPS CDC) does not take into account the sizes of the triangles when it constructs BVHs using a top-down strategy. To split triangles in a BVH node into two BVH nodes, IPS CDC has to compute both the split axis and the split position. In this work, we use the principal axes of the tensor of inertia as the potential split axes and the center of mass as the split position, where the computations of both the tensor of inertia and the center of mass require knowledge of the areas of the triangles. We show that our method improves performance (up to 20% faster) of our IPS Path Planner when it is used to plan collision-free disassembly paths for three different test cases taken from manufacturing industries.

- Strategy for Automated Dense Parking: How to Navigate in Narrow Lanes

    Author: Polack, Philip | Stanley Robotics
    Author: Cord, Aur�lien | Stanley Robotics
    Author: Dallen, Louis-Marie | Stanley Robotics
 
    keyword: Collision Avoidance; Optimization and Optimal Control; Kinematics

    Abstract : This paper presents the architecture of a high-density parking solution based on car-like robots specifically designed to move cars. The main difficulty is to park the vehicles close to one another which implies hard constraints on the robot motion and localization. In particular, this paper focuses on navigation in narrow lanes. We propose a Lyapunov-based control strategy that has been derived after expressing the problem in a Configuration Space formulation. The current solution has been implemented and tested on Stanley Robotics' robots and has been running in production for several months. Thanks to the Configuration Space formulation, we are able to guarantee the obstacles' integrity. Moreover, a method for calibrating the GPS orientation with a high-precision is derived from the present control strategy.

- Multimodal Trajectory Predictions for Urban Environments Using Geometric Relationship between a Vehicle and Lanes

    Author: Kawasaki, Atsushi | Toshiba Corporation
    Author: Seki, Akihito | Toshiba Corporation
 
    keyword: Collision Avoidance; Deep Learning in Robotics and Automation; Motion and Path Planning

    Abstract : Implementation of safe and efficient autonomous driving systems requires accurate prediction of the long-term trajectories of surrounding vehicles. High uncertainty in traffic behavior makes it difficult to predict trajectories in urban environments, which have various road geometries. To overcome this problem, we propose a method called lane-based multimodal prediction network (LAMP-Net), which can handle arbitrary shapes and numbers of traffic lanes and predict both the future trajectory along each lane and the probability of each lane being selected. A vector map is used to define the lane geometry and a novel lane feature is introduced to represent the generalized geometric relationships between the vehicle state and lanes. Our network takes this feature as the input and is trained to be versatile for arbitrarily shaped lanes. Moreover, we introduce a vehicle motion model constraint to our network. Our prediction method combined with the constraint significantly enhances prediction accuracy. We evaluate the prediction performance on two datasets which contain a wide variety of real-world traffic scenarios. Experimental results show that our proposed LAMP-Net outperforms state-of-the-art methods.

- Online Optimal Motion Generation with Guaranteed Safety in Shared Workspace

    Author: Zheng, Pu | University Grenoble Alpes
    Author: Wieber, Pierre-Brice | INRIA Rh�ne-Alpes
    Author: Aycard, Olivier | University Grenoble
 
    keyword: Collision Avoidance; Optimization and Optimal Control; Robot Safety

    Abstract : For new, safer manipulator robots, the probability of serious injury due to collisions with humans remains low (5%), even at speeds as high as 2 m/s. Collisions would better be avoided nevertheless, because they disrupt the tasks of both the robot and the human. We propose in this paper to equip robots with exteroceptive sensors and online motion generation so that the robot is able to perceive and react to the motion of the human in order to reduce the occurrence of collisions. We adapt a Model Predictive Control scheme which has been demonstrated previously with two industrial manipulator robots avoiding collisions while sharing their workspace. It's impossible to guarantee that no collision will ever take place in a partially unknown dynamic environment such as a shared workspace, but we can guarantee instead that, if a collision takes place, the robot is at rest at the time of collision, so that it doesn�t inject its own kinetic energy in the collision. The proposed control scheme is validated in simulation.

- Episodic Koopman Learning of Nonlinear Robot Dynamics with Applications to Fast Multirotor Landing

    Author: Folkestad, Carl | California Institute of Technology
    Author: Pastor, Daniel | Caltech
    Author: Burdick, Joel | California Institute of Technology
 
    keyword: Learning and Adaptive Systems; Aerial Systems: Perception and Autonomy; Optimization and Optimal Control

    Abstract : This paper presents a novel episodic method to learn a robot's nonlinear dynamics model and an increasingly optimal control sequence for a set of tasks. The method is based on the Koopman operator approach to nonlinear dynamical systems analysis, which models the flow of observables in a function space, rather than a flow in a state space. Practically, this method estimates a nonlinear diffeomorphism that lifts the dynamics to a higher dimensional space where they are linear. Efficient Model Predictive Control methods can then be applied to the lifted model. This approach allows for real time implementation in on-board hardware, with rigorous incorporation of both input and state constraints during learning. We demonstrate the method in a real-time implementation of fast multirotor landing, where the nonlinear ground effect is learned and used to improve landing speed and quality.

## Micro/Nano Robots

- Reconfigurable Magnetic Microswarm for Thrombolysis under Ultrasound Imaging

    Author: Wang, Qianqian | The Chinese University of Hong Kong
    Author: Wang, Ben | The Chinese University of Hong Kong
    Author: Yu, Jiangfan | University of Toronto
    Author: Schweizer, Kathrin | ETH Zurich
    Author: Nelson, Bradley J. | ETH Zurich
    Author: Zhang, Li | The Chinese University of Hong Kong
 
    keyword: Micro/Nano Robots; Medical Robots and Systems; Swarms

    Abstract : We propose thrombolysis using a magnetic nanoparticle microswarm with tissue plasminogen activator (tPA) under ultrasound imaging. The microswarm is generated in blood using an oscillating magnetic field and can be navigated with locomotion along both the long and short axis. By modulating the input field, the aspect ratio of the microswarm can be reversibly tuned, showing the ability to adapt to different confined environments. Simulation results indicate that both in-plane and out-of-plane fluid convection are induced around the microswarm, which can be further enhanced by tuning the aspect ratio of the microswarm. Under ultrasound imaging, the microswarm is navigated in a microchannel towards a blood clot and deformed to obtain optimal lysis. Experimental results show that the lysis rate reaches -0.1725 - 0.0612 mm^3/min in the 37&#9702;C blood environment under the influence of the microswarm-induced fluid convection and tPA. The lysis rate is enhanced 2.5-fold compared to that without the microswarm (-0.0681 - 0.0263 mm^3/min). Our method provides a new strategy to increase the efficiency of thrombolysis by applying microswarm-induced fluid convection, indicating that swarming micro/nanorobots have the potential to act as effective tools towards targeted therapy.

- Improving Optical Micromanipulation with Force-Feedback Bilateral Coupling

    Author: Gerena, Edison | Sorbonne Université Facult� Pierre Et Mairie Curie
    Author: Legendre, Florent | Sorbonne Université
    Author: Vitry, Youen | ULB
    Author: R�gnier, Stéphane | Sorbonne University
    Author: Haliyo, Dogan Sinan | Sorbonne Université
 
    keyword: Micro/Nano Robots; Haptics and Haptic Interfaces; Biological Cell Manipulation

    Abstract : Micromanipulation is challenging due to the specific physical effects governing the microworld. Interactive approaches using only visual feedback are limited to the 2D image of the microscope, and have forcibly lower bandwidth. Recently, haptic feedback teleoperation systems have been developed to try to overcome those difficulties. This paper explores the case of an optical tweezers platform coupled to an haptic device providing transparent force feedback. The impact of haptic feedback regarding user dexterity on tactile exploration tasks is studied using 3 �m microbeads and a test bench with micro sized shapes. The results reveal a consistent improvement in both users' trajectory tracking and their control of the contact forces. This also validates the experimental setup which performed reliably on 140 different trials of the evaluation.

- Maneuver at Micro Scale: Steering by Actuation Frequency Control in Micro Bristle Robots

    Author: Hao, Zhijian | Georgia Institute of Technology
    Author: Kim, DeaGyu | Georgia Institute of Technology
    Author: Mohazab, Ali Reza | Foundation for the Advancement of Sciences, Humanities, Enginee
    Author: Ansari, Azadeh | Georgia Institute of Technology
 
    keyword: Micro/Nano Robots; Mechanism Design; Automation at Micro-Nano Scales

    Abstract : This paper presents a novel steering mechanism, which leads to frequency-controlled locomotion demonstrated for the first time in micro bristle robots. The miniaturized robots are 3D-printed, 12 mm - 8 mm - 6 mm in size, with bristle feature sizes down to 400 &#956;m. The robots can be steered by utilizing the distinct resonance behaviors of the asymmetrical bristle sets. The left and right sets of the bristles have different diameters, and thus different stiffnesses and resonant frequencies. The unique response of each bristle side to the vertical vibrations of a single on-board piezoelectric actuator causes differential steering of the robot. The robot can be modeled as two coupled uniform bristle robots, representing the left and the right sides. At distinct frequencies, the robots can move in all four principal directions: forward, backward, left and right. Furthermore, the full 360� 2D plane can be covered by superimposing the principal actuation frequency components with desired amplitudes. In addition to miniaturized robots, the presented resonance-based steering mechanism can be applied over multiple scales and to other mechanical systems.

- Scaling down an Insect-Size Microrobot, HAMR-VI into HAMR-Jr

    Author: Jayaram, Kaushik | University of Colorado Boulder
    Author: Shum, Jennifer | Harvard University
    Author: Castellanos, Sam | Harvard University
    Author: Helbling, Elizabeth Farrell | Harvard University
    Author: Wood, Robert | Harvard University
 
    keyword: Micro/Nano Robots; Biologically-Inspired Robots; Legged Robots

    Abstract : Here, we present HAMR-Jr, a 22.5 mm, 320 mg quadrupedal microrobot. With eight independently actuated degrees of freedom, HAMR-Jr is, to our knowledge, the most mechanically dexterous legged robot at its scale and is capable of high-speed locomotion (13.91 bodylengths/s) at a variety of stride frequency (1-200 Hz) using multiple gaits. We achieved this using a design and fabrication process that is flexible, allowing scaling with minimum changes to our workflow. We further characterized HAMR-Jr's open-loop locomotion and compared it with the larger scale HAMR-VI microrobot to demonstrate the effectiveness of scaling laws in predicting running performance.

- Model Predictive Control with Obstacle Avoidance for Inertia Actuated AFM Probes Inside a Scanning Electron Microscope

    Author: Liang, Shuai | Pierre and Marie Curie University, the Institute for Intelligent
    Author: Boudaoud, Mokrane | Sorbonne Université
    Author: Morin, Pascal | UPMC
    Author: Cagneau, Barth�lemy | Université De Versailles Saint-Quentin En Yvelines
    Author: Rong, Weibin | Harbin Institute of Technology, Harbin, China
    Author: R�gnier, Stéphane | Sorbonne University
 
    keyword: Micro/Nano Robots; Automation at Micro-Nano Scales

    Abstract : The Atomic Force Microscope (AFM) is as a reliable tool for 3D imaging and manipulation at the micrometer and nanometer scales. When used inside a Scanning Elec- tron Microscope (SEM), AFM probes can be localized and controlled with a nanometer resolution by visual feedback. However, achieving trajectory control and obstacles avoidance is still a major concern for manipulation tasks. We propose a Model Predictive Control (MPC) to address these two issues while AFM probes are actuated by Piezoelectric Inertia type Actuators (PIA). The novelty of this paper is that the model of our MPC-based approach relies on a velocity map of PIAs. It enables path following and obstacle avoidance while preserving safety margins. Control inputs are optimized by Quadratic Programming, referring to their increment and distance constraints. A cost function is defined to navigate the AFM probe with a specified velocity. Simulations and experiments are carried out to demonstrate that the proposed algorithm is suitable to perform path following with obstacle avoidance using map-based velocity references. This is the first time that MPC is implemented in micro/nano-robotic systems for autonomous control inside SEM.

- Double-Modal Locomotion and Application of Soft Cruciform Thin-Film Microrobot

    Author: Su, Meng | Shenzhen Institutes of Advanced Technology&#65292;Chinese Academ
    Author: Xu, Tiantian | Chinese Academy of Sciences
    Author: Lai, Zhengyu | Chinese Academy of Science, Shenzhen Institude of Advanced Techn
    Author: Huang, Chenyang | Shenzhen Institutes of Advanced Technology, Chinese Academy of S
    Author: Liu, Jia | ShenZhen Institutes of Advanced Technology, Chinese Academy of S
    Author: Wu, Xinyu | CAS
 
    keyword: Micro/Nano Robots; Soft Robot Applications; Biologically-Inspired Robots

    Abstract : Untethered, wirelessly controlled microrobots have a broad application prospect from industrial area, to the bioengineering due to their small scales. In a narrow environment containing viscous resistance and friction fluid, rigid body may damage the micro-objects that the microrobots manipulate. In this paper, we propose a new type of soft microrobot which is informed the Cruciform Thin-film Microrobot (CTM). This soft microrobot has two motion modes: jellyfish-like mode and forklift truck mode. The forklift truck mode helps to transport micro-objects. The heaviest object that CTM could carry is ten times weighter than its own. The CTM is controlled for s-shaped trajectory control. In this paper, we study the swimming properties of the microrobot. The maximum velocity of CTM is 8mm/s. The velocity of the microrobot is inversely proportional to solution viscosity and proportional to magnetic field frequency. And the velocity is proportional to leg length and thickness. Load testing and manipulation test of the three microbeads to the same location are completed. The CTMs are of great significance for bioengineering and industrial microoperation. In future works, we will conduct more accurate trajectory control and manipulation performance tests.

- Robotic Control of a Magnetic Swarm for On-Demand Intracellular Measurement

    Author: Wang, Xian | University of Toronto
    Author: Wang, Tiancong | University of Toronto
    Author: Shan, Guanqiao | University of Toronto
    Author: Law, Junhui | University of Toronto
    Author: Dai, Changsheng | University of Toronto
    Author: Zhang, Zhuoran | University of Toronto
    Author: Sun, Yu | University of Toronto
 
    keyword: Automation in Life Sciences: Biotechnology, Pharmaceutical and Health Care; Automation at Micro-Nano Scales; Micro/Nano Robots

    Abstract : Fluorescent dyes are routinely used for biochemical measurements such as pH and ion concentrations. They, especially when used for detecting a low concentration of ions, suffer from low signal-to-noise ratios (SNR); and increasing the concentration of dyes causes more sever cytotoxicity. We invented a new approach that uses a low amount of fluorescent dye-coated magnetic nanoparticles for on-demand, accurately aggregating the nanoparticles and thus fluorescent dyes in a local region inside a cell for measurement. Experiments proved this approach is capable of achieving a significantly higher SNR and lower cytotoxicity. Different from existing magnetic micromanipulation systems that generate large swarms (several microns and above) or cannot move the generated swarm to an arbitrary position, we developed a five-pole magnetic manipulation system and technique for generating a small swarm (e.g., 1 �m; controllable size from 0.52 �m to 52.7 �m with an error &lt;7.5%) and accurately positioning the swarm (positioning control accuracy: 0.76 �m). As an example, the system performed intracellular pH mapping using a 1 �m swarm of pH sensitive fluorescent dye-coated magnetic nanoparticles. The swarm had an SNR inside a cell 10 times that by the traditional dye treatment, with both cases using the same fluorescent dye concentration. Our intracellular measurement results, for the first time, quantitatively revealed the existence of pH gradient in live migrating cells.

- Acoustofluidic Tweezers for the 3D Manipulation of Microparticles

    Author: Guo, Xinyi | Max Planck Institute for Intelligent Systems; Tianjin University
    Author: Ma, Zhichao | Max Planck Institute for Intelligent Systems
    Author: Goyal, Rahul | Max Planck Institute for Intelligent Systems
    Author: Jeong, Moonkwang | Max Planck Institute for Intelligent Systems
    Author: Pang, Wei | Tianjin University
    Author: Fischer, Peer | Max-Planck-Institute for Intelligent Systems
    Author: Duan, Xuexin | Tianjin University
    Author: Qiu, Tian | University of Stuttgart
 
    keyword: Automation at Micro-Nano Scales; Micro/Nano Robots; Automation in Life Sciences: Biotechnology, Pharmaceutical and Health Care

    Abstract : Non-contact manipulation is of great importance in the actuation of micro-robotics. It is challenging to contactless manipulate micro-scale objects over large spatial distance in fluid. Here, we describe a novel approach for the dynamic position control of microparticles in three-dimensional (3D) space, based on high-speed acoustic streaming generated by a micro-fabricated gigahertz transducer. The hydrodynamic force generated by the streaming flow field has a vertical component against gravity and a lateral component towards the center, thus the microparticle is able to be stably trapped at a position far from the transducer surface, and to be manipulated over centimeter distance in 3D. Only the hydrodynamic force is utilized in the system for particle manipulation, making it a versatile tool regardless the material properties of the trapped particle. The system shows high reliability and manipulation velocity, revealing its potentials for the applications in robotics and automation at small scales.

- Task Space Motion Control for AFM-Based Nanorobot Using Optimal and Ultralimit Archimedean Spiral Local Scan

    Author: Sun, Zhiyong | The University of Hong Kong
    Author: Xi, Ning | The University of Hong Kong
    Author: Xue, Yuxuan | University of Hong Kong
    Author: Cheng, Yu | Michigan State University
    Author: Chen, Liangliang | Michigan State University
    Author: Yang, Ruiguo | Northwestern University
    Author: Song, Bo | Hefei Institutes of Physical Science, Chinese Academy of Science
 
    keyword: Micro/Nano Robots; Automation at Micro-Nano Scales; Visual Servoing

    Abstract : Atomic force microscopy (AFM) based nanorobotic technology provides a unique manner for delicate operations at the nanoscale in various ambient thanks to its ultrahigh spatial resolution, outstanding environmental adaptability, and numerous measurement approaches. However, one vital challenge behind nanoscale operations is the task space positioning problem, known as difficulty of realizing desirable relative position between the AFM sharp tip and the target. It is noted that though one AFM possesses nanometer imaging resolution, it is hard to achieve nanometer positioning accuracy due to system uncertainties, such as the uncompensated nonlinearity and the thermal drift generated internally/externally. In order to tackle the vital positioning problem in the task space, this paper proposes a specific visual servoing control framework using local ambient image as feedback to overcome positioning uncertainty at the nanoscale. In this study, we employ the optimal Archimedean spiral scanning strategy and try to exceed the speed criterion to pursue faster and uniform local scan for generating feedback images. To fulfill reliable precise tip locating with the possible non-ideal feedback images, a type of visual servoing control approach: extended non-vector space (ENVS) controller based on subset projection method was developed for tackling environmental noise and disturbances. Experimental studies were conducted to verify the effectiveness of the proposed methodology.

- Kinematic Model of a Magnetic-Microrobot Swarm in a Rotating Magnetic Dipole Field

    Author: Chaluvadi, BhanuKiran | Blue Ocean Robotics
    Author: Stewart, Kristen | University of Utah
    Author: Sperry, Adam | University of Utah
    Author: Fu, Henry | University of Utah
    Author: Abbott, Jake | University of Utah
 
    keyword: Micro/Nano Robots; Medical Robots and Systems

    Abstract : This letter describes how a rotating magnetic dipole field will manipulate the location and shape of a swarm of magnetic microrobots, specifically microrobots that convert rotation into forward propulsion, such as helical swimmers and screws. The analysis assumes a swarm that can be described by a centroid and a covariance matrix, with the swarm comprising an arbitrary and unknown number of homogenous microrobots. The result of this letter is a kinematic model that can be used as an <i>a priori</i> model for motion planners and feedback control systems. Because the model is fully three-dimensional and does not require any localization information beyond what could realistically be determined from medical images, the method has potential for <i>in vivo</i> medical applications. The model is experimentally verified using magnetic screws moving through a soft-tissue phantom, propelled by a rotating spherical permanent magnet.

- Magnetic Milli-Robot Swarm Platform: A Safety Barrier Certificate Enabled, Low-Cost Test Bed

    Author: Hsu, Allen | SRI International
    Author: Huihua, Zhao | Georgia Institute of Technology
    Author: Gaudreault, Martin | SRI International
    Author: Wong-Foy, Annjoe | SRI International
    Author: Pelrine, Ron | SRI International
 
    keyword: Micro/Nano Robots; Multi-Robot Systems; Swarms

    Abstract : Swarms of micro- and milli-sized robots have the potential to advance biological micro-manipulation, micro-assembly and manufacturing, and provide an ideal platform for studying large swarm behaviors and control. Due to their small size and low cost, tens to hundreds of micro/milli robots can function in parallel to perform a task that otherwise would be too cumbersome or costly for a larger macroscopic robot. Here, we demonstrate a scalable system and modular circuit architecture for controlling and coordinating the motion of &gt;10's of magnetic micro/milli robots. By modifying the concepts of safety barrier certificates to our magnetic robot hardware, we achieve minimally invasive, collision-free, 2D position control (x,y) of up to N = 16 robots in a low-cost tabletop (288mm x 288mm) magnetic milli-robot platform with up to 288 degrees of freedom. We show that the introduction of random dithering can achieve a 100% success rate (i.e., no deadlocking), enabling the system to serve as a platform for the study of various swarm-like behaviors or multi-agent robotic coordination.

- A Device for Rapid, Automated Trimming of Insect-Sized Flying Robots

    Author: Dhingra, Daksh | University of Washington
    Author: Chukewad, Yogesh Madhavrao | University of Washington
    Author: Fuller, Sawyer | University of Washington
 
    keyword: Micro/Nano Robots; Automation at Micro-Nano Scales; Aerial Systems: Mechanics and Control

    Abstract : Successful demonstrations of controlled flight in flying insect-sized robots (FIRs) &lt;500~mg have all relied on piezo-actuated flapping wings because of unfavorable downward size scaling in motor-driven propellers. In practice, the mechanical complexity of flapping wings typically results in large torque bias variability about pitch and roll axes, leading to rapid rotation in free flight for vehicles that are not properly trimmed. Manual trimming by watching high-speed video is tedious and error-prone. In this letter, we introduce an alternative, a trimming device that uses feedback from motion capture cameras to determine and correct for bias torques. It does so using an automated feedback loop, without the need for any visual feedback from the user, or airborne flights which can damage the robot. We validated the device on two different robot flies. After trimming with our device, the robots both took off approximately vertically in open-loop and were able to hover in free flight under feedback control. Our system, therefore, reduces the time of essential yet time-consuming step in robot fly fabrication, facilitating their eventual mass production and practical application.

- Eye-In-Hand 3D Visual Servoing of Helical Swimmers Using Parallel Mobile Coils

    Author: Yang, Zhengxin | The Chinese Univeristy of HongKong
    Author: Yang, Lidong | The Chinese University of Hong Kong
    Author: Zhang, Li | The Chinese University of Hong Kong
 
    keyword: Micro/Nano Robots; Visual Servoing; Motion Control

    Abstract : Magnetic helical microswimmers can be propelled by rotating magnetic field and are adept at passing through narrow space. To date, various magnetic actuation systems and control methods have been developed to drive these microswimmers. However, steering their spacial movement in a large workspace is still challenging, which could be significant for potential medical applications. In this regard, this paper designs an eye-in-hand stereo-vision module and corresponding refraction-rectified location algorithm. Combined with the motor module and the coil module, the mobile-coil system is capable of generating dynamic magnetic fields in a large 3D workspace. Based on the system, a robust triple-loop stereo visual servoing strategy is proposed that operates simultaneous tracking, locating, and steering, through which the helical swimmer is able to follow a long-distance 3D path. A scaled-up magnetic helical swimmer is employed in the path following experiment. Our prototype system reaches a cylindrical workspace with a diameter more than 200 mm, and the mean error of path tracking is less than 2 mm.

- A Mobile Paramagnetic Nanoparticle Swarm with Automatic Shape Deformation Control

    Author: Yang, Lidong | The Chinese University of Hong Kong
    Author: Yu, Jiangfan | University of Toronto
    Author: Zhang, Li | The Chinese University of Hong Kong
 
    keyword: Micro/Nano Robots; Swarms; Automation at Micro-Nano Scales

    Abstract : Recently, swarm control of micro-/nanorobots has drawn much attention in the field of microrobotics. This paper reports a mobile paramagnetic nanoparticle swarm with the capability of active shape deformation that can improve its environment adaptability. We show that, by applying elliptical rotating magnetic fields, a swarm pattern called the elliptical paramagnetic nanoparticle swarm (EPNS) would be formed. When changing the field ratio- (i.e. the strength ratio between the minor axis and major axis of the elliptical field), the shape ratio- of the EPNS (i.e. the length ratio between the major axis and minor axis) will change accordingly. However, automatically control this shape deformation process has difficulties because the deformation dynamics has strong nonlinearity, model variation and long time requirement. To solve this problem, we propose a fuzzy logic-based control scheme that utilizes the knowledge and control experience from skilled human operators. Experiments show that the proposed control scheme can stably maneuver the shape deformation of the EPNS with small overshoot, which cannot be achieved by conventional PI control. Moreover, experimental results show that, with the automatic shape deformation control, shape of the EPNS is controlled with high reversibility and also can be well maintained during the planar rotational and translational locomotion of the EPNS.

- Magnetic Miniature Swimmers with Multiple Flagella

    Author: Quispe, Johan Edilberto | Sorbonne University, CNRS Institut Des Syst�mes Intelligents Et
    Author: R�gnier, Stéphane | Sorbonne University
 
    keyword: Micro/Nano Robots; Biomimetics; Simulation and Animation

    Abstract : In this paper, we introduce novel miniature swimmers with multiple rigid tails based on spherical helices. The tail distribution of these prototypes enhances its swimming features as well as allowing to carry objects with it. The proposed swimmers are actuated by a rotating magnetic field, generating the robot rotation and thus producing a considerable thrust to start self-propelling. These prototypes achieved propulsion speeds up to 6 mm/s at 3.5 Hz for a 6-mm in size prototypes. We study the efficiency of different tail distribution for a 2-tailed swimmer by varying the angular position between both tails. Moreover, it is demonstrated that these swimmers experience great sensibility when changing their tail height. Besides, these swimmers demonstrate to be effective for cargo carrying tasks since they can displace objects up to 3.5 times their weight. Finally, wall effect is studied with multi-tailed swimmer robots considering 2 containers with 20 and 50-mm in width. Results showed speeds' increments up to 59% when swimmers are actuated in the smaller container.

- Design and Control of a Large-Range Nil-Stiffness Electro-Magnetic Active Force Sensor

    Author: Cailliez, Jonathan | Sorbonne Université, Institut Des Syst�mes Intelligents Et De Ro
    Author: Weill--Duflos, Antoine | McGill University
    Author: Boudaoud, Mokrane | Sorbonne Université
    Author: R�gnier, Stéphane | Sorbonne University
    Author: Haliyo, Dogan Sinan | Sorbonne Université
 
    keyword: Micro/Nano Robots; Sensor-based Control; Calibration and Identification

    Abstract : Active force sensors are key instruments to get around the tradeoff between the sensitivity and the measure- ment range of conventional passive force sensors. Thanks to their quasi-infinite stiffness in closed loop, active sensors can be applied for force measurements on samples with a wide range of stiffness without interference with the mechanical parameters of the sensor. MEMS (Micro-Electro Mechanical Systems) active force sensors have been wildly developed in the literature but they are ill adapted for force measurements at the Newton level needed in meso-scale robotics. In this article, a novel structure for a meso-scale active force sensor is proposed for the measurement of forces from the milli-newton to the newton.This novel meso-scale sensor is based on a nil-stiffness guidance and an electromagnetic actuation. This paper deals with its design, identification, calibration and closed loop control. The sensor exhibits nil-stiffness characteristic in open loop and an almost infinite stiffness in closed loop. This allows measuring forces with a large range of gradients. First experiments shows the ability of this new sensor architecture to measure low frequency forces up to 0.8 N with a precision of 0.03 N and a closed loop -20dB cutoff frequency of 73.9Hz.

- Modeling Electromagnetic Navigation Systems for Medical Applications Using Random Forests and Artificial Neural Networks

    Author: Yu, Ruoxi | The Chinese University of Hong Kong
    Author: Charreyron, Samuel L. | ETH Zurich
    Author: Boehler, Quentin | ETH Zurich
    Author: Weibel, Cameron | ETHZ
    Author: Chautems, Christophe | ETH Zurich
    Author: Poon, Carmen C. Y. | The Chinese University of Hong Kong
    Author: Nelson, Bradley J. | ETH Zurich
 
    keyword: Micro/Nano Robots; AI-Based Methods; Model Learning for Control

    Abstract : Electromagnetic Navigation Systems (eMNS) can be used to control a variety of multiscale devices within the human body for remote surgery. Accurate modeling of the magnetic fields generated by the electromagnets of an eMNS is crucial for the precise control of these devices. Existing methods assume a linear behavior of these systems, leading to significant modeling errors within nonlinear regions exhibited at higher magnetic fields, preventing these systems from operating at full capacity. In this paper, we use a random forest (RF) and an artificial neural network (ANN) to model the nonlinear behavior of the magnetic fields generated by an eMNS. Both machine learning methods outperformed the state- of-the-art linear multipole electromagnet model (MPEM). The RF and the ANN model reduced the root mean squared error (RMSE) of the MPEM when predicting the field magnitude by approximately 40% and 87%, respectively, over the entire current range of the eMNS. At high current regions, especially between 30 and 35 A, the field-magnitude RMSE improvement of the ANN model over the MPEM was 37 mT, equivalent to 90% error reduction. This study demonstrates the feasibility of using machine learning to model an eMNS for medical applications, and its ability to account for complex nonlinear behavior at high currents. The use of machine learning thus shows promise in developing accurate field predicting models, and ultimately improving surgical procedures that use magnetic navigation.

- Automated Tracking System with Head and Tail Recognition for Time-Lapse Observation of Free-Moving C. Elegans

    Author: Dong, Shengnan | Beijing Institute of Technology
    Author: Liu, Xiaoming | Beijing Institute of Technology
    Author: Li, Pengyun | Beijing Institute of Technology
    Author: Tang, Xiaoqing | Beijing Institute of Technology
    Author: Liu, Dan | Beijing Institute of Technology
    Author: Kojima, Masaru | Osaka University
    Author: Huang, Qiang | Beijing Institute of Technology
    Author: Arai, Tatsuo | University of Electro-Communications
 
    keyword: Micro/Nano Robots

    Abstract :     Abstract�In this paper, an automated tracking system with head and tail recognition for time-lapse observation of free-moving C. elegans is presented. In microscale field, active C. elegans can move out of the view easily without an automated tracking system because of the narrow field of view and rapid speed of C. elegans. In our previous works, we constructed an automated platform with 3D freedom to track centroid region of the nematode successfully. However, tracking time was not long enough to support a full time-lapse observation. Our proposed system in this study integrate the detection method in horizontal plane with depth evaluation more tightly. Tracking time and response speed have been greatly improved. Besides, we make full use of curvature calculation to make the system recognize the head and tail of C. elegans and the recognition rate can be up to 95%. The results demonstrate that the system can fully achieve automated long-term tracking of a free-living nematode and will be a nice tool for C. elegans behavioral analysis.

## AI-Based Methods
- Towards Adaptive Benthic Habitat Mapping

    Author: Shields, Jackson | University of Sydney
    Author: Pizarro, Oscar | Australian Centre for Field Robotics
    Author: Williams, Stefan Bernard | University of Sydney
 
    keyword: AI-Based Methods; Big Data in Robotics and Automation; Field Robots

    Abstract : Autonomous Underwater Vehicles (AUVs) are increasingly being used to support scientific research and monitoring studies. One such application is in benthic habitat mapping where these vehicles collect seafloor imagery that complements broadscale bathymetric data collected using sonar. Using these two data sources, the relationship between remotely-sensed acoustic data and the sampled imagery can be learned, creating a habitat model. As the areas to be mapped are often very large and AUV systems collecting seafloor imagery can only sample from a small portion of the survey area, the information gathered should be maximised for each deployment. This paper illustrates how the habitat models themselves can be used to plan more efficient AUV surveys by identifying where to collect further samples in order to most improve the habitat model. A Bayesian neural network is used to predict visually-derived habitat classes when given broad-scale bathymetric data. This network can also estimate the uncertainty associated with a prediction, which can be deconstructed into its aleatoric (data) and epistemic (model) components. We demonstrate how these structured uncertainty estimates can be utilised to improve the model with fewer samples. Such adaptive approaches to benthic surveys have the potential to reduce costs by prioritizing further sampling efforts. We illustrate the effectiveness of the proposed approach using data collected by an AUV on offshore reefs in Tasmania, Australia.

- Multispectral Domain Invariant Image for Retrieval-Based Place Recognition

    Author: Han, Daechan | Sejong University
    Author: Hwang, Yujin | Sejong University
    Author: Kim, Namil | NAVER LABS
    Author: Choi, Yukyung | Sejong University
 
    keyword: AI-Based Methods; Localization; Intelligent Transportation Systems

    Abstract : Multispectral recognition has attracted increasing attention from the research community due to its potential competence for many applications from day to night. However, due to the domain shift between RGB and thermal image, it has still many challenges to apply and to use RGB-based task. To reduce the domain gap, we propose Multispectral domain invariant framework, which leverages the unpaired image translation method to generate a semantic and strongly discriminative invariant image by enforcing novel constraints in the objective function. We demonstrate the efficacy of the proposed method on mainly place recognition task and achieve significant improvement compared to previous works. Furthermore, we test on multispectral semantic segmentation and unsupervised domain adaptations to prove the scalability and generality of the proposed method. We will open our source code and dataset.

- Probabilistic Effect Prediction through Semantic Augmentation and Physical Simulation

    Author: Bauer, Adrian Simon | German Aerospace Center (DLR)
    Author: Schmaus, Peter | German Aerospace Center (DLR)
    Author: Stulp, Freek | DLR - Deutsches Zentrum F�r Luft Und Raumfahrt E.V
    Author: Leidner, Daniel | German Aerospace Center (DLR)
 
    keyword: AI-Based Methods; Service Robots; Task Planning

    Abstract : Nowadays, robots are mechanically able to perform highly demanding tasks, where AI-based planning methods are used to schedule a sequence of actions that result in the desired effect. However, it is not always possible to know the exact outcome of an action in advance, as failure situations may occur at any time. To enhance failure tolerance, we propose to predict the effects of robot actions by augmenting collected experience with semantic knowledge and leveraging realistic physics simulations. That is, we consider semantic similarity of actions in order to predict outcome probabilities for previously unknown tasks. Furthermore, physical simulation is used to gather simulated experience that makes the approach robust even in extreme cases. We show how this concept is used to predict action success probabilities and how this information can be exploited throughout future planning trials. The concept is evaluated in a series of real world experiments conducted with the humanoid robot Rollin' Justin.

- Anytime Integrated Task and Motion Policies for Stochastic Environments

    Author: Shah, Naman | Arizona State University
    Author: Kala Vasudevan, Deepak | Arizona State University
    Author: Kumar, Kislay | Arizona State University
    Author: Kamojjhala, Pranav | Arizona State University
    Author: Srivastava, Siddharth | University of California Berkeley
 
    keyword: AI-Based Methods; Autonomous Agents; Task Planning

    Abstract : In order to solve complex, long-horizon tasks, intelligent robots need to carry out high-level,     Abstract planning and reasoning in conjunction with motion planning. However,     Abstract models are typically lossy and plans or policies computed using them can be unexecutable. These problems are exacerbated in stochastic situations where the robot needs to reason about, and plan for multiple contingencies. We present a new approach for integrated task and motion planning in stochastic settings. In contrast to prior work in this direction, we show that our approach can effectively compute integrated task and motion policies whose branching structures encoding agent behaviors handling multiple execution-time contingencies. We prove that our algorithm is probabilistically complete and can compute feasible solution policies in an anytime fashion so that the probability of encountering an unresolved contingency decreases over time. Empirical results on a set of challenging problems show the utility and scope of our methods.

- Context-Aware Human Activity Recognition

    Author: Mojarad, Roghayeh | UPEC
    Author: Attal, Ferhat | University Paris-Est Cr�teil (UPEC)
    Author: Chibani, Abdelghani | Lissi Lab Paris EST University
    Author: Amirat, Yacine | University of Paris Est Cr�teil (UPEC)
 
    keyword: AI-Based Methods; Human-Centered Automation; Human Detection and Tracking

    Abstract : One of the main challenges in designing Ambient Assisted Living (AAL) systems is Human Activity Recognition (HAR). The latter is crucial to improve the quality of people's lives in terms of autonomy, safety, and well-being. In this paper, a novel framework exploiting the contextual information of human activities is proposed for HAR. The proposed framework allows detecting and correcting classification errors automatically. Machine-learning models are firstly used to recognize human activities. These models may predict erroneous activities; therefore, detecting and correcting these errors is necessary to improve HAR. For this purpose, two Bayesian networks are used for classification error detection and classification error correction. The proposed framework is evaluated in terms of precision, recall, F-measure, and accuracy on the Opportunity dataset, a well-known dataset for multi-label human daily living activity recognition. The evaluation results demonstrate the ability of the proposed framework to improve HAR performance.

- Interactive Natural Language-Based Person Search

    Author: Shree, Vikram | Cornell University
    Author: Chao, Wei-Lun | Cornell University
    Author: Campbell, Mark | Cornell University
 
    keyword: AI-Based Methods; Human Detection and Tracking; Cognitive Human-Robot Interaction

    Abstract : In this work, we consider the problem of searching people in an unconstrained environment, with natural language descriptions. Specifically, we study how to systematically design an algorithm to effectively acquire descriptions from humans. An algorithm is proposed by adapting models, used for visual and language understanding, to search a person of interest (POI) in a principled way, achieving promising results without the need to re-design another complicated model. We then investigate an iterative question-answering (QA) strategy that enable robots to request additional information about the POI's appearance from the user. To this end, we introduce a greedy algorithm to rank questions in terms of their significance, and equip the algorithm with the capability to dynamically adjust the length of human-robot interaction according to model's uncertainty. Our approach is validated not only on benchmark datasets but on a mobile robot, moving in a dynamic and crowded environment.

## Climbing Robots
- CCRobot-III: A Split-Type Wire-Driven Cable Climbing Robot for Cable-Stayed Bridge Inspection

    Author: Ding, Ning | The Chinese University of Hong Kong (Shenzhen)
    Author: Zheng, Zhenliang | The Chinese University of Hong Kong, Shenzhen
    Author: Song, Junlin | Shenzhen Institute of Artificial Intelligence and Robotics for S
    Author: Sun, Zhenglong | Chinese University of Hong Kong, Shenzhen
    Author: Lam, Tin Lun | The Chinese University of Hong Kong, Shenzhen
    Author: Qian, Huihuan | The Chinese University of Hong Kong, Shenzhen
 
    keyword: Climbing Robots; Legged Robots; Biologically-Inspired Robots

    Abstract : This paper presents a novel Cable Climbing Robot CCRobot-III, which is the third version designed for bridge cable inspection tasks, aiming at surpassing previous versions in terms of climbing speed and payload capacity. Benefiting from Split-type Wire-driven design, CCRobot-III can climb along a 90-110mm diameter bridge cable in inchworm-like gait at a speed of up to 12m/min, and carrying more than 40kg payload at the same time. CCRobot-III consists of a climbing precursor and a main-body frame. The two parts are connected and driven by steel wires. The climbing precursor, acting as a mobile anchor, moves quickly on a bridge cable. The main-body frame, acting as a mobile winch, carries payload and pulls itself to a certain position with steel wires. Both parts have one or two pairs of palm-based gripper, which is the key component for providing strong adhesion to support the robot climbing. Experimental results have shown that CCRobot-III possesses outstanding climbing performance, high payload capacity, and good adaptability to complex conditions of cable surface. Moreover, it has potential engineering applications on the cable-stayed bridge for fieldwork.

- Omnidirectional Tractable Three Module Robot

    Author: Suryavanshi, Kartik | International Institute of Information Technology, Hyderabad
    Author: Vadapalli, Rama | International Institute of Information Technology, Hyderabad
    Author: Vucha, Ruchitha | International Institute of Information Technology, Hyderabad
    Author: Sarkar, Abhishek | International Institute of Information Technology, Hyderabad
    Author: Krishna, Madhava | IIIT Hyderabad
 
    keyword: Climbing Robots; Mechanism Design; Field Robots

    Abstract : This paper introduces the Omnidirectional Tractable Three Module Robot for traversing inside complex pipe networks. The robot consists of three omnidirectional modules fixed 120� apart circumferentially which can rotate about their own axis allowing holonomic motion of the robot. The holonomic motion enables the robot to overcome motion singularity when negotiating T-junctions and further allows the robot to arrive in a preferred orientation while taking turns inside a pipe. We have developed a closed-form kinematic model for the robot in the paper and propose the �Motion Singularity Region� that the robot needs to avoid while negotiating T-junction. The design and motion capabilities of the robot are demonstrated both by conducting simulations in MSC ADAMS on a simplified lumped-model of the robot and with experiments on its physical embodiment.

- A Practical Climbing Robot for Steel Bridge Inspection

    Author: Nguyen, Son | University of Nevada, Reno
    Author: Pham, Anh | University of Nevada, Reno
    Author: Motley, Cadence | University of Nevada, Reno
    Author: La, Hung | University of Nevada at Reno
 
    keyword: Robot Safety; Search and Rescue Robots; Service Robots

    Abstract :  The advanced robotic and automation (ARA) lab has developed and successfully implemented a design inspired by many of the various cutting edge steel inspection robots to date. The combination of these robots concepts into a unified design came with its own set of challenges since the parameters for these features sometimes conflicted. An extensive amount of design and analysis work was performed by the ARA lab in order to find a carefully tuned balance between the implemented features on the ARA robot and general functionality. Having successfully managed to implement this conglomerate of features represents a breakthrough to the industry of steel inspection robots as the ARA lab robot is capable of traversing most complex geometries found on steel structures while still maintaining its ability to efficiently travel along these structures; a feat yet to be done until now.

- Development of a Wheeled Wall-Climbing Robot with a Shape-Adaptive Magnetic Adhesion Mechanism

    Author: Eto, Haruhiko | Sumitomo Heavy Industries, Ltd
    Author: Asada, Harry | MIT
 
    keyword: Climbing Robots; Mechanism Design; Manufacturing, Maintenance and Supply Chains

    Abstract : This paper presents a wheeled wall-climbing robot with a shape-adaptive magnetic adhesion mechanism for large steel structures. To travel up and down various curved ferromagnetic surfaces, we developed a 2 DOF rotational magnetic adhesion mechanism installed on each wheel that can change the orientation of the magnets to keep the magnetic force direction always normal to the contact surface. These magnetic wheels have a spherical shape and can move relative to the main body by a non-elastic suspension mechanism so that the robot can climb up small obstacles on the ground and find contact points for each wheel on a wall with an arbitrary curved shape. Being geometrically stable is important for the robot because this robot is intended to be a mobile base for a welding manipulator. The detailed design of the mechanism and the results of climbing tests are presented.

- Towards More Possibilities: Motion Planning and Control for Hybrid Locomotion of Wheeled-Legged Robots

    Author: Sun, Jingyuan | National University of Singapore
    Author: You, Yangwei | Institute for Infocomm Research
    Author: Zhao, Xuran | National University of Singapore
    Author: Adiwahono, Albertus Hendrawan | I2R A-STAR
    Author: Chew, Chee Meng | National University of Singapore
 
    keyword: Legged Robots; Natural Machine Motion; Climbing Robots

    Abstract : This paper proposed a control framework to tackle the hybrid locomotion problem of wheeled-legged robots. It comes as a hierarchical structure with three layers: hybrid foot placement planning, Centre of Mass (CoM) trajectory optimization and whole-body control. General mathematical representation of foot movement is developed to analyze different motion modes and decide hybrid foot placements. Gait graph widely used in legged locomotion is extended to better describe the hybrid movement by adding extra foot velocity information. Thereafter, model predictive control is introduced to optimize the CoM trajectory based on the planned foot placements considering terrain height changing. The desired trajectories together with other kinematic and dynamic constraints are fed into a whole-body controller to produce joint commands. In the end, the feasibility of the proposed approach is demonstrated by the simulation and experiments of hybrid locomotion running on our wheeled quadrupedal robot Pholus.

- Navigation for Legged Mobility: Dynamic Climbing (I)

    Author: Austin, Max | Florida State University
    Author: Harper, Mario | Florida State University
    Author: Brown, Jason | Florida State University
    Author: Collins, Emmanuel | FAMU-FSU College of Engineering
    Author: Clark, Jonathan | Florida State University
 
    keyword: Climbing Robots; Legged Robots; Motion and Path Planning

    Abstract : Autonomous navigation through unstructured terrains has been most effectively demonstrated by animals, who utilize a large set of locomotive styles to move through their native habitats. While legged robots have recently demonstrated several of these locomotion modalities (such as walking, running, jumping, and climbing vertical walls), motion planners have yet to be able to leverage these unique mobility characteristics. In this article, we outline some of the	specific motion planning challenges faced when attempting to plan for legged systems with dynamic gaits, with specific instances of these demonstrated by the dynamic climbing platform TAILS. Using a unique implementation of sampling-based model predictive optimization, we demonstrate the ability to motion plan around obstacles on vertical walls and experimentally demonstrate this on TAILS by navigating through traditionally difficult narrow gap problems.

## Failure Detection and Recovery
- Algebraic Fault Detection and Identification for Rigid Robots

    Author: Lomakin, Alexander | Universitét Erlangen-N�rnberg
    Author: Deutscher, Joachim | Universitét Erlangen-N�rnberg
 
    keyword: Robot Safety; Failure Detection and Recovery

    Abstract : This paper presents a method for algebraic fault detection and identification of nonlinear mechanical systems, describing rigid robots, by using an approximation with orthonormal Jacobi polynomials. An explicit expression is derived for the fault from the equation of motion, which is decoupled from disturbances and only depends on measurable signals and their time derivatives. Fault detection and identification is then achieved by polynomial approximation of the determined fault term. The results are illustrated by a simulation for a faulty SCARA.

- Fault Tolerance Analysis of a Hexarotor with Reconfigurable Tilted Rotors

    Author: Pose, Claudio Daniel | Facultad De Ingenieria - Universidad De Buenos Aires
    Author: Giribet, Juan Ignacio | University of Buenos Aires
    Author: Mas, Ignacio | CONICET-ITBA
 
    keyword: Failure Detection and Recovery; Aerial Systems: Mechanics and Control

    Abstract : Tilted rotors in multirotor vehicles have shown to be useful for different practical reasons. For instance, increasing yaw maneuverability or enabling full position and attitude control of hexarotor vehicles. It has also been proven that a hexagon-shaped multirotor is capable of complete attitude and altitude control under failures of one of its rotors. However, when a rotor fails, the torque that can be reached in the worst-case direction decreases considerably. <p>This work proposes to actively change the tilt angle of the rotors when a failure occurs. This rotor reconfiguration increases the maximum torque that can be achieved in the most stressful direction, reducing maneuverability limitations. Experimental validations are shown, where the proposed reconfigurable tilted rotor is used in order to control a hexarotor vehicle when a failure appears mid-flight. The impact of the delay in the reconfiguration when a failure occurs is also addressed.

- Detecting Execution Anomalies As an Oracle for Autonomy Software Robustness

    Author: Katz, Deborah S. | Carnegie Mellon University
    Author: Hutchison, Casidhe | Carnegie Mellon University
    Author: Zizyte, Milda | Carnegie Mellon University
    Author: Le Goues, Claire | Carnegie Mellon University
 
    keyword: Failure Detection and Recovery; Robot Safety; Probability and Statistical Methods

    Abstract : We propose a method for detecting execution anomalies in robotics and autonomy software. The algorithm uses system monitoring techniques to obtain profiles of executions. It uses a clustering algorithm to create clusters of those executions, representing nominal execution. A distance metric determines whether additional execution profiles belong to the existing clusters or should be considered anomalies. The method is suitable for identifying faults in robotics and autonomy systems. We evaluate the technique in simulation on two robotics systems, one of which is a real-world industrial system. We find that our technique works well to detect possibly unsafe behavior in autonomous systems.

- When Your Robot Breaks: Active Learning During Plant Failure

    Author: Schrum, Mariah | Georgia Institute of Technology
    Author: Gombolay, Matthew | Georgia Institute of Technology
 
    keyword: Failure Detection and Recovery; Learning and Adaptive Systems; Model Learning for Control

    Abstract : Detecting and adapting to catastrophic failures in robotic systems requires a robot to learn its new dynamics quickly and safely to best accomplish its goals. To address this challenging problem, we propose probabilistically-safe, online learning techniques to infer the altered dynamics of a robot at the moment a failure (e.g., physical damage) occurs. We combine model predictive control and active learning within a chance-constrained optimization framework to safely and efficiently learn the new plant model of the robot. We leverage a neural network for function approximation in learning the latent dynamics of the robot under failure conditions. Our framework generalizes to various damage conditions while being computationally light-weight to advance real-time deployment. We empirically validate within a virtual environment that we can regain control of a severely damaged aircraft in seconds and require only 0.1 seconds to find safe, information-rich trajectories, outperforming state-of-the-art approaches.

- An Integrated Dynamic Fall Protection and Recovery System for Two-Wheeled Humanoids

    Author: Zambella, Grazia | University of Pisa
    Author: Monteleone, Simone | Research Center E. Piaggio, University of Pisa
    Author: Herrera Alarc�n, Edwin Pa�l | Scuola Superiore Sant'Anna
    Author: Negrello, Francesca | Istituto Italiano Di Tecnologia
    Author: Lentini, Gianluca | University of Pisa
    Author: Caporale, Danilo | Centro Di Ricerca E. Piaggio
    Author: Grioli, Giorgio | Istituto Italiano Di Tecnologia
    Author: Garabini, Manolo | Université Di Pisa
    Author: Catalano, Manuel Giuseppe | Istituto Italiano Di Tecnologia
    Author: Bicchi, Antonio | Université Di Pisa
 
    keyword: Robot Safety; Performance Evaluation and Benchmarking; Wheeled Robots

    Abstract : Robots face the eventuality of falling. Unplanned events, external disturbances and technical failures may lead a robot to a condition where even an effective dynamic stabilization is not sufficient to maintain the equilibrium. Therefore, it is essential to equip robotic platforms with both active and passive fall protection means to minimize damages, and enable the recovery and restart without physical human intervention.<p>This work introduces a method to design an integrated safety system for two-wheeled humanoids. As a case study, the method is applied to a robot and experimentally tested under several conditions corresponding to different causes of robot instability, such as motor jamming, external disturbances, and sudden shut-down.

- Reliability Validation of Learning Enabled Vehicle Tracking

    Author: Sun, Youcheng | Queen University of Belfast
    Author: Zhou, Yifan | University of Liverpool
    Author: Maskell, Simon | University of Liverpool
    Author: Sharp, James | Dstl
    Author: Huang, Xiaowei | University of Liverpool
 
    keyword: Failure Detection and Recovery

    Abstract : This paper studies the reliability of a real-world learning-enabled system, which conducts dynamic vehicle tracking based on a high-resolution wide-area motion imagery input. The system consists of multiple neural network components -- to process the imagery inputs -- and multiple symbolic (Kalman filter) components -- to analyse the processed information for vehicle tracking. It is known that neural networks suffer from adversarial examples, which make them lack robustness. However, it is unclear if and how the adversarial examples over learning components can affect the overall system-level reliability. By integrating a coverage-guided neural network testing tool, DeepConcolic, with the vehicle tracking system, we found that (1) the overall system can be resilient to some adversarial examples thanks to the existence of other components, and (2) the overall system presents an extra level of uncertainty which cannot be determined by analysing the deep learning components only. This research suggests the need for novel verification and validation methods for learning-enabled systems.

## Learning to Predict

- Spatiotemporal Representation Learning with GAN Trained LSTM-LSTM Networks

    Author: Fu, Yiwei | The Pennsylvania State University
    Author: Sen, Shiraj | General Electric
    Author: Theurer, Charles | GE Research
    Author: Reimann, Johan | GE Research
 
    keyword: Deep Learning in Robotics and Automation; Computer Vision for Automation; Model Learning for Control

    Abstract : Learning robot behaviors in unstructured environments often requires handcrafting the features for a given task. In this paper, we present and evaluate an unsupervised representation learning architecture, Layered Spatiotemporal Memory Long Short-Term Memory (LSTM-LSTM), that learns the underlying representation without knowledge of the task. The goal of this architecture is to learn the dynamics of the environment from high-dimensional raw video inputs. Using a Generative Adversarial Network (GAN) framework with the proposed network, this architecture is able to learn a spatiotemporal representation in its lower-dimensional latent space directly from raw input sequences. We show that our approach learns the spatial and temporal information simultaneously as opposed to a two-stage learning approach of alternating between training a Convolutional Neural Network (ConvNet) and a Long Short-Term Network (LSTM). Furthermore, by using LSTM-LSTM cells that shrink in size with the increase in the number of layers, the network learns a hierarchical representation with a low-dimensional representation at the top layer. We show that this architecture achieves state-of-the-art results with a substantially lower-dimensional representation than existing methods. We evaluate our approach on a video prediction task with standard benchmark datasets like Moving MNIST and KTH Action, as well as a simulated robot dataset.

- Belief Regulated Dual Propagation Nets for Learning Action Effects on Groups of Articulated Objects

    Author: Tekden, Ahmet | Bogazici University
    Author: Ugur, Emre | Bogazici University
    Author: Erdem, Erkut | Hacettepe University
    Author: Erdem, Aykut | Hacettepe University
    Author: Imre, Mert | Delft University of Technology
    Author: Seker, Muhammet Yunus | Bogazici University
 
    keyword: Deep Learning in Robotics and Automation

    Abstract : In recent years, graph neural networks have been successfully applied for learning the dynamics of complex and partially observable physical systems. However, their use in the robotics domain is, to date, still limited. In this paper, we introduce Belief Regulated Dual Propagation Networks (BRDPN), a general-purpose learnable physics engine, which enables a robot to predict the effects of its actions in scenes containing groups of articulated multi-part objects. Specifically, our framework extends recently proposed propagation networks (PropNets) and consists of two complementary components, a physics predictor and a belief regulator. While the former predicts the future states of the object(s) manipulated by the robot, the latter constantly corrects the robot's knowledge regarding the objects and their relations. Our results showed that after training in a simulator, the robot can reliably predict the consequences of its actions in object trajectory level and exploit its own interaction experience to correct its belief about the state of the environment, enabling better predictions in partially observable environments. Furthermore, the trained model was transferred to the real world and verified in predicting trajectories of pushed interacting objects whose joint relations were initially unknown. We compared BRDPN against PropNets, and showed that BRDPN performs consistently well. Moreover, BRDPN can adapt its physic predictions, since the relations can be predicted online.

- Deep Kinematic Models for Kinematically Feasible Vehicle Trajectory Predictions

    Author: Cui, Henggang | Uber Advanced Technologies Group
    Author: Nguyen, Thi Duong | Uber Technologies Inc
    Author: Chou, Fang-Chieh | Uber
    Author: Lin, Tsung-Han | Uber
    Author: Schneider, Jeff | Carnegie Mellon University
    Author: Bradley, David | Carnegie Mellon University
    Author: Djuric, Nemanja | Uber ATG
 
    keyword: AI-Based Methods; Deep Learning in Robotics and Automation

    Abstract : Self-driving vehicles (SDVs) hold great potential for improving traffic safety and are poised to positively affect the quality of life of millions of people. To unlock this potential one of the critical aspects of the autonomous technology is understanding and predicting future movement of vehicles surrounding the SDV. This work presents a deep-learning-based method for kinematically feasible motion prediction of such traffic actors. Previous work did not explicitly encode vehicle kinematics and instead relied on the models to learn the constraints directly from the data, potentially resulting in kinematically infeasible, suboptimal trajectory predictions. To address this issue we propose a method that seamlessly combines ideas from the AI with physically grounded vehicle motion models. In this way we employ best of the both worlds, coupling powerful learning models with strong feasibility guarantees for their outputs. The proposed approach is general, being applicable to any type of learning method. Extensive experiments using deep convnets on real-world data strongly indicate its benefits, outperforming the existing state-of-the-art.

- Human Driver Behavior Prediction Based on UrbanFlow

    Author: Qiao, Zhiqian | Carnegie Mellon University
    Author: Zhao, Jing | Carnegie Mellon University
    Author: Zhu, Jin | Carnegie Mellon University
    Author: Tyree, Zachariah | General Motors Research and Development
    Author: Mudalige, Priyantha | General Motors
    Author: Schneider, Jeff | Carnegie Mellon University
    Author: Dolan, John M. | Carnegie Mellon University
 
    keyword: Learning and Adaptive Systems; Behavior-Based Systems; AI-Based Methods

    Abstract : How autonomous vehicles and human drivers share public transportation systems is an important problem, as fully automatic transportation environments are still a long way off. Understanding human drivers' behavior can be beneficial for autonomous vehicle decision making and planning, especially when the autonomous vehicle is surrounded by human drivers who have various driving behaviors and patterns of interaction with other vehicles. In this paper, we propose an LSTM-based trajectory prediction method for human drivers which can help the autonomous vehicle make better decisions, especially in urban intersection scenarios. Meanwhile, in order to collect human drivers' driving behavior data in the urban scenario, we describe a system called UrbanFlow which includes the whole procedure from raw bird's-eye view data collection via drone to the final processed trajectories. The system is mainly intended for urban scenarios but can be extended to be used for any traffic scenarios.

- Environment Prediction from Sparse Samples for Robotic Information Gathering

    Author: Caley, Jeffrey | Oregon State University
    Author: Hollinger, Geoffrey | Oregon State University
 
    keyword: Deep Learning in Robotics and Automation; Environment Monitoring and Management

    Abstract : Robots often require a model of their environment to make informed decisions. In unknown environments, the ability to infer the value of a data field from a limited number of samples is essential to many robotics applications. In this work, we propose a neural network architecture to model these spatially correlated data fields based on a limited number of spatially continuous samples. Additionally, we provide a method based on biased loss functions to suggest future areas of exploration to minimize reconstruction error. We run simulated robotic information gathering trials on both the MNIST hand written digits dataset and a Regional Ocean Modeling System (ROMS) ocean dataset for ocean monitoring. Our method outperforms Gaussian process regression in both environments for modeling the data field and action selection.

- Predicting Pushing Action Effects on Spatial Object Relations by Learning Internal Prediction Models

    Author: Paus, Fabian | Karlsruhe Institute of Technology (KIT)
    Author: Teng, Huang | Karlsruhe Institute of Technology (KIT)
    Author: Asfour, Tamim | Karlsruhe Institute of Technology (KIT)
 
    keyword: Learning and Adaptive Systems; Manipulation Planning; Humanoid Robots

    Abstract : Understanding the effects of actions is essential for planning and executing robot tasks. By imagining possible action consequences, a robot can choose specific action parameters to achieve desired goal states. We present an approach for parametrizing pushing actions based on learning internal prediction models. These pushing actions must fulfill constraints given by a high-level planner, e.g., after the push the brown box must be to the right of the orange box. In this work, we represent the perceived scenes as object-centric graphs and learn an internal model, which predicts object pose changes due to pushing actions. We train this internal model on a large synthetic data set, which was generated in simulation, and record a smaller data set on the real robot for evaluation. For a given scene and goal state, the robot generates a set of possible pushing action candidates by sampling the parameter space and evaluating the candidates by comparing the predicted effect resulting from the internal model with the desired effect provided by the high-level planner. In the evaluation, we show that our model achieves high prediction accuracy in scenes with a varying number of objects and is able to generalize to scenes with more objects than seen during training. In experiments on the humanoid robot ARMAR-6, we validate the transfer from simulation and show that the learned internal model can be used to manipulate scenes into desired states effectively.

- Under the Radar: Learning to Predict Robust Keypoints for Odometry Estimation and Metric Localisation in Radar

    Author: Barnes, Dan | University of Oxford
    Author: Posner, Ingmar | Oxford University
 
    keyword: Deep Learning in Robotics and Automation; Autonomous Vehicle Navigation; Localization

    Abstract : This paper presents a self-supervised framework for learning to detect robust keypoints for odometry estimation and metric localisation in radar. By embedding a differentiable point-based motion estimator inside our architecture, we learn keypoint locations, scores and descriptors from localisation error alone. This approach avoids imposing any assumption on what makes a robust keypoint and crucially allows them to be optimised for our application. Furthermore the architecture is sensor agnostic and can be applied to most modalities. We run experiments on 280km of real world driving from the Oxford Radar RobotCar Dataset and improve on the state-of-the-art in point-based radar odometry, reducing errors by up to 45% whilst running an order of magnitude faster, simultaneously solving metric loop closures. Combining these outputs, we provide a framework capable of full mapping and localisation with radar in urban environments.

- SpAGNN: Spatially-Aware Graph Neural Networks for Relational Behavior Forecasting from Sensor Data

    Author: Casas Romero, Sergio | Uber ATG, University of Toronto
    Author: Gulino, Cole | Carnegie Mellon University
    Author: Liao, Renjie | Uber ATG Toronto
    Author: Urtasun, Raquel | University of Toronto
 
    keyword: Deep Learning in Robotics and Automation; Autonomous Agents; Computer Vision for Transportation

    Abstract : In this paper, we tackle the problem of relational behavior forecasting from sensor data. Towards this goal, we propose a novel, spatially-aware graph neural network (SpAGNN) that models the interactions between agents in the scene. Specifically, we first exploit convolutional neural networks to detect the actors and compute their initial states. We then design a graph neural network which iteratively updates the actor states via a message passing process. Inspired by Gaussian belief propagation, our SpAGNN takes the spatially-transformed parameters of the output distributions from neighboring agents as input. Our model is fully differentiable, thus enabling end-to-end training. Importantly, our probabilistic predictions can model uncertainty at the trajectory level. We demonstrate the effectiveness of our approach by achieving significant improvements over the state-of-the-art on two real-world, self-driving datasets.

- Any Motion Detector: Learning Class-Agnostic Scene Dynamics from a Sequence of LiDAR Point Clouds

    Author: Filatov, Artem | Yandex
    Author: Rykov, Andrey | Yandex
    Author: Murashkin, Viacheslav | Google
 
    keyword: Deep Learning in Robotics and Automation; Object Detection, Segmentation and Categorization

    Abstract : Object detection and motion parameters estima- tion are crucial tasks for self-driving vehicle safe navigation in a complex urban environment. In this work we propose a novel real-time approach of temporal context aggregation for motion detection and motion parameters estimation based on 3D point cloud sequence. We introduce an ego-motion compen- sation layer to achieve real-time inference with performance comparable to a naive odometric transform of the original point cloud sequence. Not only is the proposed architecture capable of estimating the motion of common road participants like vehicles or pedestrians but also generalizes to other object categories which are not present in training data. We also conduct an in-deep analysis of different temporal context aggregation strategies such as recurrent cells and 3D convolutions. Finally, we provide comparison results of our state-of-the-art model with existing solutions on KITTI Scene Flow dataset.

- Real Time Trajectory Prediction Using Deep Conditional Generative Models

    Author: Gomez-Gonzalez, Sebastian | Max Planck Institute for Intelligent Systems
    Author: Prokudin, Sergey | Max Planck Institute
    Author: Sch�lkopf, Bernhard | Max Planck Institute for Intelligent Systems
    Author: Peters, Jan | Technische Universitét Darmstadt
 
    keyword: Deep Learning in Robotics and Automation

    Abstract : Data driven methods for time series forecasting that quantify uncertainty open new important possibilities for robot tasks with hard real time constraints, allowing the robot system to make decisions that trade off between reaction time and accuracy in the predictions. Despite the recent advances in deep learning, it is still challenging to make long term accurate predictions with the low latency required by real time robotic systems. In this paper, we propose a deep conditional generative model for trajectory prediction that is learned from a data set of collected trajectories. Our method uses an encoder and decoder deep networks that maps complete or partial trajectories to a Gaussian distributed latent space and back, allowing for fast inference of the future values of a trajectory given previous observations. The encoder and decoder networks are trained using stochastic gradient variational Bayes. In the experiments, we show that our model provides more accurate long term predictions with a lower latency that popular models for trajectory forecasting like recurrent neural networks or physical models based on differential equations. Finally, we test our proposed approach in a robot table tennis scenario to evaluate the performance of the proposed method in a robotic task with hard real time constraints.

- Ambiguity in Sequential Data: Predicting Uncertain Futures with Recurrent Models

    Author: Berlati, Alessandro | Université Di Bologna
    Author: Scheel, Oliver | BMW Group
    Author: Di Stefano, Luigi | University of Bologna
    Author: Tombari, Federico | Technische Universitét M�nchen
 
    keyword: Deep Learning in Robotics and Automation; Autonomous Agents; Intelligent Transportation Systems

    Abstract : Ambiguity is inherently present in many machine learning tasks, but seldom accounted for, as most models only output a single prediction. In this work we propose a general framework to handle ambiguous predictions with sequential data, which is of special importance, as often multiple futures are equally likely. Our approach can be applied to the most common recurrent architectures and can be used with any loss function. Additionally, we introduce a novel metric for ambiguous problems, which is better suited to account for uncertainties and coincides with our intuitive understanding of correctness in the presence of multiple labels. We test our method on several experiments and across diverse tasks dealing with time series data, such as trajectory forecasting and maneuver prediction, achieving promising results.

- Where and When: Event-Based Spatiotemporal Trajectory Prediction from the iCub's Point-Of-View

    Author: Monforte, Marco | IIT
    Author: Arriandiaga, Ander | Istituto Italiano Di Tecnologia
    Author: Glover, Arren | Istituto Italiano Di Tecnologia
    Author: Bartolozzi, Chiara | Istituto Italiano Di Tecnologia
 
    keyword: Deep Learning in Robotics and Automation; Humanoid Robots; Neurorobotics

    Abstract : Fast, non-linear trajectories have been shown to be more accurately visually measured, and hence predicted, when sampled spatially (that is when the target position changes) rather than temporally, i.e. at a fixed-rate as in traditional frame-based cameras. Event-cameras, with their asynchronous, low latency information stream, allow for spatial sampling with very high temporal resolution, improving the quality of the data and the accuracy of post-processing operations. This paper investigates the use of Long Short-Term Memory (LSTM) networks with event-cameras spatial sampling for trajectory prediction. We show the benefit of using an Encoder-Decoder architecture over parameterised models for regression on event-based human-to-robot handover trajectories. In particular, we exploit the temporal information associated to the events stream to predict not only the incoming spatial trajectory points, but also when these will occur in time. After having studied the proper LSTM input/output sequence length, the network performance are compared to other regression models. Then, prediction behavior and computational time are analysed for the proposed method. We carry out the experiment using an iCub robot equipped with event-cameras, addressing the problem from the robot perspective.

## Learning for Motion Planning 

- Learning of Key Pose Evaluation for Efficient Multi-Contact Motion Planner

    Author: Noda, Shintaro | The University of Tokyo
    Author: Murooka, Masaki | The University of Tokyo
    Author: Asano, Yuki | The University of Tokyo
    Author: Ishizaki, Ryusuke | Honda Research Institute Japan Co, .Ltd
    Author: Kawakami, Tomohiro | Honda R&amp;D Co., Ltd
    Author: Watabe, Tomoki | Honda R&amp;D Co., Ltd
    Author: Okada, Kei | The University of Tokyo
    Author: Yoshiike, Takahide | Honda Research Institute Japan
    Author: Inaba, Masayuki | The University of Tokyo
 
    keyword: Motion and Path Planning; Deep Learning in Robotics and Automation

    Abstract : It is necessary to use not only foot but also hand, knee and other body parts to support body weight for locomotion in uneven terrain. Such multi-contact motion planning is an important research topic including lots of previous works; however, a problem of computational speed of planning is still remaining. In this paper, we propose a learning-based algorithm to speed up the planning. The algorithm reduces replanning of contact states by learning an evaluation function of key pose to reach goal. We investigated the learning performance by comparing three neural network configurations and two activation function. This research aims at achieving robust robotics system in unknown environments.

- Differentiable Gaussian Process Motion Planning

    Author: Bhardwaj, Mohak | University of Washington
    Author: Boots, Byron | University of Washington
    Author: Mukadam, Mustafa | Facebook AI Research
 
    keyword: Motion and Path Planning; Learning and Adaptive Systems

    Abstract : Modern trajectory optimization based approaches to motion planning are fast, easy to implement, and effective on a wide range of robotics tasks. However, trajectory optimization algorithms have parameters that are typically set in advance (and rarely discussed in detail). Setting these parameters properly can have a significant impact on the practical performance of the algorithm, sometimes making the difference between finding a feasible plan or failing at the task entirely. We propose a method for leveraging past experience to learn how to automatically adapt the parameters of Gaussian Process Motion Planning (GPMP) algorithms. Specifically, we propose a differentiable extension to the GPMP2 algorithm, so that it can be trained end-to-end from data. We perform several experiments that validate our algorithm and illustrate the benefits of our proposed learning-based approach to motion planning.

- Learn and Link: Learning Critical Regions for Efficient Planning

    Author: Molina, Daniel | Arizona State University
    Author: Kumar, Kislay | Arizona State University
    Author: Srivastava, Siddharth | University of California Berkeley
 
    keyword: Motion and Path Planning; Deep Learning in Robotics and Automation; Learning from Demonstration

    Abstract : This paper presents a new approach to learning for motion planning (MP) where critical regions of an environment are learned from a given set of motion plans and used to improve performance on new environments and problem instances. We introduce a new suite of sampling-based motion planners, Learn and Link. Our planners leverage critical regions to overcome the limitations of uniform sampling, while still maintaining guarantees of correctness inherent to sampling-based algorithms. We also show that convolutional neural networks (CNNs) can be used to identify critical regions for motion planning problems. We evaluate Learn and Link against planners from the Open Motion Planning Library (OMPL) using an extensive suite of experiments on challenging motion planning problems. We show that our approach requires far less planning time than existing sampling-based planners.

- What the Constant Velocity Model Can Teach Us about Pedestrian Motion Prediction

    Author: Sch�ller, Christoph | Fortiss GmbH
    Author: Aravantinos, Vincent | Fortiss
    Author: Lay, Florian | Fortiss, Technical University of Munich
    Author: Knoll, Alois | Tech. Univ. Muenchen TUM
 
    keyword: Motion and Path Planning; Deep Learning in Robotics and Automation

    Abstract : Pedestrian motion prediction is a fundamental task for autonomous robots and vehicles to operate safely. In recent years many complex approaches based on neural networks have been proposed to address this problem. In this work we show that - surprisingly - a simple Constant Velocity Model can outperform even state-of-the-art neural models. This indicates that either neural networks are not able to make use of the additional information they are provided with, or that this information is not as relevant as commonly believed. Therefore, we analyze how neural networks process their input and how it impacts their predictions. Our analysis reveals pitfalls in training neural networks for pedestrian motion prediction and clarifies false assumptions about the problem itself. In particular, neural networks implicitly learn environmental priors that negatively impact their generalization capability, the motion history of pedestrians is irrelevant and interactions are too complex to predict. Our work shows how neural networks for pedestrian motion prediction can be thoroughly evaluated and our results indicate which research directions for neural motion prediction are promising in future.

- Path Planning with Local Motion Estimations

    Author: Guzzi, Jerome | IDSIA, USI-SUPSI
    Author: Chavez-Garcia, R. Omar | University of Applied Sciences of Southern Switzerland
    Author: Nava, Mirko | IDSIA
    Author: Gambardella, Luca | USI-SUPSI
    Author: Giusti, Alessandro | IDSIA Lugano, SUPSI
 
    keyword: Motion and Path Planning; Deep Learning in Robotics and Automation; Probability and Statistical Methods

    Abstract : We introduce a novel approach to long-range path planning that relies on a learned model to predict the outcome of local motions using possibly partial knowledge. The model is trained from a dataset of trajectories acquired in a self-supervised way. Sampling-based path planners use this component to evaluate edges to be added to the planning tree. We illustrate the application of this pipeline with two robots: a complex, simulated, quadruped robot (ANYmal) moving on rough terrains; and a simple, real, differential-drive robot (Mighty Thymio), whose geometry is assumed unknown, moving among obstacles. We quantitatively evaluate the model performance in predicting the outcome of short moves and long-range paths; finally, we show that planning results in reasonable paths.

- Scene Compliant Trajectory Forecast with Agent-Centric Spatio-Temporal Grids

    Author: Ridel, Daniela | University of Sao Paulo
    Author: Deo, Nachiket | UC San Diego
    Author: Wolf, Denis Fernando | University of Sao Paulo
    Author: Trivedi, Mohan | University of California San Diego (UCSD)
 
    keyword: Motion and Path Planning; Deep Learning in Robotics and Automation; Intelligent Transportation Systems

    Abstract : Forecasting long-term human motion is a challenging task due to the non-linearity, multi-modality and inherent uncertainty in future trajectories. The underlying scene and past motion of agents can provide useful cues to predict their future motion. However, the heterogeneity of the two inputs poses a challenge for learning a joint representation of the scene and past trajectories. To address this challenge, we propose a model based on grid representations to forecast agent trajectories. We represent the past trajectories of agents using binary 2-D grids, and the underlying scene as a RGB birds-eye view (BEV) image, with an agent-centric frame of reference. We encode the scene and past trajectories using convolutional layers and generate trajectory forecasts using a Convolutional LSTM (ConvLSTM) decoder. Results on the publicly available Stanford Drone Dataset (SDD) show that our model outperforms prior approaches and outputs realistic future trajectories that comply with scene structure and past motion.

- A Data-Driven Planning Framework for Robotic Texture Painting on 3D Surfaces

    Author: Vempati, Anurag Sai | ETH Zurich, Disney Research Zurich
    Author: Siegwart, Roland | ETH Zurich
    Author: Nieto, Juan | ETH Zurich
 
    keyword: Deep Learning in Robotics and Automation; Visual Learning; Task Planning

    Abstract : Painting textures on 3D surfaces requires an understanding of the surface geometry, paint flow and paint mixing. This work formulates automated painting as a planning problem and proposes a solution based on a self-supervised learning framework that enables a robot to paint monochromatic non-uniform textures on 3D surfaces. We developed a method that iteratively decides the actions to take based on constant feedback of the painting process. Inspired by some recent results, we formulate our solution using a recurrent neural network (RNN) to decide where and what to paint on the surface at each time instant. Specifically, the paint delivery tool's flow rate, orientation and position relative to the surface at each time instant are evaluated. This data can then be processed by a robot's planner of choice for generating a painting mission that can achieve the desired end result. We evaluate the proposed approach by providing qualitative and quantitative results of the different components. Furthermore, we validate the effectiveness of the approach for the application by providing renderings from a paint simulation environment and show how a robot executes the planned painting mission on a generic 3D surface.

- Learned Critical Probabilistic Roadmaps for Robotic Motion Planning

    Author: Ichter, Brian | Google Brain
    Author: Schmerling, Edward | Waymo
    Author: Lee, Tsang-Wei Edward | Google
    Author: Faust, Aleksandra | Google Brain
 
    keyword: Motion and Path Planning; Deep Learning in Robotics and Automation

    Abstract : Sampling-based motion planning techniques have emerged as an efficient algorithmic paradigm for solving complex motion planning problems. These approaches use a set of probing samples to construct an implicit graph representation of the robot's state space, allowing arbitrarily accurate representations as the number of samples increases to infinity. In practice, however, solution trajectories only rely on a few critical states, often defined by structure in the state space (e.g., doorways). In this work we propose a general method to identify these critical states via graph-theoretic techniques (betweenness centrality) and learn to predict criticality from only local environment features. These states are then leveraged more heavily via global connections within a hierarchical graph, termed Critical Probabilistic Roadmaps. Critical PRMs are demonstrated to achieve up to three orders of magnitude improvement over uniform sampling, while preserving the guarantees and complexity of sampling-based motion planning. A video is available at https://youtu.be/AYoD-pGd9ms.

- Learning Heuristic A*: Efficient Graph Search Using Neural Network

    Author: Kim, Soonkyum | Korea Institute of Science and Technology
    Author: An, Byungchul | Korea Institute of Science and Technology
 
    keyword: Motion and Path Planning; Deep Learning in Robotics and Automation

    Abstract : In this paper, we consider the path planning problem on a graph. To reduce computation load by efficiently exploring the graph, we model the heuristic function as a neural network, which is trained by a training set derived from optimal paths to estimate the optimal cost between a pair of vertices on the graph. As such heuristic function cannot be proved to be an admissible heuristic to guarantee the global optimality of the path, we adapt an admissible heuristic function for the terminating criteria. Thus, proposed Learning Heuristic A* (LHA*) guarantees the bounded suboptimality of the path. The performance of LHA* was demonstrated by simulations in a maze-like map and compared with the performance of weighted A* with the same suboptimality bound.

- 3D-CNN Based Heuristic Guided Task-Space Planner for Faster Motion Planning

    Author: Terasawa, Ryo | Sony Corporation
    Author: Ariki, Yuka | Sony Corporation
    Author: Narihira, Takuya | Sony Corporation
    Author: Tsuboi, Toshimitsu | Sony Corporation
    Author: Nagasaka, Kenichiro | Sony Corporation
 
    keyword: Deep Learning in Robotics and Automation; Motion and Path Planning; Learning and Adaptive Systems

    Abstract : Motion planning is important in a wide variety of applications such as robotic manipulation. However, it is still challenging to reliably find a collision-free path within a reasonable time. To address the issue, this paper proposes a novel framework which combines a sampling-based planner and deep learning for faster motion planning, focusing on heuristics. The proposed method extends Task-Space Rapidly-exploring Random Trees (TS-RRT) to guide the trees with a "heuristic map" where every voxel has a cost-to-go value toward the goal. It also utilizes fully convolutional neural networks (CNNs) for producing more appropriate heuristic maps, rather than manually-designed heuristics. To verify the effectiveness of the proposed method, experiments for motion planning using a real environment and mobile manipulator are carried out. The results indicate that it outperforms the existing planners, especially in terms of the average planning time with smaller variance.

- Learned Sampling Distributions for Efficient Planning in Hybrid Geometric and Object-Level Representations

    Author: Liu, Katherine | MIT
    Author: Stadler, Martina | Massachusetts Institute of Technology
    Author: Roy, Nicholas | Massachusetts Institute of Technology
 
    keyword: Deep Learning in Robotics and Automation; Autonomous Vehicle Navigation; Motion and Path Planning

    Abstract : We would like to enable a robotic agent to quickly and intelligently find promising trajectories through structured, unknown environments. Many approaches to navigation in unknown environments are limited to considering geometric information only, which leads to myopic behavior. In this work, we show that learning a sampling distribution that incorporates both geometric information and explicit, object-level semantics for sampling-based planners enables efficient planning at longer horizons in partially-known environments. We demonstrate that our learned planner is up to 2.7 times more likely to find a plan than the baseline, and can result in up to a 16% reduction in traversal costs as calculated by linear regression. We also show promising qualitative results on real-world data.

- Deep Visual Heuristics: Learning Feasibility of Mixed-Integer Programs for Manipulation Planning

    Author: Driess, Danny | University of Stuttgart
    Author: Oguz, Ozgur S. | Technical University of Munich
    Author: Ha, Jung-Su | University of Stuttgart
    Author: Toussaint, Marc | University of Stuttgart
 
    keyword: Deep Learning in Robotics and Automation; Manipulation Planning; Learning and Adaptive Systems

    Abstract : In this paper, we propose a deep neural network that predicts the feasibility of a mixed-integer program from visual input for robot manipulation planning. Integrating learning into task and motion planning is challenging, since it is unclear how the scene and goals can be encoded as input to the learning algorithm in a way that enables to generalize over a variety of tasks in environments with changing numbers of objects and goals. To achieve this, we propose to encode the scene and the target object directly in the image space.<p>Our experiments show that our proposed network generalizes to scenes with multiple objects, although during training only two objects are present at the same time. By using the learned network as a heuristic to guide the search over the discrete variables of the mixed-integer program, the number of optimization problems that have to be solved to find a feasible solution or to detect infeasibility can greatly be reduced.

- 

## Motion Control of Manipulators
- Segmentation and Averaging of sEMG Muscle Activations Prior to Synergy Extraction

    Author: Costa, �lvaro | BSI-TOYOTA Collaboration Center in the Nagoya Science Park Resea
    Author: Iáñez, Eduardo | Miguel Hern�ndez University of Elche
    Author: Sonoo, Moeka | RIKEN, CBS-TOYOTA Collaboration Center in the Nagoya Science Par
    Author: Okajima, Shotaro | RIKEN
    Author: Yamasaki, Hiroshi | BSI-TOYOTA Collaboration Center in the Nagoya Science Park Resea
    Author: Ueda, Sayako | RIKEN, CBS-TOYOTA Collaboration Center in the Nagoya Science Par
    Author: Shimoda, Shingo | RIKEN
 
    keyword: Motion Control; Rehabilitation Robotics; Kinematics

    Abstract : Averaging electromyographic activity prior to muscle synergy computation is a common method employed to compensate for the inter-repetition variability usually associated with this kind of physiological recording. Capturing muscle synergies requires the preservation of accurate temporal and spatial information for muscle activity. The natural variation in electromyography data across consecutive repetitions of the same task raises several related challenges that make averaging a non-trivial process. Duration and triggering times of muscle activity generally vary across different repetitions of the same task. Therefore, it is necessary to define a robust methodology to segment and average muscle activity that deals with these issues. Emerging from this need, the present work proposes a standard protocol for segmenting and averaging muscle activations from periodic motions in a way that accurately preserves the temporal and spatial information contained in the original data and enables the isolation of a single averaged motion period. This protocol has been validated with muscle activity data recorded from 15 participants performing elbow flexion/extension motions, a series of actions driven by well-established muscle synergies. Using the averaged data, muscle synergies were computed, permitting their behavior to be compared with previous results related to the evaluated task. The comparison between the method proposed and a widely used methodology based on motion flags, shown

- Energy-Optimal Cooperative Manipulation Via Provable Internal-Force Regulation

    Author: Verginis, Christos | Electrical Engineering, KTH Royal Institute of Technology
    Author: Dimarogonas, Dimos V. | KTH Royal Institute of Technology
 
    keyword: Motion Control of Manipulators; Cooperating Robots

    Abstract : This paper considers the optimal cooperative robotic manipulation problem in terms of energy resources. In particular, we consider rigid cooperative manipulation systems, i.e., with rigid grasping contacts, and study energy-optimal conditions in the sense of minimization of the arising internal forces, which are inter-agent forces that do not contribute to object motion. Firstly, we use recent results to derive a closed form expression for the internal forces. Secondly, by using a standard inverse dynamics control protocol, we provide novel conditions on the force distribution to the robotic agents for provable internal force minimization. Moreover, we derive novel results on the provable achievement of a desired non-zero inter-agent internal force vector. Extensive simulation results in a realistic environment verify the theoretical analysis.

- Robot Telekinesis: Application of a Unimanual and Bimanual Object Manipulation Technique to Robot Control

    Author: Lee, Joon Hyub | Korea Advanced Institute of Science and Technology
    Author: Kim, Yongkwan | Korea Advanced Institute of Science and Technology
    Author: An, Sang-Gyun | Korea Advanced Institute of Science and Technology
    Author: Bae, Seok-Hyung | Korea Advanced Institute of Science and Technology
 
    keyword: Motion Control of Manipulators; Telerobotics and Teleoperation; Human-Centered Robotics

    Abstract : Unlike large and dangerous industrial robots at production lines in factories that are strictly fenced off, collaborative robots are smaller and safer and can be installed adjacent to human workers and collaborate with them. However, controlling and teaching new moves to collaborative robots can be difficult and time-consuming when using existing methods, such as pressing buttons on a teaching pendant and physically grabbing and moving the robot via direct teaching. We present Robot Telekinesis, a novel robot interaction technique that lets the user remotely control the movement of the end effector of a robot arm with unimanual and bimanual hand gestures that closely resemble handling a physical object. Through formal evaluation, we show that using a teaching pendant is slow and confusing and that direct teaching is fast and intuitive but physically demanding. Robot Telekinesis is as fast and intuitive as direct teaching without the need for physical contact or physical effort.

- A Set-Theoretic Approach to Multi-Task Execution and Prioritization

    Author: Notomista, Gennaro | Georgia Institute of Technology
    Author: Mayya, Siddharth | University of Pennsylvania
    Author: Selvaggio, Mario | Université Degli Studi Di Napoli Federico II
    Author: Santos, Mar�a | Georgia Institute of Technology
    Author: Secchi, Cristian | Univ. of Modena &amp; Reggio Emilia
 
    keyword: Motion Control of Manipulators; Redundant Robots

    Abstract : Executing multiple tasks concurrently is important in many robotic applications. Moreover, the prioritization of tasks is essential in applications where safety-critical tasks need to precede application-related objectives, in order to protect both the robot from its surroundings and vice versa. Furthermore, the possibility of switching the priority of tasks during their execution gives the robotic system the flexibility of changing its objectives over time. In this paper, we present an optimization-based task execution and prioritization framework that lends itself to the case of time-varying priorities as well as variable number of tasks. We introduce the concept of extended set-based tasks, encode them using control barrier functions, and execute them by means of a constrained-optimization problem, which can be efficiently solved in an online fashion. Finally, we show the application of the proposed approach to the case of a redundant robotic manipulator.

- Task Space Control of Articulated Robot Near Kinematic Singularity: Forward Dynamics Approach

    Author: Lee, Donghyeon | Pohang University of Science and Technology(POSTECH)
    Author: Lee, Woongyong | POSTECH
    Author: Park, Jonghoon | Neuromeka
    Author: Chung, Wan Kyun | POSTECH
 
    keyword: Motion Control; Kinematics; Compliance and Impedance Control

    Abstract : In this study, a forward dynamics-based control (FDC) framework is proposed for task space control of a non-redundant robot manipulator. The FDC framework utilizes forward dynamic robot simulation and an impedance controller to solve the inverse kinematics problem. For the practical use of the proposed control framework, the accuracy, robustness, and stability of robot motion are considered. Taking advantage of the stability of the implicit Euler method, a high-gain PD controller enables accurate end-effector pose tracking in the task space without losing stability even near the kinematic singularities. Also, the robustness of the controller is enhanced by borrowing the structure of the nonlinear robust internal-loop compensator. Lastly, the selective joint damping injection and spring force saturation are applied to the impedance controller so that the robot motion can always stay within the given dynamic constraints. This study suggests a new, effective solution for the kinematic singularity problem of non-redundant robot manipulators.

- Variable Impedance Control in Cartesian Latent Space While Avoiding Obstacles in Null Space

    Author: Parent, David | Institut De Robòtica I Informàtica Industrial (CSIC-UPC)
    Author: Colomé, Adrià | Institut De Robòtica I Informàtica Industrial (CSIC-UPC), Q28180
    Author: Torras, Carme | Csic - Upc
 
    keyword: Motion Control of Manipulators; Compliance and Impedance Control; Redundant Robots

    Abstract : Human-robot interaction is one of the keys of assistive robots. Robots are expected to be compliant with people but at the same time correctly perform the tasks. In such applications, Cartesian impedance control is preferred over joint control, as the desired interaction and environmental feedback can be described more naturally, and the force to be exerted by the robot can be readily adjusted.<p>This paper addresses the problem of controlling a robot arm in the operational space with variable stiffness so as to continuously adapt the force exerted in each phase of motion according to the precision requirements. Moreover, performing dimensionality reduction we can separate the degrees of freedom (DoF) relevant for the task from the redundant ones. The stiffness of the former can be adjusted constantly to achieve the required accuracy, while task-redundant DoF can be used to achieve other goals such as avoiding obstacles by moving in the directions where accuracy is not critical. The designed method is tested teaching the robot to give water to drink to a model of human head. Our empirical results demonstrate that the robot can learn precision requirements from demonstration. Furthermore, dimensionality reduction is proved to be useful to avoid obstacles.

- 

## Computer Vision for Medical Robots
- Attention-Guided Lightweight Network for Real-Time Segmentation of Robotic Surgical Instruments

    Author: Ni, ZhenLiang | Chinese Academy of Sciences
    Author: Bian, Gui-Bin | Institute of Automation, Chinese Academy of Sciences
    Author: Hou, Zeng-Guang | Chinese Academy of Science
    Author: Zhou, Xiao-Hu | Institute of Automation Chinese Academy of Sciences
    Author: Xie, Xiaoliang | Institutation of Automation, Chinese Academy of Sciences
    Author: Li, Zhen | Institute of Automation, Chinese Academy of Sciences
 
    keyword: Computer Vision for Medical Robotics; Object Detection, Segmentation and Categorization

    Abstract : The real-time segmentation of surgical instruments plays a crucial role in robot-assisted surgery. However, it is still a challenging task to implement deep learning models to do real-time segmentation for surgical instruments due to their high computational costs and slow inference speed. In this paper, we propose an attention-guided lightweight network (LWANet), which can segment surgical instruments in real-time. LWANet adopts encoder-decoder architecture, where the encoder is the lightweight network MobileNetV2, and the decoder consists of depthwise separable convolution, attention fusion block, and transposed convolution. Depthwise separable convolution is used as the basic unit to construct the decoder, which can reduce the model size and computational costs. Attention fusion block captures global contexts and encodes semantic dependencies between channels to emphasize target regions, contributing to locating the surgical instrument. Transposed convolution is performed to upsample feature maps for acquiring refined edges. LWANet can segment surgical instruments in real-time while takes little computational costs. Based on 960�544 inputs, its inference speed can reach 39 fps with only 3.39 GFLOPs. Also, it has a small model size and the number of parameters is only 2.06 M. The proposed network is evaluated on two datasets. It achieves state-of-the-art performance 94.10% mean IOU on Cata7 and obtains a new record on EndoVis 2017 with a 4.10% increase on mean IOU.

- Automated Robotic Breast Ultrasound Acquisition Using Ultrasound Feedback

    Author: Welleweerd, Marcel Klaas | University of Twente
    Author: De Groot, Antonius Gerardus | University of Twente
    Author: de Looijer, Stijn | Delft University of Technology
    Author: Siepel, Fran�oise J | University of Twente
    Author: Stramigioli, Stefano | University of Twente
 
    keyword: Computer Vision for Medical Robotics; Visual Servoing; Medical Robots and Systems

    Abstract : Current challenges in automated robotic breast ultrasound (US) acquisitions include keeping acoustic coupling between the breast and the US probe, minimizing tissue deformations and safety. In this paper, we present how an autonomous 3D breast US acquisition can be performed utilizing a 7DOF robot equipped with a linear US transducer. Robotic 3D breast US acquisitions would increase the diagnostic value of the modality since they allow patient specific scans and have a high reproducibility, accuracy and efficiency. Additionally, 3D US acquisitions allow more flexibility in examining the breast and simplify registration with preoperative images like MRI. To overcome the current challenges, the robot follows a reference-based trajectory adjusted by a visual servoing algorithm. The reference trajectory is a patient specific trajectory coming from e.g. an MRI. The visual servoing algorithm commands in-plane rotations and corrects the probe contact based on confidence maps. A safety aware, intrinsically passive framework is utilised to actuate the robot. The approach is illustrated with experiments on a phantom, which show that the robot only needs minor pre-procedural information to consistently image the phantom while relying mainly on US feedback.

- Robust and Accurate 3D Curve to Surface Registration with Tangent and Normal Vectors

    Author: Min, Zhe | The Chinese University of Hong Kong
    Author: Zhu, Delong | The Chinese University of Hong Kong
    Author: Meng, Max Q.-H. | The Chinese University of Hong Kong
 
    keyword: Computer Vision for Medical Robotics; Medical Robots and Systems

    Abstract : This paper presents a robust and accurate approach for the rigid registration of pre-operative and intra-operative point sets in textit{image-guided surgery (IGS)}. Three challenges are identified in the textit{pre-to-intraoperative} registration: the intra-operative 3D data (usually forms a 3D curve in space) (1) is often contaminated with noise and outliers; (2) usually only covers a partial region of the whole pre-operative model; (3) is usually sparse. To tackle those challenges, we utilize the tangent vectors extracted from the sparse intra-operative textit{data} points and the normal vectors extracted from the pre-operative textit{model} points. % the normal vectors and the tangent vectors are first extracted from the pre-and-intra operative point set and utilized in the registration. Our first contribution is to formulate a novel probabilistic distribution of the error between a pair of corresponding tangent and normal vectors. The second contribution is, based on the novel distribution, we formulate the registration of two multi-dimensional (6D) point sets as a textit{maximum likelihood (ML)} problem and solve it under the textit{expectation maximization (EM)} framework. Our last contribution is, in order to facilitate the computation process, the derivatives of the objective function with respect to desired parameters are presented.

- Single Shot Pose Estimation of Surgical Robot Instruments' Shafts from Monocular Endoscopic Images

    Author: Yoshimura, Masakazu | The University of Tokyo
    Author: Marques Marinho, Murilo | The University of Tokyo
    Author: Harada, Kanako | The University of Tokyo
    Author: Mitsuishi, Mamoru | The University of Tokyo
 
    keyword: Computer Vision for Medical Robotics; AI-Based Methods; Calibration and Identification

    Abstract : Surgical robots are used to perform minimally invasive surgery and alleviate much of the burden imposed on surgeons. Our group has developed a surgical robot to aid in the removal of tumors at the base of the skull via access through the nostrils. To avoid injuring the patients, a collision-avoidance algorithm that depends on having an accurate model for the poses of the instruments' shafts is used. Given that the model's parameters can change over time owing to interactions between instruments and other disturbances, the online estimation of the poses of the instrument's shaft is essential. In this work, we propose a new method to estimate the pose of the surgical instruments' shafts using a monocular endoscope. Our method is based on the use of an automatically annotated training dataset and an improved pose-estimation deep-learning architecture. In preliminary experiments, we show that our method can surpass state of the art vision-based marker-less pose estimation techniques (providing an error decrease of 55% in position estimation, 64% in pitch, and 69% in yaw) by using artificial images.

- End-To-End Real-Time Catheter Segmentation with Optical Flow-Guided Warping During Endovascular Intervention

    Author: Nguyen, Anh | Imperial College London
    Author: Kundrat, Dennis | Imperial College London
    Author: Dagnino, Giulio | Imperial College London
    Author: Chi, Wenqiang | Imperial College London
    Author: Abdelaziz, Mohamed Essam Mohamed Kassem | Imperial College London
    Author: Ma, YingLiang | School of Computing, Electronics and Mathematics, Coventry Unive
    Author: Kwok, Trevor M Y | Imperial College London
    Author: Riga, Celia | Imperial College London
    Author: Yang, Guang-Zhong | Shanghai Jiao Tong University
 
    keyword: Computer Vision for Medical Robotics; Object Detection, Segmentation and Categorization

    Abstract : Accurate real-time catheter segmentation is an important pre-requisite for robot-assisted endovascular intervention. Most of the existing learning-based methods for catheter segmentation and tracking are only trained on small-scale datasets or synthetic data due to the difficulties of ground-truth annotation. Furthermore, the temporal continuity in intraoperative imaging sequences is not fully utilised. In this paper, we present FW-Net, an end-to-end and real-time deep learning framework for endovascular intervention. The proposed FW-Net has three modules: a segmentation network with encoder-decoder architecture, a flow network to extract optical flow information, and a novel flow-guided warping function to learn the frame-to-frame temporal continuity. We show that by effectively learning temporal continuity, the network can successfully segment and track the catheters in real-time sequences using only raw ground-truth for training. Detailed validation results confirm that our FW-Net outperforms state-of-the-art techniques while achieving real-time performance.

- Pathological Airway Segmentation with Cascaded Neural Networks for Bronchoscopic Navigation

    Author: Zhang, Hanxiao | Imperial College London
    Author: Shen, Mali | The Hamlyn Centre for Robotic Surgery, Imperial College London
    Author: Shah, Pallav L | Imperial College London
    Author: Yang, Guang-Zhong | Shanghai Jiao Tong University
 
    keyword: Computer Vision for Medical Robotics; Visual Learning; Surgical Robotics: Planning

    Abstract : Robotic bronchoscopic intervention requires detailed 3D airway maps for both localisation and enhanced visualisation, especially at peripheral airways. Patient-specific airway maps can be generated from preoperative chest CT scans. Due to pathological abnormalities and anatomical variations, automatically delineating the airway tree with distal branches is a challenging task. In the paper, we propose a cascaded 2D+3D model that has been tailored for airway segmentation from pathological CT scans. A novel 2D neural network is developed to generate the initial predictions where the peripheral airways are refined by a 3D adversarial training model. A sampling strategy based on a sequence of morphological operations is employed for the concatenation of the 2D and 3D models. The method has been validated on 20 pathological CT scans with results demonstrating improved segmentation accuracy and consistency, especially in peripheral airways.

## Grippers and Other End-Effectors

- A Novel Underactuated End-Effector for Planar Sequential Grasping of Multiple Objects

    Author: Mucchiani, Caio | University of Pennsylvania
    Author: Yim, Mark | University of Pennsylvania
 
    keyword: Grasping; Mechanism Design

    Abstract : We propose a serpentine type tendon driven underactuated end-effector design with a closing mechanism that is triggered upon contact with an object. This end-effector can grasp objects without knowing the size a priori and is able to grasp a new object while securing another one previously grasped, and so grasp multiple objects sequentially with a single DOF actuation. Design parameters based on the object dimensions are proposed. A low-cost prototype demonstrates two implementations (radius estimation and autonomous grasp of circular objects by torque control, and sequential grasps of multiple objects) of the end-effector through several experiments. A method for estimating applied internal forces is also proposed. This end-effector can benefit robotic manipulation in tasks such as fetching applications, industrial pick-and place of single or multiple objects and human-robot hand-off interactions.

- Design and Analysis of a Synergy-Inspired Three-Fingered Hand

    Author: Chen, Wenrui | Hunan University
    Author: Xiao, ZhiLan | Hunan University
    Author: Lu, JingWen | HuNan University
    Author: Zhao, Zilong | Hunan University
    Author: Wang, Yaonan | Hunan University
 
    keyword: Multifingered Hands; Underactuated Robots; Compliant Joint/Mechanism

    Abstract : Hand synergy from neuroscience provides an effective tool for anthropomorphic hands to realize versatile grasping with simple planning and control. This paper aims to extend the synergy-inspired design from anthropomorphic hands to multi-fingered robot hands. The synergy-inspired hands are not necessarily humanoid in morphology but perform primary characteristics and functions similar to the human hand. At first, the biomechanics of hand synergy is investigated. Three biomechanical characteristics of the human hand synergy are explored as a basis for the mechanical simplification of the robot hands. Secondly, according to the synergy characteristics, a three-fingered hand is designed, and its kinematic model is developed for the analysis of some typical grasping and manipulation functions. Finally, a prototype is developed and preliminary grasping experiments validate the effectiveness of the design and analysis.

- Multiplexed Manipulation: Versatile Multimodal Grasping Via a Hybrid Soft Gripper

    Author: Chin, Lillian | Massachusetts Institute of Technology
    Author: Barscevicius, Felipe | MIT
    Author: Lipton, Jeffrey | University of Washington
    Author: Rus, Daniela | MIT
 
    keyword: Grippers and Other End-Effectors; Dexterous Manipulation; Soft Robot Materials and Design

    Abstract : The success of hybrid suction + parallel-jaw grippers in the Amazon Robotics/Picking Challenge have demonstrated the effectiveness of multimodal grasping approaches. However, existing multimodal grippers combine grasping modes in isolation and do not incorporate the benefits of compliance found in soft robotic manipulators. In this paper, we present a gripper that integrates three modes of grasping: suction, parallel jaw, and soft fingers. Using complaint handed shearing auxetics actuators as the foundation, this gripper is able to multiplex manipulation by creating unique grasping primitives through permutations of these grasping techniques. This gripper is able to grasp 88% of tested objects, 14% of which could only be grasped using a combination of grasping modes. The gripper is also able to perform in-hand object re-orientation of flat objects without the need for pre-grasp manipulation.

- Modeling, Optimization, and Experimentation of the ParaGripper for In-Hand Manipulation without Parasitic Rotation

    Author: Liu, Huan | University of Naples, Federico II
    Author: Zhao, Longhai | Shanghai Jiao Tong University
    Author: Siciliano, Bruno | Univ. Napoli Federico II
    Author: Ficuciello, Fanny | Université Di Napoli Federico II
 
    keyword: Grippers and Other End-Effectors; Dexterous Manipulation; Mechanism Design

    Abstract : Recently, underactuated robotic hands have been exploited for dexterous in-hand manipulation, after having been proven efficient in performing versatile adaptive grasps. However, the reported in-hand manipulation skills are usually associated with parasitic motion, which may complicate control and application of the hand. This paper presents the modeling, optimization and experimentation of the ParaGripper, an underactuated gripper capable of performing in-hand manipulation without parasitic rotation. The underactuated finger uses two serially connected parallelograms to ensure pure translation of the fingertips. If the object remains stationary within the fingertips, the gripper can translate the object without parasitic rotation. The kinematics and kinetostatics of the hand--object system are derived and the manipulation workspace is optimized. The ParaGripper is designed and fabricated according to suitable optimal parameters. Experiments show that the ParaGripper could perform non-parasitic in-hand manipulation and versatile adaptive grasps.

- Underactuated Gecko Adhesive Gripper for Simple and Versatile Grasp

    Author: Hirano, Daichi | Japan Aerospace Exploration Agency
    Author: Tanishima, Nobutaka | JAXA
    Author: Bylard, Andrew | Stanford University
    Author: Chen, Tony G. | Stanford University
 
    keyword: Grippers and Other End-Effectors; Biologically-Inspired Robots; Space Robotics and Automation

    Abstract : Gecko-inspired adhesives have several desirable characteristics in robotic grasping: controllable activation and deactivation of adhesion, ability to grasp and release with minimal disturbance, and grasping without the need of form closure. Previously proposed grippers with this technology either require a complex activation mechanism or multiple activation steps. In this paper, we present an underactuated gecko-inspired adhesive gripper that can grasp a wide range of curved surfaces using a single actuator through a simple tendon-driven mechanism that attaches and adheres in one step. We derive a theoretical model of the adhesive contact area and resulting gripper grasp force, which is verified experimentally. The actual performance of the proposed mechanism is demonstrated by successfully grasping several surfaces with different curvature diameters.

- Examining the Frictional Behavior of Primitive Contact Geometries for Use As Robotic Finger Pads

    Author: Leddy, Michael | Yale University
    Author: Dollar, Aaron | Yale University
 
    keyword: Grippers and Other End-Effectors; Grasping; Multifingered Hands

    Abstract : Prosthetic and robotic grippers rely on soft finger pads to better acquire objects of varying size, shape and surface. However, the frictional behavior of soft finger pads of different designs and geometries have yet to be quantitatively compared, in large part due to the difficulty in modeling soft contact mechanics. In this paper, we experimentally examine the frictional behavior of several common primitive contact geometries in terms of their performance under shear loads that would tend to cause the contact to slip and the grasp to potentially fail. The effective static and kinetic coefficients of friction were recorded for each finger pad under a range of common grasping loads. The results show that the variance in contact curvature, contact patch geometry and pressure distribution have influences on key parameters for grasping at low forces. The advantages and disadvantages of these simple geometries are discussed for design of single finger, multi-finger and manipulation-based robotic hands.

- Design of 3D-Printed Assembly Mechanisms Based on Special Wooden Joinery Techniques and Its Application to a Robotic Hand

    Author: Katsumaru, Akihiro | Ritsumeikan University
    Author: Ozawa, Ryuta | Meiji University
 
    keyword: Multifingered Hands; Mechanism Design

    Abstract : Recently, it has become possible to easily design and fabricate robotic systems in the laboratory and at home due to the recent development of 3D printer technology. On the other hand, the strength of the plastic materials used in reasonably priced 3D printers and the accuracy of the printed parts are generally low. These problems affect the part-joining quality. Therefore, this paper describes a design method inspired by ancient Japanese wooden joinery techniques for assembling 3D-printed parts and presents the design of a robotic hand as its application. The joinery techniques use special shapes to assemble components and allow us to assemble the robotic hand without glue, screws or nails and to easily disassemble it.

- Parallel Gripper with Displacement-Magnification Mechanism and Extendable Finger Mechanism

    Author: Tanaka, Junya | Toshiba Corporation
    Author: Sugahara, Atsushi | Toshiba Corporation
 
    keyword: Grippers and Other End-Effectors; Mechanism Design; Force and Tactile Sensing

    Abstract : We propose a gripper displacement-magnification mechanism and an extendable finger mechanism, both of which can be attached to a commercially available parallel gripper. We then verify the operation of the mechanism in order to expand applications of the parallel gripper. The displacement-magnification mechanism has a stacked rack-and-pinion system that doubles displacement. The extendable finger mechanism has two nails that extend and contract, reducing impact force and detecting changes in product height from expansion and contraction amounts. The parallel gripper has a width of 95 mm, a depth of 110 mm, and a height of 214 mm and weighs 1.36 kg. It has an open/close stroke of 60 mm, a gripping force of 7.4 N, and an opening/closing speed of 100 mm/s or more. Further, it was confirmed that the ends and inclinations of products can be reliably detected using the extending/contracting nail. The mechanism verification confirmed that our parallel gripper achieved the desired performance and is therefore useful.

- Sheet-Based Gripper Featuring Passive Pull-In Functionality for Bin Picking and for Picking up Thin Flexible Objects

    Author: Morino, Kota | Kanazawa University
    Author: Kikuchi, Shiro | YKK
    Author: Chikagawa, Shinichi | YKK AP
    Author: Izumi, Masakazu | YKK AP
    Author: Watanabe, Tetsuyou | Kanazawa University
 
    keyword: Factory Automation; Industrial Robots; Grippers and Other End-Effectors

    Abstract : This study investigates the effect of the surface texture of soft deformable fingertips on the maximum resistible force under dry and wet conditions, and proposes a new hybrid structure that provides a stable grasp under both conditions. One definition of stable grasp is the capability of balancing a large external force or moment while grasping. For soft fingertips, both the friction and surface deformation contribute to the stability. Therefore, we investigate the maximum resistible force, which is defined as the maximum tangential force at which the fingertip can maintain contact when applying and increasing the tangential/shear force. We investigate the slit textures with primitive patterns and demonstrate that the non-pattern performs the best under dry conditions, whereas the horizontal slit pattern performs the best under wet (oily) conditions. Based on this, a concentric hybrid texture of the two patterns is proposed, and its effectiveness is verified by a grasping test.

- An Origami-Inspired Variable Friction Surface for Increasing the Dexterity of Robotic Grippers

    Author: Lu, Qiujie | Imperial College London
    Author: Clark, Angus Benedict | Imperial College London
    Author: Shen, Matthew | Imperial College London
    Author: Rojas, Nicolas | Imperial College London
 
    keyword: Dexterous Manipulation; Mechanism Design; Grippers and Other End-Effectors

    Abstract : While the grasping capability of robotic grippers has shown significant development, the ability to manipulate objects within the hand is still limited. One explanation for this limitation is the lack of controlled contact variation between the grasped object and the gripper. For instance, human hands have the ability to firmly grip object surfaces, as well as slide over object faces, an aspect that aids the enhanced manipulation of objects within the hand without losing contact. In this letter, we present a parametric, origami-inspired thin surface capable of transitioning between a high friction and a low friction state, suitable for implementation as an epidermis in robotic fingers. A numerical analysis of the proposed surface based on its design parameters, force analysis, and performance in in-hand manipulation tasks is presented. Through the development of a simple two-fingered two-degree-of-freedom gripper utilizing the proposed variable-friction surfaces with different parameters, we experimentally demonstrate the improved manipulation capabilities of the hand when compared to the same gripper without changeable friction. Results show that the pattern density and valley gap are the main parameters that effect the in-hand manipulation performance. The origami-inspired thin surface with a higher pattern density generated a smaller valley gap and smaller height change, producing a more stable improvement of the manipulation capabilities of the hand.

- A Shape Memory Polymer Adhesive Gripper for Pick-And-Place Applications

    Author: Son, ChangHee | University of Illinois at Urbana-Champaign
    Author: Kim, Seok | University of Illinois at Urbana-Champaign
 
    keyword: Grippers and Other End-Effectors

    Abstract : Over the past few years, shape memory polymer (SMP) has been extensively studied in terms of its remarkable reversible dry adhesive properties and related smart adhesive applications. However, its exceptional properties have not been exploited for further opportunities such as pick-and-place applications, which would otherwise advance the robotic manipulation. This work explores the use of an SMP to design an adhesive gripper that picks and places a target solid object employing the reversible dry adhesion of an SMP. Compared with other single surface contact grippers including vacuum, electromagnetic, electroadhesion, and gecko grippers, the SMP adhesive gripper interacts with not only flat and smooth dry surfaces but also moderately rough and even wet surfaces for pick-and-place with high adhesion strength (&gt; 2 atmospheres). In this work, associated physical mechanisms, SMP adhesive mechanics, and thermal conditions are studied. In particular, the numerical and experimental study elucidates that the optimal compositional and topological SMP design may substantially enhance its adhesion strength and reversibility, which leads to a strong grip force simultaneously with a minimized releasing force. Finally, the versatility and utility of the SMP adhesive gripper are highlighted through diverse pick-and-place demonstrations.

- A High-Payload Proprioceptive Hybrid Robotic Gripper with Soft Origamic Actuators

    Author: Su, Yinyin | Southern University of Science and Technology
    Author: Fang, Zhonggui | Southern University of Science and Technology
    Author: Zhu, Wenpei | Southern University of Science and Technology
    Author: Sun, Xiaochen | Southern University of Science and Technology
    Author: Zhu, Yuming | SUSTech
    Author: Wang, Hexiang | Harbin Institute of Technology
    Author: Tang, Kailuan | Southern University of Science and Technology
    Author: Huang, Hailin | Harbin Institute of Technology, Shenzhen
    Author: Liu, Sicong | Southern University of Science and Technology
    Author: Wang, Zheng | The University of Hong Kong
 
    keyword: Grippers and Other End-Effectors; Soft Robot Materials and Design; Perception for Grasping and Manipulation

    Abstract : Proprioception is the ability to perceive environmental stimulations through internal sensory organs. Enabling proprioception is critical for robots to be aware of the environmental interactions and respond appropriately, particularly for high-payload grippers to ensure safety when handling delicate objects. State-of-the-art robotic grippers with soft actuators are typically equipped with pressure sensors for pneumatic regulation and control, but very few utilized them for proprioceptive purposes. This lack of environmental awareness was largely compensated by their inherent compliance and conformity, but also due to the generally limited force capabilities. Targeting at this gap, this work proposes a novel hybrid robotic gripper design with high-payload soft origami actuators and rigid supporting frames, achieving up to 567N actuator output force or 300N finger gripping force at 150kPa low pneumatic pressure and 3.2kg self-weight. Despite the substantially higher force capability over state-of-the-art soft grippers, the proposed hybrid gripper could retain the excellent inherent compliance thanks to the novel soft origami actuators being used. Moreover, by only using the embedded pneumatic pressure sensor, a novel scheme of multi-actuator proprioception is proposed to enable the hybrid gripper with environmental awareness, achieving real-time position and force estimations of errors at &lt;1% and 5.6%, respectively. The principles, design, prototyping, and experiments of the

## Formal Methods in Robotics and Automation
- Reality As a Simulation of Reality: Robot Illusions, Fundamental Limits, and a Physical Demonstration

    Author: Shell, Dylan | Texas A&amp;M University
    Author: O'Kane, Jason | University of South Carolina
 
    keyword: Formal Methods in Robotics and Automation; Simulation and Animation; Path Planning for Multiple Mobile Robots or Agents

    Abstract : We consider problems in which robots conspire to present a view of the world that differs from reality. The inquiry is motivated by the problem of validating robot behavior physically despite there being a discrepancy between the robots we have at hand and those we wish to study, or the environment for testing that is available versus that which is desired, or other potential mismatches in this vein. After formulating the concept of a convincing illusion, essentially a notion of system simulation that takes place in the real world, we examine the implications of this type of simulability in terms of infrastructure requirements. Time is one important resource: some robots may be able to simulate some others but, perhaps, only at a rate that is slower than real-time.	This difference gives a way of relating the simulating and the simulated systems in a form that is relative. We establish some theorems, including one with the flavor of an impossibility result, and providing several examples throughout. Finally, we present data from a simple multi-robot experiment based on this theory, with a robot navigating amid an unbounded field of obstacles.

- Finding Missing Skills for High-Level Behaviors

    Author: Pacheck, Adam | Cornell University
    Author: Moarref, Salar | Cornell University
    Author: Kress-Gazit, Hadas | Cornell University
 
    keyword: Formal Methods in Robotics and Automation; Task Planning

    Abstract : Recently, Linear Temporal Logic (LTL) has been used as a formalism for defining high-level robot tasks, and LTL synthesis has been used to automatically create correct-by-construction robot control. The underlying premise of this approach is that the robot has a set of actions, or skills, that can be composed to achieve the high-level task. In this paper we consider LTL specifications that cannot be synthesized into robot control due to lack of appropriate skills; we present algorithms for automatically suggesting new or modified skills for the robot that will guarantee the task will be achieved. We demonstrate our approach with a physical Baxter robot and a simulated KUKA IIWA arm.

- Near-Optimal Reactive Synthesis Incorporating RuntimeInformation

    Author: Bharadwaj, Sudarshanan | UT Austin
    Author: P. Vinod, Abraham | University of New Mexico
    Author: Dimitrova, Rayna | The University of Sheffield
    Author: Topcu, Ufuk | The University of Texas at Austin
 
    keyword: Formal Methods in Robotics and Automation; Autonomous Agents

    Abstract : We consider the problem of optimal reactive synthesis --- compute a strategy that satisfies a mission specification in a dynamic environment, and optimize a performance metric. We incorporate task-critical information, that is only available at runtime, into the strategy synthesis in order to improve performance. Existing approaches to utilize such time-varying information requires online re-synthesis, which is not computationally feasible in real-time applications. In this paper, we pre-synthesize a set of strategies corresponding to emph{candidate instantiations} (pre-specified representative information scenarios). We then propose a novel switching mechanism to dynamically switch between the strategies at runtime while guaranteeing all liveness goals are met. We also characterize bounds on the performance suboptimality. We demonstrate our approach in two examples --- robotic motion planning where the likelihood of the position of the robot's goal is updated in real-time, and an air traffic management problem for urban air mobility.

- Control Synthesis from Linear Temporal Logic Specifications Using Model-Free Reinforcement Learning

    Author: Bozkurt, Alper Kamil | Duke University
    Author: Wang, Yu | Duke University
    Author: Zavlanos, Michael M. | Duke University
    Author: Pajic, Miroslav | Duke University
 
    keyword: Formal Methods in Robotics and Automation; Motion and Path Planning; Probability and Statistical Methods

    Abstract : We present a reinforcement learning (RL) framework to synthesize a control policy from a given linear temporal logic (LTL) specification in an unknown stochastic environment that can be modeled as a Markov Decision Process (MDP). Specifically, we learn a policy that maximizes the probability of satisfying the LTL formula without learning the transition probabilities. We introduce a novel rewarding and discounting mechanism based on the LTL formula such that (i) an optimal policy maximizing the total discounted reward effectively maximizes the probabilities of satisfying LTL objectives, and (ii) a model-free RL algorithm using these rewards and discount factors is guaranteed to converge to such a policy. Finally, we illustrate the applicability of our RL-based synthesis approach on two motion planning case studies.

- A Framework for Formal Verification of Behavior Trees with Linear Temporal Logic

    Author: Biggar, Oliver | University of Melbourne
    Author: Zamani, Mohammad | DSTG
 
    keyword: Formal Methods in Robotics and Automation; Control Architectures and Programming

    Abstract : Despite the current increasing popularity of Behavior Trees (BTs) in the robotics community, there does not currently exist a method to formally verify their correctness without compromising their most valuable traits: modularity, flexibility and reusability. In this paper we present a new mathematical framework in which we formally express Behavior Trees in Linear Temporal Logic (LTL). We show how this framework equivalently represents classical BTs. Then we utilize the proposed framework to construct an algorithm to verify that a given BT satisfies a given LTL specification. We prove that this algorithm is sound. Importantly, we prove that this method does not compromise the flexible design process of BTs, i.e. changes to subtrees can be verified separately and their combination can be assured to be correct. We present an example of the proposed algorithm in use.

- Safety Assessment of Collaborative Robotics through Automated Formal Verification (I)

    Author: Vicentini, Federico | Stiima CNR
    Author: Askarpour, Mehrnoosh | Politecnico Di Milano
    Author: Rossi, Matteo Giovanni | Politecnico Di Milano
    Author: Dino, Mandrioli | Politecnico Di Milano
 
    keyword: Formal Methods in Robotics and Automation; Physical Human-Robot Interaction

    Abstract : A crucial aspect of physical human�robot collaboration (HRC) is to maintain a safe common workspace for human operator. However, close proximity between human�robot and unpredictability of human behavior raises serious challenges in terms of safety. This article proposes a risk analysis methodology for collaborative robotic applications, which is compatible with well-known standards in the area and relies on formal verification techniques to automate the traditional risk analysis methods. In particular, the methodology relies on temporal logic-based mod- els to describe the different possible ways in which tasks can be carried out, and on fully automated formal verification techniques to explore the corresponding state space to detect and modify the hazardous situations at early stages of system design.

## Parallel Robots
- R-Min: A Fast Collaborative Underactuated Parallel Robot for Pick-And-Place Operations

    Author: Jeanneau, Guillaume | École Centrale De Nantes
    Author: B�goc, Vincent | Icam
    Author: Briot, S�bastien | LS2N
    Author: Goldsztejn, Alexandre | CNRS IRCCyN
 
    keyword: Parallel Robots; Mechanism Design; Physical Human-Robot Interaction

    Abstract : This paper introduces an intrinsically safe parallel manipulator dedicated to fast pick-and-place operations, called R-Min. It has been designed to reduce the risk of injury during a collision with a human operator, while maintaining high speed and acceleration. The proposed architecture is based on a modification of the well-known planar five-bar mechanism, where additional passive joints are introduced to the distal links in order to create a planar seven-bar mechanism with two degrees of underactuation, so that it can passively reconfigure in case of collision. A supplementary passive leg, in which a tension spring is mounted, is added between the base and the end-effector in order to constrain the additional degrees of freedom.<p>A prototype of this new collaborative parallel robot is designed and its equilibrium configurations under several types of loadings are analyzed. Its dynamics is also studied. We analyze the impact force occurring during a collision between our prototype and the head of an operator and compare these results with those that would have been obtained with a rigid five-bar mechanism. Simulation results of impact during a standard pick-and-place trajectory of duration 0.3~s show that a regular five-bar mechanism would injure a human, while our robot would avoid the trauma.

- High-Flexibility Locomotion and Whole-Torso Control for a Wheel-Legged Robot on Challenging Terrain

    Author: Xu, Kang | Beijing Institute of Technology
    Author: Wang, Shoukun | Beijing Institute of Technology
    Author: Wang, Xiuwen | Beijing Institute of Technology
    Author: Wang, Junzheng | Beijing Institute of Technology
    Author: Chen, Zhihua | Beijing Institute of Technology
    Author: Liu, Daohe | Beijing Institute of Technology
 
    keyword: Parallel Robots; Wheeled Robots; Legged Robots

    Abstract : In this paper, we propose a parallel six-wheeled-legged robot that can traverse irregular terrain while carrying objectives to do heavy-duty work. This robot is equipped with six Stewart platforms as legs and tightly integrates the additional degrees of freedom introduced by the wheels. The presented control strategy with physical system used to adapt the diverse degrees of each leg to irregular terrain such that robot increases the traversability, and simultaneously to maintain the horizontal whole-torso pose. This strategy makes use of Contact Scheduler (CS) and Whole-Torso Control (WTC) to control the multiple degrees of freedom (DOF) leg for performing high-flexibility locomotion and adapting the rough terrain like actively parallel suspension system. We conducted experiments on flat, slope, soft and sand-gravel surface, which validate the proposed control method and physical system. Especially, we attempt to traverse over sand-gravel terrain with 3 people about 240kg payload.

- Prince's Tears, a Large Cable-Driven Parallel Robot for an Artistic Exhibition

    Author: Merlet, Jean-Pierre | INRIA
    Author: Papegay, Yves | INRIA
    Author: Gasc, Anne-Valerie | ENSAM-M
 
    keyword: Parallel Robots; Kinematics; Robotics in Construction

    Abstract : This paper presents the development and results of a large 3 d.o.f cable-driven parallel robot (CDPR) that has been extensively used between June and August 2019 for an artistic exhibition. The purpose of the exhibition was to 3D print a wall of glass powder, which will slowly collapse after the deposit of each layer. Positioning control on the assigned trajectory was an issue because of the CDPR geometry imposed by the specific configuration of the exhibition place. We describe how this problem was solved using a combination of cable length estimation based on the winch rotation measured by encoder, together with 3 on-board lidars that were used to provide a measure of the robot position. To the best of our knowledge this is the first time that such method was used for controlling a large CDPR. This CDPR has run for 174 hours since 6/18/2019, averaging a run time of 4h15mn per day. The 3D printing of the wall started on 7/18/2019 and stops on 8/31/2019. During this period the robot was used for 32 days with an average of 2h18mn run-time per day. The robot has traveled on a total distance of 4757 meters, of which 3893 meters on the assigned trajectory. During the period 76 layers have been deposited, representing a mass of 1.5 tons of glass powder.

- Singularity Analysis and Reconfiguration Mode of the 3-CRS Parallel Manipulator

    Author: Bouzgarrou, Chedli | Institut Pascal UMR 6602 - UCA/CNRS/SIGMA
    Author: Koessler, Adrien | Institut Pascal
    Author: Bouton, Nicolas | Institut Pascal - SIGMA Clermont-Ferrand
 
    keyword: Parallel Robots; Kinematics; Mechanism Design

    Abstract : The 3-CRS manipulator is an original parallel mechanism having 6 degrees of freedom (DOFs) with only 3 limbs. This mechanism uses a motorized cylindrical joint per limb. This new paradigm of actuation opens research fields on new families of robots that should particularly interest the parallel robotics community. According to its dimensional synthesis, this mechanism can have remarkable kinematic properties such as a large orientation workspace or reconfiguration capabilities. In this paper, we introduce this mechanism and we study its singularities by using a geometric approach. This approach simplifies considerably singularity analysis problem by considering the relative geometric configurations of three planes defined by the distal links of the limbs. Thanks to that, a reconfiguration mode of the 3-CRS, that doubles its reachable workspace, is highlighted. This property is illustrated on a physical prototype of the robot.

- Trajectory Optimization for a Class of Robots Belonging to Constrained Collaborative Mobile Agents (CCMA) Family

    Author: Kumar, Nitish | Computational Robotics Lab, Institute for Intelligent Interactiv
    Author: Coros, Stelian | Carnegie Mellon University
 
    keyword: Parallel Robots; Optimization and Optimal Control; Multi-Robot Systems

    Abstract : We present a novel class of robots belonging to Constrained Collaborative Mobile Agents (CCMA) family which consists of ground mobile bases with non-holonomic constraints. Moreover, these mobile robots are constrained by closed-loop kinematic chains consisting of revolute joints which can be either passive or actuated. We also describe a novel trajectory optimization method which is general with respect to number of mobile robots, topology of the closed-loop kinematic chains and placement of the actuators at the revolute joints. We also extend the standalone trajectory optimization method to optimize concurrently the design parameters and the control policy. We describe various CCMA system examples, in simulation, differing in design, topology, number of mobile robots and actuation space. The simulation results for standalone trajectory optimization with fixed design parameters is presented for CCMA system examples. We also show how this method can be used for tasks other than end-effector positioning such as internal collision avoidance and external obstacle avoidance. The concurrent design and control policy optimization is demonstrated, in simulations, to increase the CCMA system workspace and manipulation capabilities. Finally, the trajectory optimization method is validated in experiments through two 4-DOF prototypes consisting of 3 tracked mobile bases.

-  Multiaxis Reaction System (MARS) for Vibration Control of Planar Cable-Driven Parallel Robots (I)

    Author: Rushton, Mitchell | University of Waterloo
    Author: Jamshidifar, Hamed | University of Waterloo
    Author: Khajepour, Amir | University of Waterloo


## Mechanism and Verification
- Reconfiguration Solution of a Variable Topology Truss: Design and Experiment

    Author: Park, Eugene | Seoul National University
    Author: Bae, Jangho | Seoul National University
    Author: Park, Sumin | Seoul National University
    Author: Yim, Mark | University of Pennsylvania
    Author: Kim, Jongwon | Seoul National University
    Author: Seo, TaeWon | Hanyang University
 
    keyword: Cellular and Modular Robots; Mechanism Design

    Abstract : In this paper, an active ball joint actuator, called the master node, is developed for the purpose of reconfiguring truss structures. We propose a variable topology truss system, which is an advanced variable geometry truss system that can reconfigure its own topology to expand its functions. However, reconfiguration of a variable topology truss is difficult, because the controllability of trusses needs to be maintained during the process. We solve this problem by adding the master node to the system, which can move trusses without losing their controllability. The master node is designed and fabricated for a variable topology truss. The reconfiguration test using the master node is performed on a reduced prototype of the system. The results prove that using the master node for reconfiguration is viable.

- Development of Body Rotational Wheeled Robot and Its Verification of Effectiveness

    Author: Sim, Byeong-Seop | Chonbuk National University
    Author: Kim, Kun-Jung | Chonbuk National University
    Author: Yu, Kee-Ho | Chonbuk National University
 
    keyword: Field Robots; Mechanism Design; Wheeled Robots

    Abstract : A wheeled robot operating on various terrains such as scattered obstacles and slopes is required to cope with and overcome the driving environment. In this paper, in order to overcome a step-type obstacle and to steadily ascend on the slope, the main body rotation mechanism, which controls the load distribution on the robot wheels was proposed for a wheel-drive robot. By rotating the center of the body mass, the friction/traction force required for climbing step obstacles can be reduced. In the case of slope traveling, the slip can be suppressed, and the traveling ability improved by controlling the load distribution excessively increased on the downhill wheel due to the attitude change of the robot's body. The mechanical effect of the proposed body rotation mechanism was analyzed. In addition, based on the design and manufacture of the robot platform, the effectiveness of the proposed mechanism was convincingly demonstrated by indoor test for step-obstacle climbing and slope-traveling.

- Error Bounds for PD-Controlled Mechanical Systems under Bounded Disturbances Using Interval Arithmetic

    Author: Calzolari, Davide | German Aerospace Center, Technical University of Munich
    Author: Giordano, Alessandro Massimo | DLR (German Aerospace Center)
    Author: Albu-Sch�ffer, Alin | DLR - German Aerospace Center
 
    keyword: Performance Evaluation and Benchmarking; Industrial Robots

    Abstract : We present a numerical algorithm based on invariant set theory to evaluate the worst-case performance of PD-controlled mechanical systems affected by bounded disturbances. By performing a specific coordinate transformation, the search and computation of positive invariant sets is simplified. It is shown that, thanks to the preservation of problem structure, the proposed method allows to obtain tight, component-wise bounds on the states, which are especially useful for performance evaluation and tuning of a PD controller. The bounds are formally guaranteed and can be used for safety certification. The method is compared to ultimate boundedness, and the superior results are shown via numerical simulations.

- Hardware-In-The-Loop Iterative Optimal Feedback Control without Model-Based Future Prediction (I)

    Author: Chen, Yuqing | Singapore University of Technology and Design
    Author: Braun, David | Vanderbilt University
 
    keyword: Optimization and Optimal Control; Control Architectures and Programming

    Abstract : Optimal control provides a systematic approach to control robots. However, computing optimal controllers for hardware-in-the-loop control is sensitively affected by modeling assumptions, computationally expensive in online implementation, and time-consuming in practical application. This makes the theoretical appeal of optimization challenging to exploit in real-world implementation. In this paper, we present a novel online optimal control formulation that aims to address the above-mentioned limitations. The formulation combines a model with measured state information to efficiently find near-optimal feedback controllers. The idea to combine a model with measurements from the actual motion is similar to what is used in model predictive control formulations, with the difference that here the model is not used for future prediction, the optimization is performed along the measured trajectory of the system, and the online computation is reduced to a minimum; it requires a small-scale, one time step, static optimization, instead of a large-scale, finite time horizon, dynamic optimization. The formulation can be used to solve optimal control problems defined with nonlinear cost, nonlinear dynamics, and box-constrained control inputs. Numerical simulations and hardware-in-the-loop experiments demonstrate the effectiveness of the proposed hardware-in-the-loop optimal control approach.

- Analysis and Synthesis of Underactuated Compliant Mechanisms Based on Transmission Properties of Motion and Force (I)
 
    Author: Chen, Wenrui | Hunan University
    Author: Xiong, Caihua | Huazhong Univ. of Science &amp; Tech
    Author: Wang, Yaonan | Hunan University
 
    keyword: Underactuated Robots; Compliant Joint/Mechanism; Grasping

    Abstract : This paper analyzes and designs the transmission structure for underactuated compliant mechanisms (UCMs). The transmission structure of UCMs consists of serial and parallel transmission chains. At first, the UCMs are classified systematically according to the number and distribution of the serial and parallel transmissions. Next, the active and passive transmission properties of motion and force in UCMs are analyzed on the defined four subspaces of tangent and cotangent spaces of joint space. Synthesizing the classification and the transmission properties of UCMs, the congruent relationship between mechanical structure and transmission function is established, and different cases of UCMs are discussed and compared. A novel type of UCMs can achieve the independent regulation of passive stiffness, active force and active motion that is useful for improving the transmission performance in robotic and prosthetic hands. Finally, a functional oriented design method is proposed and used to design a single-actuator two-fingered gripper for enveloping and precision grasps. The results demonstrate the validity of the proposed method.

- Radar Sensors in Collaborative Robotics: Fast Simulation and Experimental Validation

    Author: Stetco, Christian | Alpen-Adria Universitét Klagenfurt
    Author: Ubezio, Barnaba | Joanneum Research Robotics Forschungsgesellschaft MbH
    Author: M�hlbacher-Karrer, Stephan | JOANNEUM RESEARCH Forschungsgesellschaft mbH - ROBOTICS
    Author: Zangl, Hubert | Alpen-Adria-Universitaet Klagenfurt
 
    keyword: Range Sensing; Simulation and Animation; Human Detection and Tracking

    Abstract : With the availability of small system in package realizations, radar systems become more and more attractive for a variety of applications in robotics, in particular also for collaborative robotics. As the simulation of robot systems in realistic scenarios has become an important tool, not only for design and optimization, but also e.g. for machine learning approaches, realistic simulation models are needed. In the case of radar sensor simulations, this means providing more realistic results than simple proximity sensors, e.g. in the presence of multiple objects and/or humans, objects with different relative velocities and differentiation between background and foreground movement. Due to the short wavelength in the millimeter range, we propose to utilize methods known from computer graphics (e.g. z-buffer approach, Lambertian reflectance model) to quickly acquire depth images and reflection estimates. This information is used to calculate an estimate of the received signal for a Frequency Modulated Continuous Wave (FMCW) radar by superposition of the corresponding signal contributions. Due to the moderate computational complexity, the approach can be used with various simulation environments such as V-Rep or Gazebo. Validity and benefits of the approach are demonstrated by means of a comparison with experimental data obtained with a radar sensor on a UR10 arm in different scenarios.

## Model Learning for Control
-  Sparse, Online, Locally Adaptive Regression Using Gaussian Processes for Bayesian Robot Model Learning and Control

    Author: Wilcox, Brian | UC San Diego
    Author: Yip, Michael C. | University of California, San Diego

- DISCO: Double Likelihood-Free Inference Stochastic Control

    Author: Barcelos, Lucas | The University of Sydney
    Author: Oliveira, Rafael | University of Sydney
    Author: Possas, Rafael | University of Sydney
    Author: Ott, Lionel | University of Sydney
    Author: Ramos, Fabio | University of Sydney, NVIDIA
 
    keyword: Model Learning for Control; Learning and Adaptive Systems; Robust/Adaptive Control of Robotic Systems

    Abstract : Accurate simulation of complex physical systems enables the development, testing, and certification of control strategies before they are deployed into the real systems. As simulators become more advanced, the analytical tractability of the differential equations and associated numerical solvers incorporated in the simulations diminishes, making them difficult to analyse. A potential solution is the use of probabilistic inference to assess the uncertainty of the simulation parameters given real observations of the system. Unfortunately the likelihood function required for inference is generally expensive to compute or totally intractable. In this paper we propose to leverage the power of modern simulators and recent techniques in Bayesian statistics for likelihood-free inference to design a control framework that is efficient and robust with respect to the uncertainty over simulation parameters. The posterior distribution over simulation parameters is propagated through a potentially non-analytical model of the system with the unscented transform, and a variant of the information theoretical model predictive control. This approach provides a more efficient way to evaluate trajectory roll outs than Monte Carlo sampling, reducing the online computation burden. Experiments show that the controller proposed attained superior performance and robustness on classical control and robotics tasks when compared to models not accounting for the uncertainty over model parameters.

- Discovering Interpretable Dynamics by Sparsity Promotion on Energy and the Lagrangian

    Author: Chu, Khanh Hoang | Tohoku University
    Author: Hayashibe, Mitsuhiro | Tohoku University
 
    keyword: Model Learning for Control; Dynamics; Calibration and Identification

    Abstract : Data-driven modeling frameworks that adopt sparse regression techniques, such as sparse identification of nonlinear dynamics (SINDy) and its modifications, are developed to resolve difficulties in extracting underlying dynamics from experimental data. In contrast to neural-network-based methods, these methods are designed to obtain white-box analytical models. In this work, we incorporate the concept of SINDy and knowledge in the field of classical mechanics to identify interpretable and sparse expressions of total energy and the Lagrangian that shelters the hidden dynamics. Moreover, our method (hereafter referred as Lagrangian-SINDy) is developed to use knowledge of simple systems that form the system being analyzed to ensure the likelihood of correct results and to improve the learning pace. Lagrangian-SINDy is highly accurate in discovering interpretable dynamics via energy-related physical quantities. Its performance is validated with three popular multi-DOF nonlinear dynamical systems, namely the spherical pendulum, double pendulum and cart-pendulum system. Comparisons with other SINDy-based methods are made and Lagrangian-SINDy is found to provide the most compact analytical models.

- Online Simultaneous Semi-Parametric Dynamics Model Learning

    Author: Smith, Joshua | University of Edinburgh
    Author: Mistry, Michael | University of Edinburgh
 
    keyword: Model Learning for Control; Robust/Adaptive Control of Robotic Systems; Dynamics

    Abstract : Accurate models of robots' dynamics are critical for control, stability, motion optimization, and interaction. Semi-Parametric approaches to dynamics learning combine physics-based Parametric models with unstructured Non-Parametric regression with the hope to achieve both accuracy and generalizability. In this paper, we highlight the non-stationary problem created when attempting to adapt both Parametric and Non-Parametric components simultaneously. We present a consistency transform designed to compensate for this non-stationary effect, such that the contributions of both models can adapt simultaneously without adversely affecting the performance of the platform. Thus, we are able to apply the Semi-Parametric learning approach for continuous iterative online adaptation, without relying on batch or offline updates. We validate the transform via a perfect virtual model as well as by applying the overall system on a Kuka LWR IV manipulator. We demonstrate improved tracking performance during online learning and show a clear transference of contribution between the two components with a learning bias towards the Parametric component.

- Sufficiently Accurate Model Learning

    Author: Zhang, Clark | University of Pennsylvania
    Author: Khan, Arbaaz | University of Pennsylvania
    Author: Paternain, Santiago | University of Pennsylvania
    Author: Ribeiro, Alejandro | University of Pennsylvania
 
    keyword: Model Learning for Control; Robust/Adaptive Control of Robotic Systems; Motion Control

    Abstract : Modeling how a robot interacts with the environment around it is an important prerequisite for designing control and planning algorithms. In fact, the performance of controllers and planners is highly dependent on the quality of the model. One popular approach is to learn data driven models in order to compensate for inaccurate physical measurements and to adapt to systems that evolve over time. In this paper, we investigate a method to regularize model learning techniques to provide better error characteristics for traditional control and planning algorithms. This work proposes learning ``Sufficiently Accurate" models of dynamics using a primal-dual method that can explicitly enforce constraints on the error in pre-defined parts of the state-space. The result of this method is that the error characteristics of the learned model is more predictable and can be better utilized by planning and control algorithms. The characteristics of Sufficiently Accurate models are analyzed through experiments on a simulated ball paddle system.

- Active Learning of Dynamics for Data-Driven Control Using Koopman Operators (I)

    Author: Abraham, Ian | Northwestern University
    Author: Murphey, Todd | Northwestern University
 
    keyword: Model Learning for Control; Optimization and Optimal Control

    Abstract : This paper presents an active learning strategy for robotic systems that takes into account task information, enables fast learning, and allows control to be readily synthesized by taking advantage of the Koopman operator representation. We first motivate the use of representing nonlinear systems as linear Koopman operator systems by illustrating the improved model-based control performance with an actuated Van der Pol system. Information-theoretic methods are then applied to the Koopman operator formulation of dynamical systems where we derive a controller for active learning of robot dynamics. The active learning controller is shown to increase the rate of information about the Koopman operator. In addition, our active learning controller can readily incorporate policies built on the Koopman dynamics, enabling the benefits of fast active learning and improved control. Results using a quadcopter illustrate single-execution active learning and stabilization capabilities during free-fall. The results for active learning are extended for automating Koopman observables and we implement our method on real robotic systems.

## Mobile Manipulation
- Towards Plan Transformations for Real-World Mobile Fetch and Place

    Author: Kazhoyan, Gayane | University of Bremen
    Author: Niedzwiecki, Arthur | Institute for Artificial Intelligence, University of Bremen
    Author: Beetz, Michael | University of Bremen
 
    keyword: Mobile Manipulation; Autonomous Agents; Service Robots

    Abstract : In this paper, we present an approach and an implemented framework for applying plan transformations to real-world mobile manipulation plans, in order to specialize them to the specific situation at hand. The framework can improve execution cost and achieve better performance by autonomously transforming robot's behavior at runtime. To demonstrate the feasibility of our approach, we apply three example transformations to the plan of a PR2 robot performing simple table setting and cleaning tasks in the real world. Based on a large amount of experiments in a fast plan projection simulator, we make conclusions on improved execution performance.

- Planning an Efficient and Robust Base Sequence for a Mobile Manipulator Performing Multiple Pick-And-Place Tasks

    Author: Xu, Jingren | Osaka University
    Author: Harada, Kensuke | Osaka University
    Author: Wan, Weiwei | Osaka University
    Author: Ueshiba, Toshio | National Institute of Advanced Industrial Science And
    Author: Domae, Yukiyasu | The National Institute of Advanced Industrial Science and Techno
 
    keyword: Mobile Manipulation

    Abstract : In this paper, we address efficiently and robustly collecting objects stored in different trays using a mobile manipulator. A resolution complete method, based on precomputed reachability database, is proposed to explore collision-free inverse kinematics (IK) solutions and then a resolution complete set of feasible base positions can be determined. This method approximates a set of representative IK solutions that are especially helpful when solving IK and checking collision are treated separately. For real world applications, we take into account the base positioning uncertainty and plan a sequence of base positions that reduce the number of necessary base movements for collecting the target objects, the base sequence is robust in that the mobile manipulator is able to complete the part-supply task even there is certain deviation from the planned base positions. Our experiments demonstrate both the efficiency compared to regular base sequence and the feasibility in real world applications.

- Towards Mobile Multi-Task Manipulation in a Confined and Integrated Environment with Irregular Objects

    Author: Han, Zhao | UMass Lowell
    Author: Allspaw, Jordan | University of Massachusetts Lowell
    Author: LeMasurier, Gregory | University of Massachusetts Lowell
    Author: Parrillo, Jenna | University of Massachusetts Lowell
    Author: Giger, Daniel | University of Massachusetts Lowell
    Author: Ahmadzadeh, S. Reza | University of Massachusetts Lowell
    Author: Yanco, Holly | UMass Lowell
 
    keyword: Mobile Manipulation

    Abstract : The FetchIt! Mobile Manipulation Challenge, held at the IEEE International Conference on Robots and Automation (ICRA) in May 2019, offered an environment with complex and integrated task sets, irregular objects, confined space, and machining, introducing new challenges in the mobile manipulation domain. Here we describe our efforts to address these challenges by demonstrating the assembly of a kit of mechanical parts in a caddy. In addition to implementation details, we examine the issues in this task set extensively, and we discuss our software architecture in the hope of providing a base for other researchers. To evaluate performance and consistency, we conducted 20 full runs, then examined failure cases with possible solutions. We conclude by identifying future research directions to address the open challenges.

- Linear Time-Varying MPC for Nonprehensile Object Manipulation with a Nonholonomic Mobile Robot

    Author: Bertoncelli, Filippo | University of Modena and Reggio Emilia
    Author: Ruggiero, Fabio | Université Di Napoli Federico II
    Author: Sabattini, Lorenzo | University of Modena and Reggio Emilia
 
    keyword: Mobile Manipulation; Contact Modeling; Optimization and Optimal Control

    Abstract : This paper proposes a technique to manipulate an object with a nonholonomic mobile robot by pushing, which is a nonprehensile manipulation motion primitive. Such a primitive involves unilateral constraints associated with the friction between the robot and the manipulated object. Violating this constraint produces the slippage of the object during the manipulation, preventing the correct achievement of the task. A linear time-varying model predictive control is designed to include the unilateral constraint within the control action properly. The approach is verified in a dynamic simulation environment through a Pioneer 3-DX wheeled robot executing the pushing manipulation of a package.

- A Mobile Manipulation System for One-Shot Teaching of Complex Tasks in Homes

    Author: Bajracharya, Max | Toyota Research Institute
    Author: Borders, James | Toyota Research Institute
    Author: Helmick, Daniel | Toyota Research Institute
    Author: Kollar, Thomas | Toyota Research Institute
    Author: Laskey, Michael | University of California, Berkeley
    Author: Leichty, John | Toyota Research Institute
    Author: Ma, Jeremy | California Institute of Technology
    Author: Nagarajan, Umashankar | Honda Research Institute USA Inc
    Author: Ochiai, Akiyoshi | Toyota Research Institute
    Author: Petersen, Joshua | Toyota Research Institute
    Author: Shankar, Krishna | Toyota Research Institute
    Author: Stone, Kevin | Toyota Research Institute
    Author: Takaoka, Yutaka | Toyota Mortor Corporation
 
    keyword: Mobile Manipulation; Learning from Demonstration; Domestic Robots

    Abstract : We describe a mobile manipulation hardware and software system capable of autonomously performing complex human-level tasks in real homes, after being taught the task with a single demonstration from a person in virtual reality. This is enabled by a highly capable mobile manipulation robot, whole-body task space hybrid position/force control, teaching of parameterized primitives linked to a robust learned dense visual embeddings representation of the scene, and a task graph of the taught behaviors. We demonstrate the robustness of the approach by presenting results for performing a variety of tasks, under different environmental conditions, in multiple real homes. Our approach achieves 85% overall success rate on three tasks that consist of an average of 45 behaviors each. The video is available at: https://youtu.be/HSyAGMGikLk.

## Computer Vision for Transportation
- 2D to 3D Line-Based Registration with Unknown Associations Via Mixed-Integer Programming

    Author: Parkison, Steven | University of Michigan
    Author: Walls, Jeffrey | University of Michigan
    Author: Wolcott, Ryan | University of Michigan
    Author: Saad, Mohammad | Toyota Research Institute
    Author: Eustice, Ryan | University of Michigan
 
    keyword: Computer Vision for Transportation; Localization; Mapping

    Abstract : Determining the rigid-body transformation between 2D image data and 3D point cloud data has applications for mobile robotics including sensor calibration and localizing into a prior map. Common approaches to 2D-3D registration use least-squares solvers assuming known associations often provided by heuristic front-ends, or iterative nearest-neighbor. We present a linear line-based 2D-3D registration algorithm formulated as a mixed-integer program to simultaneously solve for the correct transformation and data association. Our formulation is explicitly formulated to handle outliers, by modeling associations as integer variables. Additionally, we can constrain the registration to SE(2) to improve runtime and accuracy. We evaluate this search over multiple real-world data sets demonstrating adaptability to scene variation

- An Efficient Solution to the Relative Pose Estimation with a Common Direction

    Author: Ding, Yaqing | Nanjing University of Science and Technology
    Author: Yang, Jian | Nanjing University of Science &amp; Technology
    Author: Kong, Hui | Nanjing University of Science and Technology
 
    keyword: Computer Vision for Transportation; Sensor Fusion; Performance Evaluation and Benchmarking

    Abstract : In this paper, we propose an efficient solution to the calibrated camera motion estimation with a common direction. This case is relevant to smart phones, tablets, and other camera-IMU (Inertial measurement unit) systems, which have accelerometers to measure the gravity direction. We can align one of the axes of the camera with this common direction so that the relative rotation between the views reduces to only 1-DOF (degree of freedom). This allows us to use only three point correspondences for relative pose estimation. Unlike previous work, we derive new constraints on the simplified essential matrix using an elimination strategy based on Gr"{o}bner basis. In this case, computing the coefficients of these constraints require less computation and we only need to solve a polynomial eigenvalue problem. We show detailed analyses and comparisons against the existing 3-point algorithms, with satisfactory results obtained.

- Task-Aware Novelty Detection for Visual-Based Deep Learning in Autonomous Systems

    Author: Chen, Valerie | Yale University
    Author: Yoon, Man-Ki | Yale University
    Author: Shao, Zhong | Yale University
 
    keyword: Computer Vision for Transportation; Deep Learning in Robotics and Automation; Autonomous Vehicle Navigation

    Abstract : Deep-learning driven safety-critical autonomous systems, such as self-driving cars, must be able to detect situations where its trained model is not able to make a trustworthy prediction. This ability to determine the novelty of a new input with respect to a trained model is critical for such systems because novel inputs due to changes in the environment, adversarial attacks, or even unintentional noise can potentially lead to erroneous, perhaps life-threatening decisions. This paper proposes a learning framework that leverages information learned by the prediction model in a task-aware manner to detect novel scenarios. We use network saliency to provide the learning architecture with knowledge of the input areas that are most relevant to the decision-making and learn an association between the saliency map and the predicted output to determine the novelty of the input. We demonstrate the efficacy of this method through experiments on real-world driving datasets as well as through driving scenarios in our in-house indoor driving environment where the novel image can be sampled from another similar driving dataset with similar features or from adversarial attacked images from the training dataset. We find that our method is able to systematically detect novel inputs and quantify the deviation from the target prediction through this task-aware approach.

- DirectShape: Direct Photometric Alignment of Shape Priors for Visual Vehicle Pose and Shape Estimation

    Author: Wang, Rui | Technical University of Munich
    Author: Yang, Nan | Technical University of Munich
    Author: Stueckler, Joerg | Max-Planck Institute for Intelligent Systems
    Author: Cremers, Daniel | Technical University of Munich
 
    keyword: Computer Vision for Transportation; Semantic Scene Understanding; Autonomous Vehicle Navigation

    Abstract : Scene understanding from images is a challenging problem which is encountered in autonomous driving. On the object level, while 2D methods have gradually evolved from computing simple bounding boxes to delivering finer grained results like instance segmentations, the 3D family is still dominated by estimating 3D bounding boxes. In this paper, we propose a novel approach to jointly infer the 3D rigid-body poses and shapes of vehicles from a stereo image pair using shape priors. Unlike previous works that geometrically align shapes to point clouds from dense stereo reconstruction, our approach works directly on images by combining a photometric and a silhouette alignment term in the energy function. An adaptive sparse point selection scheme is proposed to efficiently measure the consistency with both terms. In experiments, we show superior performance of our method on 3D pose and shape estimation over the previous geometric approach. Moreover, we demonstrate that our method can also be applied as a refinement step and significantly boost the performances of several state-of-the-art deep learning based 3D object detectors. All related materials and a demonstration video are available at the project page https://vision.in.tum.de/research/vslam/direct-shape.

- RoadText-1K: Text Detection &amp; Recognition Dataset for Driving Videos

    Author: Battu, Sangeeth Reddy | IIIT Hyderabad
    Author: Mathew, Minesh | International Institute of Information Technology, Hyderabad
    Author: Gomez, Lluis | Computer Vision Center, Universitat Autonoma De Barcelona
    Author: Rusi�ol, Mar�al | Computer Vision Center
    Author: Karatzas, Dimosthenis | Computer Vision Center, Universitat Aut�noma De Barcelona
    Author: Jawahar, C.V. | IIIT, Hyderabad
 
    keyword: Computer Vision for Transportation; Intelligent Transportation Systems; Semantic Scene Understanding

    Abstract : Understanding text is crucial to understand the semantics of outdoor scenes and hence is a critical requirement to build intelligent systems for driver assistance and self- driving. Most of the existing datasets for text detection and recognition comprise still images and are mostly compiled keeping text in mind. This paper introduces a new �RoadText- 1K - dataset for text in driving videos. The dataset is 20 times larger than the existing largest dataset for text in videos. Our dataset comprises 1000 video clips of driving without any bias towards the text and with annotations for text bounding boxes and transcriptions in every frame. State of the art methods for text detection, recognition and tracking are evaluated on the new dataset and the results signify the challenges in unconstrained driving videos compared to existing datasets. This suggests that RoadText-1K is suited for research and development of reading systems robust enough to be incorporated into more complex downstream tasks like driver assistance and self-driving.

- End-To-End Learning for Inter-Vehicle Distance and Relative Velocity Estimation in ADAS with a Monocular Camera

    Author: Song, Zhenbo | Nanjing University of Science and Technology
    Author: Lu, Jianfeng | Nanjing University of Science &amp; Technology
    Author: Zhang, Tong | Australian National University, Motovis Australia Pty Ltd
    Author: Li, Hongdong | Australian National University and NICTA
 
    keyword: Computer Vision for Transportation; Deep Learning in Robotics and Automation; Intelligent Transportation Systems

    Abstract : Inter-vehicle distance and relative velocity estimations are two basic functions for any ADAS (Advanced driver-assistance systems). In this paper, we propose a monocular camera based inter-vehicle distance and relative velocity estimation method based on end-to-end training of a deep neural network. The key novelty of our method is the integration of multiple visual cues provided by any two time-consecutive monocular frames, which include deep feature cue, scene geometry cue, as well as temporal optical flow clue. We also propose a vehicle-centric sampling mechanism to alleviate the effect of perspective distortion in the motion field (i.e. optical flow). We implement the method by a light-weight deep neural network. Extensive experiments are conducted which confirm the superior performance of our method over other state-of-the-art methods, in terms of estimation accuracy, computational speed, and memory footprint.

## Haptics and Haptic Interfaces
- Learning an Action-Conditional Model for Haptic Texture Generation

    Author: Heravi, Negin | Stanford
    Author: Yuan, Wenzhen | Carnegie Mellon University
    Author: Okamura, Allison M. | Stanford University
    Author: Bohg, Jeannette | Stanford University
 
    keyword: Haptics and Haptic Interfaces; Visual Learning

    Abstract : Rich haptic sensory feedback in response to user interactions is desirable for an effective, immersive virtual reality or teleoperation system. However, this feedback depends on material properties and user interactions in a complex, non-linear manner. Therefore, it is challenging to model the mapping from material and user interactions to haptic feedback in a way that generalizes over many variations of the user's input. Current methodologies are typically conditioned on user interactions, but require a separate model for each material. In this paper, we present a learned action-conditional model that uses data from a vision-based tactile sensor (GelSight) and user's action as input. This model predicts an induced acceleration that could be used to provide haptic vibration feedback to a user. We trained our proposed model on a publicly available dataset (Penn Haptic Texture Toolkit) that we augmented with GelSight measurements of the different materials. We show that a unified model over all materials outperforms previous methods and generalizes to new actions and new instances of the material categories in the dataset.

- Just Noticeable Differences for Joint Torque Feedback During Static Poses

    Author: Kim, Hubert | Virginia Tech
    Author: Guo, Hongxu | Virginia Polytechnic Institute and State University
    Author: Asbeck, Alan | Virginia Tech
 
    keyword: Haptics and Haptic Interfaces; Physical Human-Robot Interaction; Wearable Robots

    Abstract : Joint torque feedback is a new and promising means of kinesthetic feedback for providing information to a person or guiding them during a motion task. However, little work has been done in determining the psychophysical parameters of how well humans can detect external torques. In this study, we determine the human perceptual ability to detect kinesthetic feedback at the elbow during all possible combinations of preload torques and test stimulus torques, with the elbow in a static posture. To accomplish this, we constructed an exoskeleton for the elbow providing joint torque feedback. The device is designed to convey 0.54 Nm of stall torque for up to 120 seconds via a semi-rigid sleeve structure. Using this device, we assessed perception capability using the Interweaving Staircase Method. We found that users could detect average torques of 0.14-0.18 Nm in the extension or flexion directions with no preload. When a preload of 1.27 Nm was applied, this increased to 0.25-0.27 Nm for when flexion stimuli were applied, and 0.18-0.3 Nm when extension stimuli were applied, depending on the preload direction.

- Design of a Parallel Haptic Device with Gravity Compensation by Using Its System Weight

    Author: Hur, Sung-moon | Korea Institute of Science &amp; Technology (KIST)
    Author: Park, Jaeyoung | Korea Institute of Science and Technology
    Author: Park, Jaeheung | Seoul National University
    Author: Oh, Yonghwan | Korea Institute of Science &amp; Technology (KIST)
 
    keyword: Haptics and Haptic Interfaces; Mechanism Design

    Abstract : This paper proposes a 6 degree of freedom(DoF) manipulator for haptic application. The proposed haptic device, named GHap, is designed based on the four-bar-linkage mechanism for linear motion with the ring-type gimbal mechanism. To improve the force display ability, the device is designed to compensate the gravity force of the manipulator by its own weight. The conceptual mechanical design is compared by placing the third joint, which controls the four-bar mechanism, in two different configurations. The forward kinematics and the jacobian of GHap are presented. Finally, the gravity compensation method and open-loop force display performance of the proposed haptic device are validated by an experiment with the GHap prototype.

- Enhanced Haptic Sensations Using a Novel Electrostatic Vibration Actuator with Frequency Beating Phenomenon

    Author: Koo, Jeong-Hoi | Miami University
    Author: Schuster, Jeremy M. | Miami University
    Author: Tantiyartyanontha, Takdanai | Miami University
    Author: Kim, Young-Min | Kiom
    Author: Yang, Tae-Heon | Korea National University of Transportation
 
    keyword: Haptics and Haptic Interfaces

    Abstract : Generating haptic sensations in large touch displays is highly desirable, yet producing them for such application is challenging with conventional haptic actuators used in hand-held devices. This study proposes an electrostatic actuator utilizing frequency beating phenomenon with the goals of generating haptic sensations for large touch sensitive displays (TSDs). Unlike typical electrostatic actuators, the proposed haptic actuator incorporates two high-volt electrodes and a spring supported disk (moveable grounded mass) to enhance the intensity and pattern of haptic sensations. After fabricating a proof-of-concept prototype, its performance was experimentally evaluated by varying the beat frequency and the carrier frequency. Using mock-up LCD panels, a feasibility of the proposed actuator was evaluated for generating meaningful haptic sensations in large TSDs. Testing results show that the prototype generated a variety of unique vibration patterns at varying intensities based on combinations of the two input voltage signals. The results further show that the proposed actuator can produce sufficiently strong vibrotactile feedbacks in mock-up panels, indicating that the proposed electrostatic actuators can be a viable option for providing haptic sensations in large TSDs.

- Electromagnetic Haptic Feedback System for Use with a Graphical Display Using Flat Coils and Sensor Array

    Author: Berkelman, Peter | University of Hawaii-Manoa
    Author: Abdul-Ghani, Hamza | California Institute of Technology
 
    keyword: Haptics and Haptic Interfaces; Virtual Reality and Interfaces

    Abstract : We have developed a haptic interaction system which wirelessly generates 3D forces onto a magnet fixed to a user's fingertip or a stylus. Magnet position sensing and haptic force generation are both performed through a thin screen, and the actuation and sensing components are sufficiently thin to be easily mounted behind the screen in the same enclosure. Thus the system is well suited for an interactive co-located haptic and graphic display.<p>The location of the magnet during haptic interaction is obtained by an array of Hall effect sensors. Flat rectangular coils generate Lorentz forces on the magnet and can act in combination to produce 3D forces in any direction, both parallel and normal to the screen surface. The active area is approximately 120x120 mm, with effective force generation and position sensing from the screen to an elevation of approximately 15 mm. The localization methods do not depend on the size, shape, or magnetization strength of the magnet, so that larger or smaller magnets may be used for greater forces or more ease of manipulation, without modifying the software other than the force actuation model. The design of the system is presented, including modeling and analysis of the sensing and actuation methods. Experimental results are given for field sensing, magnet localization, and haptic interaction with simulated objects. Forces up to 3.0 N are demonstrated in different directions while sensing planar magnet position to an accuracy within 2.0 mm.

- An Instrumented Master Tool Manipulator (MTM) for Force Feedback in the Da Vinci Surgical Robot

    Author: Black, David Gregory | University of British Columbia
    Author: Hadi Hosseinabadi, Amir Hossein | University of British Columbia
    Author: Salcudean, Septimiu E. | University of British Columbia
 
    keyword: Haptics and Haptic Interfaces; Surgical Robotics: Laparoscopy; Force and Tactile Sensing

    Abstract : We integrated a force/torque sensor into the wrist of the Master Tool Manipulator (MTM) of the da Vinci Standard Surgical system. The added sensor can be used to monitor the surgeon interaction forces and to improve the haptic experience. The proposed mechanical design is expected to have little effect on the surgeon's operative experience and is simple and inexpensive to implement. We also developed a software package that allows for seamless integration of the force sensor into the da Vinci Research Kit (dVRK) and the Robot Operating System (ROS). The complete mechanical and electrical modifications, as well as the software packages are discussed. Two example applications of impedance control at the MTM and joystick control of the PSM are presented to demonstrate the successful integration of the sensor into the MTM and the interface to the dVRK.

## Visual Tracking

- Multi-Person Pose Tracking Using Sequential Monte Carlo with Probabilistic Neural Pose Predictor

    Author: Okada, Masashi | Panasonic Corporation
    Author: Takenaka, Shinji | Panasonic System Networks R&amp;D Lab. Co., Ltd
    Author: Taniguchi, Tadahiro | Ritsumeikan University
 
    keyword: Visual Tracking; Deep Learning in Robotics and Automation; Probability and Statistical Methods

    Abstract : It is an effective strategy for the multi-person pose tracking task in videos to employ prediction and pose matching in a frame-by-frame manner. For this type of approach, uncertainty-aware modeling is essential because precise prediction is impossible. However, previous studies have relied on only a single prediction without incorporating uncertainty, which can cause critical tracking errors if the prediction is unreliable. This paper proposes an extension to this approach with Sequential Monte Carlo (SMC). This naturally reformulates the tracking scheme to handle multiple predictions (or hypotheses) of poses, thereby mitigating the negative effect of prediction errors. An important component of SMC, i.e., a proposal distribution, is designed as a probabilistic neural pose predictor, which can propose diverse and plausible hypotheses by incorporating epistemic uncertainty and heteroscedastic aleatoric uncertainty. In addition, a recurrent architecture is introduced to our neural modeling to utilize time-sequence information of poses to manage difficult situations, such as the frequent disappearance and reappearances of poses. Compared to existing baselines, the proposed method achieves a state-of-the-art MOTA score on the PoseTrack2018 validation dataset by reducing approximately 50% of tracking errors from a state-of-the art baseline method.

- 4D Generic Video Object Proposals

    Author: Osep, Aljosa | Technical University Munich
    Author: Voigtlaender, Paul | RWTH Aachen University
    Author: Weber, Mark | RWTH Aachen University
    Author: Luiten, Jonathon | RWTH Aachen University
    Author: Leibe, Bastian | RWTH Aachen University
 
    keyword: Visual Tracking; Object Detection, Segmentation and Categorization; Computer Vision for Other Robotic Applications

    Abstract : Many high-level video understanding methods require input in the form of object proposals. Currently, such proposals are predominantly generated with the help of networks that were trained for detecting and segmenting a set of known object classes, which limits their applicability to cases where all objects of interest are represented in the training set. We propose an approach that can reliably extract spatio-temporal object proposals for both known and unknown object categories from stereo video. Our 4D Generic Video Tubes (4D-GVT) method combines motion cues, stereo data, and data-driven object instance segmentation in a probabilistic framework to compute a compact set of video-object proposals that precisely localizes object candidates and their contours in 3D space and time.

- Simultaneous Tracking and Elasticity Parameter Estimation of Deformable Objects

    Author: Sengupta, Agniva | INRIA
    Author: Lagneau, Romain | INSA Rennes
    Author: Krupa, Alexandre | INRIA Rennes - Bretagne Atlantique
    Author: Marchand, Eric | Univ Rennes, Inria, CNRS, IRISA
    Author: Marchal, Maud | INSA/INRIA
 
    keyword: Visual Tracking; RGB-D Perception

    Abstract : In this paper, we propose a novel method to simultaneously track the deformation of soft objects and estimate their elasticity parameters. The tracking of the deformable object is performed by combining the visual information acquired with a RGB-D sensor with interactive Finite Element Method simulations of the object. The visual information is more particularly used to distort the simulated object. In parallel, the elasticity parameter estimation minimizes the error between the tracked object and a simulated object deformed by the forces that are measured using a force sensor. Once the elasticity parameters are estimated, our tracking algorithm can then also be used to estimate the deformation forces applied on an object without the use of a force sensor. We validated our method on several soft objects with different shape complexities. Our evaluations show the ability of our method to estimate the elasticity parameters as well as its use to estimate the forces applied on a deformable object without any force sensor. These results open novel perspectives to better track and control deformable objects during robotic manipulations.

- AVOT: Audio-Visual Object Tracking of Multiple Objects for Robotics

    Author: Wilson, Justin | University of North Carolina at Chapel Hill
    Author: Lin, Ming C. | University of North Carolina
 
    keyword: Visual Tracking

    Abstract : Existing state-of-the-art object tracking can run into challenges when objects collide, occlude, or come close to one another. These visually based trackers may also fail to differentiate between objects with the same appearance but different materials. Existing methods may stop tracking or incorrectly start tracking another object. These failures are uneasy for trackers to recover from since they often use results from previous frames. By using audio of the impact sounds from object collisions, rolling, etc., our audio-visual object tracking (AVOT) neural network can reduce tracking error and drift. We train AVOT end to end and use audio-visual inputs over all frames. Our audio-based technique may be used in conjunction with other neural networks to augment visually based object detection and tracking methods. We evaluate its runtime frames-per-second (FPS) performance and intersection over union (IoU) performance against OpenCV object tracking implementations and a deep learning method. Our experiments, using the synthetic Sound-20K audio-visual dataset, demonstrate that AVOT outperforms single-modality deep learning methods, when there is audio from object collisions. A proposed scheduler network to switch between AVOT and other methods based on audio onset further maximizes accuracy and performance over all frames in multimodal object tracking.

- Efficient Pig Counting in Crowds with Keypoints Tracking and Spatial-Aware Temporal Response Filtering

    Author: Chen, Guang | JD.com
    Author: Shen, Shiwen | JD.com
    Author: Wen, Longyin | JD Digits
    Author: Luo, Si | JD Digits
    Author: Bo, Liefeng | University of Washington
 
    keyword: Visual Tracking; Computer Vision for Other Robotic Applications; Deep Learning in Robotics and Automation

    Abstract : Pig counting is a crucial task for large-scale pig farming. Pigs are usually visually counted by human. But this process is very time-consuming and error-prone. Few studies in literature developed automated pig counting method. The existing works only focused on pig counting using single image, and its level of accuracy faced challenges due to pig movements, occlusion and overlapping. Especially, the field of view of a single image is very limited, and could not meet the needs of pig counting for large pig grouping houses. Towards addressing these challenges, we presented a real-time automated pig counting system in crowds using only one monocular fisheye camera with an inspection robot. Our system showed that it achieved performance superior to human. Our pipeline began with a novel bottom-up pig detection algorithm to avoid false negatives due to overlapping, occlusion and deformable pig shapes. This detection included a deep convolution neural network (CNN) for pig body part keypoints detection and the keypoints association method to identify individual pigs. It then employed an efficient on-line tracking method to associate pigs across image frames. Finally, pig counts were estimated by a novel spatial-aware temporal response filtering (STRF) method to suppress false positives caused by pig or camera movements or tracking failures. The whole pipeline has been deployed in an edge computing device, and demonstrated the effectiveness.

- 6-PACK: Category-Level 6D Pose Tracker with Anchor-Based Keypoints

    Author: Wang, Chen | Shanghai Jiao Tong University
    Author: Martín-Martín, Roberto | Stanford University
    Author: Xu, Danfei | Stanford Univesity
    Author: Lv, Jun | Shanghai Jiao Tong University
    Author: Lu, Cewu | ShangHai Jiao Tong University
    Author: Fei-Fei, Li | Stanford University
    Author: Savarese, Silvio | Stanford University
    Author: Zhu, Yuke | Stanford University
 
    keyword: Visual Tracking; RGB-D Perception; Deep Learning in Robotics and Automation

    Abstract : We present 6-PACK, a deep learning approach to category-level 6D object pose tracking on RGB-D data. Our method tracks in real time novel object instances of known object categories such as bowls, laptops, and mugs. 6-PACK learns to compactly represent an object by a handful of 3D keypoints, based on which the interframe motion of an object instance can be estimated through keypoint matching. These keypoints are learned end-to-end without manual supervision in order to be most effective for tracking. Our experiments show that our method substantially outperforms existing methods on the NOCS category-level 6D pose estimation benchmark and supports a physical robot to perform simple vision-based closed-loop manipulation tasks.

- Multimodal Tracking Framework for Visual Odometry in Challenging Illumination Conditions

    Author: Beauvisage, Axel | City University, London
    Author: Ahiska, Kenan | Cranfield University
    Author: Aouf, Nabil | City University of London
 
    keyword: Visual Tracking; Visual-Based Navigation; Localization

    Abstract : Research on visual odometry and localisation is largely dominated by solutions developed in the visible spectrum, where illumination is a critical factor. Other parts of the electromagnetic spectrum are currently being investigated to generate solutions dealing with extreme illumination conditions. Multispectral setups are particularly interesting as they provide information from different parts of the spectrum at once. However, the main challenge of such camera setups is the lack of similarity between the images produced, which makes conventional stereo matching techniques obsolete.<p>This work investigates a new way of concurrently processing images from different spectra for application to visual odometry. It particularly focuses on the visible and Long Wave InfraRed (LWIR) spectral bands where dissimilarity between pixel intensities is maximal. A new Multimodal Monocular Visual Odometry solution (MMS-VO) is presented. With this novel approach, features are tracked simultaneously, but only the camera providing the best tracking quality is used to estimate motion. Visual odometry is performed within a windowed bundle adjustment framework, by alternating between the cameras as the nature of the scene changes. Furthermore, the motion estimation process is robustified by selecting adequate keyframes based on parallax.</p><p>The algorithm was tested on a series of visible-thermal datasets, acquired from a car with real driving conditions.

- Real-Time Multi-Diver Tracking and Re-Identification for Underwater Human-Robot Collaboration

    Author: de Langis, Karin Johanna Denton | University of Minnesota
    Author: Sattar, Junaed | University of Minnesota
 
    keyword: Visual Tracking; Marine Robotics; Human-Centered Robotics

    Abstract : Autonomous underwater robots working with teams of human divers may need to distinguish between different divers, e.g., to recognize a lead diver or to follow a specific team member. This paper describes a technique that enables autonomous underwater robots to track divers in real time as well as to reidentify them. The approach is an extension of Simple Online Realtime Tracking (SORT) with an appearance metric (deep SORT). Initial diver detection is performed with a custom CNN designed for realtime diver detection, and appearance features are subsequently extracted for each detected diver. Next, realtime tracking-by-detection is performed with an extension of the deep SORT algorithm. We evaluate this technique on a series of videos of divers performing human-robot collaborative tasks and show that our methods result in more divers being accurately identified during tracking. We also discuss the practical considerations of applying multi-person tracking to on-board autonomous robot operations, and we consider how failure cases can be addressed during on-board tracking.

- Autonomous Tissue Scanning under Free-Form Motion for Intraoperative Tissue Characterisation

    Author: Zhan, Jian | Imperial College London
    Author: Cartucho, Jo�o | Imperial College London
    Author: Giannarou, Stamatia | Imperial College London
 
    keyword: Visual Tracking; Visual Servoing; Surgical Robotics: Laparoscopy

    Abstract : In Minimally Invasive Surgery (MIS), tissue scanning with imaging probes is required for subsurface visualisation to characterise the state of the tissue. However, scanning of large tissue surfaces in the presence of motion is a challenging task for the surgeon. Recently, robot-assisted local tissue scanning has been investigated for motion stabilisation of imaging probes to facilitate the capturing of good quality images and reduce the surgeon's cognitive load. Nonetheless, these approaches require the tissue surface to be static or translating with periodic motion. To eliminate these assumptions, we propose a visual servoing framework for autonomous tissue scanning, able to deal with free-form tissue motion. The 3D structure of the surgical scene is recovered, and a feature-based method is proposed to estimate the motion of the tissue in real-time. The desired scanning trajectory is manually defined on a reference frame and continuously updated using projective geometry to follow the tissue motion and control the movement of the robotic arm. The advantage of the proposed method is that it does not require the learning of the tissue motion prior to scanning and can deal with free-form motion. We deployed this framework on the da Vinci surgical robot using the da Vinci Research Kit (dVRK) for Ultrasound tissue scanning. Our framework can be easily extended to other probe-based imaging modalities.

- High Speed Three Dimensional Tracking of Swimming Cell by Synchronous Modulation between TeCE Camera and TAG Lens

    Author: Yamato, Kazuki | Gunma University
    Author: Chiba, Hiroyuki | Gunma University
    Author: Oku, Hiromasa | Gunma University
 
    keyword: Micro/Nano Robots; Visual Tracking; Biological Cell Manipulation

    Abstract : In this study, high speed three dimensional (3D) tracking of a swimming cell was achieved by synchronizing a temporally coded exposure (TeCE) camera and a tunable acoustic gradient index (TAG) lens. Because a TeCE camera can acquire the specific focal plane from a TAG lens at high speed, high speed 3D information acquisition can be accomplished using both a TeCE camera and a TAG lens. In addition, a TeCE camera can acquire the focal plane from a TAG lens irrespective of illumination conditions because a TeCE camera can control exposure. To verify the superiority of the TeCE camera and TAG lens with respect to illumination conditions, we conduct a high speed 3D tracking experiment wherein a swimming cell is tracked via two observation methods, namely bright-field and phase difference observations. The experimental results indicate that high speed 3D tracking can be achieved with both observation methods. Thus, high speed 3D tracking of a swimming cell was confirmed to be independent of illumination conditions.

- Track to Reconstruct and Reconstruct to Track

    Author: Luiten, Jonathon | RWTH Aachen University
    Author: Fischer, Tobias | RWTH Aachen University
    Author: Leibe, Bastian | RWTH Aachen University
 
    keyword: Visual Tracking; Human Detection and Tracking; Deep Learning in Robotics and Automation

    Abstract : Object tracking and 3D reconstruction are often performed together, with tracking used as input for reconstruction. However, the obtained reconstructions also provide useful information for improving tracking. We propose a novel method that closes this loop, first tracking to reconstruct, and then reconstructing to track. Our approach, MOTSFusion (Multi-Object Tracking, Segmentation and dynamic object Fusion), exploits the 3D motion extracted from dynamic object reconstructions to track objects through long periods of complete occlusion and to recover missing detections. Our approach first builds up short tracklets using 2D optical flow, and then fuses these into dynamic 3D object reconstructions. The precise 3D object motion of these reconstructions is used to merge tracklets through occlusion into long-term tracks, and to locate objects when detections are missing. On KITTI, our reconstruction-based tracking reduces the number of ID switches of the initial tracklets by more than 50%, and outperforms all previous approaches for both bounding box and segmentation tracking.

- PointTrackNet: An End-To-End Network for 3-D Object Detection and Tracking from Point Clouds

    Author: Wang, Sukai | Robotics and Multi-Perception Lab (RAM-LAB), Robotics Institute,
    Author: Sun, Yuxiang | Hong Kong University of Science and Technology
    Author: Liu, Chengju | Tongji University
    Author: Liu, Ming | Hong Kong University of Science and Technology
 
    keyword: Automation Technologies for Smart Cities; Service Robots; Field Robots

    Abstract : Recent machine learning-based multi-object tracking (MOT) frameworks are becoming popular for 3-D point clouds. Most traditional tracking approaches use filters (e.g., Kalman filter or particle filter) to predict object locations in a time sequence, however, they are vulnerable to extreme motion conditions, such as sudden braking and turning. In this letter, we propose PointTrackNet, an end-to-end 3-D object detection and tracking network, to generate foreground masks, 3-D bounding boxes, and point-wise tracking association displacements for each detected object. The network merely takes as input two adjacent point-cloud frames. Experimental results on the KITTI tracking dataset show competitive results over the state-of-the-arts, especially in the irregularly and rapidly changing scenarios.


## Planning, Scheduling and Coordination
- An Online Scheduling Algorithm for Human-Robot Collaborative Kitting

    Author: Maderna, Riccardo | Politecnico Di Milano
    Author: Poggiali, Matteo | Politecnico Di Milano
    Author: Zanchettin, Andrea Maria | Politecnico Di Milano
    Author: Rocco, Paolo | Politecnico Di Milano
 
    keyword: Planning, Scheduling and Coordination; Human Factors and Human-in-the-Loop; Industrial Robots

    Abstract : In manufacturing, kitting is the process of grouping separate items together to be supplied as one unit to the assembly line. This is a key logistic task, which is usually performed manually by human operators. However, picking objects from the warehouse implies a great repetitiveness in arm motion. Moreover, the weight and position of items may increase the physical strain and induce the development of work-related musculoskeletal disorders. The inclusion of a collaborative robot in the process may help to reduce the operator's effort and increase productivity. This paper introduces an online scheduling algorithm to guide the picking operations of the human and the robot. The proposed approach has been experimentally evaluated and compared with an offline scheduler, as well as with the baseline case of manual kitting.

- A Model-Free Approach to Meta-Level Control of Anytime Algorithms

    Author: Svegliato, Justin | University of Massachusetts Amherst
    Author: Sharma, Prakhar | University of Massachusetts Amherst
    Author: Zilberstein, Shlomo | University of Massachusetts
 
    keyword: Planning, Scheduling and Coordination; Learning and Adaptive Systems

    Abstract : Anytime algorithms offer a trade-off between solution quality and computation time that has proven to be useful in autonomous systems for a wide range of real-time planning problems. In order to optimize this trade-off, an autonomous system has to solve a challenging meta-level control problem: it must decide when to interrupt the anytime algorithm and act on the current solution. Prevailing meta-level control techniques, however, make a number of unrealistic assumptions that reduce their effectiveness and usefulness in the real world. Eliminating these assumptions, we first introduce a model-free approach to meta-level control based on reinforcement learning and prove its optimality. We then offer a general meta-level control technique that can use different reinforcement learning methods. Finally, we show that our approach is effective across several common benchmark domains and a mobile robot domain.

- Simultaneous Task Allocation and Motion Scheduling for Complex Tasks Executed by Multiple Robots

    Author: Behrens, Jan Kristof | Czech Institute of Informatics, Robotics and Cybernetics, Czech
    Author: Stepanova, Karla | Czech Technical University
    Author: Babuska, Robert | Delft University of Technology
 
    keyword: Planning, Scheduling and Coordination; Intelligent and Flexible Manufacturing; Multi-Robot Systems

    Abstract : The coordination of multiple robots operating simultaneously in the same workspace requires the integration of task allocation and motion scheduling. We focus on tasks in which the robot's actions are not confined to small volumes, but can also occupy a large time-varying portion of the workspace, such as in welding along a line. The optimization of such tasks presents a considerable challenge mainly due to the fact that different variants of task execution exist, for instance, there can be multiple starting points of lines or closed curves, different filling patterns of areas, etc. We propose a generic and computationally efficient optimization method which is based on constraint programming. It takes into account the kinematics of the robots and guarantees that the motions of the robots are collision-free while minimizing the overall makespan. We evaluate our approach on several use-cases of varying complexity: cutting, additive manufacturing, spot welding, inserting and tightening bolts, performed by a dual-arm robot. In terms of the makespan, the result is superior to task execution by one robot arm as well as by two arms not working simultaneously.

- Efficient Planning for High-Speed MAV Flight in Unknown Environments Using Online Sparse Topological Graphs

    Author: Collins, Matthew | Carnegie Mellon University
    Author: Michael, Nathan | Carnegie Mellon University
 
    keyword: Planning, Scheduling and Coordination; Dynamics

    Abstract : Safe high-speed autonomous navigation for MAVs in unknown environments requires fast planning to enable the robot to react quickly to incoming information about obstacles within the world. Furthermore, when operating in environments not known a priori, the robot may make decisions that lead to dead ends, necessitating global replanning through a map of the environment outside of a local planning grid. This work proposes a computationally-efficient planning architecture for safe high-speed operation in unknown environments that incorporates a notion of longer-term memory into the planner enabling the robot to accurately plan to locations no longer contained within a local map. A motion primitive-based local receding horizon planner that uses a probabilistic collision avoidance methodology enables the robot to generate safe plans at fast replan rates. To provide global guidance, a memory-efficient sparse topological graph is created online from a time history of the robot's path and a geometric notion of visibility within the environment to search for alternate pathways towards the desired goal if a dead end is encountered.	The safety and performance of the proposed planning system is evaluated at speeds up to 10m/s, and the approach is tested in a set of large-scale, complex simulation environments containing dead ends. These scenarios lead to failure cases for competing methods; however, the proposed approach enables the robot to safely reroute and reach the goal.

- Evaluating Adaptation Performance of Hierarchical Deep Reinforcement Learning

    Author: Van Stralen, Neale | University of Illinois at Urbana Champaign
    Author: Kim, Seung Hyun | University of Illinois at Urbana-Champaign
    Author: Tran, Huy | University of Illinois at Urbana Champaign
    Author: Chowdhary, Girish | University of Illinois at Urbana Champaign
 
    keyword: Planning, Scheduling and Coordination; Path Planning for Multiple Mobile Robots or Agents

    Abstract : Deep Reinforcement Learning has been used to exploit specific environments, but has difficulty transferring learned policies to new situations. This issue poses a problem for practical applications of Reinforcement Learning, as real-world scenarios may introduce unexpected differences that drastically reduce policy performance. We propose the use of differentiated sub-policies governed by a hierarchical controller to support adaptation in such scenarios. We also introduce a confidence-based training process for the hierarchical controller which improves training stability and convergence times. We evaluate these methods in a new Capture the Flag environment designed to explore adaptation in autonomous multi-agent settings.

- An Approximation Algorithm for a Task Allocation, Sequencing and Scheduling Problem Involving a Human-Robot Team

    Author: Hari, Sai Krishna Kanth | Texas a &amp; M University
    Author: Nayak, Abhishek | Texas a &amp; M University
    Author: Rathinam, Sivakumar | TAMU
 
    keyword: Planning, Scheduling and Coordination; Path Planning for Multiple Mobile Robots or Agents; Task Planning

    Abstract : This article presents an approximation algorithm for a Task Allocation, Sequencing and Scheduling Problem (TASSP) involving a team of human operators and robots. The robots have to travel to a given set of targets and collaboratively work on the tasks at the targets with the human operators. The problem aims to find a sequence of targets for each robot to visit and schedule the tasks at the targets with the human operators such that each target is visited exactly once by some robot, the scheduling constraints are satisfied and the maximum mission time of any robot is minimum. This problem is a generalization of the single Traveling Salesman Problem and is NP-Hard. Given k robots and m human operators, an algorithm is developed for solving the TASSP with an approximation ratio equal to 5/2-1/k when m&gt;=k and equal to 7/2-1/k otherwise. Computational results are also presented to corroborate the performance of the proposed algorithm.

## Reactive and Sensor-Based Planning
- Iterator-Based Temporal Logic Task Planning

    Author: Zudaire, Sebastian | Universidad De Buenos Aires
    Author: Garrett, Martin | CNEA
    Author: Uchitel, Sebastian | Universidad De Buenos Aires
 
    keyword: Reactive and Sensor-Based Planning; Task Planning

    Abstract : Temporal logic task planning for robotic systems suffers from state explosion when specifications involve large numbers of discrete locations. We provide a novel approach, particularly suited for tasks specifications with universally quantified locations, that has constant time with respect to the number of locations, enabling synthesis of plans for an arbitrary number of them. We propose a hybrid control framework that uses an iterator to manage the discretized workspace hiding it from a plan enacted by a discrete event controller. A downside of our approach is that it incurs in increased overhead when executing a synthesised plan. We demonstrate that the overhead is reasonable for missions of a fixed-wing Unmanned Aerial Vehicle in simulated and real scenarios for up to 700 000 locations.

- Reactive Temporal Logic Planning for Multiple Robots in Unknown Environments

    Author: Kantaros, Yiannis | University of Pennsylvania
    Author: Malencia, Matthew | University of Pennsylvania
    Author: Kumar, Vijay | University of Pennsylvania
    Author: Pappas, George J. | University of Pennsylvania
 
    keyword: Reactive and Sensor-Based Planning; Path Planning for Multiple Mobile Robots or Agents; Autonomous Agents

    Abstract : This paper proposes a new reactive mission planning algorithm for multiple robots that operate in unknown environments. The robots are equipped with individual sensors that allow them to collectively learn and continuously update a map of the unknown environment. The goal of the robots is to accomplish complex tasks, captured by global co-safe Linear Temporal Logic (LTL) formulas. The majority of existing temporal logic planning approaches rely on discrete     Abstractions of the robot dynamics operating in known environments and, as a result, they cannot be applied to the more realistic scenarios where the environment is initially unknown. In this paper, we address this novel challenge by proposing the first reactive, and     Abstraction-free LTL planning algorithm that can be applied for complex mission planning of multiple robots operating in unknown environments. Our algorithm is reactive in the sense that temporal logic planning is adapting to the updated map of the environment and     Abstraction-free as it does not rely on designing     Abstractions of robot dynamics. Our proposed algorithm is complete under mild assumptions on the structure of the environment and the sensor models. Our paper provides extensive numerical simulations and hardware experiments that illustrate the theoretical analysis and show that the proposed algorithm can address complex planning tasks in unknown environments.

- Higher Order Function Networks for View Planning and Multi-View Reconstruction

    Author: Engin, Kazim Selim | University of Minnesota
    Author: Mitchell, Eric | Samsung AI Center NY
    Author: Lee, Daewon | Samsung AI Center New York
    Author: Isler, Volkan | University of Minnesota
    Author: Lee, Daniel | Cornell Tech
 
    keyword: Reactive and Sensor-Based Planning; Sensor Fusion; Learning and Adaptive Systems

    Abstract : We consider the problem of planning views for a robot to acquire images of an object for visual inspection and reconstruction. In contrast to offline methods which require a 3D model of the object as input or online methods which rely on only local measurements, our method uses a neural network which encodes shape information for a large number of objects. We build on recent deep learning methods capable of generating a complete 3D reconstruction of an object from a single image. Specifically, in this work, we extend a recent method which uses Higher Order Functions (HOF) to represent the shape of the object. We present a new generalization of this method to incorporate multiple images as input and establish a connection between visibility and reconstruction quality. This relationship forms the foundation of our view planning method where we compute viewpoints to visually cover the output of the multi-view HOF network with as few images as possible. Experiments indicate that our method provides a good compromise between online and offline methods: Similar to online methods, our method does not require the true object model as input. In terms of number of views, it is much more efficient. In most cases, its performance is comparable to the optimal offline case even on object classes the network has not been trained on.

- Residual Reactive Navigation: Combining Classical and Learned Navigation Strategies for Deployment in Unknown Environments

    Author: Rana, Krishan | Queensland University of Technology
    Author: Talbot, Ben | Queensland University of Technology
    Author: Dasagi, Vibhavari | Queensland University of Technology
    Author: Milford, Michael J | Queensland University of Technology
    Author: S�nderhauf, Niko | Queensland University of Technology
 
    keyword: Reactive and Sensor-Based Planning; Deep Learning in Robotics and Automation

    Abstract : In this work we focus on improving the efficiency and generalisation of learned navigation strategies when transferred from its training environment to previously unseen ones. We present an extension of the residual reinforcement learning framework from the robotic manipulation literature and adapt it to the vast and unstructured environments that mobile robots can operate in. The concept is based on learning a residual control effect to add to a typical sub-optimal classical controller in order to close the performance gap, whilst guiding the exploration process during training for improved data efficiency. We exploit this tight coupling and propose a novel deployment strategy, switching Residual Reactive Navigation (sRNN), which yields efficient trajectories whilst probabilistically switching to a classical controller in cases of high policy uncertainty. Our approach achieves improved performance over end-to-end alternatives and can be incorporated as part of a complete navigation stack for cluttered indoor navigation tasks in the real world. The code and training environment for this project is made publicly available at url{https://sites.google.com/view/srrn/home}.

- Online Grasp Plan Refinement for Reducing Defects During Robotic Layup of Composite Prepreg Sheets

    Author: Malhan, Rishi | University of Southern California
    Author: Jomy Joseph, Rex | University of Southern California
    Author: Shembekar, Aniruddha | University of Southern California
    Author: Kabir, Ariyan M | University of Southern California
    Author: Bhatt, Prahar | University of Southern California
    Author: Gupta, Satyandra K. | University of Southern California
 
    keyword: Reactive and Sensor-Based Planning; Failure Detection and Recovery; Industrial Robots

    Abstract : High-performance composites are increasingly being used in the industry. Sheet layup is a process of manufacturing composite components using deformable sheets. We have developed a robotic cell to automate the layup process and overcome the limitations of the manual layup. Generating offline trajectories for robots and executing them without online refinement can introduce defects in the process due to uncertainties in the model of the sheet and environmental factors. Our system computes layup and grasping trajectories for the robots and refines them during the layup process based on the sensor data. We use an approach that augments physical experiments with simulations to train a Gaussian process regression model offline. The use of GPR enables us to quickly refine grasp plans and perform a defect-free layup without slowing down the layup process. We present experimental results on two components.

- Object-Centric Task and Motion Planning in Dynamic Environments

    Author: Migimatsu, Toki | Stanford University
    Author: Bohg, Jeannette | Stanford University
 
    keyword: Reactive and Sensor-Based Planning; Task Planning; Optimization and Optimal Control

    Abstract : We address the problem of applying Task and Motion Planning (TAMP) in real world environments. TAMP combines symbolic and geometric reasoning to produce sequential manipulation plans, typically specified as joint-space trajectories, which are valid only as long as the environment is static and perception and control are highly accurate. In case of any changes in the environment, slow re-planning is required. We propose a TAMP algorithm that optimizes over Cartesian frames defined relative to target objects. The resulting plan then remains valid even if the objects are moving and can be executed by reactive controllers that adapt to these changes in real time. We apply our TAMP framework to a torque-controlled robot in a pick and place setting and demonstrate its ability to adapt to changing environments, inaccurate perception, and imprecise control, both in simulation and the real world.

